{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EbrFD1vMR_qS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sub ls -4, cn -24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "RRVN-4QOSKAx",
    "outputId": "0fae4e16-1266-4d53-81fe-2ef0c08efb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PM2.5 (µg/m³)  PM10 (µg/m³)  NO (µg/m³)  NO2 (µg/m³)  \\\n",
      "PM2.5 (µg/m³)             1.000000      0.971965    0.373754     0.640640   \n",
      "PM10 (µg/m³)              0.971965      1.000000    0.399088     0.662788   \n",
      "NO (µg/m³)                0.373754      0.399088    1.000000     0.730045   \n",
      "NO2 (µg/m³)               0.640640      0.662788    0.730045     1.000000   \n",
      "NOx (ppb)                 0.532189      0.561058    0.923716     0.906751   \n",
      "NH3 (µg/m³)               0.357580      0.361703    0.151340     0.253047   \n",
      "SO2 (µg/m³)               0.474879      0.501886    0.301583     0.560502   \n",
      "CO (mg/m³)                0.811053      0.800087    0.437240     0.613115   \n",
      "Ozone (µg/m³)             0.360807      0.387940    0.114755     0.294678   \n",
      "Benzene (µg/m³)           0.660188      0.650194    0.364053     0.571268   \n",
      "Toluene (µg/m³)           0.579207      0.565682    0.348638     0.558999   \n",
      "Eth-Benzene (µg/m³)       0.576010      0.575755    0.220560     0.348399   \n",
      "MP-Xylene (µg/m³)         0.622838      0.613167    0.341168     0.450243   \n",
      "AT (°C)                  -0.693228     -0.649012   -0.288165    -0.501859   \n",
      "RH (%)                   -0.127794     -0.147521   -0.101927    -0.118674   \n",
      "WS (m/s)                 -0.440910     -0.444671   -0.171094    -0.316472   \n",
      "WD (deg)                  0.618676      0.638375    0.212483     0.541640   \n",
      "TOT-RF (mm)              -0.079959     -0.087931   -0.023789    -0.042939   \n",
      "SR (W/mt2)               -0.254205     -0.236603   -0.017062    -0.152572   \n",
      "VWS (m/s)                 0.587988      0.586375    0.219888     0.534965   \n",
      "\n",
      "                     NOx (ppb)  NH3 (µg/m³)  SO2 (µg/m³)  CO (mg/m³)  \\\n",
      "PM2.5 (µg/m³)         0.532189     0.357580     0.474879    0.811053   \n",
      "PM10 (µg/m³)          0.561058     0.361703     0.501886    0.800087   \n",
      "NO (µg/m³)            0.923716     0.151340     0.301583    0.437240   \n",
      "NO2 (µg/m³)           0.906751     0.253047     0.560502    0.613115   \n",
      "NOx (ppb)             1.000000     0.199124     0.464946    0.552195   \n",
      "NH3 (µg/m³)           0.199124     1.000000     0.183562    0.267799   \n",
      "SO2 (µg/m³)           0.464946     0.183562     1.000000    0.436332   \n",
      "CO (mg/m³)            0.552195     0.267799     0.436332    1.000000   \n",
      "Ozone (µg/m³)         0.239347    -0.031336     0.350066    0.193381   \n",
      "Benzene (µg/m³)       0.495447     0.163993     0.375538    0.767429   \n",
      "Toluene (µg/m³)       0.468824     0.108062     0.402584    0.736941   \n",
      "Eth-Benzene (µg/m³)   0.275488     0.384161     0.213696    0.543637   \n",
      "MP-Xylene (µg/m³)     0.411931     0.338438     0.191293    0.583475   \n",
      "AT (°C)              -0.407202    -0.295760    -0.329842   -0.642644   \n",
      "RH (%)               -0.126222     0.166413    -0.096716   -0.016413   \n",
      "WS (m/s)             -0.257716    -0.188241    -0.189204   -0.351290   \n",
      "WD (deg)              0.374252     0.310288     0.503212    0.537546   \n",
      "TOT-RF (mm)          -0.033684     0.021587    -0.045795   -0.090918   \n",
      "SR (W/mt2)           -0.085265    -0.217655    -0.032574   -0.212490   \n",
      "VWS (m/s)             0.384238     0.371836     0.476563    0.523142   \n",
      "\n",
      "                     Ozone (µg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  \\\n",
      "PM2.5 (µg/m³)             0.360807         0.660188         0.579207   \n",
      "PM10 (µg/m³)              0.387940         0.650194         0.565682   \n",
      "NO (µg/m³)                0.114755         0.364053         0.348638   \n",
      "NO2 (µg/m³)               0.294678         0.571268         0.558999   \n",
      "NOx (ppb)                 0.239347         0.495447         0.468824   \n",
      "NH3 (µg/m³)              -0.031336         0.163993         0.108062   \n",
      "SO2 (µg/m³)               0.350066         0.375538         0.402584   \n",
      "CO (mg/m³)                0.193381         0.767429         0.736941   \n",
      "Ozone (µg/m³)             1.000000         0.137430         0.064749   \n",
      "Benzene (µg/m³)           0.137430         1.000000         0.916537   \n",
      "Toluene (µg/m³)           0.064749         0.916537         1.000000   \n",
      "Eth-Benzene (µg/m³)       0.124065         0.410844         0.315598   \n",
      "MP-Xylene (µg/m³)         0.166786         0.432369         0.354100   \n",
      "AT (°C)                  -0.058221        -0.656708        -0.601086   \n",
      "RH (%)                   -0.220463        -0.068898         0.011616   \n",
      "WS (m/s)                 -0.232577        -0.251467        -0.222919   \n",
      "WD (deg)                  0.261878         0.493105         0.478402   \n",
      "TOT-RF (mm)              -0.029184         0.008532        -0.012696   \n",
      "SR (W/mt2)                0.033808        -0.186680        -0.155902   \n",
      "VWS (m/s)                 0.150409         0.506511         0.491434   \n",
      "\n",
      "                     Eth-Benzene (µg/m³)  MP-Xylene (µg/m³)   AT (°C)  \\\n",
      "PM2.5 (µg/m³)                   0.576010           0.622838 -0.693228   \n",
      "PM10 (µg/m³)                    0.575755           0.613167 -0.649012   \n",
      "NO (µg/m³)                      0.220560           0.341168 -0.288165   \n",
      "NO2 (µg/m³)                     0.348399           0.450243 -0.501859   \n",
      "NOx (ppb)                       0.275488           0.411931 -0.407202   \n",
      "NH3 (µg/m³)                     0.384161           0.338438 -0.295760   \n",
      "SO2 (µg/m³)                     0.213696           0.191293 -0.329842   \n",
      "CO (mg/m³)                      0.543637           0.583475 -0.642644   \n",
      "Ozone (µg/m³)                   0.124065           0.166786 -0.058221   \n",
      "Benzene (µg/m³)                 0.410844           0.432369 -0.656708   \n",
      "Toluene (µg/m³)                 0.315598           0.354100 -0.601086   \n",
      "Eth-Benzene (µg/m³)             1.000000           0.826221 -0.416362   \n",
      "MP-Xylene (µg/m³)               0.826221           1.000000 -0.480393   \n",
      "AT (°C)                        -0.416362          -0.480393  1.000000   \n",
      "RH (%)                         -0.092781          -0.147604  0.020239   \n",
      "WS (m/s)                       -0.286424          -0.365164  0.163643   \n",
      "WD (deg)                        0.423609           0.328281 -0.486551   \n",
      "TOT-RF (mm)                    -0.044903          -0.037945  0.007355   \n",
      "SR (W/mt2)                     -0.289572          -0.398472  0.371176   \n",
      "VWS (m/s)                       0.452958           0.396769 -0.491029   \n",
      "\n",
      "                       RH (%)  WS (m/s)  WD (deg)  TOT-RF (mm)  SR (W/mt2)  \\\n",
      "PM2.5 (µg/m³)       -0.127794 -0.440910  0.618676    -0.079959   -0.254205   \n",
      "PM10 (µg/m³)        -0.147521 -0.444671  0.638375    -0.087931   -0.236603   \n",
      "NO (µg/m³)          -0.101927 -0.171094  0.212483    -0.023789   -0.017062   \n",
      "NO2 (µg/m³)         -0.118674 -0.316472  0.541640    -0.042939   -0.152572   \n",
      "NOx (ppb)           -0.126222 -0.257716  0.374252    -0.033684   -0.085265   \n",
      "NH3 (µg/m³)          0.166413 -0.188241  0.310288     0.021587   -0.217655   \n",
      "SO2 (µg/m³)         -0.096716 -0.189204  0.503212    -0.045795   -0.032574   \n",
      "CO (mg/m³)          -0.016413 -0.351290  0.537546    -0.090918   -0.212490   \n",
      "Ozone (µg/m³)       -0.220463 -0.232577  0.261878    -0.029184    0.033808   \n",
      "Benzene (µg/m³)     -0.068898 -0.251467  0.493105     0.008532   -0.186680   \n",
      "Toluene (µg/m³)      0.011616 -0.222919  0.478402    -0.012696   -0.155902   \n",
      "Eth-Benzene (µg/m³) -0.092781 -0.286424  0.423609    -0.044903   -0.289572   \n",
      "MP-Xylene (µg/m³)   -0.147604 -0.365164  0.328281    -0.037945   -0.398472   \n",
      "AT (°C)              0.020239  0.163643 -0.486551     0.007355    0.371176   \n",
      "RH (%)               1.000000  0.005939 -0.110311    -0.091070   -0.039782   \n",
      "WS (m/s)             0.005939  1.000000 -0.326121     0.062207    0.183953   \n",
      "WD (deg)            -0.110311 -0.326121  1.000000    -0.049481   -0.110741   \n",
      "TOT-RF (mm)         -0.091070  0.062207 -0.049481     1.000000   -0.072362   \n",
      "SR (W/mt2)          -0.039782  0.183953 -0.110741    -0.072362    1.000000   \n",
      "VWS (m/s)           -0.064636 -0.404742  0.776447    -0.037391   -0.185938   \n",
      "\n",
      "                     VWS (m/s)  \n",
      "PM2.5 (µg/m³)         0.587988  \n",
      "PM10 (µg/m³)          0.586375  \n",
      "NO (µg/m³)            0.219888  \n",
      "NO2 (µg/m³)           0.534965  \n",
      "NOx (ppb)             0.384238  \n",
      "NH3 (µg/m³)           0.371836  \n",
      "SO2 (µg/m³)           0.476563  \n",
      "CO (mg/m³)            0.523142  \n",
      "Ozone (µg/m³)         0.150409  \n",
      "Benzene (µg/m³)       0.506511  \n",
      "Toluene (µg/m³)       0.491434  \n",
      "Eth-Benzene (µg/m³)   0.452958  \n",
      "MP-Xylene (µg/m³)     0.396769  \n",
      "AT (°C)              -0.491029  \n",
      "RH (%)               -0.064636  \n",
      "WS (m/s)             -0.404742  \n",
      "WD (deg)              0.776447  \n",
      "TOT-RF (mm)          -0.037391  \n",
      "SR (W/mt2)           -0.185938  \n",
      "VWS (m/s)             1.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\DHAN RAJ\\\\Downloads\\\\btp_forecast_preprocessed_data\\\\kolkata\\\\daily\\\\imputed_daily_kolkata_data.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "data = df.drop(columns=['Timestamp'])\n",
    "# Assuming df is your DataFrame\n",
    "correlation_matrix = data.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correlation threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Find pairs with correlation above threshold\n",
    "highly_correlated_pairs = [(column1, 'PM2.5 (µg/m³)') for column1 in correlation_matrix.columns if abs(correlation_matrix[column1]['PM2.5 (µg/m³)']) > threshold and column1 != 'PM2.5 (µg/m³)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality Test for pair ('PM10 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=7.3350  , p=0.0069  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=7.3551  , p=0.0067  , df=1\n",
      "likelihood ratio test: chi2=7.3305  , p=0.0068  , df=1\n",
      "parameter F test:         F=7.3350  , p=0.0069  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=3.7886  , p=0.0229  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=7.6120  , p=0.0222  , df=2\n",
      "likelihood ratio test: chi2=7.5857  , p=0.0225  , df=2\n",
      "parameter F test:         F=3.7886  , p=0.0229  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.0093  , p=0.0294  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=9.0863  , p=0.0282  , df=3\n",
      "likelihood ratio test: chi2=9.0487  , p=0.0287  , df=3\n",
      "parameter F test:         F=3.0093  , p=0.0294  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.2486  , p=0.0620  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=9.0691  , p=0.0594  , df=4\n",
      "likelihood ratio test: chi2=9.0316  , p=0.0603  , df=4\n",
      "parameter F test:         F=2.2486  , p=0.0620  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.7576  , p=0.1188  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=8.8778  , p=0.1140  , df=5\n",
      "likelihood ratio test: chi2=8.8418  , p=0.1155  , df=5\n",
      "parameter F test:         F=1.7576  , p=0.1188  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.3644  , p=0.2259  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=8.2854  , p=0.2179  , df=6\n",
      "likelihood ratio test: chi2=8.2540  , p=0.2201  , df=6\n",
      "parameter F test:         F=1.3644  , p=0.2259  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.3168  , p=0.2386  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=9.3465  , p=0.2287  , df=7\n",
      "likelihood ratio test: chi2=9.3066  , p=0.2314  , df=7\n",
      "parameter F test:         F=1.3168  , p=0.2386  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.1268  , p=0.3422  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=9.1573  , p=0.3292  , df=8\n",
      "likelihood ratio test: chi2=9.1189  , p=0.3324  , df=8\n",
      "parameter F test:         F=1.1268  , p=0.3422  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.0723  , p=0.3805  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=9.8227  , p=0.3650  , df=9\n",
      "likelihood ratio test: chi2=9.7785  , p=0.3687  , df=9\n",
      "parameter F test:         F=1.0723  , p=0.3805  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=0.8469  , p=0.5833  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=8.6362  , p=0.5669  , df=10\n",
      "likelihood ratio test: chi2=8.6020  , p=0.5702  , df=10\n",
      "parameter F test:         F=0.8469  , p=0.5833  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NO2 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=5.4111  , p=0.0202  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=5.4260  , p=0.0198  , df=1\n",
      "likelihood ratio test: chi2=5.4126  , p=0.0200  , df=1\n",
      "parameter F test:         F=5.4111  , p=0.0202  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.4850  , p=0.2270  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=2.9836  , p=0.2250  , df=2\n",
      "likelihood ratio test: chi2=2.9795  , p=0.2254  , df=2\n",
      "parameter F test:         F=1.4850  , p=0.2270  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.5468  , p=0.2008  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=4.6703  , p=0.1976  , df=3\n",
      "likelihood ratio test: chi2=4.6604  , p=0.1984  , df=3\n",
      "parameter F test:         F=1.5468  , p=0.2008  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.6706  , p=0.1545  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=6.7381  , p=0.1504  , df=4\n",
      "likelihood ratio test: chi2=6.7173  , p=0.1516  , df=4\n",
      "parameter F test:         F=1.6706  , p=0.1545  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.1028  , p=0.3571  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=5.5703  , p=0.3503  , df=5\n",
      "likelihood ratio test: chi2=5.5562  , p=0.3518  , df=5\n",
      "parameter F test:         F=1.1028  , p=0.3571  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.0379  , p=0.3989  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=6.3029  , p=0.3901  , df=6\n",
      "likelihood ratio test: chi2=6.2847  , p=0.3921  , df=6\n",
      "parameter F test:         F=1.0379  , p=0.3989  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.9081  , p=0.4992  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=6.4458  , p=0.4888  , df=7\n",
      "likelihood ratio test: chi2=6.4267  , p=0.4909  , df=7\n",
      "parameter F test:         F=0.9081  , p=0.4992  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.9751  , p=0.4539  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=7.9244  , p=0.4409  , df=8\n",
      "likelihood ratio test: chi2=7.8957  , p=0.4437  , df=8\n",
      "parameter F test:         F=0.9751  , p=0.4539  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.8104  , p=0.0624  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=16.5838 , p=0.0556  , df=9\n",
      "likelihood ratio test: chi2=16.4585 , p=0.0579  , df=9\n",
      "parameter F test:         F=1.8104  , p=0.0624  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.6707  , p=0.0827  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=17.0372 , p=0.0735  , df=10\n",
      "likelihood ratio test: chi2=16.9048 , p=0.0765  , df=10\n",
      "parameter F test:         F=1.6707  , p=0.0827  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NOx (ppb)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=4.9545  , p=0.0262  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=4.9681  , p=0.0258  , df=1\n",
      "likelihood ratio test: chi2=4.9568  , p=0.0260  , df=1\n",
      "parameter F test:         F=4.9545  , p=0.0262  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.4636  , p=0.0856  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=4.9498  , p=0.0842  , df=2\n",
      "likelihood ratio test: chi2=4.9386  , p=0.0846  , df=2\n",
      "parameter F test:         F=2.4636  , p=0.0856  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.4692  , p=0.2213  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=4.4362  , p=0.2181  , df=3\n",
      "likelihood ratio test: chi2=4.4272  , p=0.2189  , df=3\n",
      "parameter F test:         F=1.4692  , p=0.2213  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.1087  , p=0.0777  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=8.5049  , p=0.0747  , df=4\n",
      "likelihood ratio test: chi2=8.4719  , p=0.0757  , df=4\n",
      "parameter F test:         F=2.1087  , p=0.0777  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.4910  , p=0.1899  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=7.5311  , p=0.1840  , df=5\n",
      "likelihood ratio test: chi2=7.5052  , p=0.1857  , df=5\n",
      "parameter F test:         F=1.4910  , p=0.1899  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.6239  , p=0.1371  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=9.8611  , p=0.1306  , df=6\n",
      "likelihood ratio test: chi2=9.8167  , p=0.1326  , df=6\n",
      "parameter F test:         F=1.6239  , p=0.1371  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.6523  , p=0.1171  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=11.7275 , p=0.1099  , df=7\n",
      "likelihood ratio test: chi2=11.6648 , p=0.1121  , df=7\n",
      "parameter F test:         F=1.6523  , p=0.1171  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.4969  , p=0.1538  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=12.1658 , p=0.1440  , df=8\n",
      "likelihood ratio test: chi2=12.0982 , p=0.1469  , df=8\n",
      "parameter F test:         F=1.4969  , p=0.1538  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.1706  , p=0.0218  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=19.8829 , p=0.0186  , df=9\n",
      "likelihood ratio test: chi2=19.7030 , p=0.0198  , df=9\n",
      "parameter F test:         F=2.1706  , p=0.0218  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.9321  , p=0.0376  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=19.7025 , p=0.0322  , df=10\n",
      "likelihood ratio test: chi2=19.5257 , p=0.0341  , df=10\n",
      "parameter F test:         F=1.9321  , p=0.0376  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('CO (mg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=30.4058 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=30.4894 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=30.0723 , p=0.0000  , df=1\n",
      "parameter F test:         F=30.4058 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=17.7535 , p=0.0000  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=35.6701 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=35.1004 , p=0.0000  , df=2\n",
      "parameter F test:         F=17.7535 , p=0.0000  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=10.2586 , p=0.0000  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=30.9744 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=30.5433 , p=0.0000  , df=3\n",
      "parameter F test:         F=10.2586 , p=0.0000  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=9.5649  , p=0.0000  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=38.5779 , p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=37.9115 , p=0.0000  , df=4\n",
      "parameter F test:         F=9.5649  , p=0.0000  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=6.5453  , p=0.0000  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=33.0604 , p=0.0000  , df=5\n",
      "likelihood ratio test: chi2=32.5689 , p=0.0000  , df=5\n",
      "parameter F test:         F=6.5453  , p=0.0000  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=5.5972  , p=0.0000  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=33.9890 , p=0.0000  , df=6\n",
      "likelihood ratio test: chi2=33.4693 , p=0.0000  , df=6\n",
      "parameter F test:         F=5.5972  , p=0.0000  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=4.8515  , p=0.0000  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=34.4351 , p=0.0000  , df=7\n",
      "likelihood ratio test: chi2=33.9014 , p=0.0000  , df=7\n",
      "parameter F test:         F=4.8515  , p=0.0000  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=4.2115  , p=0.0001  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=34.2274 , p=0.0000  , df=8\n",
      "likelihood ratio test: chi2=33.6996 , p=0.0000  , df=8\n",
      "parameter F test:         F=4.2115  , p=0.0001  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=4.1834  , p=0.0000  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=38.3215 , p=0.0000  , df=9\n",
      "likelihood ratio test: chi2=37.6608 , p=0.0000  , df=9\n",
      "parameter F test:         F=4.1834  , p=0.0000  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=3.0192  , p=0.0009  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=30.7878 , p=0.0006  , df=10\n",
      "likelihood ratio test: chi2=30.3590 , p=0.0007  , df=10\n",
      "parameter F test:         F=3.0192  , p=0.0009  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Benzene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=16.4600 , p=0.0001  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=16.5053 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=16.3820 , p=0.0001  , df=1\n",
      "parameter F test:         F=16.4600 , p=0.0001  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=14.2894 , p=0.0000  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=28.7102 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=28.3396 , p=0.0000  , df=2\n",
      "parameter F test:         F=14.2894 , p=0.0000  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=8.7743  , p=0.0000  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=26.4927 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=26.1764 , p=0.0000  , df=3\n",
      "parameter F test:         F=8.7743  , p=0.0000  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=6.2891  , p=0.0001  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=25.3656 , p=0.0000  , df=4\n",
      "likelihood ratio test: chi2=25.0752 , p=0.0000  , df=4\n",
      "parameter F test:         F=6.2891  , p=0.0001  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=5.0029  , p=0.0002  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=25.2697 , p=0.0001  , df=5\n",
      "likelihood ratio test: chi2=24.9813 , p=0.0001  , df=5\n",
      "parameter F test:         F=5.0029  , p=0.0002  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=4.3814  , p=0.0002  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=26.6062 , p=0.0002  , df=6\n",
      "likelihood ratio test: chi2=26.2864 , p=0.0002  , df=6\n",
      "parameter F test:         F=4.3814  , p=0.0002  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=3.7097  , p=0.0006  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=26.3311 , p=0.0004  , df=7\n",
      "likelihood ratio test: chi2=26.0175 , p=0.0005  , df=7\n",
      "parameter F test:         F=3.7097  , p=0.0006  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=3.2857  , p=0.0010  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=26.7035 , p=0.0008  , df=8\n",
      "likelihood ratio test: chi2=26.3808 , p=0.0009  , df=8\n",
      "parameter F test:         F=3.2857  , p=0.0010  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=3.7095  , p=0.0001  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=33.9798 , p=0.0001  , df=9\n",
      "likelihood ratio test: chi2=33.4591 , p=0.0001  , df=9\n",
      "parameter F test:         F=3.7095  , p=0.0001  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.9812  , p=0.0010  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=30.4007 , p=0.0007  , df=10\n",
      "likelihood ratio test: chi2=29.9826 , p=0.0009  , df=10\n",
      "parameter F test:         F=2.9812  , p=0.0010  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Toluene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=3.1906  , p=0.0743  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=3.1994  , p=0.0737  , df=1\n",
      "likelihood ratio test: chi2=3.1947  , p=0.0739  , df=1\n",
      "parameter F test:         F=3.1906  , p=0.0743  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=8.1816  , p=0.0003  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=16.4384 , p=0.0003  , df=2\n",
      "likelihood ratio test: chi2=16.3160 , p=0.0003  , df=2\n",
      "parameter F test:         F=8.1816  , p=0.0003  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=5.5645  , p=0.0009  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=16.8013 , p=0.0008  , df=3\n",
      "likelihood ratio test: chi2=16.6733 , p=0.0008  , df=3\n",
      "parameter F test:         F=5.5645  , p=0.0009  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=4.4533  , p=0.0014  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=17.9612 , p=0.0013  , df=4\n",
      "likelihood ratio test: chi2=17.8150 , p=0.0013  , df=4\n",
      "parameter F test:         F=4.4533  , p=0.0014  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.2247  , p=0.0068  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=16.2879 , p=0.0061  , df=5\n",
      "likelihood ratio test: chi2=16.1674 , p=0.0064  , df=5\n",
      "parameter F test:         F=3.2247  , p=0.0068  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.7390  , p=0.0120  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=16.6328 , p=0.0107  , df=6\n",
      "likelihood ratio test: chi2=16.5070 , p=0.0113  , df=6\n",
      "parameter F test:         F=2.7390  , p=0.0120  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.5997  , p=0.0116  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=18.4522 , p=0.0101  , df=7\n",
      "likelihood ratio test: chi2=18.2974 , p=0.0107  , df=7\n",
      "parameter F test:         F=2.5997  , p=0.0116  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.3690  , p=0.0157  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=19.2534 , p=0.0136  , df=8\n",
      "likelihood ratio test: chi2=19.0849 , p=0.0144  , df=8\n",
      "parameter F test:         F=2.3690  , p=0.0157  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.6486  , p=0.0049  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=24.2615 , p=0.0039  , df=9\n",
      "likelihood ratio test: chi2=23.9945 , p=0.0043  , df=9\n",
      "parameter F test:         F=2.6486  , p=0.0049  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.2151  , p=0.0151  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=22.5884 , p=0.0124  , df=10\n",
      "likelihood ratio test: chi2=22.3564 , p=0.0134  , df=10\n",
      "parameter F test:         F=2.2151  , p=0.0151  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Eth-Benzene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=21.1827 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=21.2409 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=21.0373 , p=0.0000  , df=1\n",
      "parameter F test:         F=21.1827 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=7.2683  , p=0.0007  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=14.6033 , p=0.0007  , df=2\n",
      "likelihood ratio test: chi2=14.5066 , p=0.0007  , df=2\n",
      "parameter F test:         F=7.2683  , p=0.0007  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=4.7782  , p=0.0026  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=14.4271 , p=0.0024  , df=3\n",
      "likelihood ratio test: chi2=14.3327 , p=0.0025  , df=3\n",
      "parameter F test:         F=4.7782  , p=0.0026  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.4224  , p=0.0467  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=9.7701  , p=0.0445  , df=4\n",
      "likelihood ratio test: chi2=9.7266  , p=0.0453  , df=4\n",
      "parameter F test:         F=2.4224  , p=0.0467  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.9997  , p=0.0762  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=10.1006 , p=0.0724  , df=5\n",
      "likelihood ratio test: chi2=10.0541 , p=0.0737  , df=5\n",
      "parameter F test:         F=1.9997  , p=0.0762  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.5448  , p=0.1602  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=9.3807  , p=0.1533  , df=6\n",
      "likelihood ratio test: chi2=9.3405  , p=0.1553  , df=6\n",
      "parameter F test:         F=1.5448  , p=0.1602  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.4549  , p=0.1797  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=10.3265 , p=0.1708  , df=7\n",
      "likelihood ratio test: chi2=10.2778 , p=0.1734  , df=7\n",
      "parameter F test:         F=1.4549  , p=0.1797  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.5458  , p=0.0095  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=20.6898 , p=0.0080  , df=8\n",
      "likelihood ratio test: chi2=20.4953 , p=0.0086  , df=8\n",
      "parameter F test:         F=2.5458  , p=0.0095  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.0566  , p=0.0307  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=18.8389 , p=0.0266  , df=9\n",
      "likelihood ratio test: chi2=18.6774 , p=0.0281  , df=9\n",
      "parameter F test:         F=2.0566  , p=0.0307  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.1224  , p=0.0204  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=21.6428 , p=0.0170  , df=10\n",
      "likelihood ratio test: chi2=21.4297 , p=0.0183  , df=10\n",
      "parameter F test:         F=2.1224  , p=0.0204  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('MP-Xylene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=17.1569 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=17.2041 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=17.0702 , p=0.0000  , df=1\n",
      "parameter F test:         F=17.1569 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=7.9862  , p=0.0004  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=16.0459 , p=0.0003  , df=2\n",
      "likelihood ratio test: chi2=15.9292 , p=0.0003  , df=2\n",
      "parameter F test:         F=7.9862  , p=0.0004  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=5.6002  , p=0.0008  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=16.9091 , p=0.0007  , df=3\n",
      "likelihood ratio test: chi2=16.7795 , p=0.0008  , df=3\n",
      "parameter F test:         F=5.6002  , p=0.0008  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=4.5288  , p=0.0012  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=18.2659 , p=0.0011  , df=4\n",
      "likelihood ratio test: chi2=18.1147 , p=0.0012  , df=4\n",
      "parameter F test:         F=4.5288  , p=0.0012  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.2145  , p=0.0069  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=16.2363 , p=0.0062  , df=5\n",
      "likelihood ratio test: chi2=16.1166 , p=0.0065  , df=5\n",
      "parameter F test:         F=3.2145  , p=0.0069  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=3.0041  , p=0.0065  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=18.2426 , p=0.0057  , df=6\n",
      "likelihood ratio test: chi2=18.0915 , p=0.0060  , df=6\n",
      "parameter F test:         F=3.0041  , p=0.0065  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.4446  , p=0.0173  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=17.3516 , p=0.0153  , df=7\n",
      "likelihood ratio test: chi2=17.2147 , p=0.0161  , df=7\n",
      "parameter F test:         F=2.4446  , p=0.0173  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.4249  , p=0.0134  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=19.7077 , p=0.0115  , df=8\n",
      "likelihood ratio test: chi2=19.5312 , p=0.0123  , df=8\n",
      "parameter F test:         F=2.4249  , p=0.0134  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.0591  , p=0.0305  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=18.8618 , p=0.0264  , df=9\n",
      "likelihood ratio test: chi2=18.6999 , p=0.0279  , df=9\n",
      "parameter F test:         F=2.0591  , p=0.0305  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.7327  , p=0.0690  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=17.6695 , p=0.0608  , df=10\n",
      "likelihood ratio test: chi2=17.5271 , p=0.0635  , df=10\n",
      "parameter F test:         F=1.7327  , p=0.0690  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('AT (°C)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=16.0906 , p=0.0001  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=16.1348 , p=0.0001  , df=1\n",
      "likelihood ratio test: chi2=16.0170 , p=0.0001  , df=1\n",
      "parameter F test:         F=16.0906 , p=0.0001  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=9.0488  , p=0.0001  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=18.1807 , p=0.0001  , df=2\n",
      "likelihood ratio test: chi2=18.0312 , p=0.0001  , df=2\n",
      "parameter F test:         F=9.0488  , p=0.0001  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=5.1336  , p=0.0016  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=15.5003 , p=0.0014  , df=3\n",
      "likelihood ratio test: chi2=15.3913 , p=0.0015  , df=3\n",
      "parameter F test:         F=5.1336  , p=0.0016  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=4.1033  , p=0.0026  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=16.5497 , p=0.0024  , df=4\n",
      "likelihood ratio test: chi2=16.4254 , p=0.0025  , df=4\n",
      "parameter F test:         F=4.1033  , p=0.0026  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.6865  , p=0.0026  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=18.6204 , p=0.0023  , df=5\n",
      "likelihood ratio test: chi2=18.4631 , p=0.0024  , df=5\n",
      "parameter F test:         F=3.6865  , p=0.0026  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.8432  , p=0.0094  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=17.2654 , p=0.0084  , df=6\n",
      "likelihood ratio test: chi2=17.1300 , p=0.0088  , df=6\n",
      "parameter F test:         F=2.8432  , p=0.0094  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.7745  , p=0.0073  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=19.6927 , p=0.0063  , df=7\n",
      "likelihood ratio test: chi2=19.5166 , p=0.0067  , df=7\n",
      "parameter F test:         F=2.7745  , p=0.0073  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.5609  , p=0.0091  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=20.8126 , p=0.0077  , df=8\n",
      "likelihood ratio test: chi2=20.6159 , p=0.0082  , df=8\n",
      "parameter F test:         F=2.5609  , p=0.0091  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.2630  , p=0.0165  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=20.7298 , p=0.0139  , df=9\n",
      "likelihood ratio test: chi2=20.5345 , p=0.0149  , df=9\n",
      "parameter F test:         F=2.2630  , p=0.0165  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.9230  , p=0.0386  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=19.6099 , p=0.0332  , df=10\n",
      "likelihood ratio test: chi2=19.4348 , p=0.0351  , df=10\n",
      "parameter F test:         F=1.9230  , p=0.0386  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('WD (deg)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=34.5288 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=34.6237 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=34.0871 , p=0.0000  , df=1\n",
      "parameter F test:         F=34.5288 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=15.6744 , p=0.0000  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=31.4929 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=31.0478 , p=0.0000  , df=2\n",
      "parameter F test:         F=15.6744 , p=0.0000  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=8.4627  , p=0.0000  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=25.5520 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=25.2576 , p=0.0000  , df=3\n",
      "parameter F test:         F=8.4627  , p=0.0000  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=5.7827  , p=0.0001  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=23.3230 , p=0.0001  , df=4\n",
      "likelihood ratio test: chi2=23.0772 , p=0.0001  , df=4\n",
      "parameter F test:         F=5.7827  , p=0.0001  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.4484  , p=0.0043  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=17.4177 , p=0.0038  , df=5\n",
      "likelihood ratio test: chi2=17.2800 , p=0.0040  , df=5\n",
      "parameter F test:         F=3.4484  , p=0.0043  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.6372  , p=0.0152  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=16.0143 , p=0.0137  , df=6\n",
      "likelihood ratio test: chi2=15.8977 , p=0.0143  , df=6\n",
      "parameter F test:         F=2.6372  , p=0.0152  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.9465  , p=0.0594  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=13.8162 , p=0.0545  , df=7\n",
      "likelihood ratio test: chi2=13.7292 , p=0.0562  , df=7\n",
      "parameter F test:         F=1.9465  , p=0.0594  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.7509  , p=0.0829  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=14.2297 , p=0.0760  , df=8\n",
      "likelihood ratio test: chi2=14.1374 , p=0.0783  , df=8\n",
      "parameter F test:         F=1.7509  , p=0.0829  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.3065  , p=0.2288  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=11.9680 , p=0.2151  , df=9\n",
      "likelihood ratio test: chi2=11.9025 , p=0.2189  , df=9\n",
      "parameter F test:         F=1.3065  , p=0.2288  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.5466  , p=0.1177  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=15.7712 , p=0.1064  , df=10\n",
      "likelihood ratio test: chi2=15.6577 , p=0.1099  , df=10\n",
      "parameter F test:         F=1.5466  , p=0.1177  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('VWS (m/s)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=27.0703 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=27.1448 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=26.8135 , p=0.0000  , df=1\n",
      "parameter F test:         F=27.0703 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=15.6409 , p=0.0000  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=31.4255 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=30.9823 , p=0.0000  , df=2\n",
      "parameter F test:         F=15.6409 , p=0.0000  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=7.4014  , p=0.0001  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=22.3473 , p=0.0001  , df=3\n",
      "likelihood ratio test: chi2=22.1217 , p=0.0001  , df=3\n",
      "parameter F test:         F=7.4014  , p=0.0001  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=3.7121  , p=0.0052  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=14.9717 , p=0.0048  , df=4\n",
      "likelihood ratio test: chi2=14.8699 , p=0.0050  , df=4\n",
      "parameter F test:         F=3.7121  , p=0.0052  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=2.2261  , p=0.0496  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=11.2442 , p=0.0467  , df=5\n",
      "likelihood ratio test: chi2=11.1866 , p=0.0478  , df=5\n",
      "parameter F test:         F=2.2261  , p=0.0496  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.7478  , p=0.1067  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=10.6135 , p=0.1011  , df=6\n",
      "likelihood ratio test: chi2=10.5622 , p=0.1029  , df=6\n",
      "parameter F test:         F=1.7478  , p=0.1067  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.4103  , p=0.1973  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=10.0098 , p=0.1880  , df=7\n",
      "likelihood ratio test: chi2=9.9641  , p=0.1906  , df=7\n",
      "parameter F test:         F=1.4103  , p=0.1973  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.2050  , p=0.2924  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=9.7934  , p=0.2798  , df=8\n",
      "likelihood ratio test: chi2=9.7495  , p=0.2830  , df=8\n",
      "parameter F test:         F=1.2050  , p=0.2924  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.0242  , p=0.4183  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=9.3817  , p=0.4028  , df=9\n",
      "likelihood ratio test: chi2=9.3414  , p=0.4064  , df=9\n",
      "parameter F test:         F=1.0242  , p=0.4183  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.1423  , p=0.3269  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=11.6485 , p=0.3093  , df=10\n",
      "likelihood ratio test: chi2=11.5864 , p=0.3137  , df=10\n",
      "parameter F test:         F=1.1423  , p=0.3269  , df_denom=1064, df_num=10\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Apply Granger's Causality Test\n",
    "for pair in highly_correlated_pairs:\n",
    "    print()\n",
    "    print(f\"Granger Causality Test for pair {pair}:\")\n",
    "    granger_test_result = grangercausalitytests(df[list(pair)], maxlag=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CO (mg/m³)',\n",
       " 'Benzene (µg/m³)',\n",
       " 'Toluene (µg/m³)',\n",
       " 'MP-Xylene (µg/m³)',\n",
       " 'PM2.5 (µg/m³)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['CO (mg/m³)','Benzene (µg/m³)','Toluene (µg/m³)','MP-Xylene (µg/m³)','PM2.5 (µg/m³)']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13999311, 0.10782101, 0.08011795, 0.03898786, 0.01194619])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = df[cols]\n",
    "df_corr.index = df['Timestamp']\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "johan_test_temp = df_corr\n",
    "coint_johansen(johan_test_temp,-1,1).eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.72</td>\n",
       "      <td>12.11</td>\n",
       "      <td>14.22</td>\n",
       "      <td>3.39</td>\n",
       "      <td>102.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.59</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.29</td>\n",
       "      <td>3.70</td>\n",
       "      <td>97.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.90</td>\n",
       "      <td>25.69</td>\n",
       "      <td>26.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>93.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>1.29</td>\n",
       "      <td>33.04</td>\n",
       "      <td>37.91</td>\n",
       "      <td>6.67</td>\n",
       "      <td>105.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>1.69</td>\n",
       "      <td>46.25</td>\n",
       "      <td>52.63</td>\n",
       "      <td>8.25</td>\n",
       "      <td>119.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>1.22</td>\n",
       "      <td>35.99</td>\n",
       "      <td>41.19</td>\n",
       "      <td>6.63</td>\n",
       "      <td>112.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.89</td>\n",
       "      <td>15.05</td>\n",
       "      <td>18.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.78</td>\n",
       "      <td>19.89</td>\n",
       "      <td>18.80</td>\n",
       "      <td>3.11</td>\n",
       "      <td>127.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.89</td>\n",
       "      <td>17.63</td>\n",
       "      <td>22.93</td>\n",
       "      <td>4.56</td>\n",
       "      <td>109.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>1.29</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.93</td>\n",
       "      <td>8.45</td>\n",
       "      <td>9.61</td>\n",
       "      <td>2.13</td>\n",
       "      <td>110.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.63</td>\n",
       "      <td>20.17</td>\n",
       "      <td>16.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>103.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.87</td>\n",
       "      <td>29.41</td>\n",
       "      <td>25.56</td>\n",
       "      <td>5.12</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.83</td>\n",
       "      <td>23.18</td>\n",
       "      <td>16.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>158.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.88</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.42</td>\n",
       "      <td>2.49</td>\n",
       "      <td>139.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.87</td>\n",
       "      <td>18.28</td>\n",
       "      <td>18.18</td>\n",
       "      <td>2.90</td>\n",
       "      <td>116.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.79</td>\n",
       "      <td>20.19</td>\n",
       "      <td>17.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>99.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.67</td>\n",
       "      <td>23.28</td>\n",
       "      <td>18.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>103.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.67</td>\n",
       "      <td>22.01</td>\n",
       "      <td>16.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>1.01</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>124.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>1.17</td>\n",
       "      <td>7.95</td>\n",
       "      <td>9.64</td>\n",
       "      <td>3.04</td>\n",
       "      <td>147.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.80</td>\n",
       "      <td>17.72</td>\n",
       "      <td>25.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>137.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>48.52</td>\n",
       "      <td>35.87</td>\n",
       "      <td>7.43</td>\n",
       "      <td>132.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.90</td>\n",
       "      <td>112.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>1.16</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.77</td>\n",
       "      <td>4.85</td>\n",
       "      <td>109.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>1.00</td>\n",
       "      <td>14.63</td>\n",
       "      <td>16.32</td>\n",
       "      <td>2.84</td>\n",
       "      <td>129.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>1.11</td>\n",
       "      <td>23.37</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.01</td>\n",
       "      <td>98.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>1.20</td>\n",
       "      <td>17.96</td>\n",
       "      <td>21.13</td>\n",
       "      <td>4.96</td>\n",
       "      <td>115.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.76</td>\n",
       "      <td>7.69</td>\n",
       "      <td>12.57</td>\n",
       "      <td>4.12</td>\n",
       "      <td>98.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.43</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>69.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.40</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.31</td>\n",
       "      <td>58.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2024-01-01        0.72            12.11            14.22               3.39   \n",
       "2024-01-02        0.59            20.14            18.29               3.70   \n",
       "2024-01-03        0.90            25.69            26.01               4.84   \n",
       "2024-01-04        1.29            33.04            37.91               6.67   \n",
       "2024-01-05        1.69            46.25            52.63               8.25   \n",
       "2024-01-06        1.22            35.99            41.19               6.63   \n",
       "2024-01-07        0.89            15.05            18.83               3.50   \n",
       "2024-01-08        0.78            19.89            18.80               3.11   \n",
       "2024-01-09        0.89            17.63            22.93               4.56   \n",
       "2024-01-10        1.29             9.63             9.78               3.15   \n",
       "2024-01-11        0.93             8.45             9.61               2.13   \n",
       "2024-01-12        0.63            20.17            16.97               3.30   \n",
       "2024-01-13        0.87            29.41            25.56               5.12   \n",
       "2024-01-14        0.83            23.18            16.01               4.27   \n",
       "2024-01-15        0.88            17.00            12.42               2.49   \n",
       "2024-01-16        0.87            18.28            18.18               2.90   \n",
       "2024-01-17        0.79            20.19            17.60               3.45   \n",
       "2024-01-18        0.67            23.28            18.44               3.34   \n",
       "2024-01-19        0.67            22.01            16.51               3.90   \n",
       "2024-01-20        1.01             4.31             5.05               1.91   \n",
       "2024-01-21        1.17             7.95             9.64               3.04   \n",
       "2024-01-22        0.80            17.72            25.21               4.37   \n",
       "2024-01-23        1.00            48.52            35.87               7.43   \n",
       "2024-01-24        0.60            14.06            11.83               2.90   \n",
       "2024-01-25        1.16            23.24            22.77               4.85   \n",
       "2024-01-26        1.00            14.63            16.32               2.84   \n",
       "2024-01-27        1.11            23.37            19.88               4.01   \n",
       "2024-01-28        1.20            17.96            21.13               4.96   \n",
       "2024-01-29        0.76             7.69            12.57               4.12   \n",
       "2024-01-30        0.43             4.27             4.29               1.23   \n",
       "2024-01-31        0.40             4.01             7.87               1.31   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2024-01-01         102.58  \n",
       "2024-01-02          97.01  \n",
       "2024-01-03          93.04  \n",
       "2024-01-04         105.41  \n",
       "2024-01-05         119.15  \n",
       "2024-01-06         112.77  \n",
       "2024-01-07         125.58  \n",
       "2024-01-08         127.41  \n",
       "2024-01-09         109.73  \n",
       "2024-01-10         111.51  \n",
       "2024-01-11         110.29  \n",
       "2024-01-12         103.24  \n",
       "2024-01-13         123.00  \n",
       "2024-01-14         158.87  \n",
       "2024-01-15         139.88  \n",
       "2024-01-16         116.59  \n",
       "2024-01-17          99.03  \n",
       "2024-01-18         103.19  \n",
       "2024-01-19          91.11  \n",
       "2024-01-20         124.94  \n",
       "2024-01-21         147.98  \n",
       "2024-01-22         137.20  \n",
       "2024-01-23         132.69  \n",
       "2024-01-24         112.50  \n",
       "2024-01-25         109.74  \n",
       "2024-01-26         129.29  \n",
       "2024-01-27          98.85  \n",
       "2024-01-28         115.18  \n",
       "2024-01-29          98.28  \n",
       "2024-01-30          69.20  \n",
       "2024-01-31          58.32  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums = [i.split()[0] for i in cols]\n",
    "val = pd.read_excel(\"C:/Users/DHAN RAJ/Downloads/Kolkata_daily_Jan.xlsx\")\n",
    "origin = '2021-01-01'\n",
    "start = '2024-01-01'\n",
    "end = '2024-01-31'\n",
    "time_period = pd.date_range(start,end)\n",
    "val['Timestamp'] = time_period\n",
    "val = val.drop(columns=['From Date'])\n",
    "val.set_index('Timestamp', inplace=True)\n",
    "val = val[colums]\n",
    "val.columns = cols\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
      "Timestamp                                                                     \n",
      "2024-01-01        0.72            12.11            14.22               3.39   \n",
      "2024-01-02        0.59            20.14            18.29               3.70   \n",
      "2024-01-03        0.90            25.69            26.01               4.84   \n",
      "2024-01-04        1.29            33.04            37.91               6.67   \n",
      "2024-01-05        1.69            46.25            52.63               8.25   \n",
      "2024-01-06        1.22            35.99            41.19               6.63   \n",
      "2024-01-07        0.89            15.05            18.83               3.50   \n",
      "2024-01-08        0.78            19.89            18.80               3.11   \n",
      "2024-01-09        0.89            17.63            22.93               4.56   \n",
      "2024-01-10        1.29             9.63             9.78               3.15   \n",
      "2024-01-11        0.93             8.45             9.61               2.13   \n",
      "2024-01-12        0.63            20.17            16.97               3.30   \n",
      "2024-01-13        0.87            29.41            25.56               5.12   \n",
      "2024-01-14        0.83            23.18            16.01               4.27   \n",
      "2024-01-15        0.88            17.00            12.42               2.49   \n",
      "2024-01-16        0.87            18.28            18.18               2.90   \n",
      "2024-01-17        0.79            20.19            17.60               3.45   \n",
      "2024-01-18        0.67            23.28            18.44               3.34   \n",
      "2024-01-19        0.67            22.01            16.51               3.90   \n",
      "2024-01-20        1.01             4.31             5.05               1.91   \n",
      "2024-01-21        1.17             7.95             9.64               3.04   \n",
      "2024-01-22        0.80            17.72            25.21               4.37   \n",
      "2024-01-23        1.00            48.52            35.87               7.43   \n",
      "2024-01-24        0.60            14.06            11.83               2.90   \n",
      "2024-01-25        1.16            23.24            22.77               4.85   \n",
      "2024-01-26        1.00            14.63            16.32               2.84   \n",
      "2024-01-27        1.11            23.37            19.88               4.01   \n",
      "2024-01-28        1.20            17.96            21.13               4.96   \n",
      "2024-01-29        0.76             7.69            12.57               4.12   \n",
      "2024-01-30        0.43             4.27             4.29               1.23   \n",
      "2024-01-31        0.40             4.01             7.87               1.31   \n",
      "\n",
      "            PM2.5 (µg/m³)  \n",
      "Timestamp                  \n",
      "2024-01-01         102.58  \n",
      "2024-01-02          97.01  \n",
      "2024-01-03          93.04  \n",
      "2024-01-04         105.41  \n",
      "2024-01-05         119.15  \n",
      "2024-01-06         112.77  \n",
      "2024-01-07         125.58  \n",
      "2024-01-08         127.41  \n",
      "2024-01-09         109.73  \n",
      "2024-01-10         111.51  \n",
      "2024-01-11         110.29  \n",
      "2024-01-12         103.24  \n",
      "2024-01-13         123.00  \n",
      "2024-01-14         158.87  \n",
      "2024-01-15         139.88  \n",
      "2024-01-16         116.59  \n",
      "2024-01-17          99.03  \n",
      "2024-01-18         103.19  \n",
      "2024-01-19          91.11  \n",
      "2024-01-20         124.94  \n",
      "2024-01-21         147.98  \n",
      "2024-01-22         137.20  \n",
      "2024-01-23         132.69  \n",
      "2024-01-24         112.50  \n",
      "2024-01-25         109.74  \n",
      "2024-01-26         129.29  \n",
      "2024-01-27          98.85  \n",
      "2024-01-28         115.18  \n",
      "2024-01-29          98.28  \n",
      "2024-01-30          69.20  \n",
      "2024-01-31          58.32  \n"
     ]
    }
   ],
   "source": [
    "val[cols]= val[cols].fillna(val[cols].rolling(8,min_periods=1).mean())\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Db8BJQONjbAT"
   },
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, window_size=1):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][4]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJhF1cIDleQ1",
    "outputId": "f571aa4c-d18c-41ef-d9c2-652ab09f9b3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1094, 1, 5), (1094,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2, y2 = df_to_X_y2(df_corr)\n",
    "X2.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMOArQgyoTnq",
    "outputId": "405a6dfd-4335-4d27-de23-a2fed6e08f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1040, 1, 5), (1040,), (54, 1, 5), (54,), (30, 1, 5), (30,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, y2_train = X2[:1040], y2[:1040]\n",
    "X2_val, y2_val = X2[1040:], y2[1040:]\n",
    "X2_test, y2_test = df_to_X_y2(val)\n",
    "X2_train.shape, y2_train.shape, X2_val.shape, y2_val.shape, X2_test.shape, y2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpFVgXYJqbt8",
    "outputId": "4696c3ab-a8cb-45e1-c691-faed44ba0086"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m17,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,449</span> (72.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,449\u001b[0m (72.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,449</span> (72.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,449\u001b[0m (72.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model4 = Sequential()\n",
    "model4.add(InputLayer((1, 5)))\n",
    "model4.add(LSTM(64))\n",
    "model4.add(Dense(8, 'relu'))\n",
    "model4.add(Dense(1, 'linear'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3RD8D_SXqkk8"
   },
   "outputs": [],
   "source": [
    "cp4 = ModelCheckpoint('checkpoint.model4kd.keras',monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model4.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GB5aik6bqogC",
    "outputId": "cfabcd42-c96b-4336-a89e-e51352dd6d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 3803.5784 - mean_absolute_error: 42.3116\n",
      "Epoch 1: val_loss improved from inf to 9287.76074, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4078.7039 - mean_absolute_error: 49.7841 - val_loss: 9287.7607 - val_mean_absolute_error: 90.1747\n",
      "Epoch 2/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5273.0957 - mean_absolute_error: 53.0323\n",
      "Epoch 2: val_loss improved from 9287.76074 to 9255.82324, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4239.1167 - mean_absolute_error: 51.5159 - val_loss: 9255.8232 - val_mean_absolute_error: 89.9821\n",
      "Epoch 3/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2794.9429 - mean_absolute_error: 41.0921\n",
      "Epoch 3: val_loss improved from 9255.82324 to 9216.72656, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3857.7507 - mean_absolute_error: 49.3076 - val_loss: 9216.7266 - val_mean_absolute_error: 89.7506\n",
      "Epoch 4/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5799.4365 - mean_absolute_error: 59.0385\n",
      "Epoch 4: val_loss improved from 9216.72656 to 9170.97949, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4218.2388 - mean_absolute_error: 51.2811 - val_loss: 9170.9795 - val_mean_absolute_error: 89.4822\n",
      "Epoch 5/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2832.8376 - mean_absolute_error: 42.2931\n",
      "Epoch 5: val_loss improved from 9170.97949 to 9116.26465, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3980.1313 - mean_absolute_error: 50.0258 - val_loss: 9116.2646 - val_mean_absolute_error: 89.1658\n",
      "Epoch 6/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4031.2034 - mean_absolute_error: 50.1314 \n",
      "Epoch 6: val_loss improved from 9116.26465 to 9054.56641, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4018.6609 - mean_absolute_error: 50.0452 - val_loss: 9054.5664 - val_mean_absolute_error: 88.8227\n",
      "Epoch 7/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4193.6475 - mean_absolute_error: 51.0227\n",
      "Epoch 7: val_loss improved from 9054.56641 to 8992.27930, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3758.1970 - mean_absolute_error: 48.4377 - val_loss: 8992.2793 - val_mean_absolute_error: 88.4723\n",
      "Epoch 8/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3406.8044 - mean_absolute_error: 45.1518\n",
      "Epoch 8: val_loss improved from 8992.27930 to 8928.34473, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3747.0408 - mean_absolute_error: 47.8650 - val_loss: 8928.3447 - val_mean_absolute_error: 88.1090\n",
      "Epoch 9/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4303.2100 - mean_absolute_error: 49.7962\n",
      "Epoch 9: val_loss improved from 8928.34473 to 8857.91895, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4161.2739 - mean_absolute_error: 50.5273 - val_loss: 8857.9189 - val_mean_absolute_error: 87.7009\n",
      "Epoch 10/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4833.2197 - mean_absolute_error: 54.8642\n",
      "Epoch 10: val_loss improved from 8857.91895 to 8766.52441, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3926.9607 - mean_absolute_error: 49.1683 - val_loss: 8766.5244 - val_mean_absolute_error: 87.1666\n",
      "Epoch 11/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4486.0049 - mean_absolute_error: 56.1400\n",
      "Epoch 11: val_loss improved from 8766.52441 to 8641.83691, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3646.7878 - mean_absolute_error: 47.5199 - val_loss: 8641.8369 - val_mean_absolute_error: 86.4452\n",
      "Epoch 12/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2975.3806 - mean_absolute_error: 44.6371\n",
      "Epoch 12: val_loss improved from 8641.83691 to 8508.91504, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3639.8064 - mean_absolute_error: 47.0195 - val_loss: 8508.9150 - val_mean_absolute_error: 85.6668\n",
      "Epoch 13/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2646.5737 - mean_absolute_error: 42.4902\n",
      "Epoch 13: val_loss improved from 8508.91504 to 8364.41797, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3322.2910 - mean_absolute_error: 44.4413 - val_loss: 8364.4180 - val_mean_absolute_error: 84.8201\n",
      "Epoch 14/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3835.1641 - mean_absolute_error: 49.5623\n",
      "Epoch 14: val_loss improved from 8364.41797 to 8191.92285, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3805.5344 - mean_absolute_error: 47.4587 - val_loss: 8191.9229 - val_mean_absolute_error: 83.8129\n",
      "Epoch 15/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3214.7090 - mean_absolute_error: 45.0361\n",
      "Epoch 15: val_loss improved from 8191.92285 to 8024.13086, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3576.1323 - mean_absolute_error: 46.3983 - val_loss: 8024.1309 - val_mean_absolute_error: 82.8138\n",
      "Epoch 16/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4992.9053 - mean_absolute_error: 52.8218\n",
      "Epoch 16: val_loss improved from 8024.13086 to 7863.12549, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3642.6118 - mean_absolute_error: 45.5857 - val_loss: 7863.1255 - val_mean_absolute_error: 81.8336\n",
      "Epoch 17/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4985.9385 - mean_absolute_error: 56.8413\n",
      "Epoch 17: val_loss improved from 7863.12549 to 7706.68066, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3507.9087 - mean_absolute_error: 44.9900 - val_loss: 7706.6807 - val_mean_absolute_error: 80.8561\n",
      "Epoch 18/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 4300.5557 - mean_absolute_error: 52.0858\n",
      "Epoch 18: val_loss improved from 7706.68066 to 7520.75684, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3389.0732 - mean_absolute_error: 43.7510 - val_loss: 7520.7568 - val_mean_absolute_error: 79.6993\n",
      "Epoch 19/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4940.5620 - mean_absolute_error: 50.6985\n",
      "Epoch 19: val_loss improved from 7520.75684 to 7327.67920, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3289.2505 - mean_absolute_error: 42.6515 - val_loss: 7327.6792 - val_mean_absolute_error: 78.5012\n",
      "Epoch 20/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2759.9468 - mean_absolute_error: 37.7452\n",
      "Epoch 20: val_loss improved from 7327.67920 to 7160.45410, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2935.5649 - mean_absolute_error: 39.9055 - val_loss: 7160.4541 - val_mean_absolute_error: 77.4533\n",
      "Epoch 21/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4112.1504 - mean_absolute_error: 53.5439\n",
      "Epoch 21: val_loss improved from 7160.45410 to 7008.33008, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3102.6589 - mean_absolute_error: 40.9128 - val_loss: 7008.3301 - val_mean_absolute_error: 76.4963\n",
      "Epoch 22/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4984.1274 - mean_absolute_error: 57.7133\n",
      "Epoch 22: val_loss improved from 7008.33008 to 6866.36035, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3222.2075 - mean_absolute_error: 41.7513 - val_loss: 6866.3604 - val_mean_absolute_error: 75.5971\n",
      "Epoch 23/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3260.6323 - mean_absolute_error: 46.1943\n",
      "Epoch 23: val_loss improved from 6866.36035 to 6734.80225, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3055.4238 - mean_absolute_error: 40.4542 - val_loss: 6734.8022 - val_mean_absolute_error: 74.7504\n",
      "Epoch 24/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3000.1233 - mean_absolute_error: 39.0820\n",
      "Epoch 24: val_loss improved from 6734.80225 to 6616.51953, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2903.7153 - mean_absolute_error: 38.2961 - val_loss: 6616.5195 - val_mean_absolute_error: 73.9754\n",
      "Epoch 25/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2988.4199 - mean_absolute_error: 38.2535\n",
      "Epoch 25: val_loss improved from 6616.51953 to 6506.74170, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2715.0581 - mean_absolute_error: 37.1813 - val_loss: 6506.7417 - val_mean_absolute_error: 73.2639\n",
      "Epoch 26/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2581.6738 - mean_absolute_error: 32.9029\n",
      "Epoch 26: val_loss improved from 6506.74170 to 6400.62598, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2760.5610 - mean_absolute_error: 37.1282 - val_loss: 6400.6260 - val_mean_absolute_error: 72.5711\n",
      "Epoch 27/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2575.5322 - mean_absolute_error: 35.1355\n",
      "Epoch 27: val_loss improved from 6400.62598 to 6302.19043, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2653.6875 - mean_absolute_error: 35.8437 - val_loss: 6302.1904 - val_mean_absolute_error: 71.9214\n",
      "Epoch 28/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2038.1777 - mean_absolute_error: 34.7132\n",
      "Epoch 28: val_loss improved from 6302.19043 to 6200.36035, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2483.3486 - mean_absolute_error: 34.4574 - val_loss: 6200.3604 - val_mean_absolute_error: 71.2456\n",
      "Epoch 29/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2760.1250 - mean_absolute_error: 34.7976\n",
      "Epoch 29: val_loss improved from 6200.36035 to 6103.87402, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2613.4260 - mean_absolute_error: 35.2088 - val_loss: 6103.8740 - val_mean_absolute_error: 70.5935\n",
      "Epoch 30/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1698.8228 - mean_absolute_error: 27.2770\n",
      "Epoch 30: val_loss improved from 6103.87402 to 6014.66016, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2372.7053 - mean_absolute_error: 33.2845 - val_loss: 6014.6602 - val_mean_absolute_error: 69.9827\n",
      "Epoch 31/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3211.8604 - mean_absolute_error: 39.8837\n",
      "Epoch 31: val_loss improved from 6014.66016 to 5925.93359, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2463.4138 - mean_absolute_error: 34.1333 - val_loss: 5925.9336 - val_mean_absolute_error: 69.3693\n",
      "Epoch 32/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3071.6099 - mean_absolute_error: 35.4880\n",
      "Epoch 32: val_loss improved from 5925.93359 to 5837.62842, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2489.3174 - mean_absolute_error: 34.1006 - val_loss: 5837.6284 - val_mean_absolute_error: 68.7567\n",
      "Epoch 33/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2077.8804 - mean_absolute_error: 32.9780\n",
      "Epoch 33: val_loss improved from 5837.62842 to 5751.85596, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2345.2991 - mean_absolute_error: 33.7055 - val_loss: 5751.8560 - val_mean_absolute_error: 68.1592\n",
      "Epoch 34/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3052.7847 - mean_absolute_error: 42.1043\n",
      "Epoch 34: val_loss improved from 5751.85596 to 5671.57422, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2548.3062 - mean_absolute_error: 35.0902 - val_loss: 5671.5742 - val_mean_absolute_error: 67.5947\n",
      "Epoch 35/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3159.8813 - mean_absolute_error: 36.1782\n",
      "Epoch 35: val_loss improved from 5671.57422 to 5596.62744, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2340.4966 - mean_absolute_error: 32.2534 - val_loss: 5596.6274 - val_mean_absolute_error: 67.0618\n",
      "Epoch 36/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2257.0054 - mean_absolute_error: 33.5022\n",
      "Epoch 36: val_loss improved from 5596.62744 to 5520.86230, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2325.7944 - mean_absolute_error: 33.0313 - val_loss: 5520.8623 - val_mean_absolute_error: 66.5180\n",
      "Epoch 37/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2671.8508 - mean_absolute_error: 36.0371\n",
      "Epoch 37: val_loss improved from 5520.86230 to 5449.33545, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2274.5884 - mean_absolute_error: 32.5051 - val_loss: 5449.3354 - val_mean_absolute_error: 65.9995\n",
      "Epoch 38/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1231.9387 - mean_absolute_error: 23.7566\n",
      "Epoch 38: val_loss improved from 5449.33545 to 5378.22754, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2210.1985 - mean_absolute_error: 32.1201 - val_loss: 5378.2275 - val_mean_absolute_error: 65.4790\n",
      "Epoch 39/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1737.8392 - mean_absolute_error: 30.5555\n",
      "Epoch 39: val_loss improved from 5378.22754 to 5309.38135, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2200.1838 - mean_absolute_error: 31.2053 - val_loss: 5309.3813 - val_mean_absolute_error: 64.9819\n",
      "Epoch 40/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 680.2811 - mean_absolute_error: 17.5168\n",
      "Epoch 40: val_loss improved from 5309.38135 to 5237.73193, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2010.4982 - mean_absolute_error: 29.8330 - val_loss: 5237.7319 - val_mean_absolute_error: 64.4799\n",
      "Epoch 41/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2600.1033 - mean_absolute_error: 37.4428\n",
      "Epoch 41: val_loss improved from 5237.73193 to 5164.08545, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2290.4873 - mean_absolute_error: 32.0534 - val_loss: 5164.0854 - val_mean_absolute_error: 63.9759\n",
      "Epoch 42/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1937.5002 - mean_absolute_error: 33.0541\n",
      "Epoch 42: val_loss improved from 5164.08545 to 5091.84814, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2185.9795 - mean_absolute_error: 32.0512 - val_loss: 5091.8481 - val_mean_absolute_error: 63.4887\n",
      "Epoch 43/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1287.6135 - mean_absolute_error: 23.9013\n",
      "Epoch 43: val_loss improved from 5091.84814 to 5024.53223, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2054.0818 - mean_absolute_error: 30.5520 - val_loss: 5024.5322 - val_mean_absolute_error: 63.0308\n",
      "Epoch 44/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2626.0405 - mean_absolute_error: 37.0642\n",
      "Epoch 44: val_loss improved from 5024.53223 to 4956.92236, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2186.9946 - mean_absolute_error: 31.4332 - val_loss: 4956.9224 - val_mean_absolute_error: 62.5671\n",
      "Epoch 45/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1187.0439 - mean_absolute_error: 21.8006\n",
      "Epoch 45: val_loss improved from 4956.92236 to 4890.80322, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1888.5668 - mean_absolute_error: 29.2296 - val_loss: 4890.8032 - val_mean_absolute_error: 62.1094\n",
      "Epoch 46/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2511.6211 - mean_absolute_error: 34.3040\n",
      "Epoch 46: val_loss improved from 4890.80322 to 4824.77490, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1955.8119 - mean_absolute_error: 29.5893 - val_loss: 4824.7749 - val_mean_absolute_error: 61.6487\n",
      "Epoch 47/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1471.7649 - mean_absolute_error: 22.8188\n",
      "Epoch 47: val_loss improved from 4824.77490 to 4760.32764, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1920.3616 - mean_absolute_error: 28.7467 - val_loss: 4760.3276 - val_mean_absolute_error: 61.1954\n",
      "Epoch 48/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1776.2061 - mean_absolute_error: 31.3699\n",
      "Epoch 48: val_loss improved from 4760.32764 to 4699.25781, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1683.2855 - mean_absolute_error: 27.7186 - val_loss: 4699.2578 - val_mean_absolute_error: 60.7656\n",
      "Epoch 49/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1819.4154 - mean_absolute_error: 27.9719 \n",
      "Epoch 49: val_loss improved from 4699.25781 to 4636.35840, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1827.3967 - mean_absolute_error: 28.1210 - val_loss: 4636.3584 - val_mean_absolute_error: 60.3237\n",
      "Epoch 50/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2010.3846 - mean_absolute_error: 28.3568\n",
      "Epoch 50: val_loss improved from 4636.35840 to 4574.95020, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1828.6637 - mean_absolute_error: 28.0481 - val_loss: 4574.9502 - val_mean_absolute_error: 59.8945\n",
      "Epoch 51/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2303.5303 - mean_absolute_error: 32.2648\n",
      "Epoch 51: val_loss improved from 4574.95020 to 4515.52148, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2011.6869 - mean_absolute_error: 29.2149 - val_loss: 4515.5215 - val_mean_absolute_error: 59.4744\n",
      "Epoch 52/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2000.9299 - mean_absolute_error: 27.6074\n",
      "Epoch 52: val_loss improved from 4515.52148 to 4458.01123, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1777.6560 - mean_absolute_error: 27.3479 - val_loss: 4458.0112 - val_mean_absolute_error: 59.0558\n",
      "Epoch 53/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2927.0977 - mean_absolute_error: 34.6178\n",
      "Epoch 53: val_loss improved from 4458.01123 to 4398.47852, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2040.0853 - mean_absolute_error: 29.7775 - val_loss: 4398.4785 - val_mean_absolute_error: 58.6272\n",
      "Epoch 54/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1578.5549 - mean_absolute_error: 23.9420\n",
      "Epoch 54: val_loss improved from 4398.47852 to 4340.41162, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1835.2043 - mean_absolute_error: 27.8082 - val_loss: 4340.4116 - val_mean_absolute_error: 58.1889\n",
      "Epoch 55/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3148.2944 - mean_absolute_error: 40.7489\n",
      "Epoch 55: val_loss improved from 4340.41162 to 4285.12744, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1880.1251 - mean_absolute_error: 28.4567 - val_loss: 4285.1274 - val_mean_absolute_error: 57.7707\n",
      "Epoch 56/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1620.3308 - mean_absolute_error: 26.2552\n",
      "Epoch 56: val_loss improved from 4285.12744 to 4228.96143, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1622.1323 - mean_absolute_error: 26.3332 - val_loss: 4228.9614 - val_mean_absolute_error: 57.3414\n",
      "Epoch 57/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2314.2749 - mean_absolute_error: 34.7963\n",
      "Epoch 57: val_loss improved from 4228.96143 to 4171.34424, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1736.3904 - mean_absolute_error: 27.0376 - val_loss: 4171.3442 - val_mean_absolute_error: 56.8942\n",
      "Epoch 58/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1120.1448 - mean_absolute_error: 23.0702\n",
      "Epoch 58: val_loss improved from 4171.34424 to 4114.33838, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1642.1056 - mean_absolute_error: 26.4123 - val_loss: 4114.3384 - val_mean_absolute_error: 56.4453\n",
      "Epoch 59/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1432.9639 - mean_absolute_error: 25.6938\n",
      "Epoch 59: val_loss improved from 4114.33838 to 4056.95947, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1660.8337 - mean_absolute_error: 26.9286 - val_loss: 4056.9595 - val_mean_absolute_error: 55.9858\n",
      "Epoch 60/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 909.0844 - mean_absolute_error: 20.1328\n",
      "Epoch 60: val_loss improved from 4056.95947 to 4004.05200, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1484.5875 - mean_absolute_error: 24.7057 - val_loss: 4004.0520 - val_mean_absolute_error: 55.5649\n",
      "Epoch 61/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2669.9246 - mean_absolute_error: 35.8381\n",
      "Epoch 61: val_loss improved from 4004.05200 to 3946.20630, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1782.8474 - mean_absolute_error: 27.3708 - val_loss: 3946.2063 - val_mean_absolute_error: 55.1024\n",
      "Epoch 62/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1169.8496 - mean_absolute_error: 23.3566\n",
      "Epoch 62: val_loss improved from 3946.20630 to 3892.61157, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1483.9080 - mean_absolute_error: 24.9316 - val_loss: 3892.6116 - val_mean_absolute_error: 54.6702\n",
      "Epoch 63/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1241.1580 - mean_absolute_error: 23.6241\n",
      "Epoch 63: val_loss improved from 3892.61157 to 3839.80200, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1499.3918 - mean_absolute_error: 24.5617 - val_loss: 3839.8020 - val_mean_absolute_error: 54.2479\n",
      "Epoch 64/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1139.5204 - mean_absolute_error: 21.6543\n",
      "Epoch 64: val_loss improved from 3839.80200 to 3785.74121, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1494.7417 - mean_absolute_error: 24.5732 - val_loss: 3785.7412 - val_mean_absolute_error: 53.8080\n",
      "Epoch 65/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1523.6443 - mean_absolute_error: 24.0243\n",
      "Epoch 65: val_loss improved from 3785.74121 to 3733.51099, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1569.9321 - mean_absolute_error: 25.6102 - val_loss: 3733.5110 - val_mean_absolute_error: 53.3842\n",
      "Epoch 66/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 770.8461 - mean_absolute_error: 18.4496\n",
      "Epoch 66: val_loss improved from 3733.51099 to 3680.90845, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1504.0177 - mean_absolute_error: 24.8599 - val_loss: 3680.9084 - val_mean_absolute_error: 52.9474\n",
      "Epoch 67/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1128.6707 - mean_absolute_error: 24.7375\n",
      "Epoch 67: val_loss improved from 3680.90845 to 3629.83154, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1515.7764 - mean_absolute_error: 25.2420 - val_loss: 3629.8315 - val_mean_absolute_error: 52.5190\n",
      "Epoch 68/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1056.3907 - mean_absolute_error: 20.5677\n",
      "Epoch 68: val_loss improved from 3629.83154 to 3579.39038, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1405.1345 - mean_absolute_error: 24.0137 - val_loss: 3579.3904 - val_mean_absolute_error: 52.0916\n",
      "Epoch 69/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 952.0667 - mean_absolute_error: 20.6694\n",
      "Epoch 69: val_loss improved from 3579.39038 to 3526.48022, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1343.0869 - mean_absolute_error: 23.4129 - val_loss: 3526.4802 - val_mean_absolute_error: 51.6278\n",
      "Epoch 70/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1135.5525 - mean_absolute_error: 24.5099\n",
      "Epoch 70: val_loss improved from 3526.48022 to 3476.20508, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1459.8116 - mean_absolute_error: 24.3552 - val_loss: 3476.2051 - val_mean_absolute_error: 51.1935\n",
      "Epoch 71/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2137.1409 - mean_absolute_error: 27.9857\n",
      "Epoch 71: val_loss improved from 3476.20508 to 3425.54077, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1477.4504 - mean_absolute_error: 24.1432 - val_loss: 3425.5408 - val_mean_absolute_error: 50.7470\n",
      "Epoch 72/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1487.3751 - mean_absolute_error: 26.6892\n",
      "Epoch 72: val_loss improved from 3425.54077 to 3376.21680, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1321.2921 - mean_absolute_error: 23.4031 - val_loss: 3376.2168 - val_mean_absolute_error: 50.3102\n",
      "Epoch 73/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1335.5800 - mean_absolute_error: 25.8323\n",
      "Epoch 73: val_loss improved from 3376.21680 to 3325.90601, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1336.7305 - mean_absolute_error: 23.4068 - val_loss: 3325.9060 - val_mean_absolute_error: 49.8583\n",
      "Epoch 74/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1610.2065 - mean_absolute_error: 23.8484\n",
      "Epoch 74: val_loss improved from 3325.90601 to 3278.06470, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1436.8109 - mean_absolute_error: 23.5619 - val_loss: 3278.0647 - val_mean_absolute_error: 49.4288\n",
      "Epoch 75/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 658.7758 - mean_absolute_error: 17.1173\n",
      "Epoch 75: val_loss improved from 3278.06470 to 3229.30737, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1228.0304 - mean_absolute_error: 22.3248 - val_loss: 3229.3074 - val_mean_absolute_error: 48.9800\n",
      "Epoch 76/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 927.6598 - mean_absolute_error: 17.6714\n",
      "Epoch 76: val_loss improved from 3229.30737 to 3181.51270, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1343.4316 - mean_absolute_error: 22.8975 - val_loss: 3181.5127 - val_mean_absolute_error: 48.5402\n",
      "Epoch 77/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 617.6215 - mean_absolute_error: 14.5266\n",
      "Epoch 77: val_loss improved from 3181.51270 to 3136.29224, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1163.6450 - mean_absolute_error: 21.3650 - val_loss: 3136.2922 - val_mean_absolute_error: 48.1222\n",
      "Epoch 78/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1159.8557 - mean_absolute_error: 21.1309\n",
      "Epoch 78: val_loss improved from 3136.29224 to 3090.46655, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1170.8660 - mean_absolute_error: 21.3294 - val_loss: 3090.4666 - val_mean_absolute_error: 47.6882\n",
      "Epoch 79/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1356.5544 - mean_absolute_error: 23.6735\n",
      "Epoch 79: val_loss improved from 3090.46655 to 3041.63794, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1358.5289 - mean_absolute_error: 23.0876 - val_loss: 3041.6379 - val_mean_absolute_error: 47.2296\n",
      "Epoch 80/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 645.7738 - mean_absolute_error: 17.1933\n",
      "Epoch 80: val_loss improved from 3041.63794 to 2997.68896, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1180.0042 - mean_absolute_error: 21.7270 - val_loss: 2997.6890 - val_mean_absolute_error: 46.8217\n",
      "Epoch 81/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 459.5169 - mean_absolute_error: 13.8568\n",
      "Epoch 81: val_loss improved from 2997.68896 to 2951.97339, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.6881 - mean_absolute_error: 21.1051 - val_loss: 2951.9734 - val_mean_absolute_error: 46.3916\n",
      "Epoch 82/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 943.2957 - mean_absolute_error: 19.6038\n",
      "Epoch 82: val_loss improved from 2951.97339 to 2907.72314, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.2736 - mean_absolute_error: 20.8854 - val_loss: 2907.7231 - val_mean_absolute_error: 45.9753\n",
      "Epoch 83/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 976.7085 - mean_absolute_error: 19.9902\n",
      "Epoch 83: val_loss improved from 2907.72314 to 2863.59424, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.5648 - mean_absolute_error: 20.9160 - val_loss: 2863.5942 - val_mean_absolute_error: 45.5519\n",
      "Epoch 84/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 787.4826 - mean_absolute_error: 15.7455\n",
      "Epoch 84: val_loss improved from 2863.59424 to 2819.47363, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.1262 - mean_absolute_error: 20.7150 - val_loss: 2819.4736 - val_mean_absolute_error: 45.1307\n",
      "Epoch 85/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 908.0576 - mean_absolute_error: 17.7514\n",
      "Epoch 85: val_loss improved from 2819.47363 to 2774.68286, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1176.6770 - mean_absolute_error: 21.3693 - val_loss: 2774.6829 - val_mean_absolute_error: 44.7114\n",
      "Epoch 86/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 360.3467 - mean_absolute_error: 12.6137\n",
      "Epoch 86: val_loss improved from 2774.68286 to 2733.66846, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.8749 - mean_absolute_error: 19.7378 - val_loss: 2733.6685 - val_mean_absolute_error: 44.3214\n",
      "Epoch 87/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 903.7897 - mean_absolute_error: 22.0831\n",
      "Epoch 87: val_loss improved from 2733.66846 to 2691.55518, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.2732 - mean_absolute_error: 20.6995 - val_loss: 2691.5552 - val_mean_absolute_error: 43.9190\n",
      "Epoch 88/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 752.7451 - mean_absolute_error: 15.1551\n",
      "Epoch 88: val_loss improved from 2691.55518 to 2650.37793, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.7389 - mean_absolute_error: 20.6776 - val_loss: 2650.3779 - val_mean_absolute_error: 43.5297\n",
      "Epoch 89/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1213.6545 - mean_absolute_error: 22.2984\n",
      "Epoch 89: val_loss improved from 2650.37793 to 2611.17871, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.5150 - mean_absolute_error: 20.5515 - val_loss: 2611.1787 - val_mean_absolute_error: 43.1544\n",
      "Epoch 90/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1221.0187 - mean_absolute_error: 20.8127\n",
      "Epoch 90: val_loss improved from 2611.17871 to 2569.75806, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1008.6161 - mean_absolute_error: 19.5784 - val_loss: 2569.7581 - val_mean_absolute_error: 42.7668\n",
      "Epoch 91/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1123.2292 - mean_absolute_error: 19.8826\n",
      "Epoch 91: val_loss improved from 2569.75806 to 2530.82837, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 924.4664 - mean_absolute_error: 18.8005 - val_loss: 2530.8284 - val_mean_absolute_error: 42.3970\n",
      "Epoch 92/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1551.6627 - mean_absolute_error: 27.7183\n",
      "Epoch 92: val_loss improved from 2530.82837 to 2488.95142, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1070.6273 - mean_absolute_error: 20.7970 - val_loss: 2488.9514 - val_mean_absolute_error: 41.9899\n",
      "Epoch 93/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1251.0945 - mean_absolute_error: 23.5433\n",
      "Epoch 93: val_loss improved from 2488.95142 to 2450.39966, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 931.5575 - mean_absolute_error: 19.2451 - val_loss: 2450.3997 - val_mean_absolute_error: 41.6163\n",
      "Epoch 94/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1515.0107 - mean_absolute_error: 25.0421\n",
      "Epoch 94: val_loss improved from 2450.39966 to 2411.58618, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1006.7433 - mean_absolute_error: 19.8383 - val_loss: 2411.5862 - val_mean_absolute_error: 41.2460\n",
      "Epoch 95/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 769.2438 - mean_absolute_error: 19.5726\n",
      "Epoch 95: val_loss improved from 2411.58618 to 2370.96899, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1001.6049 - mean_absolute_error: 20.0287 - val_loss: 2370.9690 - val_mean_absolute_error: 40.8630\n",
      "Epoch 96/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1159.8105 - mean_absolute_error: 19.6496\n",
      "Epoch 96: val_loss improved from 2370.96899 to 2335.35498, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1008.0016 - mean_absolute_error: 19.9125 - val_loss: 2335.3550 - val_mean_absolute_error: 40.5309\n",
      "Epoch 97/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 472.1981 - mean_absolute_error: 13.8732\n",
      "Epoch 97: val_loss improved from 2335.35498 to 2297.15259, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 880.8157 - mean_absolute_error: 18.2459 - val_loss: 2297.1526 - val_mean_absolute_error: 40.1745\n",
      "Epoch 98/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 320.7481 - mean_absolute_error: 11.9869\n",
      "Epoch 98: val_loss improved from 2297.15259 to 2262.78125, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 808.0666 - mean_absolute_error: 17.3405 - val_loss: 2262.7812 - val_mean_absolute_error: 39.8512\n",
      "Epoch 99/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1013.1027 - mean_absolute_error: 21.3789\n",
      "Epoch 99: val_loss improved from 2262.78125 to 2223.52539, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.1476 - mean_absolute_error: 20.6208 - val_loss: 2223.5254 - val_mean_absolute_error: 39.4808\n",
      "Epoch 100/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 387.1677 - mean_absolute_error: 13.9955\n",
      "Epoch 100: val_loss improved from 2223.52539 to 2189.89722, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 870.9604 - mean_absolute_error: 17.9948 - val_loss: 2189.8972 - val_mean_absolute_error: 39.1542\n",
      "Epoch 101/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 994.0574 - mean_absolute_error: 17.8823\n",
      "Epoch 101: val_loss improved from 2189.89722 to 2155.22705, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 897.1779 - mean_absolute_error: 18.0618 - val_loss: 2155.2271 - val_mean_absolute_error: 38.8158\n",
      "Epoch 102/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 848.6520 - mean_absolute_error: 18.2763\n",
      "Epoch 102: val_loss improved from 2155.22705 to 2119.75903, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 801.9163 - mean_absolute_error: 17.4591 - val_loss: 2119.7590 - val_mean_absolute_error: 38.4600\n",
      "Epoch 103/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 424.0945 - mean_absolute_error: 13.0690\n",
      "Epoch 103: val_loss improved from 2119.75903 to 2086.19580, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 753.5426 - mean_absolute_error: 17.0758 - val_loss: 2086.1958 - val_mean_absolute_error: 38.1248\n",
      "Epoch 104/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1047.8247 - mean_absolute_error: 21.7596\n",
      "Epoch 104: val_loss improved from 2086.19580 to 2051.66382, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 854.4047 - mean_absolute_error: 18.3088 - val_loss: 2051.6638 - val_mean_absolute_error: 37.7774\n",
      "Epoch 105/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 911.0548 - mean_absolute_error: 17.5118\n",
      "Epoch 105: val_loss improved from 2051.66382 to 2019.12756, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839.5275 - mean_absolute_error: 17.9571 - val_loss: 2019.1276 - val_mean_absolute_error: 37.4455\n",
      "Epoch 106/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 732.1140 - mean_absolute_error: 15.7608\n",
      "Epoch 106: val_loss improved from 2019.12756 to 1986.08154, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 815.1273 - mean_absolute_error: 17.6470 - val_loss: 1986.0815 - val_mean_absolute_error: 37.1045\n",
      "Epoch 107/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1162.9139 - mean_absolute_error: 22.9835\n",
      "Epoch 107: val_loss improved from 1986.08154 to 1954.36255, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 823.0457 - mean_absolute_error: 18.1582 - val_loss: 1954.3625 - val_mean_absolute_error: 36.7783\n",
      "Epoch 108/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1134.9988 - mean_absolute_error: 21.1154\n",
      "Epoch 108: val_loss improved from 1954.36255 to 1922.91821, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 840.2837 - mean_absolute_error: 17.9340 - val_loss: 1922.9182 - val_mean_absolute_error: 36.4482\n",
      "Epoch 109/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 902.9865 - mean_absolute_error: 20.8419\n",
      "Epoch 109: val_loss improved from 1922.91821 to 1890.92041, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 746.3343 - mean_absolute_error: 17.0219 - val_loss: 1890.9204 - val_mean_absolute_error: 36.0953\n",
      "Epoch 110/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1331.8208 - mean_absolute_error: 23.4724\n",
      "Epoch 110: val_loss improved from 1890.92041 to 1859.91736, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 793.6102 - mean_absolute_error: 17.1614 - val_loss: 1859.9174 - val_mean_absolute_error: 35.7588\n",
      "Epoch 111/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 721.4062 - mean_absolute_error: 18.2790\n",
      "Epoch 111: val_loss improved from 1859.91736 to 1829.82739, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 771.7520 - mean_absolute_error: 17.0683 - val_loss: 1829.8274 - val_mean_absolute_error: 35.4507\n",
      "Epoch 112/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 499.6837 - mean_absolute_error: 15.6869\n",
      "Epoch 112: val_loss improved from 1829.82739 to 1801.61743, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 729.2557 - mean_absolute_error: 16.9354 - val_loss: 1801.6174 - val_mean_absolute_error: 35.1493\n",
      "Epoch 113/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 340.1595 - mean_absolute_error: 14.1591\n",
      "Epoch 113: val_loss improved from 1801.61743 to 1770.47424, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 718.5965 - mean_absolute_error: 17.1200 - val_loss: 1770.4742 - val_mean_absolute_error: 34.8296\n",
      "Epoch 114/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 650.4354 - mean_absolute_error: 16.8754\n",
      "Epoch 114: val_loss improved from 1770.47424 to 1741.09375, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 772.2490 - mean_absolute_error: 17.4733 - val_loss: 1741.0938 - val_mean_absolute_error: 34.5206\n",
      "Epoch 115/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 836.3839 - mean_absolute_error: 18.6248\n",
      "Epoch 115: val_loss improved from 1741.09375 to 1713.23987, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 725.7175 - mean_absolute_error: 16.6026 - val_loss: 1713.2399 - val_mean_absolute_error: 34.2228\n",
      "Epoch 116/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 517.1847 - mean_absolute_error: 14.5370\n",
      "Epoch 116: val_loss improved from 1713.23987 to 1684.68286, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 775.2842 - mean_absolute_error: 16.9969 - val_loss: 1684.6829 - val_mean_absolute_error: 33.9280\n",
      "Epoch 117/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 716.1616 - mean_absolute_error: 14.7465\n",
      "Epoch 117: val_loss improved from 1684.68286 to 1657.61279, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 710.0675 - mean_absolute_error: 15.8219 - val_loss: 1657.6128 - val_mean_absolute_error: 33.6231\n",
      "Epoch 118/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 803.8591 - mean_absolute_error: 16.1697\n",
      "Epoch 118: val_loss improved from 1657.61279 to 1632.44507, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 677.9406 - mean_absolute_error: 16.0005 - val_loss: 1632.4451 - val_mean_absolute_error: 33.3420\n",
      "Epoch 119/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 857.2269 - mean_absolute_error: 19.7615\n",
      "Epoch 119: val_loss improved from 1632.44507 to 1604.56787, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 735.1389 - mean_absolute_error: 16.6911 - val_loss: 1604.5679 - val_mean_absolute_error: 33.0377\n",
      "Epoch 120/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 373.6952 - mean_absolute_error: 12.0556\n",
      "Epoch 120: val_loss improved from 1604.56787 to 1578.16223, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 672.7459 - mean_absolute_error: 16.1283 - val_loss: 1578.1622 - val_mean_absolute_error: 32.7336\n",
      "Epoch 121/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 528.7219 - mean_absolute_error: 13.8641\n",
      "Epoch 121: val_loss improved from 1578.16223 to 1553.60608, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 668.4989 - mean_absolute_error: 15.7302 - val_loss: 1553.6061 - val_mean_absolute_error: 32.4547\n",
      "Epoch 122/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 787.2079 - mean_absolute_error: 17.8606\n",
      "Epoch 122: val_loss improved from 1553.60608 to 1527.23462, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 660.1749 - mean_absolute_error: 15.7739 - val_loss: 1527.2346 - val_mean_absolute_error: 32.1545\n",
      "Epoch 123/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 554.9792 - mean_absolute_error: 14.9096 \n",
      "Epoch 123: val_loss improved from 1527.23462 to 1506.03296, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 560.9623 - mean_absolute_error: 14.9637 - val_loss: 1506.0330 - val_mean_absolute_error: 31.8999\n",
      "Epoch 124/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 345.0752 - mean_absolute_error: 12.3834\n",
      "Epoch 124: val_loss improved from 1506.03296 to 1479.20569, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 667.2347 - mean_absolute_error: 15.9706 - val_loss: 1479.2057 - val_mean_absolute_error: 31.5737\n",
      "Epoch 125/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1649.4309 - mean_absolute_error: 25.0122\n",
      "Epoch 125: val_loss improved from 1479.20569 to 1458.07898, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 680.7349 - mean_absolute_error: 16.1516 - val_loss: 1458.0790 - val_mean_absolute_error: 31.3170\n",
      "Epoch 126/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 632.2897 - mean_absolute_error: 14.8129\n",
      "Epoch 126: val_loss improved from 1458.07898 to 1433.86670, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 639.9995 - mean_absolute_error: 15.7472 - val_loss: 1433.8667 - val_mean_absolute_error: 31.0264\n",
      "Epoch 127/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 490.0711 - mean_absolute_error: 14.4385\n",
      "Epoch 127: val_loss improved from 1433.86670 to 1410.52197, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 678.6161 - mean_absolute_error: 15.9084 - val_loss: 1410.5220 - val_mean_absolute_error: 30.7382\n",
      "Epoch 128/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 526.7622 - mean_absolute_error: 14.9286\n",
      "Epoch 128: val_loss improved from 1410.52197 to 1389.85449, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 595.9340 - mean_absolute_error: 15.3211 - val_loss: 1389.8545 - val_mean_absolute_error: 30.4720\n",
      "Epoch 129/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 534.1146 - mean_absolute_error: 14.7075\n",
      "Epoch 129: val_loss improved from 1389.85449 to 1365.74939, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 641.8460 - mean_absolute_error: 15.9066 - val_loss: 1365.7494 - val_mean_absolute_error: 30.1811\n",
      "Epoch 130/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 598.9178 - mean_absolute_error: 15.3998\n",
      "Epoch 130: val_loss improved from 1365.74939 to 1345.65796, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 568.5222 - mean_absolute_error: 15.1799 - val_loss: 1345.6580 - val_mean_absolute_error: 29.9158\n",
      "Epoch 131/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 896.3751 - mean_absolute_error: 16.6568\n",
      "Epoch 131: val_loss improved from 1345.65796 to 1323.06140, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 676.9387 - mean_absolute_error: 15.6980 - val_loss: 1323.0614 - val_mean_absolute_error: 29.6237\n",
      "Epoch 132/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 771.9005 - mean_absolute_error: 17.5076\n",
      "Epoch 132: val_loss improved from 1323.06140 to 1303.34485, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 606.1686 - mean_absolute_error: 15.2859 - val_loss: 1303.3448 - val_mean_absolute_error: 29.3661\n",
      "Epoch 133/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 300.7283 - mean_absolute_error: 10.1225\n",
      "Epoch 133: val_loss improved from 1303.34485 to 1283.27893, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 495.8078 - mean_absolute_error: 13.9686 - val_loss: 1283.2789 - val_mean_absolute_error: 29.1034\n",
      "Epoch 134/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 910.8638 - mean_absolute_error: 17.6824\n",
      "Epoch 134: val_loss improved from 1283.27893 to 1263.96802, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.8479 - mean_absolute_error: 15.0350 - val_loss: 1263.9680 - val_mean_absolute_error: 28.8386\n",
      "Epoch 135/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1292.4655 - mean_absolute_error: 21.4772\n",
      "Epoch 135: val_loss improved from 1263.96802 to 1242.83875, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 657.5021 - mean_absolute_error: 15.7572 - val_loss: 1242.8387 - val_mean_absolute_error: 28.5815\n",
      "Epoch 136/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 806.2598 - mean_absolute_error: 18.1159\n",
      "Epoch 136: val_loss improved from 1242.83875 to 1224.35327, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 607.6808 - mean_absolute_error: 15.1051 - val_loss: 1224.3533 - val_mean_absolute_error: 28.3685\n",
      "Epoch 137/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 513.3121 - mean_absolute_error: 14.1365\n",
      "Epoch 137: val_loss improved from 1224.35327 to 1206.07788, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 534.9980 - mean_absolute_error: 14.4155 - val_loss: 1206.0779 - val_mean_absolute_error: 28.1380\n",
      "Epoch 138/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 910.6902 - mean_absolute_error: 20.4699\n",
      "Epoch 138: val_loss improved from 1206.07788 to 1188.73022, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 565.0737 - mean_absolute_error: 14.8021 - val_loss: 1188.7302 - val_mean_absolute_error: 27.9065\n",
      "Epoch 139/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 506.7035 - mean_absolute_error: 14.2652\n",
      "Epoch 139: val_loss improved from 1188.73022 to 1171.64978, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 572.8970 - mean_absolute_error: 14.7232 - val_loss: 1171.6498 - val_mean_absolute_error: 27.6842\n",
      "Epoch 140/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 626.7126 - mean_absolute_error: 14.5051\n",
      "Epoch 140: val_loss improved from 1171.64978 to 1153.86609, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.8594 - mean_absolute_error: 13.9217 - val_loss: 1153.8661 - val_mean_absolute_error: 27.4674\n",
      "Epoch 141/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 771.1840 - mean_absolute_error: 14.5768\n",
      "Epoch 141: val_loss improved from 1153.86609 to 1134.19238, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 555.6114 - mean_absolute_error: 14.3758 - val_loss: 1134.1924 - val_mean_absolute_error: 27.2430\n",
      "Epoch 142/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 860.3171 - mean_absolute_error: 18.8453\n",
      "Epoch 142: val_loss improved from 1134.19238 to 1121.09131, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540.6941 - mean_absolute_error: 14.6063 - val_loss: 1121.0913 - val_mean_absolute_error: 27.0221\n",
      "Epoch 143/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 363.0324 - mean_absolute_error: 11.5775\n",
      "Epoch 143: val_loss improved from 1121.09131 to 1104.49060, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 482.0226 - mean_absolute_error: 13.6414 - val_loss: 1104.4906 - val_mean_absolute_error: 26.8060\n",
      "Epoch 144/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1107.7422 - mean_absolute_error: 19.0963\n",
      "Epoch 144: val_loss improved from 1104.49060 to 1088.06714, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 552.3754 - mean_absolute_error: 14.4799 - val_loss: 1088.0671 - val_mean_absolute_error: 26.5871\n",
      "Epoch 145/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 300.5284 - mean_absolute_error: 12.2573\n",
      "Epoch 145: val_loss improved from 1088.06714 to 1070.19812, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 478.6198 - mean_absolute_error: 13.7256 - val_loss: 1070.1981 - val_mean_absolute_error: 26.3504\n",
      "Epoch 146/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 318.5385 - mean_absolute_error: 13.1888\n",
      "Epoch 146: val_loss improved from 1070.19812 to 1055.42358, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 535.8330 - mean_absolute_error: 14.5789 - val_loss: 1055.4236 - val_mean_absolute_error: 26.1368\n",
      "Epoch 147/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 114.1576 - mean_absolute_error: 7.9419\n",
      "Epoch 147: val_loss improved from 1055.42358 to 1042.40125, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.6393 - mean_absolute_error: 13.7548 - val_loss: 1042.4012 - val_mean_absolute_error: 25.9390\n",
      "Epoch 148/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1034.2278 - mean_absolute_error: 22.0020\n",
      "Epoch 148: val_loss improved from 1042.40125 to 1026.67859, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 522.7427 - mean_absolute_error: 14.4167 - val_loss: 1026.6786 - val_mean_absolute_error: 25.7227\n",
      "Epoch 149/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 305.4412 - mean_absolute_error: 10.9108\n",
      "Epoch 149: val_loss improved from 1026.67859 to 1013.65393, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.4449 - mean_absolute_error: 13.0325 - val_loss: 1013.6539 - val_mean_absolute_error: 25.5339\n",
      "Epoch 150/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 997.5754 - mean_absolute_error: 17.1819\n",
      "Epoch 150: val_loss improved from 1013.65393 to 996.29718, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499.3418 - mean_absolute_error: 13.6893 - val_loss: 996.2972 - val_mean_absolute_error: 25.3063\n",
      "Epoch 151/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 841.1151 - mean_absolute_error: 15.7993\n",
      "Epoch 151: val_loss improved from 996.29718 to 987.82849, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.2639 - mean_absolute_error: 13.2616 - val_loss: 987.8285 - val_mean_absolute_error: 25.1685\n",
      "Epoch 152/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 260.3015 - mean_absolute_error: 11.6612\n",
      "Epoch 152: val_loss improved from 987.82849 to 971.38831, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.7623 - mean_absolute_error: 13.2454 - val_loss: 971.3883 - val_mean_absolute_error: 24.9384\n",
      "Epoch 153/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 142.5105 - mean_absolute_error: 8.5452\n",
      "Epoch 153: val_loss improved from 971.38831 to 956.61133, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.1192 - mean_absolute_error: 12.7683 - val_loss: 956.6113 - val_mean_absolute_error: 24.7356\n",
      "Epoch 154/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 353.2792 - mean_absolute_error: 11.4599\n",
      "Epoch 154: val_loss improved from 956.61133 to 946.73230, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.4525 - mean_absolute_error: 12.9538 - val_loss: 946.7323 - val_mean_absolute_error: 24.5758\n",
      "Epoch 155/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 735.1633 - mean_absolute_error: 14.1183\n",
      "Epoch 155: val_loss improved from 946.73230 to 933.78619, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.1934 - mean_absolute_error: 13.2425 - val_loss: 933.7862 - val_mean_absolute_error: 24.3975\n",
      "Epoch 156/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 923.0962 - mean_absolute_error: 17.2998\n",
      "Epoch 156: val_loss improved from 933.78619 to 922.34491, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 467.8159 - mean_absolute_error: 13.5744 - val_loss: 922.3449 - val_mean_absolute_error: 24.2279\n",
      "Epoch 157/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 147.7769 - mean_absolute_error: 9.0251\n",
      "Epoch 157: val_loss improved from 922.34491 to 909.82220, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 418.3047 - mean_absolute_error: 13.0883 - val_loss: 909.8222 - val_mean_absolute_error: 24.0486\n",
      "Epoch 158/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 320.1431 - mean_absolute_error: 11.9293\n",
      "Epoch 158: val_loss improved from 909.82220 to 898.20929, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.6749 - mean_absolute_error: 12.7431 - val_loss: 898.2093 - val_mean_absolute_error: 23.8809\n",
      "Epoch 159/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 352.4908 - mean_absolute_error: 11.8579\n",
      "Epoch 159: val_loss improved from 898.20929 to 887.62628, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.6388 - mean_absolute_error: 12.9370 - val_loss: 887.6263 - val_mean_absolute_error: 23.7253\n",
      "Epoch 160/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 88.9697 - mean_absolute_error: 7.1961\n",
      "Epoch 160: val_loss improved from 887.62628 to 876.81000, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412.7527 - mean_absolute_error: 12.6878 - val_loss: 876.8100 - val_mean_absolute_error: 23.5618\n",
      "Epoch 161/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 335.3914 - mean_absolute_error: 12.2167\n",
      "Epoch 161: val_loss improved from 876.81000 to 865.64673, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 393.5136 - mean_absolute_error: 12.4760 - val_loss: 865.6467 - val_mean_absolute_error: 23.3950\n",
      "Epoch 162/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 352.0551 - mean_absolute_error: 11.8577\n",
      "Epoch 162: val_loss improved from 865.64673 to 855.32080, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 414.1769 - mean_absolute_error: 12.6212 - val_loss: 855.3208 - val_mean_absolute_error: 23.2354\n",
      "Epoch 163/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 453.2361 - mean_absolute_error: 11.9396\n",
      "Epoch 163: val_loss improved from 855.32080 to 843.89148, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.9197 - mean_absolute_error: 12.5971 - val_loss: 843.8915 - val_mean_absolute_error: 23.0488\n",
      "Epoch 164/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 313.6147 - mean_absolute_error: 11.4534\n",
      "Epoch 164: val_loss improved from 843.89148 to 833.77380, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 399.9072 - mean_absolute_error: 12.5660 - val_loss: 833.7738 - val_mean_absolute_error: 22.8866\n",
      "Epoch 165/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 250.2803 - mean_absolute_error: 10.7021\n",
      "Epoch 165: val_loss improved from 833.77380 to 825.88629, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 370.6071 - mean_absolute_error: 12.4080 - val_loss: 825.8863 - val_mean_absolute_error: 22.7768\n",
      "Epoch 166/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 197.2682 - mean_absolute_error: 9.7957\n",
      "Epoch 166: val_loss improved from 825.88629 to 815.79382, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.9784 - mean_absolute_error: 12.1983 - val_loss: 815.7938 - val_mean_absolute_error: 22.5935\n",
      "Epoch 167/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 101.4166 - mean_absolute_error: 6.7198\n",
      "Epoch 167: val_loss improved from 815.79382 to 809.42157, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 336.2495 - mean_absolute_error: 11.7042 - val_loss: 809.4216 - val_mean_absolute_error: 22.5004\n",
      "Epoch 168/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 192.2351 - mean_absolute_error: 8.9387\n",
      "Epoch 168: val_loss improved from 809.42157 to 798.16937, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 338.0675 - mean_absolute_error: 11.6994 - val_loss: 798.1694 - val_mean_absolute_error: 22.3038\n",
      "Epoch 169/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 828.3737 - mean_absolute_error: 19.9227\n",
      "Epoch 169: val_loss improved from 798.16937 to 793.03979, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.1388 - mean_absolute_error: 13.4603 - val_loss: 793.0398 - val_mean_absolute_error: 22.2374\n",
      "Epoch 170/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 225.5753 - mean_absolute_error: 9.1876\n",
      "Epoch 170: val_loss improved from 793.03979 to 779.11792, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.1262 - mean_absolute_error: 13.2592 - val_loss: 779.1179 - val_mean_absolute_error: 21.9742\n",
      "Epoch 171/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 418.2076 - mean_absolute_error: 12.8504\n",
      "Epoch 171: val_loss improved from 779.11792 to 771.71954, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.0940 - mean_absolute_error: 12.3693 - val_loss: 771.7195 - val_mean_absolute_error: 21.8621\n",
      "Epoch 172/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 300.6931 - mean_absolute_error: 11.6901\n",
      "Epoch 172: val_loss improved from 771.71954 to 764.53479, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.2989 - mean_absolute_error: 12.6865 - val_loss: 764.5348 - val_mean_absolute_error: 21.7411\n",
      "Epoch 173/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 388.1232 - mean_absolute_error: 12.0276\n",
      "Epoch 173: val_loss improved from 764.53479 to 757.52435, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.2291 - mean_absolute_error: 12.2607 - val_loss: 757.5244 - val_mean_absolute_error: 21.6066\n",
      "Epoch 174/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 285.3668 - mean_absolute_error: 10.1859\n",
      "Epoch 174: val_loss improved from 757.52435 to 747.95557, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.6314 - mean_absolute_error: 12.2123 - val_loss: 747.9556 - val_mean_absolute_error: 21.3974\n",
      "Epoch 175/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 331.4890 - mean_absolute_error: 11.5949\n",
      "Epoch 175: val_loss improved from 747.95557 to 738.34375, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.0826 - mean_absolute_error: 12.0582 - val_loss: 738.3438 - val_mean_absolute_error: 21.2438\n",
      "Epoch 176/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 468.6768 - mean_absolute_error: 16.5596\n",
      "Epoch 176: val_loss improved from 738.34375 to 731.43994, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.8909 - mean_absolute_error: 12.2138 - val_loss: 731.4399 - val_mean_absolute_error: 21.1087\n",
      "Epoch 177/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 933.2313 - mean_absolute_error: 19.0953\n",
      "Epoch 177: val_loss improved from 731.43994 to 725.72601, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 391.1089 - mean_absolute_error: 12.5154 - val_loss: 725.7260 - val_mean_absolute_error: 21.0183\n",
      "Epoch 178/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 271.9870 - mean_absolute_error: 11.5958\n",
      "Epoch 178: val_loss improved from 725.72601 to 720.25104, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 319.6584 - mean_absolute_error: 11.9200 - val_loss: 720.2510 - val_mean_absolute_error: 20.9160\n",
      "Epoch 179/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 294.6450 - mean_absolute_error: 12.6136\n",
      "Epoch 179: val_loss improved from 720.25104 to 711.15924, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.4072 - mean_absolute_error: 12.0592 - val_loss: 711.1592 - val_mean_absolute_error: 20.7246\n",
      "Epoch 180/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 309.6577 - mean_absolute_error: 12.0195\n",
      "Epoch 180: val_loss improved from 711.15924 to 703.29456, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.8808 - mean_absolute_error: 12.3346 - val_loss: 703.2946 - val_mean_absolute_error: 20.5488\n",
      "Epoch 181/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 343.2061 - mean_absolute_error: 11.8007\n",
      "Epoch 181: val_loss improved from 703.29456 to 698.86456, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 348.7535 - mean_absolute_error: 12.0118 - val_loss: 698.8646 - val_mean_absolute_error: 20.4951\n",
      "Epoch 182/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 460.4024 - mean_absolute_error: 13.7254\n",
      "Epoch 182: val_loss improved from 698.86456 to 690.73834, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 331.5949 - mean_absolute_error: 11.7429 - val_loss: 690.7383 - val_mean_absolute_error: 20.2934\n",
      "Epoch 183/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 259.2991 - mean_absolute_error: 10.7866\n",
      "Epoch 183: val_loss improved from 690.73834 to 689.19305, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.3233 - mean_absolute_error: 11.6289 - val_loss: 689.1931 - val_mean_absolute_error: 20.3418\n",
      "Epoch 184/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 227.7634 - mean_absolute_error: 10.8852\n",
      "Epoch 184: val_loss improved from 689.19305 to 678.17224, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.2956 - mean_absolute_error: 12.4372 - val_loss: 678.1722 - val_mean_absolute_error: 20.0350\n",
      "Epoch 185/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 301.0955 - mean_absolute_error: 10.0613\n",
      "Epoch 185: val_loss improved from 678.17224 to 675.46185, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.9761 - mean_absolute_error: 11.4713 - val_loss: 675.4619 - val_mean_absolute_error: 20.0218\n",
      "Epoch 186/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 860.8442 - mean_absolute_error: 19.8383\n",
      "Epoch 186: val_loss improved from 675.46185 to 665.78711, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 369.5338 - mean_absolute_error: 12.7099 - val_loss: 665.7871 - val_mean_absolute_error: 19.7842\n",
      "Epoch 187/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 694.9900 - mean_absolute_error: 15.2515\n",
      "Epoch 187: val_loss improved from 665.78711 to 661.46826, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.7545 - mean_absolute_error: 12.1358 - val_loss: 661.4683 - val_mean_absolute_error: 19.6847\n",
      "Epoch 188/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 179.1070 - mean_absolute_error: 9.4411\n",
      "Epoch 188: val_loss improved from 661.46826 to 656.79053, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.6421 - mean_absolute_error: 11.1249 - val_loss: 656.7905 - val_mean_absolute_error: 19.6100\n",
      "Epoch 189/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 318.6078 - mean_absolute_error: 11.1499\n",
      "Epoch 189: val_loss improved from 656.79053 to 648.34308, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 305.6797 - mean_absolute_error: 11.2405 - val_loss: 648.3431 - val_mean_absolute_error: 19.3902\n",
      "Epoch 190/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 155.1007 - mean_absolute_error: 7.1339\n",
      "Epoch 190: val_loss improved from 648.34308 to 646.08319, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 300.7845 - mean_absolute_error: 11.0481 - val_loss: 646.0832 - val_mean_absolute_error: 19.3903\n",
      "Epoch 191/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 686.2073 - mean_absolute_error: 18.3275\n",
      "Epoch 191: val_loss improved from 646.08319 to 639.91327, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 340.3584 - mean_absolute_error: 12.2910 - val_loss: 639.9133 - val_mean_absolute_error: 19.2234\n",
      "Epoch 192/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 282.6669 - mean_absolute_error: 11.7194\n",
      "Epoch 192: val_loss improved from 639.91327 to 635.10040, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 318.1195 - mean_absolute_error: 11.8658 - val_loss: 635.1004 - val_mean_absolute_error: 19.1243\n",
      "Epoch 193/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 284.7910 - mean_absolute_error: 10.8761\n",
      "Epoch 193: val_loss improved from 635.10040 to 628.87885, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 331.4745 - mean_absolute_error: 11.7204 - val_loss: 628.8788 - val_mean_absolute_error: 18.9798\n",
      "Epoch 194/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 327.7258 - mean_absolute_error: 11.7166\n",
      "Epoch 194: val_loss improved from 628.87885 to 624.39075, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 326.6903 - mean_absolute_error: 11.7022 - val_loss: 624.3907 - val_mean_absolute_error: 18.9113\n",
      "Epoch 195/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 191.0069 - mean_absolute_error: 9.8278\n",
      "Epoch 195: val_loss improved from 624.39075 to 615.80048, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 306.2159 - mean_absolute_error: 11.4063 - val_loss: 615.8005 - val_mean_absolute_error: 18.5976\n",
      "Epoch 196/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 228.5368 - mean_absolute_error: 11.3754\n",
      "Epoch 196: val_loss did not improve from 615.80048\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.6263 - mean_absolute_error: 11.6725 - val_loss: 616.2930 - val_mean_absolute_error: 18.6646\n",
      "Epoch 197/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 254.4561 - mean_absolute_error: 10.5836\n",
      "Epoch 197: val_loss improved from 615.80048 to 610.22253, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 255.8966 - mean_absolute_error: 10.6069 - val_loss: 610.2225 - val_mean_absolute_error: 18.5434\n",
      "Epoch 198/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 302.1519 - mean_absolute_error: 11.7115\n",
      "Epoch 198: val_loss improved from 610.22253 to 605.83563, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 334.8433 - mean_absolute_error: 12.1213 - val_loss: 605.8356 - val_mean_absolute_error: 18.4230\n",
      "Epoch 199/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 560.8823 - mean_absolute_error: 16.0671\n",
      "Epoch 199: val_loss improved from 605.83563 to 601.29242, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 318.0639 - mean_absolute_error: 11.6328 - val_loss: 601.2924 - val_mean_absolute_error: 18.3201\n",
      "Epoch 200/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 199.2592 - mean_absolute_error: 10.0739\n",
      "Epoch 200: val_loss improved from 601.29242 to 599.43256, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271.9101 - mean_absolute_error: 10.7468 - val_loss: 599.4326 - val_mean_absolute_error: 18.2839\n",
      "Epoch 201/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 342.1041 - mean_absolute_error: 14.7028\n",
      "Epoch 201: val_loss improved from 599.43256 to 596.10663, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 265.2488 - mean_absolute_error: 10.8794 - val_loss: 596.1066 - val_mean_absolute_error: 18.2348\n",
      "Epoch 202/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 245.0243 - mean_absolute_error: 10.7294\n",
      "Epoch 202: val_loss improved from 596.10663 to 589.48022, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 268.2003 - mean_absolute_error: 10.8594 - val_loss: 589.4802 - val_mean_absolute_error: 18.0335\n",
      "Epoch 203/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 431.6233 - mean_absolute_error: 14.5067\n",
      "Epoch 203: val_loss improved from 589.48022 to 586.53699, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.7029 - mean_absolute_error: 12.1531 - val_loss: 586.5370 - val_mean_absolute_error: 18.0024\n",
      "Epoch 204/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 284.3571 - mean_absolute_error: 10.5974\n",
      "Epoch 204: val_loss improved from 586.53699 to 580.38037, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.3474 - mean_absolute_error: 11.0286 - val_loss: 580.3804 - val_mean_absolute_error: 17.8439\n",
      "Epoch 205/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 390.5671 - mean_absolute_error: 13.3300\n",
      "Epoch 205: val_loss improved from 580.38037 to 578.41254, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 301.6125 - mean_absolute_error: 11.4936 - val_loss: 578.4125 - val_mean_absolute_error: 17.8113\n",
      "Epoch 206/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 371.2863 - mean_absolute_error: 11.2590\n",
      "Epoch 206: val_loss improved from 578.41254 to 577.19958, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 290.8321 - mean_absolute_error: 10.8265 - val_loss: 577.1996 - val_mean_absolute_error: 17.8288\n",
      "Epoch 207/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 362.6269 - mean_absolute_error: 12.2943\n",
      "Epoch 207: val_loss improved from 577.19958 to 570.20325, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 281.8360 - mean_absolute_error: 11.1572 - val_loss: 570.2032 - val_mean_absolute_error: 17.6440\n",
      "Epoch 208/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 311.8750 - mean_absolute_error: 12.5340\n",
      "Epoch 208: val_loss improved from 570.20325 to 567.90845, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 270.3922 - mean_absolute_error: 11.0005 - val_loss: 567.9084 - val_mean_absolute_error: 17.6008\n",
      "Epoch 209/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 344.2803 - mean_absolute_error: 12.6175\n",
      "Epoch 209: val_loss improved from 567.90845 to 562.02661, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.4504 - mean_absolute_error: 11.1469 - val_loss: 562.0266 - val_mean_absolute_error: 17.4866\n",
      "Epoch 210/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 216.9963 - mean_absolute_error: 10.0184\n",
      "Epoch 210: val_loss improved from 562.02661 to 561.77429, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 301.2851 - mean_absolute_error: 11.1681 - val_loss: 561.7743 - val_mean_absolute_error: 17.5052\n",
      "Epoch 211/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 257.7148 - mean_absolute_error: 11.9387\n",
      "Epoch 211: val_loss improved from 561.77429 to 556.73804, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.6484 - mean_absolute_error: 11.1199 - val_loss: 556.7380 - val_mean_absolute_error: 17.3890\n",
      "Epoch 212/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 201.1878 - mean_absolute_error: 8.8948\n",
      "Epoch 212: val_loss did not improve from 556.73804\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.8809 - mean_absolute_error: 10.9505 - val_loss: 557.4284 - val_mean_absolute_error: 17.4159\n",
      "Epoch 213/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 184.0142 - mean_absolute_error: 9.6077\n",
      "Epoch 213: val_loss improved from 556.73804 to 550.49042, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 250.4439 - mean_absolute_error: 10.6287 - val_loss: 550.4904 - val_mean_absolute_error: 17.2878\n",
      "Epoch 214/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 209.1192 - mean_absolute_error: 8.2191\n",
      "Epoch 214: val_loss improved from 550.49042 to 547.19098, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 279.6318 - mean_absolute_error: 10.9665 - val_loss: 547.1910 - val_mean_absolute_error: 17.2271\n",
      "Epoch 215/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 259.7097 - mean_absolute_error: 11.0174\n",
      "Epoch 215: val_loss did not improve from 547.19098\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.1690 - mean_absolute_error: 10.8255 - val_loss: 547.6061 - val_mean_absolute_error: 17.2362\n",
      "Epoch 216/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 307.9898 - mean_absolute_error: 12.1989\n",
      "Epoch 216: val_loss improved from 547.19098 to 542.47632, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 277.3719 - mean_absolute_error: 10.8213 - val_loss: 542.4763 - val_mean_absolute_error: 17.1618\n",
      "Epoch 217/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 212.9936 - mean_absolute_error: 10.7357\n",
      "Epoch 217: val_loss improved from 542.47632 to 536.51477, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 253.6632 - mean_absolute_error: 10.5328 - val_loss: 536.5148 - val_mean_absolute_error: 17.0748\n",
      "Epoch 218/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 256.8524 - mean_absolute_error: 12.1486\n",
      "Epoch 218: val_loss improved from 536.51477 to 536.49060, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 260.0553 - mean_absolute_error: 10.8893 - val_loss: 536.4906 - val_mean_absolute_error: 17.0648\n",
      "Epoch 219/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 490.4356 - mean_absolute_error: 15.1873\n",
      "Epoch 219: val_loss improved from 536.49060 to 535.39111, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.4364 - mean_absolute_error: 10.9462 - val_loss: 535.3911 - val_mean_absolute_error: 17.0504\n",
      "Epoch 220/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 290.5446 - mean_absolute_error: 12.1997\n",
      "Epoch 220: val_loss improved from 535.39111 to 530.92767, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.5846 - mean_absolute_error: 10.6286 - val_loss: 530.9277 - val_mean_absolute_error: 16.9899\n",
      "Epoch 221/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 174.8962 - mean_absolute_error: 8.6434\n",
      "Epoch 221: val_loss improved from 530.92767 to 526.84900, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 249.5792 - mean_absolute_error: 10.4831 - val_loss: 526.8490 - val_mean_absolute_error: 16.9229\n",
      "Epoch 222/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 175.0219 - mean_absolute_error: 8.4546\n",
      "Epoch 222: val_loss did not improve from 526.84900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.0642 - mean_absolute_error: 10.0155 - val_loss: 530.4075 - val_mean_absolute_error: 16.9768\n",
      "Epoch 223/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 434.1007 - mean_absolute_error: 15.2996\n",
      "Epoch 223: val_loss improved from 526.84900 to 523.56586, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 260.3865 - mean_absolute_error: 10.8708 - val_loss: 523.5659 - val_mean_absolute_error: 16.8689\n",
      "Epoch 224/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 190.5414 - mean_absolute_error: 9.3297\n",
      "Epoch 224: val_loss did not improve from 523.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.5126 - mean_absolute_error: 10.8611 - val_loss: 525.8683 - val_mean_absolute_error: 16.9428\n",
      "Epoch 225/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 368.9447 - mean_absolute_error: 11.8924\n",
      "Epoch 225: val_loss improved from 523.56586 to 518.65112, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.5920 - mean_absolute_error: 10.1864 - val_loss: 518.6511 - val_mean_absolute_error: 16.7919\n",
      "Epoch 226/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 304.6600 - mean_absolute_error: 13.2646\n",
      "Epoch 226: val_loss improved from 518.65112 to 516.46460, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 265.7993 - mean_absolute_error: 10.9640 - val_loss: 516.4646 - val_mean_absolute_error: 16.7793\n",
      "Epoch 227/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 352.4620 - mean_absolute_error: 13.6301\n",
      "Epoch 227: val_loss improved from 516.46460 to 516.25592, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 254.6734 - mean_absolute_error: 10.7847 - val_loss: 516.2559 - val_mean_absolute_error: 16.7916\n",
      "Epoch 228/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 411.5004 - mean_absolute_error: 10.9666\n",
      "Epoch 228: val_loss improved from 516.25592 to 513.36267, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 265.2527 - mean_absolute_error: 10.6010 - val_loss: 513.3627 - val_mean_absolute_error: 16.7046\n",
      "Epoch 229/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 98.0133 - mean_absolute_error: 7.5258\n",
      "Epoch 229: val_loss improved from 513.36267 to 512.33368, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.5547 - mean_absolute_error: 10.3807 - val_loss: 512.3337 - val_mean_absolute_error: 16.6992\n",
      "Epoch 230/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 305.2021 - mean_absolute_error: 11.6250\n",
      "Epoch 230: val_loss improved from 512.33368 to 507.52652, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 260.5469 - mean_absolute_error: 10.7655 - val_loss: 507.5265 - val_mean_absolute_error: 16.6407\n",
      "Epoch 231/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 385.1681 - mean_absolute_error: 12.9905\n",
      "Epoch 231: val_loss improved from 507.52652 to 506.74115, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 284.6644 - mean_absolute_error: 11.3724 - val_loss: 506.7411 - val_mean_absolute_error: 16.6321\n",
      "Epoch 232/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 322.1167 - mean_absolute_error: 13.4403\n",
      "Epoch 232: val_loss improved from 506.74115 to 504.83884, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.4110 - mean_absolute_error: 11.2176 - val_loss: 504.8388 - val_mean_absolute_error: 16.6075\n",
      "Epoch 233/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 197.6623 - mean_absolute_error: 9.8000\n",
      "Epoch 233: val_loss improved from 504.83884 to 501.29532, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 253.6414 - mean_absolute_error: 10.3320 - val_loss: 501.2953 - val_mean_absolute_error: 16.5875\n",
      "Epoch 234/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 130.4506 - mean_absolute_error: 8.1260\n",
      "Epoch 234: val_loss improved from 501.29532 to 499.43088, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 237.2380 - mean_absolute_error: 10.2369 - val_loss: 499.4309 - val_mean_absolute_error: 16.5396\n",
      "Epoch 235/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 174.9081 - mean_absolute_error: 8.5964\n",
      "Epoch 235: val_loss improved from 499.43088 to 496.51636, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.4632 - mean_absolute_error: 10.2806 - val_loss: 496.5164 - val_mean_absolute_error: 16.5422\n",
      "Epoch 236/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 455.5149 - mean_absolute_error: 13.1668\n",
      "Epoch 236: val_loss did not improve from 496.51636\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.9925 - mean_absolute_error: 11.0966 - val_loss: 498.8496 - val_mean_absolute_error: 16.5589\n",
      "Epoch 237/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 197.7004 - mean_absolute_error: 9.0385\n",
      "Epoch 237: val_loss improved from 496.51636 to 495.44046, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.7332 - mean_absolute_error: 10.2309 - val_loss: 495.4405 - val_mean_absolute_error: 16.5127\n",
      "Epoch 238/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 93.3812 - mean_absolute_error: 7.1613\n",
      "Epoch 238: val_loss improved from 495.44046 to 492.69357, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 221.3346 - mean_absolute_error: 10.0876 - val_loss: 492.6936 - val_mean_absolute_error: 16.4745\n",
      "Epoch 239/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 173.4768 - mean_absolute_error: 8.5489\n",
      "Epoch 239: val_loss did not improve from 492.69357\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.9503 - mean_absolute_error: 10.0163 - val_loss: 494.9422 - val_mean_absolute_error: 16.5076\n",
      "Epoch 240/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 162.1630 - mean_absolute_error: 8.7436\n",
      "Epoch 240: val_loss improved from 492.69357 to 489.96637, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 259.2611 - mean_absolute_error: 10.6910 - val_loss: 489.9664 - val_mean_absolute_error: 16.4637\n",
      "Epoch 241/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 423.0011 - mean_absolute_error: 12.6982\n",
      "Epoch 241: val_loss did not improve from 489.96637\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.3238 - mean_absolute_error: 10.8280 - val_loss: 493.2129 - val_mean_absolute_error: 16.5108\n",
      "Epoch 242/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 149.4232 - mean_absolute_error: 8.7633\n",
      "Epoch 242: val_loss did not improve from 489.96637\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.6821 - mean_absolute_error: 10.7191 - val_loss: 490.0424 - val_mean_absolute_error: 16.4860\n",
      "Epoch 243/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 191.7895 - mean_absolute_error: 9.1521\n",
      "Epoch 243: val_loss improved from 489.96637 to 486.52975, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.9714 - mean_absolute_error: 10.0561 - val_loss: 486.5298 - val_mean_absolute_error: 16.4302\n",
      "Epoch 244/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 196.6350 - mean_absolute_error: 9.9774\n",
      "Epoch 244: val_loss improved from 486.52975 to 481.52664, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 224.1554 - mean_absolute_error: 9.9099 - val_loss: 481.5266 - val_mean_absolute_error: 16.3803\n",
      "Epoch 245/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 324.4662 - mean_absolute_error: 12.8513\n",
      "Epoch 245: val_loss did not improve from 481.52664\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.0125 - mean_absolute_error: 10.1294 - val_loss: 483.2183 - val_mean_absolute_error: 16.3932\n",
      "Epoch 246/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 240.4495 - mean_absolute_error: 9.9877\n",
      "Epoch 246: val_loss improved from 481.52664 to 480.45535, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.0548 - mean_absolute_error: 10.6422 - val_loss: 480.4554 - val_mean_absolute_error: 16.3650\n",
      "Epoch 247/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 377.7825 - mean_absolute_error: 14.7745\n",
      "Epoch 247: val_loss did not improve from 480.45535\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.9310 - mean_absolute_error: 10.5846 - val_loss: 482.0529 - val_mean_absolute_error: 16.3926\n",
      "Epoch 248/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 205.9778 - mean_absolute_error: 11.1226\n",
      "Epoch 248: val_loss improved from 480.45535 to 479.30432, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 241.1735 - mean_absolute_error: 10.3937 - val_loss: 479.3043 - val_mean_absolute_error: 16.3564\n",
      "Epoch 249/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 267.2337 - mean_absolute_error: 10.7401\n",
      "Epoch 249: val_loss improved from 479.30432 to 476.56293, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224.9084 - mean_absolute_error: 9.9678 - val_loss: 476.5629 - val_mean_absolute_error: 16.3194\n",
      "Epoch 250/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 360.6961 - mean_absolute_error: 13.3291\n",
      "Epoch 250: val_loss improved from 476.56293 to 475.73300, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 258.4127 - mean_absolute_error: 10.9300 - val_loss: 475.7330 - val_mean_absolute_error: 16.3264\n",
      "Epoch 251/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 237.3392 - mean_absolute_error: 10.8078\n",
      "Epoch 251: val_loss improved from 475.73300 to 473.49460, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 225.2691 - mean_absolute_error: 10.1697 - val_loss: 473.4946 - val_mean_absolute_error: 16.2850\n",
      "Epoch 252/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 143.3120 - mean_absolute_error: 8.7925\n",
      "Epoch 252: val_loss improved from 473.49460 to 471.07053, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 230.3074 - mean_absolute_error: 10.0889 - val_loss: 471.0705 - val_mean_absolute_error: 16.2634\n",
      "Epoch 253/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 354.1212 - mean_absolute_error: 13.1109\n",
      "Epoch 253: val_loss did not improve from 471.07053\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.7332 - mean_absolute_error: 10.4133 - val_loss: 474.9171 - val_mean_absolute_error: 16.3048\n",
      "Epoch 254/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 306.2560 - mean_absolute_error: 12.5966\n",
      "Epoch 254: val_loss did not improve from 471.07053\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.6221 - mean_absolute_error: 10.1182 - val_loss: 472.2245 - val_mean_absolute_error: 16.2706\n",
      "Epoch 255/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 195.0406 - mean_absolute_error: 8.5338\n",
      "Epoch 255: val_loss improved from 471.07053 to 469.04147, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 221.4421 - mean_absolute_error: 9.9858 - val_loss: 469.0415 - val_mean_absolute_error: 16.2534\n",
      "Epoch 256/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 351.5451 - mean_absolute_error: 12.5315\n",
      "Epoch 256: val_loss improved from 469.04147 to 467.76971, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 238.3921 - mean_absolute_error: 10.3614 - val_loss: 467.7697 - val_mean_absolute_error: 16.2343\n",
      "Epoch 257/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 152.2285 - mean_absolute_error: 9.4853\n",
      "Epoch 257: val_loss did not improve from 467.76971\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.2218 - mean_absolute_error: 10.7448 - val_loss: 470.2133 - val_mean_absolute_error: 16.2310\n",
      "Epoch 258/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 154.7995 - mean_absolute_error: 8.7610\n",
      "Epoch 258: val_loss improved from 467.76971 to 464.55432, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 222.8058 - mean_absolute_error: 10.1165 - val_loss: 464.5543 - val_mean_absolute_error: 16.1978\n",
      "Epoch 259/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 195.9413 - mean_absolute_error: 8.9606\n",
      "Epoch 259: val_loss improved from 464.55432 to 463.71817, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 217.7564 - mean_absolute_error: 9.8132 - val_loss: 463.7182 - val_mean_absolute_error: 16.1814\n",
      "Epoch 260/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 464.5698 - mean_absolute_error: 12.7158\n",
      "Epoch 260: val_loss did not improve from 463.71817\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.0631 - mean_absolute_error: 10.4102 - val_loss: 465.8660 - val_mean_absolute_error: 16.1948\n",
      "Epoch 261/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 151.3256 - mean_absolute_error: 9.3883\n",
      "Epoch 261: val_loss did not improve from 463.71817\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.3378 - mean_absolute_error: 9.7440 - val_loss: 463.8006 - val_mean_absolute_error: 16.1946\n",
      "Epoch 262/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 343.8917 - mean_absolute_error: 12.4415\n",
      "Epoch 262: val_loss improved from 463.71817 to 461.36411, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 218.7739 - mean_absolute_error: 10.0309 - val_loss: 461.3641 - val_mean_absolute_error: 16.1446\n",
      "Epoch 263/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 311.9163 - mean_absolute_error: 13.1499\n",
      "Epoch 263: val_loss did not improve from 461.36411\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.6717 - mean_absolute_error: 10.2772 - val_loss: 462.1077 - val_mean_absolute_error: 16.1589\n",
      "Epoch 264/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 199.8349 - mean_absolute_error: 10.1281\n",
      "Epoch 264: val_loss improved from 461.36411 to 460.39954, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 194.2158 - mean_absolute_error: 9.5663 - val_loss: 460.3995 - val_mean_absolute_error: 16.1594\n",
      "Epoch 265/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 226.6870 - mean_absolute_error: 9.6802\n",
      "Epoch 265: val_loss improved from 460.39954 to 459.55096, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 224.9598 - mean_absolute_error: 9.9436 - val_loss: 459.5510 - val_mean_absolute_error: 16.1503\n",
      "Epoch 266/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 383.0953 - mean_absolute_error: 13.0120\n",
      "Epoch 266: val_loss improved from 459.55096 to 457.13892, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 227.5892 - mean_absolute_error: 9.9884 - val_loss: 457.1389 - val_mean_absolute_error: 16.1043\n",
      "Epoch 267/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 281.1916 - mean_absolute_error: 10.8714\n",
      "Epoch 267: val_loss did not improve from 457.13892\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.8743 - mean_absolute_error: 10.0862 - val_loss: 457.3444 - val_mean_absolute_error: 16.1052\n",
      "Epoch 268/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 334.4854 - mean_absolute_error: 11.3119\n",
      "Epoch 268: val_loss improved from 457.13892 to 455.92917, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 249.2051 - mean_absolute_error: 10.4633 - val_loss: 455.9292 - val_mean_absolute_error: 16.0762\n",
      "Epoch 269/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 283.1696 - mean_absolute_error: 12.1377\n",
      "Epoch 269: val_loss did not improve from 455.92917\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.1506 - mean_absolute_error: 10.0084 - val_loss: 459.6601 - val_mean_absolute_error: 16.1234\n",
      "Epoch 270/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 187.4953 - mean_absolute_error: 9.6863\n",
      "Epoch 270: val_loss improved from 455.92917 to 454.86948, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 214.3133 - mean_absolute_error: 9.9666 - val_loss: 454.8695 - val_mean_absolute_error: 16.0716\n",
      "Epoch 271/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 230.9332 - mean_absolute_error: 9.2182\n",
      "Epoch 271: val_loss improved from 454.86948 to 454.78302, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 230.3975 - mean_absolute_error: 10.2429 - val_loss: 454.7830 - val_mean_absolute_error: 16.0584\n",
      "Epoch 272/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 367.0148 - mean_absolute_error: 13.6472\n",
      "Epoch 272: val_loss improved from 454.78302 to 453.47083, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.4767 - mean_absolute_error: 10.5932 - val_loss: 453.4708 - val_mean_absolute_error: 16.0655\n",
      "Epoch 273/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 182.0944 - mean_absolute_error: 10.4268\n",
      "Epoch 273: val_loss improved from 453.47083 to 451.40863, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 213.9579 - mean_absolute_error: 9.9850 - val_loss: 451.4086 - val_mean_absolute_error: 16.0251\n",
      "Epoch 274/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 251.8158 - mean_absolute_error: 9.5426\n",
      "Epoch 274: val_loss improved from 451.40863 to 449.39920, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 234.8083 - mean_absolute_error: 10.3559 - val_loss: 449.3992 - val_mean_absolute_error: 16.0105\n",
      "Epoch 275/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 172.8152 - mean_absolute_error: 9.7115\n",
      "Epoch 275: val_loss improved from 449.39920 to 448.87967, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.2979 - mean_absolute_error: 10.2700 - val_loss: 448.8797 - val_mean_absolute_error: 15.9773\n",
      "Epoch 276/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 239.5453 - mean_absolute_error: 9.2699\n",
      "Epoch 276: val_loss did not improve from 448.87967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.8477 - mean_absolute_error: 10.2968 - val_loss: 449.4857 - val_mean_absolute_error: 15.9935\n",
      "Epoch 277/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 95.4688 - mean_absolute_error: 6.7434\n",
      "Epoch 277: val_loss improved from 448.87967 to 447.78262, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.4133 - mean_absolute_error: 9.6731 - val_loss: 447.7826 - val_mean_absolute_error: 15.9657\n",
      "Epoch 278/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 348.5388 - mean_absolute_error: 12.9331\n",
      "Epoch 278: val_loss did not improve from 447.78262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227.8021 - mean_absolute_error: 9.9986 - val_loss: 448.3620 - val_mean_absolute_error: 15.9627\n",
      "Epoch 279/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.0646 - mean_absolute_error: 10.2078 \n",
      "Epoch 279: val_loss improved from 447.78262 to 446.12213, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 224.7754 - mean_absolute_error: 10.1956 - val_loss: 446.1221 - val_mean_absolute_error: 15.9541\n",
      "Epoch 280/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 155.1826 - mean_absolute_error: 7.9529\n",
      "Epoch 280: val_loss improved from 446.12213 to 445.90176, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 224.6182 - mean_absolute_error: 10.0647 - val_loss: 445.9018 - val_mean_absolute_error: 15.9596\n",
      "Epoch 281/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 263.8164 - mean_absolute_error: 12.5278\n",
      "Epoch 281: val_loss improved from 445.90176 to 445.56784, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 259.4222 - mean_absolute_error: 10.9649 - val_loss: 445.5678 - val_mean_absolute_error: 15.9337\n",
      "Epoch 282/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 297.2967 - mean_absolute_error: 11.2402\n",
      "Epoch 282: val_loss improved from 445.56784 to 444.58139, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.5802 - mean_absolute_error: 10.2877 - val_loss: 444.5814 - val_mean_absolute_error: 15.9387\n",
      "Epoch 283/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 254.3102 - mean_absolute_error: 10.2405\n",
      "Epoch 283: val_loss improved from 444.58139 to 444.11697, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 227.4130 - mean_absolute_error: 10.1890 - val_loss: 444.1170 - val_mean_absolute_error: 15.9279\n",
      "Epoch 284/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 320.5509 - mean_absolute_error: 13.2877\n",
      "Epoch 284: val_loss improved from 444.11697 to 443.02228, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.0719 - mean_absolute_error: 10.4596 - val_loss: 443.0223 - val_mean_absolute_error: 15.9220\n",
      "Epoch 285/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 166.1598 - mean_absolute_error: 9.6330\n",
      "Epoch 285: val_loss improved from 443.02228 to 442.79144, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 216.3116 - mean_absolute_error: 10.1189 - val_loss: 442.7914 - val_mean_absolute_error: 15.9372\n",
      "Epoch 286/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 102.3094 - mean_absolute_error: 7.5809\n",
      "Epoch 286: val_loss improved from 442.79144 to 441.28113, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.9914 - mean_absolute_error: 9.9335 - val_loss: 441.2811 - val_mean_absolute_error: 15.8823\n",
      "Epoch 287/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 152.5946 - mean_absolute_error: 9.2874\n",
      "Epoch 287: val_loss improved from 441.28113 to 441.23727, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 230.5715 - mean_absolute_error: 10.1841 - val_loss: 441.2373 - val_mean_absolute_error: 15.8789\n",
      "Epoch 288/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 518.7163 - mean_absolute_error: 14.7497\n",
      "Epoch 288: val_loss improved from 441.23727 to 440.40033, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.8855 - mean_absolute_error: 10.9195 - val_loss: 440.4003 - val_mean_absolute_error: 15.8983\n",
      "Epoch 289/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 304.5061 - mean_absolute_error: 14.7482\n",
      "Epoch 289: val_loss did not improve from 440.40033\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.1498 - mean_absolute_error: 10.3469 - val_loss: 444.3168 - val_mean_absolute_error: 15.8577\n",
      "Epoch 290/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 156.6844 - mean_absolute_error: 9.1543\n",
      "Epoch 290: val_loss did not improve from 440.40033\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.4231 - mean_absolute_error: 9.7624 - val_loss: 442.1860 - val_mean_absolute_error: 15.8382\n",
      "Epoch 291/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 318.5172 - mean_absolute_error: 12.0142\n",
      "Epoch 291: val_loss improved from 440.40033 to 439.04184, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224.2646 - mean_absolute_error: 10.1770 - val_loss: 439.0418 - val_mean_absolute_error: 15.8903\n",
      "Epoch 292/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.4904 - mean_absolute_error: 9.9330 \n",
      "Epoch 292: val_loss did not improve from 439.04184\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 221.7210 - mean_absolute_error: 9.9333 - val_loss: 442.7058 - val_mean_absolute_error: 15.8653\n",
      "Epoch 293/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 259.8643 - mean_absolute_error: 11.3150\n",
      "Epoch 293: val_loss did not improve from 439.04184\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224.4017 - mean_absolute_error: 10.1373 - val_loss: 439.8279 - val_mean_absolute_error: 15.8981\n",
      "Epoch 294/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 276.0012 - mean_absolute_error: 11.5536\n",
      "Epoch 294: val_loss improved from 439.04184 to 438.87790, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 216.8542 - mean_absolute_error: 9.9676 - val_loss: 438.8779 - val_mean_absolute_error: 15.7916\n",
      "Epoch 295/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 347.2456 - mean_absolute_error: 11.4582\n",
      "Epoch 295: val_loss did not improve from 438.87790\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.1696 - mean_absolute_error: 9.7219 - val_loss: 438.9992 - val_mean_absolute_error: 15.8174\n",
      "Epoch 296/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 303.6913 - mean_absolute_error: 10.9376\n",
      "Epoch 296: val_loss improved from 438.87790 to 436.29166, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.2549 - mean_absolute_error: 9.9984 - val_loss: 436.2917 - val_mean_absolute_error: 15.8706\n",
      "Epoch 297/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 195.3355 - mean_absolute_error: 10.3627\n",
      "Epoch 297: val_loss improved from 436.29166 to 434.35617, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 217.6198 - mean_absolute_error: 10.1080 - val_loss: 434.3562 - val_mean_absolute_error: 15.8251\n",
      "Epoch 298/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 269.3841 - mean_absolute_error: 11.7903\n",
      "Epoch 298: val_loss did not improve from 434.35617\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.8076 - mean_absolute_error: 9.7843 - val_loss: 436.3162 - val_mean_absolute_error: 15.8624\n",
      "Epoch 299/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 174.1894 - mean_absolute_error: 9.6196\n",
      "Epoch 299: val_loss did not improve from 434.35617\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.8934 - mean_absolute_error: 9.7782 - val_loss: 434.9043 - val_mean_absolute_error: 15.8722\n",
      "Epoch 300/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 200.0621 - mean_absolute_error: 9.7716\n",
      "Epoch 300: val_loss did not improve from 434.35617\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.7213 - mean_absolute_error: 9.9784 - val_loss: 434.7625 - val_mean_absolute_error: 15.8068\n",
      "Epoch 301/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 262.6023 - mean_absolute_error: 11.8035\n",
      "Epoch 301: val_loss improved from 434.35617 to 434.12039, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.3615 - mean_absolute_error: 9.7245 - val_loss: 434.1204 - val_mean_absolute_error: 15.8179\n",
      "Epoch 302/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.2659 - mean_absolute_error: 10.2435 \n",
      "Epoch 302: val_loss improved from 434.12039 to 433.41211, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 220.5824 - mean_absolute_error: 10.2113 - val_loss: 433.4121 - val_mean_absolute_error: 15.8286\n",
      "Epoch 303/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 92.9699 - mean_absolute_error: 7.1829\n",
      "Epoch 303: val_loss did not improve from 433.41211\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 170.7954 - mean_absolute_error: 9.0092 - val_loss: 435.0553 - val_mean_absolute_error: 15.7756\n",
      "Epoch 304/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 199.3427 - mean_absolute_error: 9.7159\n",
      "Epoch 304: val_loss did not improve from 433.41211\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.4281 - mean_absolute_error: 9.0943 - val_loss: 434.3898 - val_mean_absolute_error: 15.7987\n",
      "Epoch 305/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 182.5470 - mean_absolute_error: 8.7101\n",
      "Epoch 305: val_loss improved from 433.41211 to 432.36145, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.1821 - mean_absolute_error: 9.7145 - val_loss: 432.3615 - val_mean_absolute_error: 15.7887\n",
      "Epoch 306/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 152.8376 - mean_absolute_error: 8.4520\n",
      "Epoch 306: val_loss did not improve from 432.36145\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.4684 - mean_absolute_error: 10.4108 - val_loss: 432.3801 - val_mean_absolute_error: 15.7298\n",
      "Epoch 307/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 106.2431 - mean_absolute_error: 7.8961\n",
      "Epoch 307: val_loss improved from 432.36145 to 432.07068, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 190.1315 - mean_absolute_error: 9.4140 - val_loss: 432.0707 - val_mean_absolute_error: 15.7920\n",
      "Epoch 308/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 274.9023 - mean_absolute_error: 11.5953\n",
      "Epoch 308: val_loss improved from 432.07068 to 431.45416, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 224.6857 - mean_absolute_error: 10.1046 - val_loss: 431.4542 - val_mean_absolute_error: 15.7387\n",
      "Epoch 309/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 145.1816 - mean_absolute_error: 8.4041\n",
      "Epoch 309: val_loss improved from 431.45416 to 431.43436, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 200.7458 - mean_absolute_error: 9.6672 - val_loss: 431.4344 - val_mean_absolute_error: 15.7861\n",
      "Epoch 310/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 164.4060 - mean_absolute_error: 9.8967\n",
      "Epoch 310: val_loss improved from 431.43436 to 431.42084, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.1021 - mean_absolute_error: 10.0059 - val_loss: 431.4208 - val_mean_absolute_error: 15.7515\n",
      "Epoch 311/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 137.7579 - mean_absolute_error: 9.0908\n",
      "Epoch 311: val_loss did not improve from 431.42084\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.7763 - mean_absolute_error: 9.5584 - val_loss: 435.2762 - val_mean_absolute_error: 15.6920\n",
      "Epoch 312/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 139.0125 - mean_absolute_error: 8.3046\n",
      "Epoch 312: val_loss improved from 431.42084 to 430.98569, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 206.6084 - mean_absolute_error: 9.7739 - val_loss: 430.9857 - val_mean_absolute_error: 15.8434\n",
      "Epoch 313/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 152.7557 - mean_absolute_error: 8.0241\n",
      "Epoch 313: val_loss did not improve from 430.98569\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.6438 - mean_absolute_error: 9.7203 - val_loss: 433.3915 - val_mean_absolute_error: 15.7439\n",
      "Epoch 314/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 363.5995 - mean_absolute_error: 10.9235\n",
      "Epoch 314: val_loss improved from 430.98569 to 429.70007, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 223.3655 - mean_absolute_error: 9.8617 - val_loss: 429.7001 - val_mean_absolute_error: 15.7458\n",
      "Epoch 315/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 237.9197 - mean_absolute_error: 10.7222\n",
      "Epoch 315: val_loss improved from 429.70007 to 429.18997, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.0049 - mean_absolute_error: 10.1807 - val_loss: 429.1900 - val_mean_absolute_error: 15.7329\n",
      "Epoch 316/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 262.6713 - mean_absolute_error: 11.1217\n",
      "Epoch 316: val_loss improved from 429.18997 to 429.06058, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 200.9180 - mean_absolute_error: 9.6113 - val_loss: 429.0606 - val_mean_absolute_error: 15.8151\n",
      "Epoch 317/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 212.8785 - mean_absolute_error: 10.3454\n",
      "Epoch 317: val_loss improved from 429.06058 to 428.97406, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.4606 - mean_absolute_error: 9.6212 - val_loss: 428.9741 - val_mean_absolute_error: 15.7435\n",
      "Epoch 318/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 264.7905 - mean_absolute_error: 11.4018\n",
      "Epoch 318: val_loss did not improve from 428.97406\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.9530 - mean_absolute_error: 10.0689 - val_loss: 429.7215 - val_mean_absolute_error: 15.7438\n",
      "Epoch 319/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 206.3934 - mean_absolute_error: 10.5051\n",
      "Epoch 319: val_loss did not improve from 428.97406\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.8887 - mean_absolute_error: 9.9764 - val_loss: 429.7091 - val_mean_absolute_error: 15.8148\n",
      "Epoch 320/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 243.9082 - mean_absolute_error: 10.3290\n",
      "Epoch 320: val_loss did not improve from 428.97406\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.7442 - mean_absolute_error: 10.0621 - val_loss: 432.0910 - val_mean_absolute_error: 15.6003\n",
      "Epoch 321/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.4754 - mean_absolute_error: 9.6502 \n",
      "Epoch 321: val_loss did not improve from 428.97406\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.6733 - mean_absolute_error: 9.6549 - val_loss: 433.0170 - val_mean_absolute_error: 15.9042\n",
      "Epoch 322/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 417.8409 - mean_absolute_error: 11.0716\n",
      "Epoch 322: val_loss improved from 428.97406 to 427.72720, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227.8545 - mean_absolute_error: 9.9986 - val_loss: 427.7272 - val_mean_absolute_error: 15.6858\n",
      "Epoch 323/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 145.1015 - mean_absolute_error: 9.0390\n",
      "Epoch 323: val_loss did not improve from 427.72720\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.9406 - mean_absolute_error: 9.7395 - val_loss: 431.8590 - val_mean_absolute_error: 15.6517\n",
      "Epoch 324/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 159.4683 - mean_absolute_error: 9.3229\n",
      "Epoch 324: val_loss improved from 427.72720 to 427.01544, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 196.0759 - mean_absolute_error: 9.6366 - val_loss: 427.0154 - val_mean_absolute_error: 15.6957\n",
      "Epoch 325/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 132.9625 - mean_absolute_error: 8.1057\n",
      "Epoch 325: val_loss improved from 427.01544 to 426.10901, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.6828 - mean_absolute_error: 9.0994 - val_loss: 426.1090 - val_mean_absolute_error: 15.7007\n",
      "Epoch 326/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 174.5067 - mean_absolute_error: 9.3603\n",
      "Epoch 326: val_loss did not improve from 426.10901\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.8290 - mean_absolute_error: 9.5010 - val_loss: 426.3160 - val_mean_absolute_error: 15.6564\n",
      "Epoch 327/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 169.4540 - mean_absolute_error: 8.9371\n",
      "Epoch 327: val_loss improved from 426.10901 to 425.75626, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.0187 - mean_absolute_error: 9.4726 - val_loss: 425.7563 - val_mean_absolute_error: 15.7469\n",
      "Epoch 328/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 132.4629 - mean_absolute_error: 7.5067\n",
      "Epoch 328: val_loss did not improve from 425.75626\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.4297 - mean_absolute_error: 9.3140 - val_loss: 426.7027 - val_mean_absolute_error: 15.7102\n",
      "Epoch 329/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 187.5037 - mean_absolute_error: 9.7240\n",
      "Epoch 329: val_loss did not improve from 425.75626\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.2885 - mean_absolute_error: 9.6995 - val_loss: 428.4400 - val_mean_absolute_error: 15.8207\n",
      "Epoch 330/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 230.4639 - mean_absolute_error: 10.6170\n",
      "Epoch 330: val_loss did not improve from 425.75626\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.9994 - mean_absolute_error: 9.9855 - val_loss: 427.2539 - val_mean_absolute_error: 15.6467\n",
      "Epoch 331/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.8748 - mean_absolute_error: 9.2499\n",
      "Epoch 331: val_loss improved from 425.75626 to 424.39175, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 188.0476 - mean_absolute_error: 9.2822 - val_loss: 424.3918 - val_mean_absolute_error: 15.6318\n",
      "Epoch 332/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 129.5028 - mean_absolute_error: 7.7467\n",
      "Epoch 332: val_loss did not improve from 424.39175\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.6857 - mean_absolute_error: 9.5497 - val_loss: 425.4962 - val_mean_absolute_error: 15.6465\n",
      "Epoch 333/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 219.0718 - mean_absolute_error: 9.7205\n",
      "Epoch 333: val_loss did not improve from 424.39175\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.9997 - mean_absolute_error: 9.4663 - val_loss: 425.9095 - val_mean_absolute_error: 15.7736\n",
      "Epoch 334/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 184.9864 - mean_absolute_error: 9.0298\n",
      "Epoch 334: val_loss did not improve from 424.39175\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.0886 - mean_absolute_error: 9.9920 - val_loss: 427.1117 - val_mean_absolute_error: 15.7594\n",
      "Epoch 335/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 242.6615 - mean_absolute_error: 11.2856\n",
      "Epoch 335: val_loss did not improve from 424.39175\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.7186 - mean_absolute_error: 9.7096 - val_loss: 426.4371 - val_mean_absolute_error: 15.5745\n",
      "Epoch 336/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 86.3185 - mean_absolute_error: 6.2003\n",
      "Epoch 336: val_loss did not improve from 424.39175\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.3303 - mean_absolute_error: 9.6294 - val_loss: 426.0465 - val_mean_absolute_error: 15.5704\n",
      "Epoch 337/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 151.5820 - mean_absolute_error: 9.1519\n",
      "Epoch 337: val_loss improved from 424.39175 to 422.60641, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.2996 - mean_absolute_error: 9.7424 - val_loss: 422.6064 - val_mean_absolute_error: 15.6335\n",
      "Epoch 338/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 201.6728 - mean_absolute_error: 9.9684\n",
      "Epoch 338: val_loss did not improve from 422.60641\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.8657 - mean_absolute_error: 9.4897 - val_loss: 423.8264 - val_mean_absolute_error: 15.7492\n",
      "Epoch 339/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 137.2744 - mean_absolute_error: 7.1782\n",
      "Epoch 339: val_loss improved from 422.60641 to 422.34808, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.4520 - mean_absolute_error: 9.6803 - val_loss: 422.3481 - val_mean_absolute_error: 15.6439\n",
      "Epoch 340/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 456.1912 - mean_absolute_error: 13.8154\n",
      "Epoch 340: val_loss did not improve from 422.34808\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.6983 - mean_absolute_error: 10.5811 - val_loss: 424.1838 - val_mean_absolute_error: 15.5297\n",
      "Epoch 341/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 341.4796 - mean_absolute_error: 13.2326\n",
      "Epoch 341: val_loss did not improve from 422.34808\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.0547 - mean_absolute_error: 10.3425 - val_loss: 422.4093 - val_mean_absolute_error: 15.6035\n",
      "Epoch 342/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 177.8310 - mean_absolute_error: 10.0237\n",
      "Epoch 342: val_loss did not improve from 422.34808\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4016 - mean_absolute_error: 9.6919 - val_loss: 422.9057 - val_mean_absolute_error: 15.5321\n",
      "Epoch 343/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 268.2271 - mean_absolute_error: 11.6870\n",
      "Epoch 343: val_loss improved from 422.34808 to 420.96805, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201.1441 - mean_absolute_error: 9.7512 - val_loss: 420.9680 - val_mean_absolute_error: 15.6247\n",
      "Epoch 344/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 246.0217 - mean_absolute_error: 10.5376\n",
      "Epoch 344: val_loss improved from 420.96805 to 420.65091, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.8875 - mean_absolute_error: 9.5415 - val_loss: 420.6509 - val_mean_absolute_error: 15.5562\n",
      "Epoch 345/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 328.3745 - mean_absolute_error: 12.1757\n",
      "Epoch 345: val_loss improved from 420.65091 to 420.52051, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 223.5712 - mean_absolute_error: 10.2592 - val_loss: 420.5205 - val_mean_absolute_error: 15.5353\n",
      "Epoch 346/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 251.1842 - mean_absolute_error: 9.8088\n",
      "Epoch 346: val_loss improved from 420.52051 to 419.88297, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.2614 - mean_absolute_error: 9.3915 - val_loss: 419.8830 - val_mean_absolute_error: 15.5314\n",
      "Epoch 347/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 194.6406 - mean_absolute_error: 9.2697\n",
      "Epoch 347: val_loss did not improve from 419.88297\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.7675 - mean_absolute_error: 9.6952 - val_loss: 420.5782 - val_mean_absolute_error: 15.6222\n",
      "Epoch 348/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 206.7945 - mean_absolute_error: 10.3494\n",
      "Epoch 348: val_loss improved from 419.88297 to 419.00467, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.3253 - mean_absolute_error: 9.8206 - val_loss: 419.0047 - val_mean_absolute_error: 15.5129\n",
      "Epoch 349/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 182.2113 - mean_absolute_error: 9.2961\n",
      "Epoch 349: val_loss did not improve from 419.00467\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.2165 - mean_absolute_error: 9.7405 - val_loss: 423.4491 - val_mean_absolute_error: 15.7837\n",
      "Epoch 350/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 207.3857 - mean_absolute_error: 7.8752\n",
      "Epoch 350: val_loss did not improve from 419.00467\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.5964 - mean_absolute_error: 9.3406 - val_loss: 419.2496 - val_mean_absolute_error: 15.4577\n",
      "Epoch 351/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 150.4191 - mean_absolute_error: 8.2560\n",
      "Epoch 351: val_loss improved from 419.00467 to 418.09048, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.0652 - mean_absolute_error: 9.8071 - val_loss: 418.0905 - val_mean_absolute_error: 15.4832\n",
      "Epoch 352/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 107.0581 - mean_absolute_error: 7.7039\n",
      "Epoch 352: val_loss did not improve from 418.09048\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.3290 - mean_absolute_error: 9.6683 - val_loss: 418.1697 - val_mean_absolute_error: 15.5176\n",
      "Epoch 353/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.1779 - mean_absolute_error: 10.1360 \n",
      "Epoch 353: val_loss improved from 418.09048 to 417.87473, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 214.2165 - mean_absolute_error: 10.1021 - val_loss: 417.8747 - val_mean_absolute_error: 15.5803\n",
      "Epoch 354/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 150.8774 - mean_absolute_error: 8.8349\n",
      "Epoch 354: val_loss did not improve from 417.87473\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.8113 - mean_absolute_error: 9.7072 - val_loss: 417.9381 - val_mean_absolute_error: 15.4787\n",
      "Epoch 355/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.2226 - mean_absolute_error: 10.0324\n",
      "Epoch 355: val_loss did not improve from 417.87473\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 218.7608 - mean_absolute_error: 10.0236 - val_loss: 417.9896 - val_mean_absolute_error: 15.4596\n",
      "Epoch 356/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 205.0825 - mean_absolute_error: 10.6240\n",
      "Epoch 356: val_loss improved from 417.87473 to 417.55371, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.0513 - mean_absolute_error: 9.5394 - val_loss: 417.5537 - val_mean_absolute_error: 15.5426\n",
      "Epoch 357/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 150.4197 - mean_absolute_error: 9.2874\n",
      "Epoch 357: val_loss did not improve from 417.55371\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.5743 - mean_absolute_error: 9.8179 - val_loss: 418.3116 - val_mean_absolute_error: 15.6768\n",
      "Epoch 358/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 160.6737 - mean_absolute_error: 9.7663\n",
      "Epoch 358: val_loss did not improve from 417.55371\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.3991 - mean_absolute_error: 9.4165 - val_loss: 418.5710 - val_mean_absolute_error: 15.5192\n",
      "Epoch 359/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 120.1135 - mean_absolute_error: 6.7370\n",
      "Epoch 359: val_loss did not improve from 417.55371\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.4179 - mean_absolute_error: 9.5075 - val_loss: 417.9888 - val_mean_absolute_error: 15.5060\n",
      "Epoch 360/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.3198 - mean_absolute_error: 9.5793 \n",
      "Epoch 360: val_loss did not improve from 417.55371\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 195.3426 - mean_absolute_error: 9.5961 - val_loss: 417.8452 - val_mean_absolute_error: 15.5784\n",
      "Epoch 361/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 291.1693 - mean_absolute_error: 11.3961\n",
      "Epoch 361: val_loss improved from 417.55371 to 416.64890, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201.5285 - mean_absolute_error: 9.7349 - val_loss: 416.6489 - val_mean_absolute_error: 15.4276\n",
      "Epoch 362/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 209.2431 - mean_absolute_error: 10.0733\n",
      "Epoch 362: val_loss did not improve from 416.64890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.8293 - mean_absolute_error: 9.9926 - val_loss: 418.5219 - val_mean_absolute_error: 15.6559\n",
      "Epoch 363/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 100.7090 - mean_absolute_error: 7.7745\n",
      "Epoch 363: val_loss did not improve from 416.64890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.0218 - mean_absolute_error: 9.6670 - val_loss: 418.5084 - val_mean_absolute_error: 15.5353\n",
      "Epoch 364/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 139.4609 - mean_absolute_error: 7.9860\n",
      "Epoch 364: val_loss improved from 416.64890 to 416.57523, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 194.4857 - mean_absolute_error: 9.4657 - val_loss: 416.5752 - val_mean_absolute_error: 15.4740\n",
      "Epoch 365/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 159.6884 - mean_absolute_error: 8.8151\n",
      "Epoch 365: val_loss did not improve from 416.57523\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.1191 - mean_absolute_error: 9.9484 - val_loss: 417.0469 - val_mean_absolute_error: 15.4873\n",
      "Epoch 366/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 210.0063 - mean_absolute_error: 8.6344\n",
      "Epoch 366: val_loss improved from 416.57523 to 416.13577, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.8943 - mean_absolute_error: 9.4899 - val_loss: 416.1358 - val_mean_absolute_error: 15.5420\n",
      "Epoch 367/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 250.6184 - mean_absolute_error: 9.0223\n",
      "Epoch 367: val_loss improved from 416.13577 to 415.51187, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.6948 - mean_absolute_error: 9.3742 - val_loss: 415.5119 - val_mean_absolute_error: 15.4496\n",
      "Epoch 368/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 139.1346 - mean_absolute_error: 7.8958\n",
      "Epoch 368: val_loss improved from 415.51187 to 413.88266, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.0168 - mean_absolute_error: 9.0577 - val_loss: 413.8827 - val_mean_absolute_error: 15.4795\n",
      "Epoch 369/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 187.5940 - mean_absolute_error: 9.2112\n",
      "Epoch 369: val_loss did not improve from 413.88266\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.8284 - mean_absolute_error: 9.5589 - val_loss: 418.9269 - val_mean_absolute_error: 15.3012\n",
      "Epoch 370/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 139.5840 - mean_absolute_error: 8.0885\n",
      "Epoch 370: val_loss improved from 413.88266 to 413.34476, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.0708 - mean_absolute_error: 9.4716 - val_loss: 413.3448 - val_mean_absolute_error: 15.3885\n",
      "Epoch 371/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.8428 - mean_absolute_error: 9.4864 \n",
      "Epoch 371: val_loss did not improve from 413.34476\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 202.5800 - mean_absolute_error: 9.5097 - val_loss: 414.5297 - val_mean_absolute_error: 15.3789\n",
      "Epoch 372/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 207.1921 - mean_absolute_error: 11.4609\n",
      "Epoch 372: val_loss improved from 413.34476 to 412.51447, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.2394 - mean_absolute_error: 9.5869 - val_loss: 412.5145 - val_mean_absolute_error: 15.5267\n",
      "Epoch 373/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.5529 - mean_absolute_error: 10.0652 \n",
      "Epoch 373: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 213.0379 - mean_absolute_error: 10.0243 - val_loss: 413.8616 - val_mean_absolute_error: 15.5539\n",
      "Epoch 374/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 106.7114 - mean_absolute_error: 7.4384\n",
      "Epoch 374: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.6067 - mean_absolute_error: 9.4295 - val_loss: 414.8330 - val_mean_absolute_error: 15.3652\n",
      "Epoch 375/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 100.6199 - mean_absolute_error: 7.1412\n",
      "Epoch 375: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.0448 - mean_absolute_error: 9.5111 - val_loss: 415.7573 - val_mean_absolute_error: 15.5520\n",
      "Epoch 376/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 194.2421 - mean_absolute_error: 10.2797\n",
      "Epoch 376: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.3348 - mean_absolute_error: 9.5008 - val_loss: 415.3514 - val_mean_absolute_error: 15.6151\n",
      "Epoch 377/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 184.7366 - mean_absolute_error: 9.5430\n",
      "Epoch 377: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.2443 - mean_absolute_error: 9.7214 - val_loss: 414.1761 - val_mean_absolute_error: 15.5177\n",
      "Epoch 378/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 191.4220 - mean_absolute_error: 10.7622\n",
      "Epoch 378: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.8421 - mean_absolute_error: 9.7985 - val_loss: 414.3302 - val_mean_absolute_error: 15.5714\n",
      "Epoch 379/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 226.6819 - mean_absolute_error: 10.3221\n",
      "Epoch 379: val_loss did not improve from 412.51447\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.3132 - mean_absolute_error: 9.9071 - val_loss: 413.5161 - val_mean_absolute_error: 15.4212\n",
      "Epoch 380/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 163.6003 - mean_absolute_error: 8.7473\n",
      "Epoch 380: val_loss improved from 412.51447 to 412.24918, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.9473 - mean_absolute_error: 9.3904 - val_loss: 412.2492 - val_mean_absolute_error: 15.3449\n",
      "Epoch 381/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 178.4342 - mean_absolute_error: 9.4416\n",
      "Epoch 381: val_loss improved from 412.24918 to 409.53137, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.7139 - mean_absolute_error: 9.8698 - val_loss: 409.5314 - val_mean_absolute_error: 15.3724\n",
      "Epoch 382/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 200.5087 - mean_absolute_error: 9.6437\n",
      "Epoch 382: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.4373 - mean_absolute_error: 10.1180 - val_loss: 410.9362 - val_mean_absolute_error: 15.3173\n",
      "Epoch 383/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.8726 - mean_absolute_error: 9.7313 \n",
      "Epoch 383: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 207.9003 - mean_absolute_error: 9.7305 - val_loss: 412.7875 - val_mean_absolute_error: 15.2827\n",
      "Epoch 384/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 169.2527 - mean_absolute_error: 9.3963\n",
      "Epoch 384: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3061 - mean_absolute_error: 9.8054 - val_loss: 413.0808 - val_mean_absolute_error: 15.2690\n",
      "Epoch 385/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 242.5233 - mean_absolute_error: 13.2976\n",
      "Epoch 385: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.6959 - mean_absolute_error: 10.1816 - val_loss: 411.3033 - val_mean_absolute_error: 15.4466\n",
      "Epoch 386/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 138.4248 - mean_absolute_error: 8.2081\n",
      "Epoch 386: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.8797 - mean_absolute_error: 9.6528 - val_loss: 412.8655 - val_mean_absolute_error: 15.2874\n",
      "Epoch 387/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 351.1913 - mean_absolute_error: 13.9215\n",
      "Epoch 387: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.2879 - mean_absolute_error: 10.0787 - val_loss: 413.7949 - val_mean_absolute_error: 15.6326\n",
      "Epoch 388/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 259.8041 - mean_absolute_error: 10.9117\n",
      "Epoch 388: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.8841 - mean_absolute_error: 9.6273 - val_loss: 409.7100 - val_mean_absolute_error: 15.4046\n",
      "Epoch 389/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 149.7131 - mean_absolute_error: 8.6419\n",
      "Epoch 389: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.9643 - mean_absolute_error: 10.0940 - val_loss: 410.4109 - val_mean_absolute_error: 15.2950\n",
      "Epoch 390/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.3408 - mean_absolute_error: 9.4935 \n",
      "Epoch 390: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 191.8618 - mean_absolute_error: 9.5222 - val_loss: 410.4446 - val_mean_absolute_error: 15.3939\n",
      "Epoch 391/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 204.3866 - mean_absolute_error: 9.9254\n",
      "Epoch 391: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.4526 - mean_absolute_error: 9.9433 - val_loss: 411.1212 - val_mean_absolute_error: 15.4035\n",
      "Epoch 392/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 386.7295 - mean_absolute_error: 12.6780\n",
      "Epoch 392: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.6554 - mean_absolute_error: 10.0112 - val_loss: 410.1926 - val_mean_absolute_error: 15.2834\n",
      "Epoch 393/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 151.5900 - mean_absolute_error: 7.3570\n",
      "Epoch 393: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.7478 - mean_absolute_error: 9.3106 - val_loss: 413.0672 - val_mean_absolute_error: 15.6258\n",
      "Epoch 394/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 361.0624 - mean_absolute_error: 12.5402\n",
      "Epoch 394: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.1446 - mean_absolute_error: 10.0896 - val_loss: 411.3906 - val_mean_absolute_error: 15.3066\n",
      "Epoch 395/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 228.1983 - mean_absolute_error: 10.7027\n",
      "Epoch 395: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.6058 - mean_absolute_error: 9.8344 - val_loss: 413.8798 - val_mean_absolute_error: 15.1780\n",
      "Epoch 396/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 222.2918 - mean_absolute_error: 11.0845\n",
      "Epoch 396: val_loss did not improve from 409.53137\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.5189 - mean_absolute_error: 9.7407 - val_loss: 411.3616 - val_mean_absolute_error: 15.2508\n",
      "Epoch 397/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.0669 - mean_absolute_error: 9.5454 \n",
      "Epoch 397: val_loss improved from 409.53137 to 409.49341, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 200.0627 - mean_absolute_error: 9.5494 - val_loss: 409.4934 - val_mean_absolute_error: 15.3089\n",
      "Epoch 398/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 234.2213 - mean_absolute_error: 10.7222\n",
      "Epoch 398: val_loss improved from 409.49341 to 408.01950, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.1222 - mean_absolute_error: 9.5950 - val_loss: 408.0195 - val_mean_absolute_error: 15.3168\n",
      "Epoch 399/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.1466 - mean_absolute_error: 9.8351  \n",
      "Epoch 399: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.8186 - mean_absolute_error: 9.8225 - val_loss: 411.2286 - val_mean_absolute_error: 15.5595\n",
      "Epoch 400/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 108.3656 - mean_absolute_error: 7.4882\n",
      "Epoch 400: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.3858 - mean_absolute_error: 9.4925 - val_loss: 410.7622 - val_mean_absolute_error: 15.2846\n",
      "Epoch 401/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 256.2467 - mean_absolute_error: 11.6625\n",
      "Epoch 401: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.9935 - mean_absolute_error: 9.4840 - val_loss: 409.2025 - val_mean_absolute_error: 15.3695\n",
      "Epoch 402/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 176.6519 - mean_absolute_error: 9.7919\n",
      "Epoch 402: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.2537 - mean_absolute_error: 9.7866 - val_loss: 409.6289 - val_mean_absolute_error: 15.4265\n",
      "Epoch 403/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 114.3162 - mean_absolute_error: 8.2946\n",
      "Epoch 403: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.0868 - mean_absolute_error: 9.5336 - val_loss: 409.6260 - val_mean_absolute_error: 15.3188\n",
      "Epoch 404/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.8214 - mean_absolute_error: 9.6792 \n",
      "Epoch 404: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 194.4614 - mean_absolute_error: 9.6796 - val_loss: 408.7775 - val_mean_absolute_error: 15.3784\n",
      "Epoch 405/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 227.3784 - mean_absolute_error: 10.2699\n",
      "Epoch 405: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.2363 - mean_absolute_error: 9.7194 - val_loss: 409.7617 - val_mean_absolute_error: 15.2976\n",
      "Epoch 406/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 136.2531 - mean_absolute_error: 8.3707\n",
      "Epoch 406: val_loss did not improve from 408.01950\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.1907 - mean_absolute_error: 9.6917 - val_loss: 409.6219 - val_mean_absolute_error: 15.1490\n",
      "Epoch 407/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 207.9904 - mean_absolute_error: 11.5154\n",
      "Epoch 407: val_loss improved from 408.01950 to 406.78989, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.8720 - mean_absolute_error: 9.9262 - val_loss: 406.7899 - val_mean_absolute_error: 15.3047\n",
      "Epoch 408/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 203.2556 - mean_absolute_error: 9.8337\n",
      "Epoch 408: val_loss did not improve from 406.78989\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.2004 - mean_absolute_error: 9.3547 - val_loss: 407.1197 - val_mean_absolute_error: 15.2173\n",
      "Epoch 409/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 132.2568 - mean_absolute_error: 8.5342\n",
      "Epoch 409: val_loss improved from 406.78989 to 406.52524, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 188.9119 - mean_absolute_error: 9.5577 - val_loss: 406.5252 - val_mean_absolute_error: 15.2546\n",
      "Epoch 410/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 188.7082 - mean_absolute_error: 8.5730\n",
      "Epoch 410: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.7096 - mean_absolute_error: 9.3718 - val_loss: 407.3880 - val_mean_absolute_error: 15.2922\n",
      "Epoch 411/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 156.0016 - mean_absolute_error: 9.2381\n",
      "Epoch 411: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.1234 - mean_absolute_error: 9.3247 - val_loss: 407.9510 - val_mean_absolute_error: 15.3156\n",
      "Epoch 412/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 135.9148 - mean_absolute_error: 8.3465\n",
      "Epoch 412: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.8463 - mean_absolute_error: 9.2672 - val_loss: 407.3080 - val_mean_absolute_error: 15.2433\n",
      "Epoch 413/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.9701 - mean_absolute_error: 9.6999  \n",
      "Epoch 413: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.2996 - mean_absolute_error: 9.6945 - val_loss: 407.5107 - val_mean_absolute_error: 15.3404\n",
      "Epoch 414/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 142.3964 - mean_absolute_error: 8.3115\n",
      "Epoch 414: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.1817 - mean_absolute_error: 9.4653 - val_loss: 407.4668 - val_mean_absolute_error: 15.2383\n",
      "Epoch 415/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 107.2523 - mean_absolute_error: 6.7506\n",
      "Epoch 415: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.6837 - mean_absolute_error: 9.2394 - val_loss: 408.6650 - val_mean_absolute_error: 15.0993\n",
      "Epoch 416/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 166.0744 - mean_absolute_error: 8.8685\n",
      "Epoch 416: val_loss did not improve from 406.52524\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.3717 - mean_absolute_error: 9.6732 - val_loss: 406.9892 - val_mean_absolute_error: 15.2926\n",
      "Epoch 417/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 117.4208 - mean_absolute_error: 7.4543\n",
      "Epoch 417: val_loss improved from 406.52524 to 406.28726, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.3427 - mean_absolute_error: 9.2105 - val_loss: 406.2873 - val_mean_absolute_error: 15.2904\n",
      "Epoch 418/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 278.1837 - mean_absolute_error: 12.0588\n",
      "Epoch 418: val_loss improved from 406.28726 to 405.68069, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 203.1935 - mean_absolute_error: 9.9029 - val_loss: 405.6807 - val_mean_absolute_error: 15.3132\n",
      "Epoch 419/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 289.4615 - mean_absolute_error: 10.9037\n",
      "Epoch 419: val_loss did not improve from 405.68069\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.4821 - mean_absolute_error: 9.7460 - val_loss: 405.7774 - val_mean_absolute_error: 15.2816\n",
      "Epoch 420/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 181.2110 - mean_absolute_error: 9.5185\n",
      "Epoch 420: val_loss did not improve from 405.68069\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.3847 - mean_absolute_error: 9.7933 - val_loss: 406.3083 - val_mean_absolute_error: 15.4042\n",
      "Epoch 421/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 454.8831 - mean_absolute_error: 11.7173\n",
      "Epoch 421: val_loss improved from 405.68069 to 404.41272, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.5410 - mean_absolute_error: 9.8843 - val_loss: 404.4127 - val_mean_absolute_error: 15.2652\n",
      "Epoch 422/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 204.1189 - mean_absolute_error: 10.3172\n",
      "Epoch 422: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.0138 - mean_absolute_error: 9.3375 - val_loss: 405.6635 - val_mean_absolute_error: 15.2158\n",
      "Epoch 423/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 217.2214 - mean_absolute_error: 10.7470\n",
      "Epoch 423: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.5346 - mean_absolute_error: 10.1291 - val_loss: 405.5483 - val_mean_absolute_error: 15.1937\n",
      "Epoch 424/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 359.9976 - mean_absolute_error: 13.7437\n",
      "Epoch 424: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.4869 - mean_absolute_error: 9.5595 - val_loss: 409.2541 - val_mean_absolute_error: 15.5935\n",
      "Epoch 425/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 172.2863 - mean_absolute_error: 9.4137\n",
      "Epoch 425: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0820 - mean_absolute_error: 9.7553 - val_loss: 404.7492 - val_mean_absolute_error: 15.2440\n",
      "Epoch 426/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 160.4933 - mean_absolute_error: 8.7706\n",
      "Epoch 426: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.8046 - mean_absolute_error: 9.6400 - val_loss: 407.7722 - val_mean_absolute_error: 15.1103\n",
      "Epoch 427/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 213.1702 - mean_absolute_error: 9.6866\n",
      "Epoch 427: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.8494 - mean_absolute_error: 9.5390 - val_loss: 409.2690 - val_mean_absolute_error: 15.5828\n",
      "Epoch 428/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 101.2333 - mean_absolute_error: 7.4068\n",
      "Epoch 428: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.4046 - mean_absolute_error: 9.3083 - val_loss: 405.1233 - val_mean_absolute_error: 15.1386\n",
      "Epoch 429/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 150.8187 - mean_absolute_error: 8.6608\n",
      "Epoch 429: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.8336 - mean_absolute_error: 9.7402 - val_loss: 404.6683 - val_mean_absolute_error: 15.3860\n",
      "Epoch 430/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.7390 - mean_absolute_error: 10.1090 \n",
      "Epoch 430: val_loss did not improve from 404.41272\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3699 - mean_absolute_error: 10.0956 - val_loss: 406.1053 - val_mean_absolute_error: 15.1369\n",
      "Epoch 431/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 106.2773 - mean_absolute_error: 7.9080\n",
      "Epoch 431: val_loss improved from 404.41272 to 403.65570, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.5661 - mean_absolute_error: 9.4436 - val_loss: 403.6557 - val_mean_absolute_error: 15.2405\n",
      "Epoch 432/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 318.7311 - mean_absolute_error: 12.6694\n",
      "Epoch 432: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.7329 - mean_absolute_error: 9.5349 - val_loss: 405.6035 - val_mean_absolute_error: 15.2784\n",
      "Epoch 433/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 268.0608 - mean_absolute_error: 10.7069\n",
      "Epoch 433: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.2137 - mean_absolute_error: 9.8028 - val_loss: 405.3463 - val_mean_absolute_error: 15.1818\n",
      "Epoch 434/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 179.5180 - mean_absolute_error: 9.6981\n",
      "Epoch 434: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.6826 - mean_absolute_error: 10.1805 - val_loss: 407.1900 - val_mean_absolute_error: 15.3793\n",
      "Epoch 435/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 272.4830 - mean_absolute_error: 12.5716\n",
      "Epoch 435: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.2468 - mean_absolute_error: 10.3412 - val_loss: 405.7018 - val_mean_absolute_error: 15.1346\n",
      "Epoch 436/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 162.9877 - mean_absolute_error: 9.5953\n",
      "Epoch 436: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.4074 - mean_absolute_error: 9.4440 - val_loss: 404.6818 - val_mean_absolute_error: 15.3680\n",
      "Epoch 437/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 317.8024 - mean_absolute_error: 12.5311\n",
      "Epoch 437: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.0633 - mean_absolute_error: 9.7740 - val_loss: 404.3924 - val_mean_absolute_error: 15.3938\n",
      "Epoch 438/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 227.8592 - mean_absolute_error: 11.3496\n",
      "Epoch 438: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.5134 - mean_absolute_error: 10.0560 - val_loss: 407.1527 - val_mean_absolute_error: 15.1042\n",
      "Epoch 439/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 200.9858 - mean_absolute_error: 10.3578\n",
      "Epoch 439: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.5188 - mean_absolute_error: 9.4915 - val_loss: 404.8753 - val_mean_absolute_error: 15.3259\n",
      "Epoch 440/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 156.9339 - mean_absolute_error: 8.5565\n",
      "Epoch 440: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.3153 - mean_absolute_error: 9.1902 - val_loss: 404.1908 - val_mean_absolute_error: 15.3373\n",
      "Epoch 441/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 258.1148 - mean_absolute_error: 11.9523\n",
      "Epoch 441: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.6321 - mean_absolute_error: 10.1411 - val_loss: 403.7605 - val_mean_absolute_error: 15.2475\n",
      "Epoch 442/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 96.1607 - mean_absolute_error: 7.2586\n",
      "Epoch 442: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.9332 - mean_absolute_error: 9.3689 - val_loss: 405.4346 - val_mean_absolute_error: 15.1298\n",
      "Epoch 443/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 157.1367 - mean_absolute_error: 8.8303\n",
      "Epoch 443: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183.6584 - mean_absolute_error: 9.3851 - val_loss: 404.6771 - val_mean_absolute_error: 15.3704\n",
      "Epoch 444/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 249.0737 - mean_absolute_error: 11.4864\n",
      "Epoch 444: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.7504 - mean_absolute_error: 9.6688 - val_loss: 404.0044 - val_mean_absolute_error: 15.1883\n",
      "Epoch 445/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 313.6443 - mean_absolute_error: 13.0445\n",
      "Epoch 445: val_loss did not improve from 403.65570\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.3469 - mean_absolute_error: 9.9027 - val_loss: 403.7209 - val_mean_absolute_error: 15.1485\n",
      "Epoch 446/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 206.7885 - mean_absolute_error: 9.8517\n",
      "Epoch 446: val_loss improved from 403.65570 to 402.25974, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.9253 - mean_absolute_error: 9.8274 - val_loss: 402.2597 - val_mean_absolute_error: 15.2358\n",
      "Epoch 447/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 258.5447 - mean_absolute_error: 11.2090\n",
      "Epoch 447: val_loss did not improve from 402.25974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.5950 - mean_absolute_error: 9.7703 - val_loss: 403.5787 - val_mean_absolute_error: 15.2766\n",
      "Epoch 448/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 114.8238 - mean_absolute_error: 7.6732\n",
      "Epoch 448: val_loss did not improve from 402.25974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.2643 - mean_absolute_error: 9.5792 - val_loss: 403.6799 - val_mean_absolute_error: 15.2599\n",
      "Epoch 449/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 112.7333 - mean_absolute_error: 8.2394\n",
      "Epoch 449: val_loss did not improve from 402.25974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.1313 - mean_absolute_error: 9.6771 - val_loss: 404.1509 - val_mean_absolute_error: 15.2694\n",
      "Epoch 450/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 129.2641 - mean_absolute_error: 8.0437\n",
      "Epoch 450: val_loss did not improve from 402.25974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.6108 - mean_absolute_error: 9.4624 - val_loss: 404.0029 - val_mean_absolute_error: 15.3421\n",
      "Epoch 451/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.2254 - mean_absolute_error: 6.7109\n",
      "Epoch 451: val_loss did not improve from 402.25974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.6541 - mean_absolute_error: 9.0989 - val_loss: 402.9655 - val_mean_absolute_error: 15.2053\n",
      "Epoch 452/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 109.0489 - mean_absolute_error: 7.6335\n",
      "Epoch 452: val_loss improved from 402.25974 to 401.33920, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.2522 - mean_absolute_error: 9.0802 - val_loss: 401.3392 - val_mean_absolute_error: 15.1761\n",
      "Epoch 453/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 187.0888 - mean_absolute_error: 9.6458\n",
      "Epoch 453: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.4119 - mean_absolute_error: 9.2504 - val_loss: 403.4647 - val_mean_absolute_error: 15.1622\n",
      "Epoch 454/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 207.8915 - mean_absolute_error: 11.1907\n",
      "Epoch 454: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.4155 - mean_absolute_error: 9.5414 - val_loss: 404.3187 - val_mean_absolute_error: 15.0790\n",
      "Epoch 455/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 164.7101 - mean_absolute_error: 9.4767\n",
      "Epoch 455: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.7993 - mean_absolute_error: 9.8274 - val_loss: 402.9413 - val_mean_absolute_error: 15.2876\n",
      "Epoch 456/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 90.2855 - mean_absolute_error: 7.1418\n",
      "Epoch 456: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.1298 - mean_absolute_error: 9.3607 - val_loss: 401.5460 - val_mean_absolute_error: 15.1455\n",
      "Epoch 457/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 192.1660 - mean_absolute_error: 9.6711\n",
      "Epoch 457: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.1708 - mean_absolute_error: 9.7653 - val_loss: 401.6240 - val_mean_absolute_error: 15.1860\n",
      "Epoch 458/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 288.5958 - mean_absolute_error: 11.4616\n",
      "Epoch 458: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.2797 - mean_absolute_error: 9.9108 - val_loss: 402.2399 - val_mean_absolute_error: 15.0316\n",
      "Epoch 459/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 186.2834 - mean_absolute_error: 10.6345\n",
      "Epoch 459: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.7809 - mean_absolute_error: 9.8702 - val_loss: 402.1335 - val_mean_absolute_error: 15.2057\n",
      "Epoch 460/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 155.6606 - mean_absolute_error: 9.0340\n",
      "Epoch 460: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.7259 - mean_absolute_error: 9.8094 - val_loss: 402.8157 - val_mean_absolute_error: 15.0639\n",
      "Epoch 461/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 131.9679 - mean_absolute_error: 7.8644\n",
      "Epoch 461: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.2056 - mean_absolute_error: 9.5676 - val_loss: 401.8279 - val_mean_absolute_error: 15.1640\n",
      "Epoch 462/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 179.2694 - mean_absolute_error: 9.5054\n",
      "Epoch 462: val_loss did not improve from 401.33920\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.7238 - mean_absolute_error: 9.6497 - val_loss: 405.6486 - val_mean_absolute_error: 15.0526\n",
      "Epoch 463/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 144.6829 - mean_absolute_error: 8.6549\n",
      "Epoch 463: val_loss improved from 401.33920 to 400.91000, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.3911 - mean_absolute_error: 9.5536 - val_loss: 400.9100 - val_mean_absolute_error: 15.2651\n",
      "Epoch 464/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 292.5934 - mean_absolute_error: 11.7102\n",
      "Epoch 464: val_loss did not improve from 400.91000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.1750 - mean_absolute_error: 9.6831 - val_loss: 404.6826 - val_mean_absolute_error: 14.9778\n",
      "Epoch 465/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 203.2100 - mean_absolute_error: 10.1509\n",
      "Epoch 465: val_loss did not improve from 400.91000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.6045 - mean_absolute_error: 9.7305 - val_loss: 401.8435 - val_mean_absolute_error: 15.2427\n",
      "Epoch 466/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 164.6320 - mean_absolute_error: 7.8675\n",
      "Epoch 466: val_loss did not improve from 400.91000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.9817 - mean_absolute_error: 9.4946 - val_loss: 402.0018 - val_mean_absolute_error: 15.2634\n",
      "Epoch 467/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 281.5366 - mean_absolute_error: 11.5770\n",
      "Epoch 467: val_loss did not improve from 400.91000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.9591 - mean_absolute_error: 9.8405 - val_loss: 402.1250 - val_mean_absolute_error: 15.3225\n",
      "Epoch 468/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 130.3171 - mean_absolute_error: 8.4211\n",
      "Epoch 468: val_loss did not improve from 400.91000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.6725 - mean_absolute_error: 9.7020 - val_loss: 408.4901 - val_mean_absolute_error: 14.9683\n",
      "Epoch 469/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 291.5533 - mean_absolute_error: 8.6037\n",
      "Epoch 469: val_loss improved from 400.91000 to 400.56668, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.0862 - mean_absolute_error: 9.5866 - val_loss: 400.5667 - val_mean_absolute_error: 15.1530\n",
      "Epoch 470/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 200.0264 - mean_absolute_error: 9.4896\n",
      "Epoch 470: val_loss did not improve from 400.56668\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.7854 - mean_absolute_error: 9.7863 - val_loss: 400.9169 - val_mean_absolute_error: 15.0857\n",
      "Epoch 471/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 166.3407 - mean_absolute_error: 8.5113\n",
      "Epoch 471: val_loss did not improve from 400.56668\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.9835 - mean_absolute_error: 9.3789 - val_loss: 401.2612 - val_mean_absolute_error: 15.2872\n",
      "Epoch 472/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 232.8405 - mean_absolute_error: 11.5897\n",
      "Epoch 472: val_loss did not improve from 400.56668\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.1966 - mean_absolute_error: 9.5690 - val_loss: 402.1094 - val_mean_absolute_error: 15.0099\n",
      "Epoch 473/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 158.4643 - mean_absolute_error: 9.6274\n",
      "Epoch 473: val_loss did not improve from 400.56668\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.5792 - mean_absolute_error: 9.7421 - val_loss: 401.9998 - val_mean_absolute_error: 15.3286\n",
      "Epoch 474/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 210.7338 - mean_absolute_error: 10.2494\n",
      "Epoch 474: val_loss did not improve from 400.56668\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.7221 - mean_absolute_error: 9.4585 - val_loss: 400.6467 - val_mean_absolute_error: 15.2407\n",
      "Epoch 475/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 219.9734 - mean_absolute_error: 9.8805\n",
      "Epoch 475: val_loss improved from 400.56668 to 400.36060, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.5518 - mean_absolute_error: 9.3910 - val_loss: 400.3606 - val_mean_absolute_error: 15.1375\n",
      "Epoch 476/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 339.8300 - mean_absolute_error: 13.6803\n",
      "Epoch 476: val_loss did not improve from 400.36060\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.1639 - mean_absolute_error: 9.7662 - val_loss: 402.5384 - val_mean_absolute_error: 15.2786\n",
      "Epoch 477/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 139.0228 - mean_absolute_error: 8.5606\n",
      "Epoch 477: val_loss improved from 400.36060 to 400.23886, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.2217 - mean_absolute_error: 9.3707 - val_loss: 400.2389 - val_mean_absolute_error: 15.1141\n",
      "Epoch 478/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 302.0831 - mean_absolute_error: 9.8723\n",
      "Epoch 478: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.0251 - mean_absolute_error: 9.6805 - val_loss: 402.4344 - val_mean_absolute_error: 15.0714\n",
      "Epoch 479/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 202.4594 - mean_absolute_error: 10.2580\n",
      "Epoch 479: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.3633 - mean_absolute_error: 9.6676 - val_loss: 404.4764 - val_mean_absolute_error: 14.9995\n",
      "Epoch 480/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 322.1519 - mean_absolute_error: 11.9093\n",
      "Epoch 480: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.7501 - mean_absolute_error: 9.8698 - val_loss: 403.0084 - val_mean_absolute_error: 15.4163\n",
      "Epoch 481/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 243.6066 - mean_absolute_error: 11.2450\n",
      "Epoch 481: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.1671 - mean_absolute_error: 10.0647 - val_loss: 402.1047 - val_mean_absolute_error: 15.0187\n",
      "Epoch 482/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 121.1739 - mean_absolute_error: 8.1553\n",
      "Epoch 482: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.3186 - mean_absolute_error: 9.5140 - val_loss: 400.4367 - val_mean_absolute_error: 15.0680\n",
      "Epoch 483/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 150.2511 - mean_absolute_error: 7.9786\n",
      "Epoch 483: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.5249 - mean_absolute_error: 9.9461 - val_loss: 404.9980 - val_mean_absolute_error: 15.4918\n",
      "Epoch 484/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 113.8658 - mean_absolute_error: 7.7972\n",
      "Epoch 484: val_loss did not improve from 400.23886\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.4718 - mean_absolute_error: 9.8428 - val_loss: 403.1865 - val_mean_absolute_error: 15.3561\n",
      "Epoch 485/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 288.0258 - mean_absolute_error: 9.5511\n",
      "Epoch 485: val_loss improved from 400.23886 to 399.61890, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.9991 - mean_absolute_error: 9.5007 - val_loss: 399.6189 - val_mean_absolute_error: 15.1276\n",
      "Epoch 486/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 229.8063 - mean_absolute_error: 10.4163\n",
      "Epoch 486: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.4537 - mean_absolute_error: 10.0035 - val_loss: 401.9405 - val_mean_absolute_error: 15.0841\n",
      "Epoch 487/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 154.2566 - mean_absolute_error: 8.5149\n",
      "Epoch 487: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.0094 - mean_absolute_error: 9.1914 - val_loss: 403.9864 - val_mean_absolute_error: 15.4579\n",
      "Epoch 488/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 98.5674 - mean_absolute_error: 7.5449\n",
      "Epoch 488: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.1677 - mean_absolute_error: 9.0918 - val_loss: 401.3632 - val_mean_absolute_error: 15.1647\n",
      "Epoch 489/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 90.2009 - mean_absolute_error: 6.8920\n",
      "Epoch 489: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.0244 - mean_absolute_error: 9.3794 - val_loss: 401.1115 - val_mean_absolute_error: 15.0877\n",
      "Epoch 490/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 159.3647 - mean_absolute_error: 8.9808\n",
      "Epoch 490: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.5476 - mean_absolute_error: 9.4789 - val_loss: 401.2326 - val_mean_absolute_error: 15.1119\n",
      "Epoch 491/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 362.1779 - mean_absolute_error: 11.5533\n",
      "Epoch 491: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.0436 - mean_absolute_error: 9.9290 - val_loss: 401.2652 - val_mean_absolute_error: 15.2957\n",
      "Epoch 492/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 162.1107 - mean_absolute_error: 8.0726\n",
      "Epoch 492: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.3859 - mean_absolute_error: 9.0179 - val_loss: 401.2132 - val_mean_absolute_error: 15.0813\n",
      "Epoch 493/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 104.9019 - mean_absolute_error: 7.7629\n",
      "Epoch 493: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.4200 - mean_absolute_error: 9.3028 - val_loss: 404.6766 - val_mean_absolute_error: 14.9891\n",
      "Epoch 494/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 123.4809 - mean_absolute_error: 7.5938\n",
      "Epoch 494: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 167.1299 - mean_absolute_error: 8.9668 - val_loss: 402.1494 - val_mean_absolute_error: 15.0753\n",
      "Epoch 495/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 182.3469 - mean_absolute_error: 10.1173\n",
      "Epoch 495: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.0256 - mean_absolute_error: 9.4488 - val_loss: 399.7308 - val_mean_absolute_error: 15.1673\n",
      "Epoch 496/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 168.0673 - mean_absolute_error: 9.0445\n",
      "Epoch 496: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.8682 - mean_absolute_error: 9.3804 - val_loss: 400.1063 - val_mean_absolute_error: 14.9961\n",
      "Epoch 497/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 201.9920 - mean_absolute_error: 11.4000\n",
      "Epoch 497: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.7323 - mean_absolute_error: 9.8311 - val_loss: 402.9326 - val_mean_absolute_error: 15.4231\n",
      "Epoch 498/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 199.4587 - mean_absolute_error: 10.1735\n",
      "Epoch 498: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.9307 - mean_absolute_error: 9.9712 - val_loss: 401.1151 - val_mean_absolute_error: 15.0389\n",
      "Epoch 499/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 276.4834 - mean_absolute_error: 10.9224\n",
      "Epoch 499: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.4796 - mean_absolute_error: 10.0478 - val_loss: 400.7902 - val_mean_absolute_error: 15.0021\n",
      "Epoch 500/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 163.0361 - mean_absolute_error: 9.1393\n",
      "Epoch 500: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.4400 - mean_absolute_error: 9.5624 - val_loss: 399.8838 - val_mean_absolute_error: 15.1784\n",
      "Epoch 501/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 166.8543 - mean_absolute_error: 9.0875\n",
      "Epoch 501: val_loss did not improve from 399.61890\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.7817 - mean_absolute_error: 9.7828 - val_loss: 400.3135 - val_mean_absolute_error: 15.1814\n",
      "Epoch 502/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 68.5186 - mean_absolute_error: 5.6715\n",
      "Epoch 502: val_loss improved from 399.61890 to 399.50818, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 170.3288 - mean_absolute_error: 9.1077 - val_loss: 399.5082 - val_mean_absolute_error: 15.0862\n",
      "Epoch 503/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 420.2357 - mean_absolute_error: 11.7134\n",
      "Epoch 503: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.5083 - mean_absolute_error: 9.6113 - val_loss: 404.7266 - val_mean_absolute_error: 14.9503\n",
      "Epoch 504/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 184.9686 - mean_absolute_error: 9.7481\n",
      "Epoch 504: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.2866 - mean_absolute_error: 10.1759 - val_loss: 403.9514 - val_mean_absolute_error: 15.4119\n",
      "Epoch 505/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 243.8474 - mean_absolute_error: 11.0951\n",
      "Epoch 505: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.3512 - mean_absolute_error: 10.1143 - val_loss: 403.4789 - val_mean_absolute_error: 14.9090\n",
      "Epoch 506/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 184.8563 - mean_absolute_error: 9.3314\n",
      "Epoch 506: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.9462 - mean_absolute_error: 9.8249 - val_loss: 402.2965 - val_mean_absolute_error: 15.4171\n",
      "Epoch 507/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 138.7442 - mean_absolute_error: 8.8079\n",
      "Epoch 507: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.8398 - mean_absolute_error: 9.6494 - val_loss: 400.5291 - val_mean_absolute_error: 15.0248\n",
      "Epoch 508/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 116.2697 - mean_absolute_error: 7.4237\n",
      "Epoch 508: val_loss did not improve from 399.50818\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.8844 - mean_absolute_error: 10.1195 - val_loss: 402.0529 - val_mean_absolute_error: 15.0051\n",
      "Epoch 509/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 113.6492 - mean_absolute_error: 7.3089\n",
      "Epoch 509: val_loss improved from 399.50818 to 399.29031, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.8987 - mean_absolute_error: 9.5142 - val_loss: 399.2903 - val_mean_absolute_error: 15.2017\n",
      "Epoch 510/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 199.8994 - mean_absolute_error: 10.6442\n",
      "Epoch 510: val_loss improved from 399.29031 to 398.84616, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.1632 - mean_absolute_error: 9.7781 - val_loss: 398.8462 - val_mean_absolute_error: 15.2252\n",
      "Epoch 511/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 126.7073 - mean_absolute_error: 8.4247\n",
      "Epoch 511: val_loss did not improve from 398.84616\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.9150 - mean_absolute_error: 9.8284 - val_loss: 401.1955 - val_mean_absolute_error: 15.0536\n",
      "Epoch 512/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 283.4050 - mean_absolute_error: 10.7751\n",
      "Epoch 512: val_loss improved from 398.84616 to 397.56506, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.5202 - mean_absolute_error: 9.7282 - val_loss: 397.5651 - val_mean_absolute_error: 15.2185\n",
      "Epoch 513/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 169.4310 - mean_absolute_error: 9.5231\n",
      "Epoch 513: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.3063 - mean_absolute_error: 9.7108 - val_loss: 398.4846 - val_mean_absolute_error: 15.0388\n",
      "Epoch 514/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 319.2355 - mean_absolute_error: 11.9828\n",
      "Epoch 514: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.5616 - mean_absolute_error: 10.1876 - val_loss: 398.0758 - val_mean_absolute_error: 15.1043\n",
      "Epoch 515/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9645 - mean_absolute_error: 9.7720  \n",
      "Epoch 515: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9578 - mean_absolute_error: 9.7674 - val_loss: 398.4453 - val_mean_absolute_error: 15.2084\n",
      "Epoch 516/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 136.5222 - mean_absolute_error: 8.8826\n",
      "Epoch 516: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.2435 - mean_absolute_error: 9.4679 - val_loss: 400.8281 - val_mean_absolute_error: 14.9619\n",
      "Epoch 517/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 132.3013 - mean_absolute_error: 8.7832\n",
      "Epoch 517: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.6022 - mean_absolute_error: 9.7707 - val_loss: 398.8034 - val_mean_absolute_error: 15.0896\n",
      "Epoch 518/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 272.1766 - mean_absolute_error: 10.5323\n",
      "Epoch 518: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.7823 - mean_absolute_error: 9.7137 - val_loss: 401.8849 - val_mean_absolute_error: 15.4128\n",
      "Epoch 519/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 266.6776 - mean_absolute_error: 11.0445\n",
      "Epoch 519: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.4872 - mean_absolute_error: 9.5415 - val_loss: 402.8354 - val_mean_absolute_error: 14.9420\n",
      "Epoch 520/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 109.8958 - mean_absolute_error: 7.1405\n",
      "Epoch 520: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.4388 - mean_absolute_error: 9.6932 - val_loss: 399.7504 - val_mean_absolute_error: 15.2991\n",
      "Epoch 521/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 230.9964 - mean_absolute_error: 10.8058\n",
      "Epoch 521: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.1079 - mean_absolute_error: 9.2788 - val_loss: 400.9488 - val_mean_absolute_error: 14.9914\n",
      "Epoch 522/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 360.2465 - mean_absolute_error: 12.3395\n",
      "Epoch 522: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.6120 - mean_absolute_error: 9.9603 - val_loss: 399.8347 - val_mean_absolute_error: 15.2250\n",
      "Epoch 523/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 146.2350 - mean_absolute_error: 9.4047\n",
      "Epoch 523: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.3595 - mean_absolute_error: 9.3607 - val_loss: 401.9598 - val_mean_absolute_error: 14.9208\n",
      "Epoch 524/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 148.1046 - mean_absolute_error: 8.9408\n",
      "Epoch 524: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.4682 - mean_absolute_error: 9.8307 - val_loss: 399.6015 - val_mean_absolute_error: 15.0966\n",
      "Epoch 525/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 94.5425 - mean_absolute_error: 6.9883\n",
      "Epoch 525: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.9006 - mean_absolute_error: 9.4403 - val_loss: 398.5751 - val_mean_absolute_error: 15.0780\n",
      "Epoch 526/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 224.7769 - mean_absolute_error: 10.5218\n",
      "Epoch 526: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.9873 - mean_absolute_error: 9.5597 - val_loss: 402.9830 - val_mean_absolute_error: 15.4442\n",
      "Epoch 527/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 190.0578 - mean_absolute_error: 8.8570\n",
      "Epoch 527: val_loss did not improve from 397.56506\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.7941 - mean_absolute_error: 9.2459 - val_loss: 398.9814 - val_mean_absolute_error: 15.0637\n",
      "Epoch 528/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 177.9720 - mean_absolute_error: 9.1792\n",
      "Epoch 528: val_loss improved from 397.56506 to 397.21991, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.9043 - mean_absolute_error: 9.4265 - val_loss: 397.2199 - val_mean_absolute_error: 15.0885\n",
      "Epoch 529/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 204.2576 - mean_absolute_error: 9.8171\n",
      "Epoch 529: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.6982 - mean_absolute_error: 10.0233 - val_loss: 401.2731 - val_mean_absolute_error: 15.3442\n",
      "Epoch 530/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 115.1192 - mean_absolute_error: 7.5054\n",
      "Epoch 530: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.5186 - mean_absolute_error: 9.2735 - val_loss: 397.9004 - val_mean_absolute_error: 14.9922\n",
      "Epoch 531/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 159.4321 - mean_absolute_error: 9.1545\n",
      "Epoch 531: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.9995 - mean_absolute_error: 9.5137 - val_loss: 397.3225 - val_mean_absolute_error: 15.1477\n",
      "Epoch 532/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 369.2065 - mean_absolute_error: 14.0144\n",
      "Epoch 532: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.3920 - mean_absolute_error: 10.0131 - val_loss: 397.7033 - val_mean_absolute_error: 15.0894\n",
      "Epoch 533/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 232.8457 - mean_absolute_error: 11.1754\n",
      "Epoch 533: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.3799 - mean_absolute_error: 9.6198 - val_loss: 398.9594 - val_mean_absolute_error: 15.1743\n",
      "Epoch 534/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 87.5312 - mean_absolute_error: 6.9525\n",
      "Epoch 534: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9814 - mean_absolute_error: 9.6130 - val_loss: 399.8865 - val_mean_absolute_error: 14.9227\n",
      "Epoch 535/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 241.9152 - mean_absolute_error: 8.9235\n",
      "Epoch 535: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.6184 - mean_absolute_error: 9.5494 - val_loss: 400.4967 - val_mean_absolute_error: 15.3264\n",
      "Epoch 536/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 189.0240 - mean_absolute_error: 10.5325\n",
      "Epoch 536: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.1295 - mean_absolute_error: 9.7072 - val_loss: 398.2010 - val_mean_absolute_error: 14.9738\n",
      "Epoch 537/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 244.9838 - mean_absolute_error: 11.4122\n",
      "Epoch 537: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.8810 - mean_absolute_error: 9.1803 - val_loss: 397.6431 - val_mean_absolute_error: 15.1003\n",
      "Epoch 538/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 166.8492 - mean_absolute_error: 9.1673\n",
      "Epoch 538: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.6208 - mean_absolute_error: 9.6660 - val_loss: 399.4640 - val_mean_absolute_error: 15.0119\n",
      "Epoch 539/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 160.2371 - mean_absolute_error: 9.9074\n",
      "Epoch 539: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.6635 - mean_absolute_error: 9.9196 - val_loss: 398.3264 - val_mean_absolute_error: 15.0063\n",
      "Epoch 540/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 114.0386 - mean_absolute_error: 8.1395\n",
      "Epoch 540: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.6185 - mean_absolute_error: 9.6005 - val_loss: 397.7577 - val_mean_absolute_error: 15.0157\n",
      "Epoch 541/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 85.7647 - mean_absolute_error: 6.5148\n",
      "Epoch 541: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.1912 - mean_absolute_error: 9.1915 - val_loss: 398.1328 - val_mean_absolute_error: 14.9919\n",
      "Epoch 542/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 342.5731 - mean_absolute_error: 14.1693\n",
      "Epoch 542: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.0490 - mean_absolute_error: 9.8477 - val_loss: 403.8159 - val_mean_absolute_error: 15.5079\n",
      "Epoch 543/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 200.8721 - mean_absolute_error: 10.8208\n",
      "Epoch 543: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.3993 - mean_absolute_error: 10.1559 - val_loss: 403.4482 - val_mean_absolute_error: 14.8762\n",
      "Epoch 544/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 211.6548 - mean_absolute_error: 10.0376\n",
      "Epoch 544: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9574 - mean_absolute_error: 9.5691 - val_loss: 406.7748 - val_mean_absolute_error: 14.8852\n",
      "Epoch 545/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 186.0816 - mean_absolute_error: 8.4231\n",
      "Epoch 545: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.4416 - mean_absolute_error: 9.4481 - val_loss: 398.1172 - val_mean_absolute_error: 15.1454\n",
      "Epoch 546/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 182.3073 - mean_absolute_error: 10.1099\n",
      "Epoch 546: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.2860 - mean_absolute_error: 9.4997 - val_loss: 398.2803 - val_mean_absolute_error: 14.9480\n",
      "Epoch 547/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 179.4680 - mean_absolute_error: 9.0023\n",
      "Epoch 547: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.5225 - mean_absolute_error: 9.9669 - val_loss: 399.6696 - val_mean_absolute_error: 15.2765\n",
      "Epoch 548/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 167.6640 - mean_absolute_error: 10.0716\n",
      "Epoch 548: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.3378 - mean_absolute_error: 9.6277 - val_loss: 399.9852 - val_mean_absolute_error: 15.3153\n",
      "Epoch 549/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 326.0948 - mean_absolute_error: 13.5807\n",
      "Epoch 549: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.4928 - mean_absolute_error: 10.2203 - val_loss: 397.9984 - val_mean_absolute_error: 15.0554\n",
      "Epoch 550/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 208.5162 - mean_absolute_error: 11.1388\n",
      "Epoch 550: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.2925 - mean_absolute_error: 9.8433 - val_loss: 402.0692 - val_mean_absolute_error: 14.9286\n",
      "Epoch 551/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 267.6336 - mean_absolute_error: 10.5814\n",
      "Epoch 551: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.7123 - mean_absolute_error: 9.6866 - val_loss: 398.2303 - val_mean_absolute_error: 15.1047\n",
      "Epoch 552/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 220.9219 - mean_absolute_error: 10.4559\n",
      "Epoch 552: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.2061 - mean_absolute_error: 9.7406 - val_loss: 398.0948 - val_mean_absolute_error: 15.1402\n",
      "Epoch 553/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 266.5650 - mean_absolute_error: 10.3559\n",
      "Epoch 553: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.2237 - mean_absolute_error: 9.7565 - val_loss: 398.6421 - val_mean_absolute_error: 15.1625\n",
      "Epoch 554/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 133.5807 - mean_absolute_error: 7.9544\n",
      "Epoch 554: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4653 - mean_absolute_error: 9.7752 - val_loss: 400.7625 - val_mean_absolute_error: 14.9127\n",
      "Epoch 555/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 258.0546 - mean_absolute_error: 11.1220\n",
      "Epoch 555: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.7455 - mean_absolute_error: 9.7583 - val_loss: 398.0927 - val_mean_absolute_error: 15.1760\n",
      "Epoch 556/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 219.6705 - mean_absolute_error: 9.8985\n",
      "Epoch 556: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.9615 - mean_absolute_error: 9.4821 - val_loss: 399.2323 - val_mean_absolute_error: 15.2044\n",
      "Epoch 557/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 176.1355 - mean_absolute_error: 9.4117\n",
      "Epoch 557: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.5848 - mean_absolute_error: 9.2813 - val_loss: 402.1378 - val_mean_absolute_error: 14.8794\n",
      "Epoch 558/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 526.6489 - mean_absolute_error: 15.0088\n",
      "Epoch 558: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.2049 - mean_absolute_error: 9.9788 - val_loss: 397.5047 - val_mean_absolute_error: 15.2230\n",
      "Epoch 559/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 109.2912 - mean_absolute_error: 8.0496\n",
      "Epoch 559: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.3096 - mean_absolute_error: 9.2179 - val_loss: 397.3478 - val_mean_absolute_error: 15.1006\n",
      "Epoch 560/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 110.5041 - mean_absolute_error: 8.0371\n",
      "Epoch 560: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.9751 - mean_absolute_error: 9.5272 - val_loss: 401.2159 - val_mean_absolute_error: 14.8867\n",
      "Epoch 561/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 274.4572 - mean_absolute_error: 13.1223\n",
      "Epoch 561: val_loss did not improve from 397.21991\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.3447 - mean_absolute_error: 10.2862 - val_loss: 398.4265 - val_mean_absolute_error: 15.0667\n",
      "Epoch 562/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 184.4694 - mean_absolute_error: 9.1663\n",
      "Epoch 562: val_loss improved from 397.21991 to 396.30301, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 197.1700 - mean_absolute_error: 9.5758 - val_loss: 396.3030 - val_mean_absolute_error: 15.1095\n",
      "Epoch 563/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 94.7439 - mean_absolute_error: 6.8610\n",
      "Epoch 563: val_loss did not improve from 396.30301\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.6695 - mean_absolute_error: 9.4163 - val_loss: 397.8998 - val_mean_absolute_error: 15.1686\n",
      "Epoch 564/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 146.8232 - mean_absolute_error: 8.4235\n",
      "Epoch 564: val_loss did not improve from 396.30301\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.9408 - mean_absolute_error: 9.4515 - val_loss: 402.7971 - val_mean_absolute_error: 14.8594\n",
      "Epoch 565/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 120.0899 - mean_absolute_error: 8.0987\n",
      "Epoch 565: val_loss improved from 396.30301 to 396.19373, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.1170 - mean_absolute_error: 9.5431 - val_loss: 396.1937 - val_mean_absolute_error: 15.0993\n",
      "Epoch 566/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 198.4203 - mean_absolute_error: 8.6515\n",
      "Epoch 566: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.8388 - mean_absolute_error: 9.3171 - val_loss: 398.3649 - val_mean_absolute_error: 15.2775\n",
      "Epoch 567/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 348.8082 - mean_absolute_error: 11.7561\n",
      "Epoch 567: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.0474 - mean_absolute_error: 9.9286 - val_loss: 398.7158 - val_mean_absolute_error: 14.9055\n",
      "Epoch 568/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 139.0965 - mean_absolute_error: 8.4736\n",
      "Epoch 568: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.7376 - mean_absolute_error: 9.5567 - val_loss: 397.8862 - val_mean_absolute_error: 15.0604\n",
      "Epoch 569/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 145.0742 - mean_absolute_error: 7.5923\n",
      "Epoch 569: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.6660 - mean_absolute_error: 9.3715 - val_loss: 398.6703 - val_mean_absolute_error: 15.1898\n",
      "Epoch 570/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 307.6420 - mean_absolute_error: 9.8310\n",
      "Epoch 570: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.0309 - mean_absolute_error: 10.3085 - val_loss: 397.3083 - val_mean_absolute_error: 15.1391\n",
      "Epoch 571/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 180.0714 - mean_absolute_error: 9.5819\n",
      "Epoch 571: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.2387 - mean_absolute_error: 9.7274 - val_loss: 397.6225 - val_mean_absolute_error: 15.0247\n",
      "Epoch 572/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 131.8267 - mean_absolute_error: 8.0272\n",
      "Epoch 572: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.9960 - mean_absolute_error: 9.2474 - val_loss: 398.7029 - val_mean_absolute_error: 14.9288\n",
      "Epoch 573/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 165.6469 - mean_absolute_error: 9.4704\n",
      "Epoch 573: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.7188 - mean_absolute_error: 9.2140 - val_loss: 397.1008 - val_mean_absolute_error: 15.0591\n",
      "Epoch 574/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 184.8477 - mean_absolute_error: 9.5245\n",
      "Epoch 574: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.6337 - mean_absolute_error: 9.5766 - val_loss: 397.7547 - val_mean_absolute_error: 14.9218\n",
      "Epoch 575/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 427.6406 - mean_absolute_error: 14.3985\n",
      "Epoch 575: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.9604 - mean_absolute_error: 9.9721 - val_loss: 398.7659 - val_mean_absolute_error: 14.9814\n",
      "Epoch 576/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 146.5087 - mean_absolute_error: 8.8779\n",
      "Epoch 576: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.6122 - mean_absolute_error: 9.5413 - val_loss: 396.2059 - val_mean_absolute_error: 14.9728\n",
      "Epoch 577/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 105.9772 - mean_absolute_error: 7.5938\n",
      "Epoch 577: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.0833 - mean_absolute_error: 9.3777 - val_loss: 397.3778 - val_mean_absolute_error: 15.0174\n",
      "Epoch 578/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 278.9753 - mean_absolute_error: 10.9334\n",
      "Epoch 578: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.0741 - mean_absolute_error: 9.5547 - val_loss: 397.7120 - val_mean_absolute_error: 15.0981\n",
      "Epoch 579/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 197.0573 - mean_absolute_error: 10.3061\n",
      "Epoch 579: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.6749 - mean_absolute_error: 9.7108 - val_loss: 398.5901 - val_mean_absolute_error: 14.8838\n",
      "Epoch 580/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 188.2772 - mean_absolute_error: 9.4021\n",
      "Epoch 580: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.7736 - mean_absolute_error: 9.7169 - val_loss: 397.5261 - val_mean_absolute_error: 15.1919\n",
      "Epoch 581/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 135.3127 - mean_absolute_error: 7.8749\n",
      "Epoch 581: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.7608 - mean_absolute_error: 9.5549 - val_loss: 397.2798 - val_mean_absolute_error: 14.9261\n",
      "Epoch 582/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 207.9594 - mean_absolute_error: 9.9129\n",
      "Epoch 582: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.2951 - mean_absolute_error: 9.5990 - val_loss: 396.4898 - val_mean_absolute_error: 15.0205\n",
      "Epoch 583/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 342.7755 - mean_absolute_error: 11.7431\n",
      "Epoch 583: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.6972 - mean_absolute_error: 10.4509 - val_loss: 397.0399 - val_mean_absolute_error: 15.1173\n",
      "Epoch 584/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 595.0997 - mean_absolute_error: 15.6291\n",
      "Epoch 584: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.2821 - mean_absolute_error: 9.8185 - val_loss: 400.9159 - val_mean_absolute_error: 14.8732\n",
      "Epoch 585/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 236.7442 - mean_absolute_error: 10.7214\n",
      "Epoch 585: val_loss did not improve from 396.19373\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.9242 - mean_absolute_error: 9.9595 - val_loss: 397.2726 - val_mean_absolute_error: 14.9185\n",
      "Epoch 586/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 165.9944 - mean_absolute_error: 8.0923\n",
      "Epoch 586: val_loss improved from 396.19373 to 396.10141, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.7373 - mean_absolute_error: 9.2608 - val_loss: 396.1014 - val_mean_absolute_error: 14.9638\n",
      "Epoch 587/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 207.4235 - mean_absolute_error: 10.9681\n",
      "Epoch 587: val_loss did not improve from 396.10141\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.0214 - mean_absolute_error: 9.7418 - val_loss: 397.2206 - val_mean_absolute_error: 15.0783\n",
      "Epoch 588/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 172.4183 - mean_absolute_error: 8.7232\n",
      "Epoch 588: val_loss did not improve from 396.10141\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.9834 - mean_absolute_error: 9.6038 - val_loss: 397.4353 - val_mean_absolute_error: 14.9954\n",
      "Epoch 589/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 285.0111 - mean_absolute_error: 11.1291\n",
      "Epoch 589: val_loss did not improve from 396.10141\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.3448 - mean_absolute_error: 9.6791 - val_loss: 397.3571 - val_mean_absolute_error: 15.0872\n",
      "Epoch 590/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 165.1457 - mean_absolute_error: 9.0587\n",
      "Epoch 590: val_loss did not improve from 396.10141\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.4209 - mean_absolute_error: 9.3992 - val_loss: 396.8013 - val_mean_absolute_error: 15.0572\n",
      "Epoch 591/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 110.2441 - mean_absolute_error: 8.4697\n",
      "Epoch 591: val_loss improved from 396.10141 to 395.76859, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.9212 - mean_absolute_error: 9.6096 - val_loss: 395.7686 - val_mean_absolute_error: 14.9022\n",
      "Epoch 592/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 119.8974 - mean_absolute_error: 8.0282\n",
      "Epoch 592: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.9081 - mean_absolute_error: 9.5589 - val_loss: 396.1602 - val_mean_absolute_error: 15.0614\n",
      "Epoch 593/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 166.2235 - mean_absolute_error: 8.4851\n",
      "Epoch 593: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.4887 - mean_absolute_error: 9.0683 - val_loss: 397.5674 - val_mean_absolute_error: 15.0845\n",
      "Epoch 594/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 129.0039 - mean_absolute_error: 7.7048\n",
      "Epoch 594: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.1580 - mean_absolute_error: 9.3393 - val_loss: 397.9016 - val_mean_absolute_error: 14.8850\n",
      "Epoch 595/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 199.9902 - mean_absolute_error: 8.2751\n",
      "Epoch 595: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.3130 - mean_absolute_error: 9.0908 - val_loss: 399.2232 - val_mean_absolute_error: 15.1987\n",
      "Epoch 596/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 216.5532 - mean_absolute_error: 10.2430\n",
      "Epoch 596: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.3219 - mean_absolute_error: 9.1590 - val_loss: 397.8114 - val_mean_absolute_error: 15.0190\n",
      "Epoch 597/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 195.2912 - mean_absolute_error: 10.6783\n",
      "Epoch 597: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.5523 - mean_absolute_error: 9.5654 - val_loss: 401.1738 - val_mean_absolute_error: 15.3634\n",
      "Epoch 598/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 162.3333 - mean_absolute_error: 8.6321\n",
      "Epoch 598: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 183.3113 - mean_absolute_error: 9.3817 - val_loss: 399.4326 - val_mean_absolute_error: 15.3283\n",
      "Epoch 599/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 103.1767 - mean_absolute_error: 7.7611\n",
      "Epoch 599: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.2676 - mean_absolute_error: 9.3259 - val_loss: 399.6681 - val_mean_absolute_error: 14.8829\n",
      "Epoch 600/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 109.6417 - mean_absolute_error: 7.3851\n",
      "Epoch 600: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.3117 - mean_absolute_error: 9.3116 - val_loss: 397.9999 - val_mean_absolute_error: 14.8813\n",
      "Epoch 601/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 145.1610 - mean_absolute_error: 8.0822\n",
      "Epoch 601: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.9353 - mean_absolute_error: 9.2724 - val_loss: 400.5502 - val_mean_absolute_error: 14.9436\n",
      "Epoch 602/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 94.0385 - mean_absolute_error: 7.2541\n",
      "Epoch 602: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.0194 - mean_absolute_error: 9.6733 - val_loss: 399.6177 - val_mean_absolute_error: 15.3397\n",
      "Epoch 603/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 114.7188 - mean_absolute_error: 8.5249\n",
      "Epoch 603: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.2623 - mean_absolute_error: 9.7803 - val_loss: 397.7572 - val_mean_absolute_error: 15.0428\n",
      "Epoch 604/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 145.2271 - mean_absolute_error: 8.5920\n",
      "Epoch 604: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 168.8237 - mean_absolute_error: 9.1462 - val_loss: 396.1028 - val_mean_absolute_error: 15.0896\n",
      "Epoch 605/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 106.3447 - mean_absolute_error: 6.6785\n",
      "Epoch 605: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.6918 - mean_absolute_error: 9.4517 - val_loss: 397.2885 - val_mean_absolute_error: 14.9818\n",
      "Epoch 606/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 151.1210 - mean_absolute_error: 9.1540\n",
      "Epoch 606: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.2554 - mean_absolute_error: 9.5447 - val_loss: 396.6496 - val_mean_absolute_error: 15.1578\n",
      "Epoch 607/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 130.9158 - mean_absolute_error: 8.4613\n",
      "Epoch 607: val_loss did not improve from 395.76859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.5641 - mean_absolute_error: 9.8080 - val_loss: 396.9212 - val_mean_absolute_error: 15.0715\n",
      "Epoch 608/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 142.6881 - mean_absolute_error: 8.9808\n",
      "Epoch 608: val_loss improved from 395.76859 to 394.83792, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.8510 - mean_absolute_error: 9.4799 - val_loss: 394.8379 - val_mean_absolute_error: 15.1135\n",
      "Epoch 609/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 392.0794 - mean_absolute_error: 12.2249\n",
      "Epoch 609: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.4713 - mean_absolute_error: 10.1748 - val_loss: 396.5603 - val_mean_absolute_error: 15.0473\n",
      "Epoch 610/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 223.9608 - mean_absolute_error: 11.4316\n",
      "Epoch 610: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.9733 - mean_absolute_error: 9.6397 - val_loss: 399.4117 - val_mean_absolute_error: 14.8345\n",
      "Epoch 611/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 245.2215 - mean_absolute_error: 12.0957\n",
      "Epoch 611: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.5609 - mean_absolute_error: 9.9881 - val_loss: 396.2401 - val_mean_absolute_error: 15.1354\n",
      "Epoch 612/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 271.0713 - mean_absolute_error: 11.6424\n",
      "Epoch 612: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.5028 - mean_absolute_error: 9.8288 - val_loss: 398.1336 - val_mean_absolute_error: 15.0962\n",
      "Epoch 613/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 226.7915 - mean_absolute_error: 9.5526\n",
      "Epoch 613: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.1798 - mean_absolute_error: 9.4063 - val_loss: 397.1047 - val_mean_absolute_error: 15.0656\n",
      "Epoch 614/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 140.9795 - mean_absolute_error: 8.6577\n",
      "Epoch 614: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165.6958 - mean_absolute_error: 8.9532 - val_loss: 400.9737 - val_mean_absolute_error: 14.8732\n",
      "Epoch 615/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 199.8970 - mean_absolute_error: 10.1304\n",
      "Epoch 615: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.7626 - mean_absolute_error: 9.6372 - val_loss: 396.4880 - val_mean_absolute_error: 14.8809\n",
      "Epoch 616/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 123.1227 - mean_absolute_error: 7.7732\n",
      "Epoch 616: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.1834 - mean_absolute_error: 9.1632 - val_loss: 398.7292 - val_mean_absolute_error: 14.9818\n",
      "Epoch 617/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 194.6960 - mean_absolute_error: 11.3239\n",
      "Epoch 617: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.8704 - mean_absolute_error: 9.6175 - val_loss: 396.1892 - val_mean_absolute_error: 14.8876\n",
      "Epoch 618/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 263.1499 - mean_absolute_error: 10.0197\n",
      "Epoch 618: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.7508 - mean_absolute_error: 9.6355 - val_loss: 398.2336 - val_mean_absolute_error: 15.2599\n",
      "Epoch 619/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 283.1151 - mean_absolute_error: 11.6649\n",
      "Epoch 619: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.7881 - mean_absolute_error: 9.7685 - val_loss: 399.2588 - val_mean_absolute_error: 15.0680\n",
      "Epoch 620/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 141.4072 - mean_absolute_error: 8.8498\n",
      "Epoch 620: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.7032 - mean_absolute_error: 9.2086 - val_loss: 397.9893 - val_mean_absolute_error: 15.0066\n",
      "Epoch 621/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 111.9465 - mean_absolute_error: 8.1739\n",
      "Epoch 621: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.1010 - mean_absolute_error: 8.8775 - val_loss: 401.6536 - val_mean_absolute_error: 14.8607\n",
      "Epoch 622/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 136.6505 - mean_absolute_error: 8.8747\n",
      "Epoch 622: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.9075 - mean_absolute_error: 9.4568 - val_loss: 396.8247 - val_mean_absolute_error: 14.9813\n",
      "Epoch 623/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.2719 - mean_absolute_error: 5.4781\n",
      "Epoch 623: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.2210 - mean_absolute_error: 9.6077 - val_loss: 397.4638 - val_mean_absolute_error: 15.1623\n",
      "Epoch 624/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 263.6656 - mean_absolute_error: 12.0512\n",
      "Epoch 624: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.9080 - mean_absolute_error: 10.0724 - val_loss: 396.8092 - val_mean_absolute_error: 14.9379\n",
      "Epoch 625/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 95.7132 - mean_absolute_error: 7.6263\n",
      "Epoch 625: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.6534 - mean_absolute_error: 9.6842 - val_loss: 399.5897 - val_mean_absolute_error: 14.9415\n",
      "Epoch 626/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 217.9705 - mean_absolute_error: 10.9081\n",
      "Epoch 626: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 171.6596 - mean_absolute_error: 9.1775 - val_loss: 397.9266 - val_mean_absolute_error: 14.9811\n",
      "Epoch 627/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 299.8561 - mean_absolute_error: 12.8804\n",
      "Epoch 627: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.5840 - mean_absolute_error: 9.5476 - val_loss: 397.6967 - val_mean_absolute_error: 14.9521\n",
      "Epoch 628/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 115.0196 - mean_absolute_error: 7.8425\n",
      "Epoch 628: val_loss did not improve from 394.83792\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.4530 - mean_absolute_error: 9.2085 - val_loss: 397.2957 - val_mean_absolute_error: 15.0692\n",
      "Epoch 629/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 219.6096 - mean_absolute_error: 10.3000\n",
      "Epoch 629: val_loss improved from 394.83792 to 394.62750, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.2701 - mean_absolute_error: 9.4522 - val_loss: 394.6275 - val_mean_absolute_error: 14.9430\n",
      "Epoch 630/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 106.5097 - mean_absolute_error: 7.5246\n",
      "Epoch 630: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.9653 - mean_absolute_error: 9.6976 - val_loss: 396.7094 - val_mean_absolute_error: 14.8609\n",
      "Epoch 631/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 125.0698 - mean_absolute_error: 8.2563\n",
      "Epoch 631: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.2754 - mean_absolute_error: 9.4537 - val_loss: 397.4295 - val_mean_absolute_error: 14.9179\n",
      "Epoch 632/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 340.9453 - mean_absolute_error: 11.5790\n",
      "Epoch 632: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.8325 - mean_absolute_error: 9.8525 - val_loss: 396.1819 - val_mean_absolute_error: 15.0877\n",
      "Epoch 633/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 130.6687 - mean_absolute_error: 8.0902\n",
      "Epoch 633: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.9138 - mean_absolute_error: 9.6065 - val_loss: 396.7368 - val_mean_absolute_error: 15.0827\n",
      "Epoch 634/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 271.6516 - mean_absolute_error: 10.8741\n",
      "Epoch 634: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.5613 - mean_absolute_error: 9.7302 - val_loss: 396.0879 - val_mean_absolute_error: 15.1655\n",
      "Epoch 635/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 289.0121 - mean_absolute_error: 12.3418\n",
      "Epoch 635: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.4736 - mean_absolute_error: 9.7919 - val_loss: 402.9276 - val_mean_absolute_error: 14.8618\n",
      "Epoch 636/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 246.8208 - mean_absolute_error: 11.1586\n",
      "Epoch 636: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.5028 - mean_absolute_error: 9.8396 - val_loss: 396.2388 - val_mean_absolute_error: 15.0394\n",
      "Epoch 637/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 272.7941 - mean_absolute_error: 12.3112\n",
      "Epoch 637: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.2104 - mean_absolute_error: 9.9455 - val_loss: 395.7230 - val_mean_absolute_error: 14.9632\n",
      "Epoch 638/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 135.6930 - mean_absolute_error: 8.2650\n",
      "Epoch 638: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.2448 - mean_absolute_error: 9.0416 - val_loss: 396.2987 - val_mean_absolute_error: 15.1566\n",
      "Epoch 639/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 140.0628 - mean_absolute_error: 8.1410\n",
      "Epoch 639: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.5699 - mean_absolute_error: 9.3869 - val_loss: 396.9438 - val_mean_absolute_error: 14.8636\n",
      "Epoch 640/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 198.7435 - mean_absolute_error: 10.7879\n",
      "Epoch 640: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.6311 - mean_absolute_error: 9.8939 - val_loss: 396.7275 - val_mean_absolute_error: 14.9760\n",
      "Epoch 641/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 128.5341 - mean_absolute_error: 7.8782\n",
      "Epoch 641: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.3466 - mean_absolute_error: 9.6431 - val_loss: 394.7268 - val_mean_absolute_error: 14.9919\n",
      "Epoch 642/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 91.1357 - mean_absolute_error: 6.3717\n",
      "Epoch 642: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.8201 - mean_absolute_error: 9.4584 - val_loss: 395.6753 - val_mean_absolute_error: 15.0431\n",
      "Epoch 643/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 210.1422 - mean_absolute_error: 10.8637\n",
      "Epoch 643: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.2778 - mean_absolute_error: 9.6428 - val_loss: 399.1635 - val_mean_absolute_error: 14.8191\n",
      "Epoch 644/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 171.5970 - mean_absolute_error: 9.4353\n",
      "Epoch 644: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.1400 - mean_absolute_error: 9.6890 - val_loss: 395.5280 - val_mean_absolute_error: 15.0248\n",
      "Epoch 645/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 341.3544 - mean_absolute_error: 11.3516\n",
      "Epoch 645: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.2956 - mean_absolute_error: 9.9427 - val_loss: 399.8203 - val_mean_absolute_error: 14.8523\n",
      "Epoch 646/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 317.9353 - mean_absolute_error: 9.3852\n",
      "Epoch 646: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.7708 - mean_absolute_error: 9.2907 - val_loss: 398.0058 - val_mean_absolute_error: 14.8885\n",
      "Epoch 647/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 207.7295 - mean_absolute_error: 10.3744\n",
      "Epoch 647: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.5524 - mean_absolute_error: 9.7409 - val_loss: 395.9059 - val_mean_absolute_error: 15.0319\n",
      "Epoch 648/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 229.2757 - mean_absolute_error: 11.0571\n",
      "Epoch 648: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.7870 - mean_absolute_error: 9.6020 - val_loss: 398.1401 - val_mean_absolute_error: 14.8946\n",
      "Epoch 649/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 219.8908 - mean_absolute_error: 9.7304\n",
      "Epoch 649: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.9840 - mean_absolute_error: 9.3940 - val_loss: 395.8116 - val_mean_absolute_error: 15.0905\n",
      "Epoch 650/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 160.9830 - mean_absolute_error: 9.2752\n",
      "Epoch 650: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.1567 - mean_absolute_error: 9.4134 - val_loss: 396.6001 - val_mean_absolute_error: 14.9256\n",
      "Epoch 651/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 402.4281 - mean_absolute_error: 14.9470\n",
      "Epoch 651: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.9449 - mean_absolute_error: 9.8208 - val_loss: 403.9143 - val_mean_absolute_error: 14.8563\n",
      "Epoch 652/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 225.3494 - mean_absolute_error: 10.5637\n",
      "Epoch 652: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.0739 - mean_absolute_error: 9.8549 - val_loss: 396.1153 - val_mean_absolute_error: 15.1192\n",
      "Epoch 653/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 157.8361 - mean_absolute_error: 8.6374\n",
      "Epoch 653: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.6088 - mean_absolute_error: 9.1817 - val_loss: 400.9192 - val_mean_absolute_error: 14.8531\n",
      "Epoch 654/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 351.6324 - mean_absolute_error: 13.1080\n",
      "Epoch 654: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.3776 - mean_absolute_error: 9.7100 - val_loss: 395.1140 - val_mean_absolute_error: 15.0943\n",
      "Epoch 655/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81.7385 - mean_absolute_error: 6.0261\n",
      "Epoch 655: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.3269 - mean_absolute_error: 9.1469 - val_loss: 398.2708 - val_mean_absolute_error: 15.2865\n",
      "Epoch 656/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.2449 - mean_absolute_error: 9.3334 \n",
      "Epoch 656: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.4999 - mean_absolute_error: 9.3616 - val_loss: 396.4851 - val_mean_absolute_error: 14.9351\n",
      "Epoch 657/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 348.6187 - mean_absolute_error: 13.8331\n",
      "Epoch 657: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.4330 - mean_absolute_error: 10.1693 - val_loss: 401.1097 - val_mean_absolute_error: 14.8492\n",
      "Epoch 658/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 170.2124 - mean_absolute_error: 9.5214\n",
      "Epoch 658: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.8047 - mean_absolute_error: 9.8712 - val_loss: 397.3931 - val_mean_absolute_error: 15.1521\n",
      "Epoch 659/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 165.4708 - mean_absolute_error: 7.5797\n",
      "Epoch 659: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.9954 - mean_absolute_error: 9.7943 - val_loss: 397.4461 - val_mean_absolute_error: 14.8850\n",
      "Epoch 660/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 213.1141 - mean_absolute_error: 10.6790\n",
      "Epoch 660: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.0606 - mean_absolute_error: 9.6436 - val_loss: 398.8520 - val_mean_absolute_error: 14.8662\n",
      "Epoch 661/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 131.8583 - mean_absolute_error: 8.2533\n",
      "Epoch 661: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.1154 - mean_absolute_error: 9.5193 - val_loss: 397.3677 - val_mean_absolute_error: 15.0179\n",
      "Epoch 662/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 368.4112 - mean_absolute_error: 11.6961\n",
      "Epoch 662: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.9596 - mean_absolute_error: 10.1378 - val_loss: 396.8170 - val_mean_absolute_error: 15.1001\n",
      "Epoch 663/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 250.9104 - mean_absolute_error: 9.0685\n",
      "Epoch 663: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.0840 - mean_absolute_error: 9.9777 - val_loss: 396.2263 - val_mean_absolute_error: 15.0134\n",
      "Epoch 664/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 253.4051 - mean_absolute_error: 9.7591\n",
      "Epoch 664: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4014 - mean_absolute_error: 9.7594 - val_loss: 398.1957 - val_mean_absolute_error: 14.8951\n",
      "Epoch 665/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 174.0552 - mean_absolute_error: 7.5658\n",
      "Epoch 665: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.3580 - mean_absolute_error: 9.5186 - val_loss: 396.5125 - val_mean_absolute_error: 15.0866\n",
      "Epoch 666/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 345.7820 - mean_absolute_error: 12.4341\n",
      "Epoch 666: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.7594 - mean_absolute_error: 9.9598 - val_loss: 398.3357 - val_mean_absolute_error: 15.0673\n",
      "Epoch 667/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 94.5052 - mean_absolute_error: 7.3939\n",
      "Epoch 667: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.2229 - mean_absolute_error: 9.4652 - val_loss: 397.7278 - val_mean_absolute_error: 15.2208\n",
      "Epoch 668/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 100.2946 - mean_absolute_error: 7.0912\n",
      "Epoch 668: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.3637 - mean_absolute_error: 9.0498 - val_loss: 396.9215 - val_mean_absolute_error: 14.9255\n",
      "Epoch 669/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 119.5031 - mean_absolute_error: 7.9461\n",
      "Epoch 669: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.8101 - mean_absolute_error: 9.2098 - val_loss: 397.4314 - val_mean_absolute_error: 15.0385\n",
      "Epoch 670/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 117.1486 - mean_absolute_error: 7.6807\n",
      "Epoch 670: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.4177 - mean_absolute_error: 9.5207 - val_loss: 398.2435 - val_mean_absolute_error: 15.1070\n",
      "Epoch 671/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 247.2100 - mean_absolute_error: 11.5957\n",
      "Epoch 671: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 185.8689 - mean_absolute_error: 9.4384 - val_loss: 395.3385 - val_mean_absolute_error: 15.0314\n",
      "Epoch 672/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 146.7788 - mean_absolute_error: 8.3118\n",
      "Epoch 672: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.7760 - mean_absolute_error: 9.8690 - val_loss: 397.8944 - val_mean_absolute_error: 14.8542\n",
      "Epoch 673/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 160.9993 - mean_absolute_error: 9.0524\n",
      "Epoch 673: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.3052 - mean_absolute_error: 9.4074 - val_loss: 397.1280 - val_mean_absolute_error: 15.0541\n",
      "Epoch 674/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 410.4445 - mean_absolute_error: 14.0903\n",
      "Epoch 674: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.4945 - mean_absolute_error: 9.9626 - val_loss: 404.6638 - val_mean_absolute_error: 14.9337\n",
      "Epoch 675/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 261.2655 - mean_absolute_error: 12.0490\n",
      "Epoch 675: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.5213 - mean_absolute_error: 9.8566 - val_loss: 395.9514 - val_mean_absolute_error: 14.9828\n",
      "Epoch 676/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.9011 - mean_absolute_error: 9.0928\n",
      "Epoch 676: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.7750 - mean_absolute_error: 9.6044 - val_loss: 394.9426 - val_mean_absolute_error: 14.9568\n",
      "Epoch 677/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 121.1704 - mean_absolute_error: 7.5440\n",
      "Epoch 677: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.8301 - mean_absolute_error: 9.2545 - val_loss: 397.0293 - val_mean_absolute_error: 14.9523\n",
      "Epoch 678/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 118.9605 - mean_absolute_error: 8.1336\n",
      "Epoch 678: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.5688 - mean_absolute_error: 9.1959 - val_loss: 397.0621 - val_mean_absolute_error: 15.0201\n",
      "Epoch 679/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 291.9138 - mean_absolute_error: 13.5522\n",
      "Epoch 679: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.2473 - mean_absolute_error: 9.6626 - val_loss: 396.8891 - val_mean_absolute_error: 14.9871\n",
      "Epoch 680/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 204.8172 - mean_absolute_error: 9.7660\n",
      "Epoch 680: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.1860 - mean_absolute_error: 9.8002 - val_loss: 395.2076 - val_mean_absolute_error: 15.0740\n",
      "Epoch 681/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 269.4426 - mean_absolute_error: 11.2033\n",
      "Epoch 681: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.5656 - mean_absolute_error: 9.6726 - val_loss: 401.1381 - val_mean_absolute_error: 14.8558\n",
      "Epoch 682/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 145.6422 - mean_absolute_error: 8.6897\n",
      "Epoch 682: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.1679 - mean_absolute_error: 9.4608 - val_loss: 401.9741 - val_mean_absolute_error: 14.8736\n",
      "Epoch 683/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 334.7192 - mean_absolute_error: 13.2309\n",
      "Epoch 683: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.1678 - mean_absolute_error: 9.8572 - val_loss: 398.1729 - val_mean_absolute_error: 15.1589\n",
      "Epoch 684/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 149.1415 - mean_absolute_error: 8.3429\n",
      "Epoch 684: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.4375 - mean_absolute_error: 9.5201 - val_loss: 397.8791 - val_mean_absolute_error: 14.8680\n",
      "Epoch 685/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 90.8756 - mean_absolute_error: 6.5902\n",
      "Epoch 685: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.4639 - mean_absolute_error: 9.1777 - val_loss: 397.6160 - val_mean_absolute_error: 15.0102\n",
      "Epoch 686/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 226.4709 - mean_absolute_error: 11.3117\n",
      "Epoch 686: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.7612 - mean_absolute_error: 9.5467 - val_loss: 394.9930 - val_mean_absolute_error: 14.9470\n",
      "Epoch 687/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 168.0716 - mean_absolute_error: 7.6278\n",
      "Epoch 687: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.0299 - mean_absolute_error: 9.3230 - val_loss: 395.8840 - val_mean_absolute_error: 14.8829\n",
      "Epoch 688/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 147.3542 - mean_absolute_error: 8.2238\n",
      "Epoch 688: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.4713 - mean_absolute_error: 9.6626 - val_loss: 394.7782 - val_mean_absolute_error: 14.8691\n",
      "Epoch 689/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 169.7485 - mean_absolute_error: 9.6452\n",
      "Epoch 689: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.5461 - mean_absolute_error: 9.3704 - val_loss: 395.0893 - val_mean_absolute_error: 14.9757\n",
      "Epoch 690/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 126.5207 - mean_absolute_error: 8.1056\n",
      "Epoch 690: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.4845 - mean_absolute_error: 9.5393 - val_loss: 395.1262 - val_mean_absolute_error: 14.9356\n",
      "Epoch 691/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 194.5648 - mean_absolute_error: 10.2945\n",
      "Epoch 691: val_loss did not improve from 394.62750\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.9325 - mean_absolute_error: 9.3583 - val_loss: 399.5193 - val_mean_absolute_error: 14.8555\n",
      "Epoch 692/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 166.2192 - mean_absolute_error: 9.8833\n",
      "Epoch 692: val_loss improved from 394.62750 to 393.81134, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 217.8483 - mean_absolute_error: 10.0011 - val_loss: 393.8113 - val_mean_absolute_error: 14.9263\n",
      "Epoch 693/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 200.8373 - mean_absolute_error: 10.9550\n",
      "Epoch 693: val_loss improved from 393.81134 to 393.64859, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.3677 - mean_absolute_error: 9.7420 - val_loss: 393.6486 - val_mean_absolute_error: 15.0360\n",
      "Epoch 694/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 162.0063 - mean_absolute_error: 8.6214\n",
      "Epoch 694: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 188.2317 - mean_absolute_error: 9.2656 - val_loss: 395.8149 - val_mean_absolute_error: 14.8562\n",
      "Epoch 695/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 193.9898 - mean_absolute_error: 10.8852\n",
      "Epoch 695: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.4945 - mean_absolute_error: 10.3391 - val_loss: 398.1172 - val_mean_absolute_error: 14.8588\n",
      "Epoch 696/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 164.5171 - mean_absolute_error: 10.2255\n",
      "Epoch 696: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.5284 - mean_absolute_error: 9.4080 - val_loss: 395.4805 - val_mean_absolute_error: 14.8950\n",
      "Epoch 697/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 167.6753 - mean_absolute_error: 8.6340\n",
      "Epoch 697: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.2077 - mean_absolute_error: 9.5603 - val_loss: 394.1764 - val_mean_absolute_error: 14.9444\n",
      "Epoch 698/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 212.6033 - mean_absolute_error: 8.6592\n",
      "Epoch 698: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.4005 - mean_absolute_error: 9.7132 - val_loss: 401.1623 - val_mean_absolute_error: 14.8658\n",
      "Epoch 699/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 240.5694 - mean_absolute_error: 10.9250\n",
      "Epoch 699: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4221 - mean_absolute_error: 9.6589 - val_loss: 394.6820 - val_mean_absolute_error: 15.0244\n",
      "Epoch 700/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 208.0411 - mean_absolute_error: 9.9278\n",
      "Epoch 700: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.0955 - mean_absolute_error: 9.7210 - val_loss: 395.6984 - val_mean_absolute_error: 15.0136\n",
      "Epoch 701/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 169.9377 - mean_absolute_error: 9.3698\n",
      "Epoch 701: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.5061 - mean_absolute_error: 9.7441 - val_loss: 395.1927 - val_mean_absolute_error: 14.8906\n",
      "Epoch 702/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 229.4783 - mean_absolute_error: 10.6464\n",
      "Epoch 702: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3690 - mean_absolute_error: 9.9484 - val_loss: 394.8958 - val_mean_absolute_error: 14.9022\n",
      "Epoch 703/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 127.6507 - mean_absolute_error: 7.9785\n",
      "Epoch 703: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.1598 - mean_absolute_error: 9.2822 - val_loss: 393.7516 - val_mean_absolute_error: 15.0278\n",
      "Epoch 704/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 130.5188 - mean_absolute_error: 8.6206\n",
      "Epoch 704: val_loss did not improve from 393.64859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 165.9654 - mean_absolute_error: 9.1654 - val_loss: 399.3230 - val_mean_absolute_error: 14.8605\n",
      "Epoch 705/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 227.7298 - mean_absolute_error: 10.4602\n",
      "Epoch 705: val_loss improved from 393.64859 to 393.10785, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.3329 - mean_absolute_error: 10.0876 - val_loss: 393.1078 - val_mean_absolute_error: 14.9668\n",
      "Epoch 706/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 270.4374 - mean_absolute_error: 11.1515\n",
      "Epoch 706: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.6511 - mean_absolute_error: 9.4907 - val_loss: 397.7102 - val_mean_absolute_error: 14.8438\n",
      "Epoch 707/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 114.6570 - mean_absolute_error: 8.2157\n",
      "Epoch 707: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.8624 - mean_absolute_error: 9.5279 - val_loss: 393.3811 - val_mean_absolute_error: 14.8807\n",
      "Epoch 708/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.6714 - mean_absolute_error: 6.0100\n",
      "Epoch 708: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 149.9547 - mean_absolute_error: 8.5333 - val_loss: 394.3453 - val_mean_absolute_error: 14.8864\n",
      "Epoch 709/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 138.5764 - mean_absolute_error: 8.8878\n",
      "Epoch 709: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.3718 - mean_absolute_error: 9.4079 - val_loss: 393.4897 - val_mean_absolute_error: 14.8542\n",
      "Epoch 710/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.7504 - mean_absolute_error: 8.6356\n",
      "Epoch 710: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 176.3174 - mean_absolute_error: 9.2523 - val_loss: 393.7422 - val_mean_absolute_error: 14.8735\n",
      "Epoch 711/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 239.1029 - mean_absolute_error: 12.0345\n",
      "Epoch 711: val_loss did not improve from 393.10785\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.2405 - mean_absolute_error: 9.9102 - val_loss: 401.3673 - val_mean_absolute_error: 14.8763\n",
      "Epoch 712/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 108.1812 - mean_absolute_error: 7.7447\n",
      "Epoch 712: val_loss improved from 393.10785 to 393.06430, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.2974 - mean_absolute_error: 9.4610 - val_loss: 393.0643 - val_mean_absolute_error: 15.1139\n",
      "Epoch 713/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 187.3093 - mean_absolute_error: 9.8415\n",
      "Epoch 713: val_loss improved from 393.06430 to 392.76791, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.3489 - mean_absolute_error: 9.6541 - val_loss: 392.7679 - val_mean_absolute_error: 14.8681\n",
      "Epoch 714/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 214.9913 - mean_absolute_error: 10.0617\n",
      "Epoch 714: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.6886 - mean_absolute_error: 9.8012 - val_loss: 394.0503 - val_mean_absolute_error: 15.0343\n",
      "Epoch 715/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 201.8544 - mean_absolute_error: 10.2599\n",
      "Epoch 715: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.0554 - mean_absolute_error: 9.5341 - val_loss: 393.8172 - val_mean_absolute_error: 15.0584\n",
      "Epoch 716/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 77.9186 - mean_absolute_error: 6.6598\n",
      "Epoch 716: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.8722 - mean_absolute_error: 9.6865 - val_loss: 397.9772 - val_mean_absolute_error: 14.8493\n",
      "Epoch 717/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 178.0980 - mean_absolute_error: 8.4333\n",
      "Epoch 717: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.7664 - mean_absolute_error: 9.5400 - val_loss: 394.9933 - val_mean_absolute_error: 15.1443\n",
      "Epoch 718/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 94.0604 - mean_absolute_error: 6.9471\n",
      "Epoch 718: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.1333 - mean_absolute_error: 9.2557 - val_loss: 396.8743 - val_mean_absolute_error: 14.8517\n",
      "Epoch 719/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 140.1858 - mean_absolute_error: 8.7116\n",
      "Epoch 719: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.9925 - mean_absolute_error: 8.7176 - val_loss: 394.0251 - val_mean_absolute_error: 14.8684\n",
      "Epoch 720/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 211.8483 - mean_absolute_error: 9.7173\n",
      "Epoch 720: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.9697 - mean_absolute_error: 9.4686 - val_loss: 393.5340 - val_mean_absolute_error: 15.1191\n",
      "Epoch 721/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 225.9383 - mean_absolute_error: 9.5840\n",
      "Epoch 721: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.6577 - mean_absolute_error: 9.7629 - val_loss: 399.7086 - val_mean_absolute_error: 14.8753\n",
      "Epoch 722/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 138.8119 - mean_absolute_error: 8.3481\n",
      "Epoch 722: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.6819 - mean_absolute_error: 9.5423 - val_loss: 393.2180 - val_mean_absolute_error: 14.9211\n",
      "Epoch 723/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 70.8710 - mean_absolute_error: 5.8285\n",
      "Epoch 723: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.0613 - mean_absolute_error: 9.1179 - val_loss: 397.9540 - val_mean_absolute_error: 14.8549\n",
      "Epoch 724/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 279.9161 - mean_absolute_error: 10.2303\n",
      "Epoch 724: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.3755 - mean_absolute_error: 9.6768 - val_loss: 393.4371 - val_mean_absolute_error: 14.9900\n",
      "Epoch 725/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 183.5592 - mean_absolute_error: 9.5542\n",
      "Epoch 725: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 174.4213 - mean_absolute_error: 9.2508 - val_loss: 397.0561 - val_mean_absolute_error: 14.8564\n",
      "Epoch 726/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 375.7287 - mean_absolute_error: 11.1843\n",
      "Epoch 726: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.2587 - mean_absolute_error: 9.8302 - val_loss: 394.5225 - val_mean_absolute_error: 14.9145\n",
      "Epoch 727/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 189.3365 - mean_absolute_error: 8.2498\n",
      "Epoch 727: val_loss did not improve from 392.76791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.5144 - mean_absolute_error: 9.3529 - val_loss: 393.6182 - val_mean_absolute_error: 15.0327\n",
      "Epoch 728/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 138.6263 - mean_absolute_error: 8.0737\n",
      "Epoch 728: val_loss improved from 392.76791 to 392.24133, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.2337 - mean_absolute_error: 9.2141 - val_loss: 392.2413 - val_mean_absolute_error: 14.8981\n",
      "Epoch 729/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 185.3577 - mean_absolute_error: 9.7471\n",
      "Epoch 729: val_loss did not improve from 392.24133\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.1956 - mean_absolute_error: 9.3919 - val_loss: 394.1133 - val_mean_absolute_error: 14.8785\n",
      "Epoch 730/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 145.4827 - mean_absolute_error: 9.1466\n",
      "Epoch 730: val_loss did not improve from 392.24133\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.5237 - mean_absolute_error: 9.4534 - val_loss: 393.6792 - val_mean_absolute_error: 14.9013\n",
      "Epoch 731/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 202.7578 - mean_absolute_error: 9.8839\n",
      "Epoch 731: val_loss did not improve from 392.24133\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.8908 - mean_absolute_error: 9.2761 - val_loss: 393.2162 - val_mean_absolute_error: 15.0127\n",
      "Epoch 732/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 114.8973 - mean_absolute_error: 7.7168\n",
      "Epoch 732: val_loss did not improve from 392.24133\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.2915 - mean_absolute_error: 9.4686 - val_loss: 400.2906 - val_mean_absolute_error: 14.8521\n",
      "Epoch 733/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 275.9957 - mean_absolute_error: 11.8502\n",
      "Epoch 733: val_loss improved from 392.24133 to 391.83966, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.1945 - mean_absolute_error: 9.3959 - val_loss: 391.8397 - val_mean_absolute_error: 14.8589\n",
      "Epoch 734/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 106.5602 - mean_absolute_error: 7.7461\n",
      "Epoch 734: val_loss did not improve from 391.83966\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.9399 - mean_absolute_error: 9.5391 - val_loss: 393.5019 - val_mean_absolute_error: 14.8506\n",
      "Epoch 735/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 135.2182 - mean_absolute_error: 8.4572\n",
      "Epoch 735: val_loss did not improve from 391.83966\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.3120 - mean_absolute_error: 9.5807 - val_loss: 398.5697 - val_mean_absolute_error: 14.9136\n",
      "Epoch 736/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 253.3192 - mean_absolute_error: 10.7784\n",
      "Epoch 736: val_loss did not improve from 391.83966\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.1111 - mean_absolute_error: 9.6279 - val_loss: 394.2224 - val_mean_absolute_error: 14.8726\n",
      "Epoch 737/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 197.0224 - mean_absolute_error: 10.3566\n",
      "Epoch 737: val_loss improved from 391.83966 to 391.51135, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.7291 - mean_absolute_error: 9.4873 - val_loss: 391.5114 - val_mean_absolute_error: 14.9264\n",
      "Epoch 738/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 134.3341 - mean_absolute_error: 8.3564\n",
      "Epoch 738: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.4816 - mean_absolute_error: 9.5170 - val_loss: 392.7258 - val_mean_absolute_error: 14.9114\n",
      "Epoch 739/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 218.0545 - mean_absolute_error: 10.4544\n",
      "Epoch 739: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.2634 - mean_absolute_error: 9.7257 - val_loss: 395.6566 - val_mean_absolute_error: 14.8758\n",
      "Epoch 740/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 117.7999 - mean_absolute_error: 7.0534\n",
      "Epoch 740: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.5909 - mean_absolute_error: 9.5352 - val_loss: 394.9662 - val_mean_absolute_error: 14.8882\n",
      "Epoch 741/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 224.6821 - mean_absolute_error: 10.1403\n",
      "Epoch 741: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.0913 - mean_absolute_error: 9.4462 - val_loss: 395.7535 - val_mean_absolute_error: 15.2326\n",
      "Epoch 742/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 173.6013 - mean_absolute_error: 9.4440\n",
      "Epoch 742: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.1809 - mean_absolute_error: 9.7150 - val_loss: 394.3339 - val_mean_absolute_error: 14.9889\n",
      "Epoch 743/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 276.2147 - mean_absolute_error: 11.7589\n",
      "Epoch 743: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.2511 - mean_absolute_error: 10.0296 - val_loss: 394.2861 - val_mean_absolute_error: 14.8704\n",
      "Epoch 744/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 166.0629 - mean_absolute_error: 8.4708\n",
      "Epoch 744: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.3385 - mean_absolute_error: 9.6052 - val_loss: 394.7287 - val_mean_absolute_error: 15.0316\n",
      "Epoch 745/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 103.3802 - mean_absolute_error: 7.6604\n",
      "Epoch 745: val_loss did not improve from 391.51135\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 175.1993 - mean_absolute_error: 9.1959 - val_loss: 392.7741 - val_mean_absolute_error: 15.0235\n",
      "Epoch 746/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 301.7098 - mean_absolute_error: 11.5723\n",
      "Epoch 746: val_loss improved from 391.51135 to 391.18460, saving model to checkpoint.model4kd.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 178.9980 - mean_absolute_error: 9.3312 - val_loss: 391.1846 - val_mean_absolute_error: 14.9386\n",
      "Epoch 747/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 136.4085 - mean_absolute_error: 8.6569\n",
      "Epoch 747: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.5562 - mean_absolute_error: 9.7594 - val_loss: 393.0494 - val_mean_absolute_error: 14.8815\n",
      "Epoch 748/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 292.4880 - mean_absolute_error: 10.4486\n",
      "Epoch 748: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.3852 - mean_absolute_error: 9.6528 - val_loss: 392.5107 - val_mean_absolute_error: 14.9742\n",
      "Epoch 749/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 104.8858 - mean_absolute_error: 7.4182\n",
      "Epoch 749: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.5130 - mean_absolute_error: 9.7534 - val_loss: 395.1363 - val_mean_absolute_error: 14.9750\n",
      "Epoch 750/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 264.5833 - mean_absolute_error: 12.3684\n",
      "Epoch 750: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.8621 - mean_absolute_error: 9.7214 - val_loss: 393.9248 - val_mean_absolute_error: 14.9916\n",
      "Epoch 751/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 185.1695 - mean_absolute_error: 10.1387\n",
      "Epoch 751: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.5367 - mean_absolute_error: 9.6156 - val_loss: 395.8917 - val_mean_absolute_error: 14.8571\n",
      "Epoch 752/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 419.7736 - mean_absolute_error: 11.7330\n",
      "Epoch 752: val_loss did not improve from 391.18460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.4735 - mean_absolute_error: 8.9850 - val_loss: 394.4564 - val_mean_absolute_error: 14.8532\n",
      "Epoch 753/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 216.4178 - mean_absolute_error: 9.8019"
     ]
    }
   ],
   "source": [
    "model4.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=1500, callbacks=[cp4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.72</td>\n",
       "      <td>12.11</td>\n",
       "      <td>14.22</td>\n",
       "      <td>3.39</td>\n",
       "      <td>102.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.59</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.29</td>\n",
       "      <td>3.70</td>\n",
       "      <td>97.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.90</td>\n",
       "      <td>25.69</td>\n",
       "      <td>26.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>93.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>1.29</td>\n",
       "      <td>33.04</td>\n",
       "      <td>37.91</td>\n",
       "      <td>6.67</td>\n",
       "      <td>105.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>1.69</td>\n",
       "      <td>46.25</td>\n",
       "      <td>52.63</td>\n",
       "      <td>8.25</td>\n",
       "      <td>119.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>1.22</td>\n",
       "      <td>35.99</td>\n",
       "      <td>41.19</td>\n",
       "      <td>6.63</td>\n",
       "      <td>112.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.89</td>\n",
       "      <td>15.05</td>\n",
       "      <td>18.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.78</td>\n",
       "      <td>19.89</td>\n",
       "      <td>18.80</td>\n",
       "      <td>3.11</td>\n",
       "      <td>127.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.89</td>\n",
       "      <td>17.63</td>\n",
       "      <td>22.93</td>\n",
       "      <td>4.56</td>\n",
       "      <td>109.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>1.29</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.93</td>\n",
       "      <td>8.45</td>\n",
       "      <td>9.61</td>\n",
       "      <td>2.13</td>\n",
       "      <td>110.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.63</td>\n",
       "      <td>20.17</td>\n",
       "      <td>16.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>103.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.87</td>\n",
       "      <td>29.41</td>\n",
       "      <td>25.56</td>\n",
       "      <td>5.12</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.83</td>\n",
       "      <td>23.18</td>\n",
       "      <td>16.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>158.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.88</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.42</td>\n",
       "      <td>2.49</td>\n",
       "      <td>139.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.87</td>\n",
       "      <td>18.28</td>\n",
       "      <td>18.18</td>\n",
       "      <td>2.90</td>\n",
       "      <td>116.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.79</td>\n",
       "      <td>20.19</td>\n",
       "      <td>17.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>99.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.67</td>\n",
       "      <td>23.28</td>\n",
       "      <td>18.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>103.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.67</td>\n",
       "      <td>22.01</td>\n",
       "      <td>16.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>1.01</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>124.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>1.17</td>\n",
       "      <td>7.95</td>\n",
       "      <td>9.64</td>\n",
       "      <td>3.04</td>\n",
       "      <td>147.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.80</td>\n",
       "      <td>17.72</td>\n",
       "      <td>25.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>137.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>48.52</td>\n",
       "      <td>35.87</td>\n",
       "      <td>7.43</td>\n",
       "      <td>132.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.90</td>\n",
       "      <td>112.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>1.16</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.77</td>\n",
       "      <td>4.85</td>\n",
       "      <td>109.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>1.00</td>\n",
       "      <td>14.63</td>\n",
       "      <td>16.32</td>\n",
       "      <td>2.84</td>\n",
       "      <td>129.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>1.11</td>\n",
       "      <td>23.37</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.01</td>\n",
       "      <td>98.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>1.20</td>\n",
       "      <td>17.96</td>\n",
       "      <td>21.13</td>\n",
       "      <td>4.96</td>\n",
       "      <td>115.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.76</td>\n",
       "      <td>7.69</td>\n",
       "      <td>12.57</td>\n",
       "      <td>4.12</td>\n",
       "      <td>98.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.43</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>69.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.40</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.31</td>\n",
       "      <td>58.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2024-01-01        0.72            12.11            14.22               3.39   \n",
       "2024-01-02        0.59            20.14            18.29               3.70   \n",
       "2024-01-03        0.90            25.69            26.01               4.84   \n",
       "2024-01-04        1.29            33.04            37.91               6.67   \n",
       "2024-01-05        1.69            46.25            52.63               8.25   \n",
       "2024-01-06        1.22            35.99            41.19               6.63   \n",
       "2024-01-07        0.89            15.05            18.83               3.50   \n",
       "2024-01-08        0.78            19.89            18.80               3.11   \n",
       "2024-01-09        0.89            17.63            22.93               4.56   \n",
       "2024-01-10        1.29             9.63             9.78               3.15   \n",
       "2024-01-11        0.93             8.45             9.61               2.13   \n",
       "2024-01-12        0.63            20.17            16.97               3.30   \n",
       "2024-01-13        0.87            29.41            25.56               5.12   \n",
       "2024-01-14        0.83            23.18            16.01               4.27   \n",
       "2024-01-15        0.88            17.00            12.42               2.49   \n",
       "2024-01-16        0.87            18.28            18.18               2.90   \n",
       "2024-01-17        0.79            20.19            17.60               3.45   \n",
       "2024-01-18        0.67            23.28            18.44               3.34   \n",
       "2024-01-19        0.67            22.01            16.51               3.90   \n",
       "2024-01-20        1.01             4.31             5.05               1.91   \n",
       "2024-01-21        1.17             7.95             9.64               3.04   \n",
       "2024-01-22        0.80            17.72            25.21               4.37   \n",
       "2024-01-23        1.00            48.52            35.87               7.43   \n",
       "2024-01-24        0.60            14.06            11.83               2.90   \n",
       "2024-01-25        1.16            23.24            22.77               4.85   \n",
       "2024-01-26        1.00            14.63            16.32               2.84   \n",
       "2024-01-27        1.11            23.37            19.88               4.01   \n",
       "2024-01-28        1.20            17.96            21.13               4.96   \n",
       "2024-01-29        0.76             7.69            12.57               4.12   \n",
       "2024-01-30        0.43             4.27             4.29               1.23   \n",
       "2024-01-31        0.40             4.01             7.87               1.31   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2024-01-01         102.58  \n",
       "2024-01-02          97.01  \n",
       "2024-01-03          93.04  \n",
       "2024-01-04         105.41  \n",
       "2024-01-05         119.15  \n",
       "2024-01-06         112.77  \n",
       "2024-01-07         125.58  \n",
       "2024-01-08         127.41  \n",
       "2024-01-09         109.73  \n",
       "2024-01-10         111.51  \n",
       "2024-01-11         110.29  \n",
       "2024-01-12         103.24  \n",
       "2024-01-13         123.00  \n",
       "2024-01-14         158.87  \n",
       "2024-01-15         139.88  \n",
       "2024-01-16         116.59  \n",
       "2024-01-17          99.03  \n",
       "2024-01-18         103.19  \n",
       "2024-01-19          91.11  \n",
       "2024-01-20         124.94  \n",
       "2024-01-21         147.98  \n",
       "2024-01-22         137.20  \n",
       "2024-01-23         132.69  \n",
       "2024-01-24         112.50  \n",
       "2024-01-25         109.74  \n",
       "2024-01-26         129.29  \n",
       "2024-01-27          98.85  \n",
       "2024-01-28         115.18  \n",
       "2024-01-29          98.28  \n",
       "2024-01-30          69.20  \n",
       "2024-01-31          58.32  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.885035</td>\n",
       "      <td>20.609687</td>\n",
       "      <td>34.589965</td>\n",
       "      <td>8.392951</td>\n",
       "      <td>102.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>1.105486</td>\n",
       "      <td>33.510139</td>\n",
       "      <td>43.237812</td>\n",
       "      <td>9.463750</td>\n",
       "      <td>100.370486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.921493</td>\n",
       "      <td>28.611215</td>\n",
       "      <td>38.746319</td>\n",
       "      <td>8.066528</td>\n",
       "      <td>94.957639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.611042</td>\n",
       "      <td>21.844757</td>\n",
       "      <td>25.318819</td>\n",
       "      <td>6.948403</td>\n",
       "      <td>94.909722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0.552535</td>\n",
       "      <td>11.527847</td>\n",
       "      <td>14.190799</td>\n",
       "      <td>3.571285</td>\n",
       "      <td>95.374306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2023-12-27    0.885035        20.609687        34.589965           8.392951   \n",
       "2023-12-28    1.105486        33.510139        43.237812           9.463750   \n",
       "2023-12-29    0.921493        28.611215        38.746319           8.066528   \n",
       "2023-12-30    0.611042        21.844757        25.318819           6.948403   \n",
       "2023-12-31    0.552535        11.527847        14.190799           3.571285   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2023-12-27     102.056818  \n",
       "2023-12-28     100.370486  \n",
       "2023-12-29      94.957639  \n",
       "2023-12-30      94.909722  \n",
       "2023-12-31      95.374306  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.55253472, 11.52784722, 14.19079861,  3.57128472,\n",
       "         95.37430556]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_start = df_corr.values[-1]\n",
    "x_test_start = np.reshape(x_test_start,(1,1,5))\n",
    "x_test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([102.58, 201.22, 235.04, 223.36, 153.35, 176.58, 179.29, 260.26,\n",
       "       144.39, 176.85, 200.03, 161.85, 324.88, 285.11, 191.13, 194.15,\n",
       "       188.7 , 201.74, 174.39, 206.83, 181.35, 234.13, 244.36, 252.99,\n",
       "       212.36, 401.43, 220.1 , 284.35, 216.37, 219.25, 204.15])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_start = val.values[0,-1]\n",
    "y_test = []\n",
    "y_test.append(y_test_start)\n",
    "for i in list(y2_test):\n",
    "    y_test.append(i)\n",
    "y_test = np.array(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(InputLayer((1, 5)))\n",
    "model4.add(LSTM(64))\n",
    "model4.add(Dense(8, 'relu'))\n",
    "model4.add(Dense(1, 'linear'))\n",
    "model4.load_weights('checkpoint.model4kd.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "FmwshpETs-jE",
    "outputId": "f9ea03ff-6d06-4ed5-cd59-5199bfdecc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.55253472  11.52784722  14.19079861   3.57128472  95.37430556]]\n",
      "\n",
      " [[  0.97         6.16         8.21         4.32       159.49      ]]\n",
      "\n",
      " [[  0.64         6.13         8.29         4.31       201.22      ]]\n",
      "\n",
      " [[  1.35         6.15         8.16         4.26       235.04      ]]\n",
      "\n",
      " [[  1.44         6.11         8.2          4.31       223.36      ]]\n",
      "\n",
      " [[  1.19         6.09         8.25         4.28       153.35      ]]\n",
      "\n",
      " [[  1.59         4.75         6.6          3.77       176.58      ]]\n",
      "\n",
      " [[  1.37         4.4          6.41         3.35       179.29      ]]\n",
      "\n",
      " [[  1.2          4.44         6.44         3.39       260.26      ]]\n",
      "\n",
      " [[  1.39         4.53         6.53         3.45       144.39      ]]\n",
      "\n",
      " [[  1.37         4.42         6.55         3.41       176.85      ]]\n",
      "\n",
      " [[  1.31         5.07         7.26         3.96       200.03      ]]\n",
      "\n",
      " [[  1.79         4.56         6.17         3.24       161.85      ]]\n",
      "\n",
      " [[  1.34         4.68         6.4          3.4        324.88      ]]\n",
      "\n",
      " [[  1.41         4.69         6.37         3.38       285.11      ]]\n",
      "\n",
      " [[  1.47         4.7          6.35         3.41       191.13      ]]\n",
      "\n",
      " [[  1.36         4.63         6.31         3.37       194.15      ]]\n",
      "\n",
      " [[  1.24         5.97         8.21         4.88       188.7       ]]\n",
      "\n",
      " [[  1.39         3.54         4.62         2.66       201.74      ]]\n",
      "\n",
      " [[  1.2          2.87         3.7          1.49       174.39      ]]\n",
      "\n",
      " [[  1.62         3.01         4.63         2.22       206.83      ]]\n",
      "\n",
      " [[  2.25         2.53         3.89         1.74       181.35      ]]\n",
      "\n",
      " [[  1.49         2.37         4.           1.77       234.13      ]]\n",
      "\n",
      " [[  1.44         2.09         4.02         1.67       244.36      ]]\n",
      "\n",
      " [[  1.84         3.74         5.58         3.31       252.99      ]]\n",
      "\n",
      " [[  1.41         4.08         5.99         3.73       212.36      ]]\n",
      "\n",
      " [[  1.27         4.09         5.94         3.72       401.43      ]]\n",
      "\n",
      " [[  1.27         4.06         5.88         3.69       220.1       ]]\n",
      "\n",
      " [[  1.33         2.75         4.48         2.65       284.35      ]]\n",
      "\n",
      " [[  1.38         2.38         3.98         2.11       216.37      ]]\n",
      "\n",
      " [[  1.47         2.38         3.99         2.12       219.25      ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAByO0lEQVR4nO3deXiU5dX48e9MlsmeEEI2srAvAcIuRC2iIItoXWirP1Fwqb4q9K1ircVXbdVWrG212qLdrGgV14oLKrLIorIIkX0HgbBkAUL2PfP8/rjzTBayzExmeWZyPtc11zyZmTxzZ5iQM+c+97lNmqZpCCGEEEIYiNnbAxBCCCGEaEkCFCGEEEIYjgQoQgghhDAcCVCEEEIIYTgSoAghhBDCcCRAEUIIIYThSIAihBBCCMORAEUIIYQQhhPo7QE4w2q1cvr0aSIjIzGZTN4ejhBCCCHsoGkapaWlJCcnYza3nyPxyQDl9OnTpKamensYQgghhHDCiRMnSElJafcxPhmgREZGAuoHjIqK8vJohBBCCGGPkpISUlNTbX/H2+OTAYo+rRMVFSUBihBCCOFj7CnPkCJZIYQQQhiOBChCCCGEMBwJUIQQQghhOBKgCCGEEMJwJEARQgghhOFIgCKEEEIIw5EARQghhBCGIwGKEEIIIQxHAhQhhBBCGI4EKEIIIYQwHAlQhBBCCGE4nQpQnnnmGUwmE/fff7/ttqqqKubOnUv37t2JiIhg5syZ5OfnN/u+nJwcZsyYQVhYGPHx8Tz00EPU1dV1ZihCCCGE8CNOByhbtmzh73//O5mZmc1uf+CBB/jkk0947733WLduHadPn+aGG26w3V9fX8+MGTOoqalhw4YNvPbaayxevJjHH3/c+Z9CCCGEaM/5Y/D1n6GqxNsjEXZyKkApKytj1qxZ/POf/6Rbt26224uLi3nllVd47rnnuOKKKxg9ejSvvvoqGzZsYNOmTQCsWLGCvXv38sYbbzBixAimT5/OU089xaJFi6ipqXHNTyWEEEI0te4PsOrXsPMdb49E2MmpAGXu3LnMmDGDyZMnN7s9Ozub2traZrcPGjSItLQ0Nm7cCMDGjRsZNmwYCQkJtsdMnTqVkpIS9uzZ0+rzVVdXU1JS0uwihBBC2K00t/m1MLxAR7/h7bff5rvvvmPLli0X3JeXl0dwcDAxMTHNbk9ISCAvL8/2mKbBiX6/fl9rFi5cyBNPPOHoUIUQQgil8ry6rij07jiE3RzKoJw4cYKf//znvPnmm4SEhLhrTBdYsGABxcXFtsuJEyc89txCCCH8QGVDYKIHKsLwHApQsrOzKSgoYNSoUQQGBhIYGMi6det48cUXCQwMJCEhgZqaGoqKipp9X35+PomJiQAkJiZesKpH/1p/TEsWi4WoqKhmFyGEEMJuemBSKRkUX+FQgDJp0iR27drF9u3bbZcxY8Ywa9Ys23FQUBCrV6+2fc+BAwfIyckhKysLgKysLHbt2kVBQYHtMStXriQqKoqMjAwX/VhCCCFEA2s9VBWr4wrJoPgKh2pQIiMjGTp0aLPbwsPD6d69u+32O++8k/nz5xMbG0tUVBQ/+9nPyMrKYvz48QBMmTKFjIwMbr31Vp599lny8vJ49NFHmTt3LhaLxUU/lhBCCNFAD05AMig+xOEi2Y48//zzmM1mZs6cSXV1NVOnTuWll16y3R8QEMCyZcu49957ycrKIjw8nDlz5vDkk0+6eihCCCFE87oTKZL1GSZN0zRvD8JRJSUlREdHU1xcLPUoQggh2ndyK/xrUuPX/5cHQaHeG08X5sjfb9mLRwghhH9ruXJHsig+QQIUIYQQ/q1lgCJ1KD5BAhQhhBD+7YIARVby+AIJUIQQQvg3meLxSRKgCCGE8G8tAxKZ4vEJEqAIIYTwb5JB8UkSoAghhPBveoAS1r3518LQJEARQgjh3/SAJLaPupYMik+QAEUIIYR/swUofRu+lgDFF0iAIoQQwr/pAUr3hgBFMig+QQIUIYQQ/stqhaoidaxP8UgNik+QAEUIIYT/qi4BzaqOu8sUjy+RAEUIIYT/0rMlQWEQmdR4m9XqvTEJu0iAIoQQwn/pAUpoNwiNVceaFaqLvTcmYRcJUIQQQvgvfTontBsEBkNwhPpaCmUNTwIUIYQQ/quySF2Hdmt+LYWyhicBihBCCP/VdIqn6bVkUAxPAhQhhBD+q2WAEhbb/HZhWBKgCCGE8F8XZFD0AEUyKEYnAYoQQgj/1VYGRaZ4DE8CFCGEEP5LMig+SwIUIYQQ/ksyKD5LAhQhhBD+SzIoPksCFCGEEP5Llhn7LAlQhBBC+CdNk2XGPkwCFCGEEP6puhSsdepYOsn6HAlQhBBC+Cc9CAkMgeAwdaxnUGrKoK7GO+MSdpEARQghhH9qOb0DYIkGU8OfPimUNTQJUIQQQvin1gIUs1kKZX2EBChCCCH8U2sBCshSYx8hAYoQQgj/1FaAIs3afIIEKEIIIfyTLUCJaX67bSWPBChGJgGKEEII/9TRFI9kUAxNAhQhhBD+qbJIXbc1xSO9UAxNAhQhhBD+SZ/CuSCDIlM8vkACFCGEEP6pwyJZyaAYmQQoQggh/JMtQIltfrssM/YJEqAIIYTwT7LM2KdJgCKEEML/tLaTsU4yKD5BAhQhhBD+p7YC6hs2A2yzSPa8CmSEIUmAIoQQwv/o2RNzEASHN79Pn+Kx1kF1iWfHJewmAYoQQgj/03R6x2Rqfl9QKASGNn+cMBwJUIQQQviftupPdFIoa3gSoAghhPA/HQUoUihreBKgCCGE8D8VbXSR1YU13C7N2gzLoQDl5ZdfJjMzk6ioKKKiosjKyuLzzz+33T9x4kRMJlOzyz333NPsHDk5OcyYMYOwsDDi4+N56KGHqKurc81PI4QQQoBkUPxAoCMPTklJ4ZlnnqF///5omsZrr73Gtddey7Zt2xgyZAgAd911F08++aTte8LCwmzH9fX1zJgxg8TERDZs2EBubi6zZ88mKCiIp59+2kU/khBCiC5PD1DCYlu/Xw9cpAbFsBwKUK655ppmX//ud7/j5ZdfZtOmTbYAJSwsjMTExFa/f8WKFezdu5dVq1aRkJDAiBEjeOqpp3j44Yf5zW9+Q3BwsJM/hhBCCNGELYMS0/r9YZJBMTqna1Dq6+t5++23KS8vJysry3b7m2++SVxcHEOHDmXBggVUVFTY7tu4cSPDhg0jISHBdtvUqVMpKSlhz549bT5XdXU1JSUlzS5CCCFEm+yd4pEMimE5lEEB2LVrF1lZWVRVVREREcHSpUvJyMgA4OabbyY9PZ3k5GR27tzJww8/zIEDB/jggw8AyMvLaxacALav8/Ly2nzOhQsX8sQTTzg6VCGEEF1VZZG67miZsfRBMSyHA5SBAweyfft2iouLef/995kzZw7r1q0jIyODu+++2/a4YcOGkZSUxKRJkzhy5Ah9+/Z1epALFixg/vz5tq9LSkpITU11+nxCCCH8nBTJ+jyHp3iCg4Pp168fo0ePZuHChQwfPpwXXnih1ceOGzcOgMOHDwOQmJhIfn5+s8foX7dVtwJgsVhsK4f0ixBCCNEmadTm8zrdB8VqtVJdXd3qfdu3bwcgKSkJgKysLHbt2kVBQYHtMStXriQqKso2TSSEEEJ0mt0ZFJniMSqHpngWLFjA9OnTSUtLo7S0lCVLlrB27Vq++OILjhw5wpIlS7jqqqvo3r07O3fu5IEHHmDChAlkZmYCMGXKFDIyMrj11lt59tlnycvL49FHH2Xu3LlYLBa3/IBCCCG6mNpKqKtUxx1lUKpLoL4WAoI8MzZhN4cClIKCAmbPnk1ubi7R0dFkZmbyxRdfcOWVV3LixAlWrVrFn//8Z8rLy0lNTWXmzJk8+uijtu8PCAhg2bJl3HvvvWRlZREeHs6cOXOa9U0RQgghOkXPipgCwNJGSUBINGACNPX4iHhPjU7YyaEA5ZVXXmnzvtTUVNatW9fhOdLT0/nss88ceVohhBDCfk17oLTcyVhnDlBBSlWRqkORAMVwZC8eIYQQ/sUWoLTRRVYnzdoMTQIUIYQQ/qWjAlmdFMoamgQoQggh/Iu9AYosNTY0CVCEEEL4F4czKBKgGJEEKEIIIfyLZFD8ggQoQggh/ItkUPyCBChCCCH8i90BSoy6lgyKIUmAIoQQwr84OsUjq3gMSQIUIYQQ/qXCwSkeyaAYkgQoQggh/ItkUPyCBChCCCH8ix5whDlQJKtp7h2TcJgEKEIIIfxHXTXUlqtjezMo9TVQU+7ecQmHSYAihBDCf1QWNRyYwBLd/mODwiDA0vB9UodiNBKgCCGE8B9NdzI2d/AnzmSSZm0GJgGKEEII/2FvgaxOf5xkUAxHAhQhhBD+w+EARTIoRiUBihBCCP/haICir/SRpcaGIwGKEEII/+FsBkUCFMORAEUIIYT/0GtJ7M6gyBSPUUmAIoQQwn84nUGRAMVoJEARwp8d3wDHvvH2KITwHFuAEmvf4yWDYliB3h6AEMJNaqvgjR+pLpkP7IbIRG+PSAj3kwyK35AMihD+qrxAtfy21sLej709GiE8w9k+KJJBMRwJUITwV+VnG4/3fOC9cQjhSQ4vM5YMilFJgCKEv6o413icsxFKTntvLEJ4ir4Xj6NTPFXFUF/nliEJ50iAIoS/appBAdj7kXfGIYSn1NdCdYk6dnSKB1SQIgxDAhQh/FVFQ4BibqiF37PUe2MRwhOaBhghHexkrAsIbNz1WKZ5DEUCFCH8lZ5BGXQ1YIITm6H4pFeHJIRb6fUnlmgVeNgrTApljUgCFCH8lZ5BSRgK6RerY5nmEf5MDzBCYxz7PllqbEgSoAjhr8obimTDu8OQ69WxTPMIf+boCh6dNGszJAlQhPBXegYlLA4G/xAwwcktUJTj1WEJ4TZ6gBJmZxdZnR7QSAbFUCRAEcJf6TUo4XEQmQC9LlVfyzSP8FfOZlBCJYNiRBKgCOGv9D4oYXHqesh16lqmeYS/6uwUj2RQDEUCFCH8UV11Yz+I8IYAZfAPwWSGU9lw/rj3xiaEu3Q2g6J/vzAECVCE8Ed69sQUACEx6jgivsk0z4feGJUQ7iVFsn5FAhQh/JFefxIWC+Ymv+aymkf4M6czKHqRrGRQjEQCFCH8UdMVPE3p0zynt0HhUc+PSwh3kgyKX5EARQh/ZOuB0iJACY+D3hPUsUzzCH/T6QyKBChGIgGKEP7IlkHpfuF9Ms0j/JUeYDhbJFtXBTUVrh2TcJoEKEL4o6Y9UFoadI0qns3dAeeOeHZcQriLtb5xs0BHAxRLZOOmmpJFMQwJUITwR23VoIBqfd/nMnUs0zzCXzTdydjRAMVkkmZtBiQBihD+qL0MCjRO8+yWaR7hJ/T6k+BICAhy/PvDpBeK0UiAIoQ/snWRbaUGBWDQ1Sqlnb8Lzh7y3LiEcBdnC2R1sqOx4UiAIoQ/6iiDEhYLfSaq4z0femJEQriXLUCJce77Zamx4UiAIoQ/aq8GRSereYQ/6XQGRZYaG41DAcrLL79MZmYmUVFRREVFkZWVxeeff267v6qqirlz59K9e3ciIiKYOXMm+fn5zc6Rk5PDjBkzCAsLIz4+noceeoi6ujrX/DRCCKiva/zPuq0MCsCgGWAOgoI9cOaAZ8YmhLu4KkCpkBoUo3AoQElJSeGZZ54hOzubrVu3csUVV3DttdeyZ88eAB544AE++eQT3nvvPdatW8fp06e54YYbbN9fX1/PjBkzqKmpYcOGDbz22mssXryYxx9/3LU/lRBdWdNPgPq8emtCu0HfK9SxTPMIX9fZAEV2NDYchwKUa665hquuuor+/fszYMAAfve73xEREcGmTZsoLi7mlVde4bnnnuOKK65g9OjRvPrqq2zYsIFNmzYBsGLFCvbu3csbb7zBiBEjmD59Ok899RSLFi2ipqbGLT+gEF2OXn8S2g0CAtt/rEzzCH/hqiJZqUExDKdrUOrr63n77bcpLy8nKyuL7OxsamtrmTx5su0xgwYNIi0tjY0bNwKwceNGhg0bRkJCgu0xU6dOpaSkxJaFEUJ0kj31J7qB0yEgGM7sg4J97h2XEO5U4WQXWZ0sMzYchwOUXbt2ERERgcVi4Z577mHp0qVkZGSQl5dHcHAwMTExzR6fkJBAXl4eAHl5ec2CE/1+/b62VFdXU1JS0uwihGhDRyt4mgqNgb6T1LFM8whfJsuM/Y7DAcrAgQPZvn07mzdv5t5772XOnDns3bvXHWOzWbhwIdHR0bZLamqqW59PCJ/WUQ+UlppO82iae8YkhLu5qgZFpngMw+EAJTg4mH79+jF69GgWLlzI8OHDeeGFF0hMTKSmpoaioqJmj8/PzycxMRGAxMTEC1b16F/rj2nNggULKC4utl1OnDjh6LCF6DocyaBAwzSPBc4ekGke4bv0ACWsncLw9ugZlKoisFpdMiTROZ3ug2K1Wqmurmb06NEEBQWxevVq230HDhwgJyeHrKwsALKysti1axcFBQW2x6xcuZKoqCgyMjLafA6LxWJb2qxfhBBtcKQGBSAkCvo11I5JsazwVa5aZqxZVZAivK6DEv/mFixYwPTp00lLS6O0tJQlS5awdu1avvjiC6Kjo7nzzjuZP38+sbGxREVF8bOf/YysrCzGjx8PwJQpU8jIyODWW2/l2WefJS8vj0cffZS5c+disVjc8gMK0eU4mkEBNc1z4FMVoFz+iNo8TQhfYW0SVDgboAQGQ3AE1JSpYMfZTIxwGYcClIKCAmbPnk1ubi7R0dFkZmbyxRdfcOWVVwLw/PPPYzabmTlzJtXV1UydOpWXXnrJ9v0BAQEsW7aMe++9l6ysLMLDw5kzZw5PPvmka38qIboyWw2KAwHKwGlqmufcIcjfA4lD3TM2IdyhukRlPgBCYpw/T2isClAqCqF7X5cMTTjPoQDllVdeaff+kJAQFi1axKJFi9p8THp6Op999pkjTyuEcIQtg2JnkSyAJRL6Xwn7l6ksigQowpfo0ztBYRAU4vx5wrpBcY6s5DEI2YtHCH/jaA2KTlbzCF/V2foTXaj0QjESCVCE8CdWa+MySUdqUAAGTIPAECg8Anm7XD82IdzFVQGKLDU2FAlQhPAnVUWg1atje/ug6CwR0H+KOpbVPMKXuDyDIgGKEUiAIoQ/0etPLFEQ6MTKONs0zwcyzSN8hy1AienceSSDYigSoAjhT2z1Jw5mT3QDpkJgKJw/BrnbXTUqIdxLMih+SQIUIfyJMz1QmgoOV0EKyDSP8B22AKWTvUv0AEcyKIYgAYoQ/sTZFTxNyWoe4WtcXSQrGRRDkABFCH9S3tCkzZEeKC31n6L6SRTlwOnvXDMuIdzJ1VM8FbLM2AgkQBHCn7gigxIcppYcg0zzCN/gsgxKt+bnE14lAYoQ/kRvc+9sDYrONs3zoUzzCONzdQalthzqqjt3LtFpEqAI4U/KXZBBAdX2PiAYik+oixBG5qoAJSQaTAHq2FWFst+vg5cuhtPbXHO+LkQCFCH8SUUnV/HogkKhWy91XPh9584lhDtpmusCFJOp8RyuKpTd/Hco2APZi11zvi5EAhQh/IleJOtsH5SmYvuo63NHOn8uIdyluhSsdeq4swEKuL5Zm15ofnq7a87XhUiAIoS/0DTXZVAAYhu2m5cMijAyPXsSYFGZv85yZQal5DSU5qrjgr1QV9P5c3YhEqAI4S+qS6G+4T/AztagAMT2VtcSoAgjazq9YzJ1/nyhLsygnGqyTL++Bs7s7/w5uxAJUITwF3r2JChMLRXuLH2KRwIUYWR6gBLWyS6yOlc2a2vZR0i2j3CIBChC+Atb/YkLsicA3fUpnqNgtbrmnEK4mqsKZHWhLuyFomdQ9Jqw3B2dP2cXIgGKEP7CVn/iggJZgKgUMAdBfTWUnHLNOYVwNVcHKGEu6iaraY0ZlBGz1LUEKA6RAEUIf+GqHii6gEBZaiyMzxagxLjmfK7a0bjwe6gqVsW7I25Wt+Xthvq6zp23C5EARQh/4coVPDpbHYosNRYG5bYMSicDFH16J3EYxA2E4Eioq4SzBzt33i5EAhQh/IUtg+KiKR6QQllhfJVF6tplNSguyqDo0zs9R4PZDEmZ6muZ5rGbBChC+AtX7cPTVNNCWSGMyF1Fsp3OoGSr656j1HXScHUtK3nsJgGKEP7C1TUo0NgLRbrJCqPSMx2unuKpPO/8Rpn1dZC7Ux0ntwxQJINiLwlQhPAXbqlBacignJelxsKgXJ5BaQhQtHpV5OqMM/tUvYklCrr3U7cljVDXuTvld8lOEqAI4S9c3QcFIDoVzIFQVwWlp113XiFcxdUBSlCIanbY9NyO0gtkk0eo+hOAuP4QGAq15XDucKeH2RVIgCKEv3B1HxRQS41j0tWxFMoKo2m2k7GLOsk2PZezhbJ6/Yk+vQNgDlArekCmeewkAYoQ/qCmAmor1LErMyjQWCgrdSjCaGorGvefclUGBSBML5R1MoNiW8EzqvntySPUtRTK2kUCFCH8gZ49CQgGS6Rrzy1LjYVR6dkTcxAEh7vuvJ3JoNRWQv5edZzcIkCRQlmHSIAihD9ouoLHFTu6NqUXykqAIozG1TsZ6zqz1Dh3pyqwDY+H6JTm9zUNUKRQtkMSoAjhD2w9UFxYf6KTDIowKlcXyOo6s6Nx0+mdlkFTj0Gq9X11CRQd69QQuwIJUITwB+7ogaLrrgcostRYGIy7AhR9iseZDIptBc+oC+8LCIKEIer49HanhtaVSIAihD9wRw8UXXRaw1LjSijNdf35hXCWoTMoo1u/X+pQ7CYBihD+wJ0ZlIBAiElTxzLNI4ykwsVdZHWhTbrJOqKyqLHHSfLI1h9jW8kjAUpHJEARwh+4owdKU1IoK4zI3RkUR6d4Tm9T1zHpbf8uNt2Tx9lW+l2EBChC+AN3dJFtylYoK71QhIG4uwbF0SmetvqfNBWfoZZFV56H4hPOja+LkABFCH/gzhoUaLKrsWRQhIHoAUqYuzIoDk7xnOqg/gQg0ALxg9WxTPO0SwIUIfyBO2tQoDGDck4CFGEglUXq2uUZlIbz1ZRCXY3939feCp6m9GkeWcnTLglQhG+pq4G3Z8FXz3l7JMZi64Pi7ime72XeXBiHu6Z4QqIBU/Pn6EhpntpQ02RuDEDaIit57CIBivAtJzbB/mXw9fPeHolx1FWrxk8AYW4qko1JA1OALDUWxuKuAMUcAKExDc9hZx2Knj2JGwiWiPYfq6/wkULZdkmAInzLmQPquroEqkq8Oxaj0LMnpgAIiXHPcwQEyVJjYTzuClDA8WZt+g7G7dWf6BKGqN/X8jMS8LdDAhThW87sbzwuOeW9cRiJrf6kO5jd+CsthbLCSGorVUYP3BOghDnYC8W2gqeN/idNBYVCj4HqWKZ52iQBivAtegYFoPik98ZhJO5ewaOzFcrKUmNhAHrgYAoAS5Trz+/IUmNNa+yB0lGBrC5phLqWAKVNEqAI31Kwr/FYAhTF1gPFTfUnOmnWJozENr0T4/odvMGxZm3nj6rxBARDwlD7zi8reTokAYrwHeVnG7MFIAGKztMZFAlQhBG4s/4EHMug6AWyicMgMNi+88tKng5JgCJ8R9PpHZAaFJ27e6DoZKmxMBK3BygN57Ung2Jv/5OmEocBJrU0uazA4eF1BRKgCN+hF8iaGt62kkFRPJVB0Zca11ZAWb57n0v4J02DfZ/Aysehprxz57IFKLGdH1dr9O609hTJ2tPiviVLBMT1V8eSRWmVQwHKwoULGTt2LJGRkcTHx3Pddddx4EDzT7UTJ07EZDI1u9xzzz3NHpOTk8OMGTMICwsjPj6ehx56iLq6us7/NMK/6QGKvoxPAhSl6SoedwoMhphUdSyFssJRJbmqyeI7t8A3L8Cmlzp3Pk9N8XSUQamvawww7Fli3FTTjQPFBRwKUNatW8fcuXPZtGkTK1eupLa2lilTplBe3jwSvuuuu8jNzbVdnn32Wdt99fX1zJgxg5qaGjZs2MBrr73G4sWLefzxx13zEwn/pQco/Sar65JTYLV6bzxG4e4usk1JoaxwlNUKW1+FRRfBgU8bb9/7cefO6+4AJczOGpQz+1VWMTgSuvd37Dn0lTxSKNsqhwKU5cuXc9tttzFkyBCGDx/O4sWLycnJITs7u9njwsLCSExMtF2iohqXgK1YsYK9e/fyxhtvMGLECKZPn85TTz3FokWLqKlxYM8D0fXoNSh9LgdMUF+jGh11dZ6qQQHZ1Vg45twReP2HsOx+1VwxeRTMWaamCvN2di7Q9ViRbAdTPPr0TvIIx/sQ2TIoOx37vi6iUzUoxcXFAMTGNp8DfPPNN4mLi2Po0KEsWLCAiooK230bN25k2LBhJCQk2G6bOnUqJSUl7Nmzp9Xnqa6upqSkpNlFdDEVhY11DwkZEJmkjktkmsdjNSggK3mEferr4Os/w8sXw7GvIDAUpj4NP10FvX8AvSeox+39yPnn8FQGpaKw/aJwW4GsHQ3aWkrKVNfFOfZ3rO1CnA5QrFYr999/P5dccglDhzau+7755pt54403WLNmDQsWLOA///kPt9xyi+3+vLy8ZsEJYPs6Ly+v1edauHAh0dHRtktqaqqzwxa+Ss+eRKeCJRKie6qvu3odSn1dky3nPRCg6N1kZVdj0ZbcnfCvK2DVr6GuCvpMhPs2QtZctccNQMa16trIAYqeQbHWQk1Z249zpMV9SyHRjUG/1KFcINDZb5w7dy67d+/m66+/bnb73XffbTseNmwYSUlJTJo0iSNHjtC3b1+nnmvBggXMnz/f9nVJSYkEKV2NXn/SY5C6jk6Bk1uguIsvNbbNj5saP/G5U8ulxu5okCV8U20VrPu9KoDV6tUf36lPw4hZF75PBl0Nn85X3VfPH4du6Y4/X4WbA5TgMAgMUUFWRaH6YNRSbRUU7FXHjqzgaSppuPp9yt0Bfa9wfrx+yKkMyrx581i2bBlr1qwhJSWl3ceOGzcOgMOHDwOQmJhIfn7zJYr614mJia2ew2KxEBUV1ewiuhg9g6LvXxElGRSgsf4ktFvjp1N3iklXy7xry6V3g2h0fAP87RL4+jkVnGRcC3O3wMhbWg9iI3pA+iXqeJ+TxbLuzqA0PXdbhbJ5u8Bap7KX0U5+aJaGbW1yKEDRNI158+axdOlSvvzyS3r37t3h92zfvh2ApCRVM5CVlcWuXbsoKGj8z23lypVERUWRkZHhyHBEV3KmocW9LYPS8J9BV69B8WT9CailxvprL4WyoqoEls2HV6fDucMQkQA3vgE/eR0iE9r/3iHXqes9Hzr33E1b3btLR0uNbf1PRjufTZSVPG1yKECZO3cub7zxBkuWLCEyMpK8vDzy8vKorFQ7Sh45coSnnnqK7Oxsjh07xscff8zs2bOZMGECmZmqGGjKlClkZGRw6623smPHDr744gseffRR5s6di8Vicf1PKPyDLYOiByiSQQE8u4JHJ4WyAuDAcnhpPGx9RX09ajbM/RYGX2Pf9w+6BjDBqa1QdMKx566rVlk8cG8GpaMdjW31J05O70BjBuX8Uagscv48fsihAOXll1+muLiYiRMnkpSUZLu88847AAQHB7Nq1SqmTJnCoEGDePDBB5k5cyaffPKJ7RwBAQEsW7aMgIAAsrKyuOWWW5g9ezZPPvmka38y4T8qi6A0Vx3rUzzRDVOLXb0GxdYDxc1N2pqyFcpKBqVLqqmAD++Dt25UvYi69YLZH8MP/+JYNiMyAdIvVsf7Pmn/sS3Z/pCbIMSB53RUR+3unWlx31JYLESnqeO8Xc6fxw85VCSrdbD/RmpqKuvWrevwPOnp6Xz22WeOPLXoys4eVNdRPSGkof4oqiFAKcuHuhr7N+jyN5JBEZ509jC8OxsK9qhapKy5MPERVVDqjIxr4fg3ajVP1n32f1/T6R1He484or0MSlUxnDukjjuTQQFIHq6WGuduV8uwBSB78QhfUKDXnwxsvC08DgIsgKY22+qqPF2DAtJNtqvasxT+MVEFJ+HxMPsjmPJb54MTaJwOOrEJShz4PfZEgSy0v6OxXjMSk9b53z8plG2VBCjC+FrWn4AqSJM6FO9nUGRXY/9XVwOf/wreuw1qStXqm3u+amy21hlRyZA6Xh07Ms3jqQAlrJ0iWb3+pDPTOzq9UFYClGYkQBHG17IHik7qUDy7D4+uW8NS45oy2WrA3xWfhMVXweaX1deX3K/qTSJbbwnhFGeathkig+LEDsZt0TMoZw9BdWnnz+cnJEARxtdWgKLXoRQ7uALAn3hqJ+OmAi2NwaEUyvqvw6vgbz9QDREt0XDTW3DlExDgdH/P1unTPMc3QGl++4/VeSxAaadI9tQ2de2KDEpEPEQmAxrk7e78+fyEBCjC2KpK1EoBaF6DAo1/JEu6cgbFCzUoIIWy/sxaD2uehjd+pDIHScPhf9bBoKvc83wxqdBzDKDZ37RNz2h4aoqnZQalNL+hB5NJbRLoClKHcgEJUISx6St4IpMuXMJom+LpojUoVmvjJztP1qCAFMr6q/Kz8MYNqmU9Goy+He5YAbEdN+XsFEeneTw9xVPRYhWPPr3TY2DrLfCdoQc6siePjQQowths0zsDL7yvqxfJVhWptuLg2SkeaJJBkSkev5GzSU3pfL8WgsLg+r/DNX+GoBD3P7ceoBz/BsrsqGvydJFsdbHamFPniv4nLUkG5QISoAhjK2jR4r4pveV6Vy2S1etPLNGe7wPTXTIofkPTYOMiWDxDLdnv3h/u+hKG3+S5MXRLh+SRoFlh/7KOH++pAKVpE7iqosZjVxbI6vQA5cx+1QxPSIBiCNZ6yF4MZw56eyTG03KTwKb0DQOri1WtSldjqz/xcPYEGjMo52SpsU+rKoZ3b4UvHlGb3g25Ae5eA/GDPT8WR6Z5bAGKm3fwDghUuzJD43SqprmmxX1LkUmqv4xmhfw9rjuvD5MAxQi2/Qc++Tn883I4tMrbozEWW4DSyn+YlojGTzhdsVDWGz1QdDHpgEn1xdDHIXxLwX7VeG3fJ2AOgqv+CD/6t+tqKhylByhH10P5ufYf66kMCly41Pj8MfX85iBIGOq65zGZmkzzbHfdeX2YBChGsPVVdV1TBkt+AtmveXc8RlFdpto/Q+sZFOjahbLeWsEDqi5BdjX2bcseUFN00alwxxdw0V3O78jrCrF9IDFT1VUd+LT9x+p78XgiQGnZrE2f3kkcqpbcu5LUoTQjAYq35e5Q0bI5CIZcr345P/lfWP2UpM7PNmRPwuMb/5NoqSsHKPqnTE8XyOr0lR1Sh+J7qkvhxGZ1POdjSBnt3fHo7Jnmqa+F6oYpXY9kUBqeQ8+g6AWyPd3wmslKnmYkQPE2PVsy+Br40asw4Zfq66/+CEv/R7WZ7qraqz/RRXXhlTzezKCAFMr6spxN6sNQTHpjPZERZFynrr9f2/oGfaDqZnR6fYg7hbbIoLhjBY9Oz6AU7IO6atef38dIgOJNNeWw6z11PHqOSq9e8X/ww7+CKQB2vqN6Eti2Fu9i9CXG7RXsdeVmbd6sQYEmhbIyxeNzjq5X10bbOTeuH8QPUQW7+9vY8V4PXCzRru9q25qmzdqs9Y3TL64skNVFp6qMjbUOCva6/vw+RgIUb9qzVKUqu/WCXk023hp1K8x6F4Ij4NhX8O+pUJTjtWF6jT0ZlK48xePtDIp0k/Vdx75S103/3zGKjqZ59ExGy8aN7tI0g3LmANSWq/+b4wa4/rlMpsaNA/XdkrswCVC8SZ/eGTUbzC3+KfpNhts/V0vPzuyHf03uem/Y9nqg6LpygGKrQfFWgNJkiqer10v5kqrixiyA0TIoAEOuU9dHvmw+naPz5AoeaJJBOd9YIJs0AswB7nk+KZS1kQDFWwr2wclv1VTOiFmtPyYpE366SqU8y/Lh1avg4ArPjtNbasobs0btBSh6DUrJKdX6vSvxZh8UUJk/TCoLWNHBslBhHMc3qF4bsX0hKtnbo7lQj4Hqd95aCweWX3i/pwMUW5Hs+Sb9T0a67/kkQLGRAMVb9OzJwOntb10enQJ3fA59JqrU4ls3NS5L9mdnDwGayg60N4URlQyYoL6m8Q92V6Bp3q9BCQppzGDJNI/vONowvWPE7ImuvWkeb2VQKgrdWyCr01fy5O9RK5a6MAlQvKG2Cna8pY5H39bx40OiYdb7KtOi1cOy+2HVE/6dMbDtwdNO9gQgIEhNgwEUn3DvmIykukR9wgTv1aBA41JjKZT1Hbb6Ex8IUA6vurBLtB6gtNV6wNX0QKg0t7HDqzuWGOu69VYFwPXVjf8PdlESoHjDvo/Vvg7RqdD3Cvu+JyAIrl0EEx9RX3/9HHxwl/8uRWtvk8CWbJsGdqGVPHr2JCgcgkK9Nw7Z1di3VBRC3i513OtS746lPfEZ0L2f+iN9qMW0tseneJqu4qlVfYdi0tz3fCaTmt6HLj/NIwGKN+jTOyNvcazQymSCiQ/DdS+DORB2vw//uaHtfgG+TF/BY8+eIF2xUFav+fBW/YlOdjX2Lcc3AJpagdLe1LK3mUyNPVH2ftj8Pm9N8eiSR7m/465eh9LVFka0IAGKp509DMe/BpNZBSjOGHGzmvKxRKlzvTIFzh937Ti9zZEMSlds1ubt+hOdLDX2Lb4wvaPTp3kOrVTbXug8HaAER6hO3zp39D9pSV9qLBkU4VHfNWRP+l3Z+MnfGX0vhzuWqz/OZw/Cp/NdMz4jqK2EwqPquKMaFGjcE6akCwUo3u6BotO7yfrBrsaHC0pZf/AMmo//HO3yhQJZXeIwVY9RV9V8msfTAYrJ1DyL4s76E52eQcnbpZrDdVESoHhSXQ1sX6KOR8/p/PkShsBNb6rjnM3+UzSrr+AJ7QbhPTp+fLRkULymWy91XV3c2EDLB32+K5erXvya2f/+lg++89NapvKzUNBQ5OkLGRSTqfXVPJ4OUKCxDgXcu4JH172fytzUVaoPoF2UBCiedOBT9ck3IhH6T3XNOROGQoBFbXt//qhrzulttg6yg+2b67XVoPjpH5bWGKUGJSgUonx7qfF/Nh3nviXfUVOnAvzHP9rN8XPlXh6VGxz/Rl3HZ3g/82YvvWnboRVQU6GO9U37PBmg6BmU6FSIsONDU2eZzSqDBF16mkcCFE+yFcfOct0eEgFBkJChjvN2uuSUVqtGWXUdBSVVHD1bzu5TxXx7tJA1Bwr4dGcu7249weJvjvLS2sOsP3gGq9XFKXFH6k+g8Q9kWX7X2VzRKBkUaLKrsW8VymqaxnMrDvDYh7vRNLh5XBoX9Y6lvKaen7+9ndp6P8lI6vTpHSOv3mkpaYRaMVNboZYcW+sbu8t6NIPS8FyeqD/RScM2PLDTUtdQVVvP6xuPERIUQL8eEfSNjyA+0oJJzwCcPwbfr1HHI2917ZMnZsLpbZC7E4Zcf8HdmqZRWF5DbnFVw6WS00XqOre4itKqOsqr66ioqaO8up7KWsfmPPv0COe2i3txw6gUIiwueEvZ2wNFFx6nskj11VB6unHawZ8ZpQYFVKHssa98KoNSV2/lsY9289a3qnfOA5MH8L+T+nG6uIrpf17P9hNFvLDqEL+YameQ7At8qUBWp0/zbPiLmuZpGlyFxHhuHHoQnu7B4M6ZPXk0TU11n9oKJ7eqWr4fzIeUMe4YodtJgOIiz608yD/WN/8POtISSJ/4CPr2COfmstcZA1SkTCAoOp2g1k/jsLp6K9WxQwgHzh3ZyvLI4+QWVXG6uJLcJkFIdZ3jnwbNJggPDiTMEkC4JVAdB6vjsOAAzCYTa/YX8P2Zch7/aA9/WH6AH49JZXZWOr3iwp3/oRzNoJhMqg6l8Hv1y9kVAhQjZVBshbK+kUGpqq1n3pJtrNqXj9kET103lFnj0gHoGRPK0zcMY96SbSxae5gf9I9jXB8vT6O5QllBw++VybcyKKCWG2/4CxxcDpc+oG4LjoDAYM+N4bKHVXBib98qV7AVyu5U9YUt92sDqC5VH05PblVt+E9uhbK85o85/g3cucL+/08NRAIUFziYX8q/v1b1H5f0687poiqOnyuntLqOHSeK2H3iHA9b/gsm+MX3I1jx2HLSu4fRtyHT0q9HBL17hGMCSqrqKKmspbSqjpKq2naO6yitqqW8pp6RpkqWWsB6egf/d3R3m+OMi7CQHBNCYlQIyTGhJEWHkBgdQrewYMJbCUIsgebGDFAbyqrr+OC7kyz+5hjfny3n398c5dUNR7liYDy3XdKLS/vFdXiOZuqqGz+J29MDRRed0hCgdJE6FFsNigECFB9aalxUUcNPX9vK1uPnCQ4085f/N5KpQ5r3A7k6M5m1B87wfvZJHnhnO5//fALRYa76SOElevYkYajnOrC6Ss/Rahq35CTs/q+6LdTDP4MlEgZO8+xzxg2AwFCoKVO/W7G9VZB5cmtDhiQbzuxT+yo1ZQpQCyhSxqrg5fR38MaP4Kcrjd37phUSoHSSpmk8+uFu6qwaV2Yk8M/ZKpVWXVfP8XMVHCkoo37fMhL2FlFkiuabwHHU1WgcOVPOkTPlsDe/02PYp6VRj4kepmJu6BdAWFxPkqJDSY4JUdfRoSREW7AEun73zQhLILOzenHLuHS+OnyWxd8cZc2BM6zeX8Dq/QX0i49gzsW9uGFkT8Ltmf45d1j9woVEQ0SC/QPR61C6Srt7WwbFAJ/ufaSbbG5xJbNf+ZZDBWVEhQTyrzljuah363/ofvPDIWw9VsixcxU88uEu/vr/RjoWaBuNLy0vbkmf5tm0CLa9oW4LjfHqkDwiIBASh8LJLfD2zWpD1JqyCx8XlaKmcFLGQM8xKvMSHKbuKz8Hr1yp6sPe/DHc/pkKtnyEBCid9OH2U3x7tJCQIDO/vibDdrslMIABCZEMSIiEnSsBiMmazbbJM8grqeJwQRlHzqjL4YIyjp2tIMBsIio0iMiQQKJCgogKbbgOCWxx+4XHAS8vhLMHeW6CGQYM8/jrYDabuGxADy4b0IPvz5Tx+sbjvJ99ksMFZTz24W6eXb6fG8ekMjurF2ndw9o+UcE+dd1jkGPdGvWVPCVdIINSU66WH4IxMij6lFpVkVpqbMBP6IfyS5nz7285XVxFQpSF1+8Yx8DEtv+jjrAE8sJNI5n58gY+3ZnLxAE9+PGYVA+O2MV8sf6kKT1AKS9QX3uyQNabeo5WAcrZhpWNQeGqUFcPRlLGtJ8VCe8Ot/xXBSl5O+Hd2XDzu2pxhQ+QAKUTiitr+d2nql7iZ1f0J6VbK394i0/BYRWgMGoOZrOJ5JhQkmNCmTDAhcvVEjPVevm8nTBgiuvO64Q+PSL4zQ+H8OCUAfw3+ySvbTzO0bPl/Ovro7zyzVEmDUrg9kt6cXHf7hd+KrUtMXZwvtQP292XVtWy/uBZ1hwowGrVGJEWw6i0bgwKOa9+cQMsai7e24LDVMPAklMqi2KwACX7eCF3LN5KcWUtfXuE89odF7X+u9rC8NQYHrhyAH/44gC//ngPY3rF0rsztVXeUpKrMpOYID3L26NxTspYtSloaa76uqsEKJfOVx3DoxuyJD0GObY9CqipoZvfgcVXw5Ev4eP/hetecn+7fheQAKUTnl95kLNl1fSJC+enP+jd+oO2vaGmLNIvhbj+7htMUqbam8dFS41dITIkiNsu6c3srF6sO3SGxd8cY93BM6zal8+qffn0jAnl8kE9mDQogay+3QkJCmhSIOtA/Qn4zYaBJworWLUvn9X7Cth89By19Y1LuD/Ypn62sUFHeS8ASgKi+XZfAaPSuxEb7sGCwdbE9lEByrkjhloxsGpvPnOXfEd1nZWRaTH8e85YujnwWt1zWV/WHzzD5qOF3P/2Nt6/92KCAnysO8Oxr9V1Uqbv/mE3m2HwD+Hbv6uvffXncFRkAlzxf50/T8/R8OPX4K2bYMcS9f/lFY92/rxuJgGKk3afKub1jccAePLaoa3Xd1jrYdt/1LErOse2J1Hf/dI4AYrObDZx+cB4Lh8Yz5EzZby+4RjvZ5/kVFElb2zK4Y1NOYQEmbm4bxzPn9lFNDiRQWlIv/tYBqXeqrH9RBGrG4KSA/mlze7vExfOpMHxhAUH8l3OebbnFBFeWwQBcKIqlJ++vhWAXt3DGJXWjVHp3RiV1o2BiZEEmD34CSm2t+GWGr+zJYdHlu6m3qpxxaB4/nrzSMKCHfsvL8Bs4vkbRzD9ha/YcbKY51ce5JfT7Fz+bhTH1qtrX53e0WVc2/UCFFcaMAWufh4++V9Y/weISoYxd3h7VO2SAMUJVqvGYx/txqrBjMwkLu3fRh3AkS9V0WZIjIr+3Ulfknb+qGpkFBLt3udzUt8eETxx7VB+NX0wG46c5cv9BazZX8Dp4iq+2n+acMtxMMGsj4rJHLKfKwbFMzI1hsCOPrXqGwZWF0NVCYREuf+HcVJ5dR1fHTrL6n35fLm/gHPljc3lAswmxqR3Y/LgBCYNjqdPj+ZTOFarRsFXp2ANBEX2oK85nCNnyjl2roJj5ypsWZbw4ACGp6opofF9ujOuT6x7P/kbqFBW0zQWrTnMH1eoFuE/Hp3C0zcMc/rnT44JZeENw7jvze94ed0RftC/B1l9DVCcbC9bgewE746js9LGq8L5snwJUJw1eo7KdK77PXz6IEQme351kgMkQHHCe9kn2JZTRHhwAI/NyGj7gdmL1fXwmyAoxL2DCottXIqXtxt6XeLe5+uk0OAAJg1OYNLgBDRN40B+Kdu2biRwq5VSLZRvzgTzzdojvLz2CNGhQVw2oAdXDIrnsgE9Wk/RWyJUIFhVpH4BDRKg1NVbKaqs5VxZDd8eK2TV3nw2fn/O1lYdIDIkkMsG9GDy4AQmDuxBTFjbUxBms4nEQFXJP6BPb1bPnEhRRQ3bThSx7fh5vsspYvuJIsqq69hw5Bwbjpzjr2sOExUSyOSMBKYNSWTCgB5qOs2VbEuNHe+FYrVqHDlTxnc559mWU8S2nCLOldcQExZETGgQMWFBRIcGN/86LNh2HBMaTHRYEJGWQDTgiU/28PpGtbv3fRP78tDUgZ1egXPVsCRuHJPKO1tPMP/d7Xz+8x+0++9kGMUn1YcWUwCk+Wj9ic4cAFnz4Mvf+n6w5U0TF6ip8O1vwPu3w5xlkOKBDRCdIAGKg86X1/DM56pO4v7JA0iMbiPwKM1XjYUARrl5ekeXlNkQoOw0fIDSlMlkYlBiFIN6V8BWCE0ewgvjRvLl/gLWHTxDUUUtH+84zcc7TmM2wci0boztFUufHuGql0yPcPXHIjpFBSjFJx3roWInTdMoqaqjsLyGwvIazpfXUFjR4lq/r6KWwvIaiitrWz1XWmwYkwcnMHlwPGN7O5jdqGjepC0mLNg2hQZq2uhQQSnZx8+Tffw86w+e4WxZDR98d4oPvjtFaFAAEwf2YNrQRC4fFE9UiAsq+rvbn0Eprqhl+8kivjt+Xk1bnSiitKrugsedLat2aAhmE4QFB1JWXYfJBL++OoPbLmmjNswJj1+TwbfHCjl6tpwFH+zipVmjjL/0WM+eJI8wTNDeKRf/TAUprTUta4feTbu0qo602DDMnpz+NBqTCa75s2rodngVLPkx3Lmy8XfYQCRAcdCzXxzgfEUtAxIiuO2SXm0/cPubYK2DlIsa98pxt8RMOPCZIetQ7FKgAr/AxEFcO6In147oSV29lW0nimxTQfvzGv/wNtU9PJi/B4YxBli/dRu1dZn06RFBarfQjqeHaAw+1DYATbYCaOjKe7qoirziKmqc2J/FZIKY0CD69ohgUkNQ0i8+wvk/buXtbxQYYG4I+BKjmDUunXqrRvbx8yzfnccXe/I4VVTJ57vz+Hx3HkEBJi7pF8e0IYlMzkggLsLi3Jj0pcaV55stNa63ahwu0LMjKsNzuODCXg6hQQFkpkQzMq0bo9Ji6NktlJLKOoorayiqqKWospaiitrGr223qa8ra+uxaqpxYHCAmT/9ZDjXDE927mdpQ7glkBduGsENL23g8915vLv1BDeOTXPpc7icXiDr6/UnOpOp1dUn9VaN/JIqThVVcup8JaeKKjnZcH3qfAWni6psW3jERViYMCCOywb04Af9e3i/wNwbAoJU0eziq9ReP2/MhJ+uMkbbgiYkQHHA9hNFvL0lB4Cnrh3a9qdeqxW+e10du7s4tqmkhkJZA63kcUgre/AEBpgZ2yuWsb1ieXjaIE4VVbLuwBn25Zbw/dkyjhSUk1dSxbnyGvYFRjEmEHbs2cOfdqji0aAAE+ndw+kTF07f+Aj6xIWjgQo8iirVlgDFVeQWVVJeY98eROHBAcRGBBMbFky38CbXDZduYfpxEN3CgokJC3ZtwWqLDEpHAswmLuody0W9Y3ns6sHsPlXC8j25fLEnn8MFZaw9cIa1B85gXrqLsb1imTokkalDE+kZE9rmOWvrrRS3CBouDokntKqAJcvXcTBwAIcLythxoojS6guzI+l6UW9aDCPTujEoMdKuQLItVbX1lFSqoKVHhMWhlTqOyEyJ4cEpA/n98v385uO9DZk8Ayz1bou/FMg2OFdWzer9BZwsrOBkk2Akr7iKOjs2LQ0OMHO2rNqWTTSZYHhKjOrhNLAHw1NiOv27WlVbz/68UnadLGLnyWJ2nSrmVFElEwfGM2tcGuN6xxoj82aJgJvfg1cmq2nAJT+BOZ9AsHGW0kuAYqd6q8ajH+5C0+CGkT3b35/j2Hr1D26JanXzPrfRt+c+s1+1jA908tOwt9h6oLQ9PdMzJpSbxzX/1FpeXcfRs+WYv9kCe1cxNraCwQFRfH+mjOo6K4cLVDM8e7r2dgsLat6FN6bxOCk6hB6RFtfXbzhK7yLrxKcdk8nEsJRohqVE89DUQRwuKOWLPfks353HrlPFbD5ayOajhTy5bC+ZKdEMToyipKoxY1HSkLVoLZh7O7g7480FbN76LR9ZGwOEsOAAhqfEMCo9hpGp3RiZFkN3ZzM1bQgJCiAkKID4KDfXegH/M6EPXx06w4Yj5/j529v5770XExxowKXH549DUQ6YA1WBqQ+rrqvntQ3H+Mvqw60GvACBZhNJMSH0jAmlZ0wYPbuFkhITSs9uofSMCSUpJgQTJrYeL2TdwTOsO3CG/XmlbD+h6rZeWH2I6NAgftA/jokD45kwII74yPbfTzV1Vg7mlzYEIiogOZBX2mqw9MmO03yy4zT94iOYNS6NG0alEB3q5YZpkQlwyweqkdupbHj/DrjxTdXF1gCMMQofsGTzcXafKiEyJJAFV3VQ35D9mroe9iPPRqPRqY2FogX71Lyzr6ivbWgmhcNLjMMtgQztGQ2DMmAvjI+t5PPbfoDVqnG6uJIjZ8r5/kwZ358p5/uzZZhNJvUfVrT6Tyu5yXVosJeDD3s4mEFpT7/4SPrFRzL38n6cPF/Bij35LN+Tx5Zjhew8WczOk8Vtfq/JpDbEjAlTBaxVlelQvo8fplaR0qcvyTGhjEztxoCEiE5lR4zGbDbx3E9GMO2F9ew6VcxzKw/yq+mdWHq8/S04uh6ueta1bcj17rHJo9SnZR+kaRor9+bzu8/2cfxcBQCDEiMZld6NnjGhpDQEHz27hRIfGWJX9uPivnFc3DeOBdMHk1dcxfqDZ1h38AxfHTpDcWUty3bmsmynagiXkRTFZQN7MHFAD4anxnD0bDm7Thaz81QRu04Wsy+3tNVp39jwYDJTosnsGc2wlBi6hQXx3+9O8dH2UxwuKOOJT/by++X7uSYzmVnj0xmeEu29rEpcf/h/78DrP1R1k589CFf/2RCN3CRAscPZsmr+8IX6dP+LKQPpEdnOp7/yc7B/mToefZv7B9eUyaSmeY6uV9M8vhSgFH4P1lrVGVXvCuuoFt1kzWYTKd3CSOkWxmWu7NrrbeXu2SgwpVsYd1zamzsu7c2Z0mq+3J9PQUk1MWFqS4WYhpUz0Q2rZyJDgpr/Qfh6C6xazqSEciZN9bFeIQ5KjA7hmRsyueeNbP6+/ggT+sdxcT8n/j2qitVyz9py1Zdi0mOuG6Qv778D7Mst4bef7uWbw+r93iPSwkNTB/KjUSkuK3JNjA7hJ2NT+cnYVOrqrWw/UaSyKwfPsPNkMXtzS9ibW8LLa9tenRYdGkRmSjTDekar65QYkqNDLgg4xvSK5ZGrBvHh9tO8uek4+/NKeS/7JO9ln2RoT1Uv9sPhyfbtWeZqaeNg5r/gnVvV6tPoFJjwkOfH0YIEKHZY+Nl+SqrqGJIcxS3j09t/8I63oL4GkkY09ibxpMSGAMXXCmX1+pO4Ac5H7novlJJTbW9P7uvqqqGmoZmbGzcK7BFpcbwAVF9qfM7xpca+aNrQRP7fRam89e0JHnh3O8t/PsHx2pcd76jgBGDTyzDufyAivvOD0zSf3X/nXFk1f1p5kLe/zcGqQXCgmbt+0Jt7J/Yjwo1/vAMDzIzpFcuYXrE8OGUgZ8uq+eqQmgpaf+gsheU1RDZkazMbpkkze8aQGhtqd/YjMiSIW8enc8u4NL7LOc+bm3JYtiuX3adKWPDBLp7+dB/Xj+rJzePSGJTo4VVXg6+B6c/C5w+ppdxRPWHEzZ4dQwsSoHRgy7FC/vud+kT+1HVD208hahp81zC948ni2Kb0oMjXCmX1+pPOLA+OSgZMKkCsOOua/+iNRq8/MQWo6TwjsfVC8X6zNk957OoMNh8t5Psz5Tz8350smjXK/iXjmgZbX1HHARYVqHz1HEx/pvMDK/xeBermIEgd1/nzeUBNnZXXNhzjxdWHbHUmM4Yl8avpg0iN7XjvJFeLi7Bw/cgUrh+ZgtWqcaasmh4RFpdkb0wmE6PTYxmdHsujV2fw3+yTvLn5OMfOVfD6xuO8vvE4Y9K7MWt8GtOHJnmu7m3c3apVxTcvwMc/U43x+k3yzHO3wg8/YrpOXb2Vxz7cDcBNY1MZldZB98KcjWrDvqAwGPojD4ywFXrL+7zdqtW+r7DtYuxgi/umAoLUhmKgOvj6I1v9SXfjZYj0AKWyUC037gLCggN58aaRBAWYWLE3n6nPr+eLPXloWscrSjj+jcocBoXBzH+q27a+ogpb7bTzZBGvbzzGJztOs/n7cxw9W055dV3j8uKUMWozRwPT60ymPL+O3322j9Jqla1+5+7xLJo1yivBSUtms4mEqBC39E+JDQ/mrgl9+PLBibz503FMH5pIgNnE1uPneeCdHYxfuJq7X9/KojWHVZ1MReu9lVxm0m/U3y9rHXzzZxVIe4lDGZSFCxfywQcfsH//fkJDQ7n44ov5/e9/z8CBjX9UqqqqePDBB3n77beprq5m6tSpvPTSSyQkJNgek5OTw7333suaNWuIiIhgzpw5LFy4kMBAYyV0Fm84xv68UmLCguzbf0Mvjh16g/eaIsX1h8BQ9Wms8Hv3blDoSrYVPJ2sXYjuCaWnVafEnsbsjtgpnVjB43bB4RCRqBpAFX7ve6+/pqmLg4Hf0J7RvHDTSB77cDffny3nf/6Tzdhe3XjkqsGMbO9DzZaG7MmwH6t9ZnpPUNOz634P1y5q9zm3HCvkxdWH+OrQ2Vbv/6vlHa42wfuFvVn31jbiIy3qEmUhPjKk4TiEqJBAry553Z9Xwm+X7ePrw+rn0OtMZo5K8exeUgZgNqueRJf0iyO/pIp3t5zgrW9zOF1cxYq9+axosgqxd1y4KsJNiWF4SjRDkqNdV+BvNqvdjrv3hUt+7tViWYcignXr1jF37lzGjh1LXV0djzzyCFOmTGHv3r2Eh6vVKg888ACffvop7733HtHR0cybN48bbriBb775BoD6+npmzJhBYmIiGzZsIDc3l9mzZxMUFMTTTz/t+p/QSfklVfx51SEAHp42qONmPpXnYe+H6nj07e4dXHvMAZAwBE5tVQ14fCFAqa+Dc+q17nyAkgInt/jcpoF2q2gokHVj/UmndO/bEKAc9a0ApaoY3p4FZw/B3WshKsmhb79qWBI/6B/H39d9z7++/p4tx85z/UsbuDoziV9OHURa9xZZgNJ82PexOh77U3V9xeOqJ8X2JXDJ/Rf87mqaxoYj53hx9SE2Hy0EVI+bS/vFUVlTT0FpFQWl1VTU1DGWPQD8t7A3G8+ebnPcwQFmIkMCGy5BRFgajyNDAokKCSSiyde2a0sg4ZZAggPNBAWYCQ4wExRgIsBssivgOVdWzXMrD/JWkzqTn17am/sud2+dia9IiArhZ5P6c9/l/fgu5zw7ThSx42QxO04UkVNYwdGz5Rw9W85H29W/bYDZxICESIbrQUtqNAMSIjucbrRaNarrrFTX1VNdZ6Wqtsl173voXqzRx4vrCxx6JyxfvrzZ14sXLyY+Pp7s7GwmTJhAcXExr7zyCkuWLOGKK64A4NVXX2Xw4MFs2rSJ8ePHs2LFCvbu3cuqVatISEhgxIgRPPXUUzz88MP85je/ITjYGF39fvvpPsqq6xiRGsONY1I7/oZDK6GuCuIzvP8fc1KmClDydqqlzkZ3/piqGwkKa9yV2FlNC2WNpLZK9aPobH8BI2dQQO1qfPwb3yqUrSiEN26A09vU19/8Gab/3uHTRIYE8YupA5k1Po0/rTjIf787ybKduXyxJ485Wb2Yd0W/xv17tr3e0Gl6bGODxdSxMPAq1Q36y9/CT1RGVtM01h44w1++PMR3OUWAakD4o9Gp3Dex7wVTIOWn9xH+jyKs5mBm/ejHTCrXKCitpqBEBTD6cUlVHTX1Vs6V1zTbsLIzTCaaBSxBAeaGS5PjQDPfnymzbW9w1bBEFkwfbIipHKMJMJtsjSp158tr2HmqmJ160HKyiDOl1ezLLWFfbglvb1HT25ZAM4MSIzGbTVTXWqmqq6e61qoCkoZApKPO2LeOT+ep64a69WdsT6f+tywuVj0SYmPVi5ednU1tbS2TJ0+2PWbQoEGkpaWxceNGxo8fz8aNGxk2bFizKZ+pU6dy7733smfPHkaOHHnB81RXV1Nd3bgvR0lJSWeG3aFvDp/lk4Z9X3573VD75h3PNmQAUi/y/vpxvWFb3i7vjsNeZxrqT+IGdL6uQg9wjFSDUnYG/nEZhMbC/6xTWS5nubAHilsYaFdju5Sfg/9cq35XgsLV1Gj2Yrh0vmpi5YSk6FD++OPh3HFJbxZ+vo+vDp3lX18f5b3sk8y7vB+zx6dg2bpYPVjPnuiueBQOfA57P8R6ahsrzifx1zWH2H1K/Z9nCTTz/y5K438u60NSdOudfsNPbQDAnDaOq0e1vRdRVW0958prKK2qpbSqrsl1XYuvaymrrqOkxe0VNXXU1jevT9A0VezadDPMtmQkRfH4NRmMb6/ppbhAt/Bg1fm2oXWCpmnklVSx40QxOxu61+44qfa32tFOH6OWAs0mLIFmLEEBhDRcdwvzbiM5pwMUq9XK/fffzyWXXMLQoSrCysvLIzg4mJiYmGaPTUhIIC8vz/aYpsGJfr9+X2sWLlzIE0884exQHVJTZ+Xxj1Rh7C3j01UDMHucP6auu7luczKnJTas5Mndqf7H8HbA1JFWWtw7Lbohg1JsoAzKmt+qjE7JKZVd6MxOrIbPoDi/q7HHlRXA69dCwV4Ij4fZH8En/6umCDf+Bab8tlOnz0iO4j93jmPdwTM8/ek+DuSX8rvP9nHk63d5puYkWmgspozrmn9TwhCsw36Mede7bH31Qe4pexBQ3XhvGZ/OT3/Qu8PupvYuLw4JCmjYzqDtLQ06omkatfUatfXWhkvTYys1dY1f1+j311kJCw5gXJ/uXa7OxB1MJlNDp+tQpg1NBNTUzbFz5RzML8NsUv/WtuAjyIwlUH1tuz3QbMhmik4HKHPnzmX37t18/fXXrhxPqxYsWMD8+fNtX5eUlJCa2smpgDb86+vvOXKmnLiIYB6c4sCKkvNH1bW+aZo3JWSoZagVZ6E0t2H5rYHZlhi7IkBp3qzN63J3NhZPA+x6r3MBitFrUHxlqXFpHrx2jVp1F5Go9iDpMQAm/FLt7rrl33DJA21uyOiIywb04NJ+cfw3+yR/WnmA6ZWfQgAs5XJSTlZwUW8VcNTVW/lo+2mWfn8Fr2r/5aK6bC6zHGLYxdO549Le9m1qp2lNNgi8tNNj74jJZCI40GTMVv9dmNlsok+PCGPvE2UHp95V8+bNY9myZaxZs4aUlMaun4mJidTU1FBUVNTs8fn5+SQmJtoek5+ff8H9+n2tsVgsREVFNbu4w6miSv6yWrVbXzB9sGP7JBQ2BCixBsigBIWq6RLwjYZtrsygRDW8H8vyoc418+pO0zRYvgDQIK4h2N37sWq25ixfyaBUnIPKIq8OpU3Fp+DVq1RwEtUTbv9MBScA/a9UTRZry2FT+ytpHBFgNvGTsamsvTOdywLU7+Sfiy7lJ3/fyF2vb2XxN0e5/E9refC9HXx9LoqlJlXD90rq5/xiygD7d9w9cwDKz0BgiFpiLIQPcyhA0TSNefPmsXTpUr788kt6927+x3j06NEEBQWxevVq220HDhwgJyeHrKwsALKysti1axcFBQW2x6xcuZKoqCgyMjI687N02j/Xf09lbT0X9YrlhlE97f/G6tLG2gAjTPGA7+xsbK1vrN/pTA8UXXicanqFppYbe9Pej+D41+qPxax3VY+WqiI4vLrDb22T0WtQLBGquRMYM4tSlKO2mC88AtFpKjjp3rfxfpOpscX35n+4vJ9L6A6VTavudQWXXjQWswlW7s3nN5/s5URhJd3Dg3l42iBmzHsOAkMIPLkJDq+y/wn06Z3Ucb63WagQLTgUoMydO5c33niDJUuWEBkZSV5eHnl5eVRWVgIQHR3NnXfeyfz581mzZg3Z2dncfvvtZGVlMX682k1zypQpZGRkcOutt7Jjxw6++OILHn30UebOnYvF4t1fqEeuGswvpw3kyeuGONYbQK8/Cevuvf4nLekN23J3eHccHTl/TK1+CgyBmA62EbCHydSkDsWL0zy1lbCiYV+VS36upv6G3KC+3vWe8+c1egYFjFsoW3hUZU7OH1P/Hrd/1vqU7MCrIH6I2lJg899d9/y1lbDtDQAs4+/i6euH8cX9E7gyI4Fe3cN47OoMvn74Cu6d2JfwuDS46C71faufVFs32OPoenXto/vvCNGUQwHKyy+/THFxMRMnTiQpKcl2eeedd2yPef7557n66quZOXMmEyZMIDExkQ8++MB2f0BAAMuWLSMgIICsrCxuueUWZs+ezZNPPum6n8pJwYFm7pvYz/E9EAoNVH+i85UMil5/Ejegc6tbmrLVoXixUHbjX6E4R00hXPJzdZu+5PvA51Bd5vg562tVBgaMm0EB5+tQrPVqSnLLv2Drv9XyX1c5e1gFJ8UnoHs/uP1ziGmjjs1shssasiibXoIqF60a3POhyshEp8KAqQD0T4jkn7PHsPahy7nz0t7Nm21dOh+CI9XvsN5jqT1Wa5P6k07UOQlhEA4VydrTvjkkJIRFixaxaFHb87fp6el89tlnjjy1sdkKZA0yvQONS42LctR/iqEdtOn3FlfWn+j0OhRvLTUuOa32VAGY/ITqsAqQPFJlFwqPqF4XmT9x7Ly2P9gmCItt96FepddhdRSgVBbBya1wYrO6nMqGmiaB2/IFKus09k7VW8jZ1WhnDqiC2LJ89T6b/XHHS4gHX6vqhs4egG//ARN+4dxzN6XvuzN6jn3BeFgsXPwzWPs0rPkdDP5h+310CvaqbQaCwqHnqM6PVwgvk9JrV9CneIxQIKsL7QYxDbvRGrkfii1AcUH9iU7PoHirWduq30BthaoDaNooz2Rq/NqZaR69/iS0m+uyTe6g13Q0bdamaarWaNsbahOyRePh9+nw5kxY/ywcXaeCk+BI6HM5JAxVU387lsC/JsHff6CyKo5mnvL3qMxJWb6atpmzzL7+JmZzY1CycZFzGa+mcneo5cvmIBg52/7vy7pPTR2fO6x2Sm+PXn+SNl7tSyWEj5Oewq5gxCkeUHUoRTkqQOnM0lZ3ckcGxZtLjU9sgZ0NU57TnrnwU//QH6m9Vo58qZqEObKM1RfqT6BxiufsQfjqT3DiW3WpbGXKJraPCuRSL1LXPQap4EvT1B/0rf+G3R+o9/CyB2DF4yrzNOYOSOygw2XuDnj9OvW8iZmqz4kjmachN8DahSoTtPXfcMn/2v+9Len77gy+xrEGcJZI+MGD8MUjsPYZtW9PUBt9UDy4vFgIT5AMiisYcYoHmhTKGrQOxWqFMwfVcfxg153XW83arFZY/rA6HjGr9TR7jwHq38VaZ19dQVNGX8Gj0wOUqiJV4HlwuQoSAkMg7WJVk3PTEvjFYfjfbXD931TAkTCkMTNkMqmg5fq/wYP7Ycrv1PRYTamaKvnbJfDKFNjxttpGoKVT2Wpap7JQTQ/N+djxabGAQBUcAGz4iypydUZVcWPGrGXnWHuMuVPVMpWchOxXW39M0/oTo34YEcJBEqB0Vn0dFDXUOhhpigeMXyhbdBzqKtWyYFes4NHZ2t17OIOy8x31hzE4AiY93vbjhv1YXe/+r2PnL29o0uaC5mFuZYlUAVp0GmRcB1MXwk+/hF+dgDs+hyufhEEzIMLOXcjCYuHiefCzbJUFybhW7Wt0YjMs/R94bhB88X+NU0onvlWZk6pilZW5danzNViZN6qp0vKC5g33HLHjbTXl12MwpF/s+PcHhcBlv1TH6//Y+nRT/i4VEAZHqj4uQvgBCVA6q/gEaPXqj2xE643mvEbPoJw54PynP3eyreDp3/lN9JrSNwysLnbdCoyOVJep2hNQtQuR7bwXhs4ETKrtvSNBlK9kUEBt1/7ALrXhXdZ9kDIaAju5EajJBH0mwk9ehwf2wOWPqoLoyvNq1dRfRqmsyX+uh+oSSL8EbvkvhNi5XUVrAoLg0gfU8TcvON5kT9Map3fG3ul8oe+IWSqDVHEWNr184f1HG+pP0rNc+7skhBdJgNJZTVvcd3ajO1eLSlYFdlq9qvA3GnfUn4BqFhYSo449VSj79XNQlqfeB+Pva/+x0T0bP0k7kkXxlRoUT4hMVEuB798J/+8d6D8FMKk+IDVlappj1nsqm9NZI2apoLf0tK2Pid2Ofa1WAgWFq2yMswKC4PJH1PGGFy9cgm3n/jtC+BKD/UX1QUZqcd+SyWTsOhQ9g+LqAAU82wvl/DHY8Fd1POV39nXwtK3med/+5/GlDIqnmANg4DQVjPx8h+oCmzUPbn63cXl3ZwVa4JL71fHXzzu2hcKWf6nrzJ90vonjkBsgYZjKDn3zQuPt9XVwXO1gLA3ahD+RAKWzbLsY9/LmKNpm5DqUM/vUtSuXGOuiPdgLZcVjUF8NvS9TtRX2yLhO1VHk7WwM1Dqif2qWDErruqXDFY/C1N+p/ahcadStqoV/8QnY+bZ931OaB/uXqeOxd3Z+DGYzTGroTrz57+r8oN5D1SVgiW78QCKEH5AApbOMuoJHZ9QMStMVPO7IoOh1KO6e4jm6HvZ9DCYzTFtof41BWCz0naSO7c2i6FM8Rt3J2J8FhcLFDcuMv/qTylp05LvX1Wqt1HGNjRM7q/8Udb66Slj/B3WbPr2TfrGx++MI4SAJUDqr8Ji6NuIUD0DScHWdv0e1EjeKkpNqx1hzUOOyVFfyRC8Ua33DbsU0LpN1hG01z/uqmLIjFVKD4lVjblfB4flj6t+sPfV1kL244ftckD3RmUyNK8SyF6spZr1AVqZ3hJ+RAKUzNK3JFI9BA5TYPhAUpj5xnTvs7dE0ctcKHp0nApTvXoP83aog9/L/c/z7B06HwFDVCOz0d+0/1mptnOKRGhTvCA5X9S2glvu2F/AfXK6yd2Hd1bJoV+p1qcq+Wevgy99CzsaG2yVAEf5FApTOqDinGkdhamwrbzTmANU2HIw1zVPgxvoTcH+AUnkeVj+ljicucG5vHEsEDLpKHXc0zVNVpFZjgUzxeNNFd6mA9Nyh9hvt6fvujLyl7c6vnaHXoux+X61aCu3W+HsuhJ+QAKUz9BU8Ucnu+U/IVWyFsju8O46m3LmCB5rXoNi7Vb0j1j2rupTGDexcAaRtmueD9j+R6/UnlujO9xMRzrNENi4jX//H1t9b546orQwwwejb3TOO5JFq80Bd+iXGa3MgRCfJO7ozjD69ozNioay7eqDoopIBE9TXNNZuuMqZg2qHW4BpT3duY7a+k9Qn8rK8xlblrbHVn0j2xOvG/Q9YolRvoQOfXnj/1n+r636T3VubdsWjqjgbpL298EsSoHTGeYNuEthS06XG9hRjupumuT+DEhAEkUnq2NVLjb94RM3/D5im/gh1RmBwY41Ce4WXthU8Un/idaExKkgBlUlr+jtVW9nYzM2ZfXcc0WMgXPaw2qU54zr3PpcQXiABSmfYmrT18uowOhSfoXpuVJ73zg6/0LiseMc78NkvVO2OOdA9K3h07tg08OAKOLxSrT6a8jvXnFOf5tn7Udut1GUFj7GMv0/tuZS3Ew5+0Xj7nqWqXig6Dfpf6f5xTPwV3LfBsR2ShfARsmlDZ/jKFE+gRWUq8ner/1BjUt37fFaryi6d3tZ4yd2hivmaSh7p3nqK6BQ4ucV1QVldjcqeAIy/B+L6uea86RerbE9pLhxe1XqzN32jQCmQNYawWFV79M0LsP5ZGDBVLQHWO8eOuU16kgjRSRKgdIbRm7Q1lZipApTcnfZ3O7WHvtS6WTCyU23U11JQmBpH8kh1GTDFdeNojaubtW35p1q9ERanWqq7ijlAbSC48a9qNU9r/z6SQTGerJ/B5n+oHayPfKmCllPZKrs2cra3RyeEz5MAxVm1leoTLxi3SVtTSZmwYwnk7XLN+apLYdl8OLRCpbRbCgxR3TP1YCRpBMQN8OxOq9ENmSJX1KBUFsHa36vjSY93bofc1ugByoHP1WvbcpM7qUExnogeqnnbppdUV9fuDRm1jGvVfUKITpEAxVn69I4lWvUgMDq91bar9uRZ9yzselcdBwSrLqp6MJI8Uk0pdWZ1iyu4sgZlx9sqK9RjkOpt4WrJIyG2LxQegf2fwfAWO99KBsWYLv5f2PKKapZ24lt1myv23RFCSIDiNFv9Sbr9+694kx6gFJ9QHUmdaSymO3cENr2sjq//u9pl1Yi9OVzVrE3TGhtvjf2pe2oLTCZVLLvuGbWap2WAYqtBkQDFUKKS1EaCW/6lGunFZ0BalrdHJYRfkFU8zrKt4PGB6R1QUxL6cujOZlFWPArWWrXENvNGYwYnAFENAUpZvipwddaxr+DsQbVqI/PGjh/vrGE/UteHVzdO6eikD4pxXXK/qjsBtSeTL3xgEcIHSIDiLF8qkNW5omHbkTVw4DMwBcDUp439n3F4HARYAA1KTzt/ni0N2ZPMn0BIlEuG1qq4/mpzR62+eRt1TZMaFCOLSYWr/gDDb4YRs7w9GiH8hgQoztKneHwlgwLNG7Y5o76ucffei+5y3z46rmIydb4OpTQP9i9Tx67clbYtek+UXf9tvK26RGWsQGpQjGrM7XD9yxAc5u2RCOE3JEBxVqGPdJFtKnG4unY2g5L9KpzZp4qCL3vYdeNyp87WoXz3uuoamzoeEj2wGduQGwAT5GyAoobVR3r2JCgcgkLdPwYhhDAACVCcYa2HouPq2JemePQMyrlDUFPh2PdWFMKahs6pl/9f54psPUmvQylxIkCpr4Otr6pjT63MiO6pNn4D2N2QRaloKJCV+hMhRBciAYozSnPVJnTmwMZP6L4gMhHC40Gzqo3OHLHu96pVfnyG+3ZodYfOZFAOLle1K2HdG/fL8YRhM9W1vjeP1J8IIbogCVCcoU/vxKT5Xjtrfblx7g77v6dgP3z7T3U89WnPNlvrrM4EKHrb8pG3qu0CPCXjOhX85u1SmypKDxQhRBckAYozfHEFj87RQllNU/vPaPUwcAb0vdx9Y3MHZ4tkzx2B79cAJlUA6UlhsY27JO96XzIoQoguSQIUZ/haD5SmHF1qfGgFHFndsHvvU+4bl7vY2t07mEHZ+m913f9K7xRCD23oibLrPalBEUJ0SRKgOMPWRbaXN0fhnKSGlTwFe1URaHua7d57L3Tv696xuYO+YWB1MVSV2Pc9tZWw7Q11PPan7hlXRwZOV5srnj+qgkSQDIoQokuRAMUZvjzF0603BEdCXZXqjtqeb/8B5w5DeA/X7t7rSZYICIlRx/buarxnqdoAMTqtcarF0ywRMPAqdaz/O0kNihCiC5EAxRm+PMVjNjf282ivDqX8rNoQEBp273VjB1V3sxXK2hmg6MWxY27zbhG03vpeJxkUIUQXIgGKoyrPq0/XADHpXh2K0+ypQ/nyt2paJDHT99t32wKUEx0/9vQ2OJWtam5GznbvuDrSd1Jj9gckgyKE6FIkQHGUXn8SHq/S8L6oo5U8ebvgu9fU8fTf+95S6pb0OhR7pnj0fXcyroWIHu4bkz0Cg5v3XwmTIlkhRNchAYqjfHl6R5fYJEDRtOb3aZrab0ezwpDrIf1iz4/P1ezthVJZpJb1gveKY1vS9+YByaAIIboUH+q4ZRC2FTw+HKD0GKSmMKqKoSgHujWZqtr3CRz7CgJD4MonvTdGV7I3QNnxFtRVqm65aePdPy57pF8CI25RNUCWSG+PRgghPEYCFEed98FNAlsKDIb4QWoqJ29nY4BSWwUrHlXHF/9Mdcr1B/YEKJrW2Ptk7J1qJ2QjMJvhukXeHoUQQnicTPE4yh+meKD1nY03LVKbIEYmw6UPeGdc7mCrQTkNVmvrjzn2lVrOGxwBmTd6bmxCCCFaJQGKo/xhigcuLJQtzYP1f1LHk38DweFeGZZbRCUDJqivbtzXpiV9aXHmjTKVIoQQBiABiiPqahqnCXx5igcuXGq8+kmoLYeeY5oXZvqDgCCITFLHrU3zlOTC/k/V8dg7PTcuIYQQbZIAxRFFOYAGQeEQEe/t0XRO4lDABKWn4eAK2P6mun3671Xdg7+xbRrYSoDy3etgrYPU8ZAwxLPjEkII0So//EvkRk0LZI1SROksSyTE9lHHS+9W15k3QcoY743JndoqlK2vg+zF6tgoS4uFEEJIgOIQX94ksDV6HUrlebUx3eRfe3c87tRWs7aDn6ssUlgcZPzQ8+MSQgjRKglQHOEvK3h0eh0KwKXzG4pJ/VR0qrpu2e5e7xw76lYItHh2TEIIIdrkcICyfv16rrnmGpKTkzGZTHz44YfN7r/tttswmUzNLtOmTWv2mMLCQmbNmkVUVBQxMTHceeedlJWVdeoH8Qh/6IHSlN6MLDoNLp7n3bG4m60GpUkG5dwR+H4NYILRt3tlWEIIIVrncIBSXl7O8OHDWbSo7eZR06ZNIzc313Z56623mt0/a9Ys9uzZw8qVK1m2bBnr16/n7rvvdnz0nuYvS4x16RfD/3sbbv8MgkK9PRr3aq0GRW/M1n9K8266QgghvM7hTrLTp09n+vTp7T7GYrGQmJjY6n379u1j+fLlbNmyhTFjVEHmX/7yF6666ir++Mc/kpxs0GkGTWsMUPxligdgYPv/ln4jqiFAKctXy8W1etj2hrpNlhYLIYThuKUGZe3atcTHxzNw4EDuvfdezp07Z7tv48aNxMTE2IITgMmTJ2M2m9m8eXOr56uurqakpKTZxePK8qG2AkzmxnoG4TvC4yDAAmiqKHb3B1BVpKa3+k329uiEEEK04PIAZdq0abz++uusXr2a3//+96xbt47p06dTX18PQF5eHvHxzXuIBAYGEhsbS15eXqvnXLhwIdHR0bZLaqoXAgS9QDY6Re1lI3yLydS8DmVrQ3HsmNvBHOC9cQkhhGiVyzcLvOmmm2zHw4YNIzMzk759+7J27VomTZrk1DkXLFjA/PnzbV+XlJR4PkjxtyXGXVF0ChR+D/uXwalstaPzyFu9PSohhBCtcPsy4z59+hAXF8fhw4cBSExMpKCgoNlj6urqKCwsbLNuxWKxEBUV1ezicbYVPH5Uf9LV6HUo+tLiIddBRA+vDUcIIUTb3B6gnDx5knPnzpGUpPZCycrKoqioiOzsbNtjvvzyS6xWK+PGjXP3cJznbz1QuiJ9JU99tboeI8WxQghhVA5P8ZSVldmyIQBHjx5l+/btxMbGEhsbyxNPPMHMmTNJTEzkyJEj/PKXv6Rfv35MnToVgMGDBzNt2jTuuusu/va3v1FbW8u8efO46aabjLuCB2SKxx/oAQpA/JDGPjBCCCEMx+EMytatWxk5ciQjR44EYP78+YwcOZLHH3+cgIAAdu7cyQ9/+EMGDBjAnXfeyejRo/nqq6+wWBq7dL755psMGjSISZMmcdVVV3HppZfyj3/8w3U/lTvIFI/v04tkAcbe4fv7KQkhhB9zOIMyceJENE1r8/4vvviiw3PExsayZMkSR5/ae6pLofyMOpYpHt/VvR9gUhslZt7o7dEIIYRoh8tX8fil88fVdWg3CIn27liE87r1gpuWQGSCClKEEEIYlgQo9pDpHf8x6Cpvj0AIIYQdZDdje8gKHiGEEMKjJECxh2RQhBBCCI+SAMUessRYCCGE8CgJUOwhUzxCCCGER0mA0pH6Oig+oY5likcIIYTwCAlQOlJyEqx1EGCByCRvj0YIIYToEiRA6Yg+vdMtHczycgkhhBCeIH9xOyIreIQQQgiPkwClI7KCRwghhPA4CVA6Iit4hBBCCI+TAKUjMsUjhBBCeJwEKO3RNCg8po5likcIIYTwGAlQ2lNRCDWl6rhbunfHIoQQQnQhEqC0R5/eiUyGoFDvjkUIIYToQiRAaY8UyAohhBBeIQFKe2SJsRBCCOEVEqC0R1bwCCGEEF4hAUp7ZIpHCCGE8AoJUNojUzxCCCGEV0iA0pbaSig9rY5likcIIYTwKAlQ2nL+uLq2REFYrHfHIoQQQnQxEqC0xVYgmw4mk3fHIoQQQnQxEqC0xVZ/ItM7QgghhKdJgNIWWcEjhBBCeI0EKG2xTfH08uowhBBCiK5IApS2yBSPEEII4TUSoLTGam1cxSNTPEIIIYTHSYDSmtLTUF8N5kCISvH2aIQQQoguRwKU1ujTO9GpEBDo1aEIIYQQXZEEKK2RFTxCCCGEV0mA0hrZxVgIIYTwKglQWlMoS4yFEEIIb5IApTV6DYpM8QghhBBeIQFKa2SKRwghhPAqCVBaqiyCyvPquFu6V4cihBBCdFUSoLSkT++E9wBLpFeHIoQQQnRVEqC0JNM7QgghhNdJgNKSrOARQgghvE4ClJZkBY8QQgjhdRKgtCRTPEIIIYTXSYDSUuExdS0ZFCGEEMJrJEBpqq4GSk6qY6lBEUIIIbxGApSmik+AZoWgMIhI8PZohBBCiC7L4QBl/fr1XHPNNSQnJ2Mymfjwww+b3a9pGo8//jhJSUmEhoYyefJkDh061OwxhYWFzJo1i6ioKGJiYrjzzjspKyvr1A/iEk1X8JhMXh2KEEII0ZU5HKCUl5czfPhwFi1a1Or9zz77LC+++CJ/+9vf2Lx5M+Hh4UydOpWqqirbY2bNmsWePXtYuXIly5YtY/369dx9993O/xSucl6WGAshhBBGYNI0TXP6m00mli5dynXXXQeo7ElycjIPPvggv/jFLwAoLi4mISGBxYsXc9NNN7Fv3z4yMjLYsmULY8aMAWD58uVcddVVnDx5kuTk5A6ft6SkhOjoaIqLi4mKinJ2+Bc6mQ0Hl0Ncf8j8ievOK4QQQgiH/n67tAbl6NGj5OXlMXnyZNtt0dHRjBs3jo0bNwKwceNGYmJibMEJwOTJkzGbzWzevLnV81ZXV1NSUtLs4hYpo+GK/5PgRAghhPAylwYoeXl5ACQkNC8wTUhIsN2Xl5dHfHx8s/sDAwOJjY21PaalhQsXEh0dbbukpqa6cthCCCGEMBifWMWzYMECiouLbZcTJ054e0hCCCGEcCOXBiiJiYkA5OfnN7s9Pz/fdl9iYiIFBQXN7q+rq6OwsND2mJYsFgtRUVHNLkIIIYTwXy4NUHr37k1iYiKrV6+23VZSUsLmzZvJysoCICsri6KiIrKzs22P+fLLL7FarYwbN86VwxFCCCGEjwp09BvKyso4fPiw7eujR4+yfft2YmNjSUtL4/777+e3v/0t/fv3p3fv3jz22GMkJyfbVvoMHjyYadOmcdddd/G3v/2N2tpa5s2bx0033WTXCh4hhBBC+D+HA5StW7dy+eWX276eP38+AHPmzGHx4sX88pe/pLy8nLvvvpuioiIuvfRSli9fTkhIiO173nzzTebNm8ekSZMwm83MnDmTF1980QU/jhBCCCH8Qaf6oHiL2/qgCCGEEMJtvNYHRQghhBDCFSRAEUIIIYThSIAihBBCCMORAEUIIYQQhiMBihBCCCEMRwIUIYQQQhiOw31QjEBfGe22XY2FEEII4XL63217Opz4ZIBSWloKILsaCyGEED6otLSU6Ojodh/jk43arFYrp0+fJjIyEpPJ5NJzl5SUkJqayokTJ6QJXAfktbKfvFb2k9fKfvJa2U9eK8e46/XSNI3S0lKSk5Mxm9uvMvHJDIrZbCYlJcWtzyG7JttPXiv7yWtlP3mt7Cevlf3ktXKMO16vjjInOimSFUIIIYThSIAihBBCCMORAKUFi8XCr3/9aywWi7eHYnjyWtlPXiv7yWtlP3mt7CevlWOM8Hr5ZJGsEEIIIfybZFCEEEIIYTgSoAghhBDCcCRAEUIIIYThSIAihBBCCMORAKWJRYsW0atXL0JCQhg3bhzffvutt4dkOL/5zW8wmUzNLoMGDfL2sAxj/fr1XHPNNSQnJ2Mymfjwww+b3a9pGo8//jhJSUmEhoYyefJkDh065J3BellHr9Vtt912wXtt2rRp3hmsFy1cuJCxY8cSGRlJfHw81113HQcOHGj2mKqqKubOnUv37t2JiIhg5syZ5Ofne2nE3mXP6zVx4sQL3lv33HOPl0bsPS+//DKZmZm2ZmxZWVl8/vnntvu9/b6SAKXBO++8w/z58/n1r3/Nd999x/Dhw5k6dSoFBQXeHprhDBkyhNzcXNvl66+/9vaQDKO8vJzhw4ezaNGiVu9/9tlnefHFF/nb3/7G5s2bCQ8PZ+rUqVRVVXl4pN7X0WsFMG3atGbvtbfeesuDIzSGdevWMXfuXDZt2sTKlSupra1lypQplJeX2x7zwAMP8Mknn/Dee++xbt06Tp8+zQ033ODFUXuPPa8XwF133dXsvfXss896acTek5KSwjPPPEN2djZbt27liiuu4Nprr2XPnj2AAd5XmtA0TdMuuugibe7cubav6+vrteTkZG3hwoVeHJXx/PrXv9aGDx/u7WH4BEBbunSp7Wur1aolJiZqf/jDH2y3FRUVaRaLRXvrrbe8MELjaPlaaZqmzZkzR7v22mu9Mh4jKygo0ABt3bp1mqap91BQUJD23nvv2R6zb98+DdA2btzorWEaRsvXS9M07bLLLtN+/vOfe29QBtatWzftX//6lyHeV5JBAWpqasjOzmby5Mm228xmM5MnT2bjxo1eHJkxHTp0iOTkZPr06cOsWbPIycnx9pB8wtGjR8nLy2v2PouOjmbcuHHyPmvD2rVriY+PZ+DAgdx7772cO3fO20PyuuLiYgBiY2MByM7Opra2ttn7atCgQaSlpcn7igtfL92bb75JXFwcQ4cOZcGCBVRUVHhjeIZRX1/P22+/TXl5OVlZWYZ4X/nkZoGudvbsWerr60lISGh2e0JCAvv37/fSqIxp3LhxLF68mIEDB5Kbm8sTTzzBD37wA3bv3k1kZKS3h2doeXl5AK2+z/T7RKNp06Zxww030Lt3b44cOcIjjzzC9OnT2bhxIwEBAd4enldYrVbuv/9+LrnkEoYOHQqo91VwcDAxMTHNHivvq9ZfL4Cbb76Z9PR0kpOT2blzJw8//DAHDhzggw8+8OJovWPXrl1kZWVRVVVFREQES5cuJSMjg+3bt3v9fSUBinDI9OnTbceZmZmMGzeO9PR03n33Xe68804vjkz4m5tuusl2PGzYMDIzM+nbty9r165l0qRJXhyZ98ydO5fdu3dL3Zed2nq97r77btvxsGHDSEpKYtKkSRw5coS+fft6epheNXDgQLZv305xcTHvv/8+c+bMYd26dd4eFiBFsgDExcUREBBwQXVyfn4+iYmJXhqVb4iJiWHAgAEcPnzY20MxPP29JO8z5/Tp04e4uLgu+16bN28ey5YtY82aNaSkpNhuT0xMpKamhqKiomaP7+rvq7Zer9aMGzcOoEu+t4KDg+nXrx+jR49m4cKFDB8+nBdeeMEQ7ysJUFD/QKNHj2b16tW226xWK6tXryYrK8uLIzO+srIyjhw5QlJSkreHYni9e/cmMTGx2fuspKSEzZs3y/vMDidPnuTcuXNd7r2maRrz5s1j6dKlfPnll/Tu3bvZ/aNHjyYoKKjZ++rAgQPk5OR0yfdVR69Xa7Zv3w7Q5d5brbFarVRXVxvjfeWRUlwf8Pbbb2sWi0VbvHixtnfvXu3uu+/WYmJitLy8PG8PzVAefPBBbe3atdrRo0e1b775Rps8ebIWFxenFRQUeHtohlBaWqpt27ZN27ZtmwZozz33nLZt2zbt+PHjmqZp2jPPPKPFxMRoH330kbZz507t2muv1Xr37q1VVlZ6eeSe195rVVpaqv3iF7/QNm7cqB09elRbtWqVNmrUKK1///5aVVWVt4fuUffee68WHR2trV27VsvNzbVdKioqbI+55557tLS0NO3LL7/Utm7dqmVlZWlZWVleHLX3dPR6HT58WHvyySe1rVu3akePHtU++ugjrU+fPtqECRO8PHLP+9WvfqWtW7dOO3r0qLZz507tV7/6lWYymbQVK1Zomub995UEKE385S9/0dLS0rTg4GDtoosu0jZt2uTtIRnOjTfeqCUlJWnBwcFaz549tRtvvFE7fPiwt4dlGGvWrNGACy5z5szRNE0tNX7ssce0hIQEzWKxaJMmTdIOHDjg3UF7SXuvVUVFhTZlyhStR48eWlBQkJaenq7dddddXfIDQ2uvEaC9+uqrtsdUVlZq9913n9atWzctLCxMu/7667Xc3FzvDdqLOnq9cnJytAkTJmixsbGaxWLR+vXrpz300ENacXGxdwfuBXfccYeWnp6uBQcHaz169NAmTZpkC040zfvvK5OmaZpncjVCCCGEEPaRGhQhhBBCGI4EKEIIIYQwHAlQhBBCCGE4EqAIIYQQwnAkQBFCCCGE4UiAIoQQQgjDkQBFCCGEEIYjAYoQQgghDEcCFCGEEEIYjgQoQgghhDAcCVCEEEIIYTgSoAghhBDCcP4/VRfCr0p1iTAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_predictions1(model, X, y, start=0, end=100):\n",
    "  predictions = model.predict(X).flatten()+100\n",
    "  df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})\n",
    "  plt.plot(df['Predictions'][start:end])\n",
    "  plt.plot(df['Actuals'][start:end])\n",
    "  return df, mae(y, predictions)\n",
    "X_test = np.vstack((x_test_start, X2_test))\n",
    "print(X_test)\n",
    "df_4, mae_4 = plot_predictions1(model4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196.987213</td>\n",
       "      <td>102.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219.068054</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>216.959076</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>217.776917</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>219.283844</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>219.916840</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>214.173462</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>210.246628</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>208.187042</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>209.710251</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210.764832</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>214.793488</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>211.811188</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>207.537598</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>208.459839</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>211.416336</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>210.476532</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>222.546082</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>203.866013</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>196.481201</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202.988068</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201.677429</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200.903702</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200.594315</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>208.240051</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>209.860199</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>206.088074</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>208.804260</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>203.359467</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200.577606</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>201.011688</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions  Actuals\n",
       "0    196.987213   102.58\n",
       "1    219.068054   201.22\n",
       "2    216.959076   235.04\n",
       "3    217.776917   223.36\n",
       "4    219.283844   153.35\n",
       "5    219.916840   176.58\n",
       "6    214.173462   179.29\n",
       "7    210.246628   260.26\n",
       "8    208.187042   144.39\n",
       "9    209.710251   176.85\n",
       "10   210.764832   200.03\n",
       "11   214.793488   161.85\n",
       "12   211.811188   324.88\n",
       "13   207.537598   285.11\n",
       "14   208.459839   191.13\n",
       "15   211.416336   194.15\n",
       "16   210.476532   188.70\n",
       "17   222.546082   201.74\n",
       "18   203.866013   174.39\n",
       "19   196.481201   206.83\n",
       "20   202.988068   181.35\n",
       "21   201.677429   234.13\n",
       "22   200.903702   244.36\n",
       "23   200.594315   252.99\n",
       "24   208.240051   212.36\n",
       "25   209.860199   401.43\n",
       "26   206.088074   220.10\n",
       "27   208.804260   284.35\n",
       "28   203.359467   216.37\n",
       "29   200.577606   219.25\n",
       "30   201.011688   204.15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.90575793850806"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df_4.index = val.index\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_4['Predictions']])\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], val['PM2.5 (µg/m³)']])\n",
    "\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train_last_few')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction_test')\n",
    "plt.plot(df_org.index[len(df_corr['PM2.5 (µg/m³)']):],df_org[len(df_corr['PM2.5 (µg/m³)']):],color='green',label='actual_test')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7EViSFyntz9j"
   },
   "outputs": [],
   "source": [
    "def df_to_X_y3(df, window_size=1):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6iv-AUQuJdX",
    "outputId": "c5d6aafb-a91e-4d2e-fd07-90734fcad509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1094, 1, 5), (1094, 5))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3, y3 = df_to_X_y3(df_corr)\n",
    "X3.shape, y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAaiWt0buKa4",
    "outputId": "9e431fbf-f8b8-4dc4-932b-d3242d2ab266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1040, 1, 5), (1040, 5), (54, 1, 5), (54, 5), (30, 1, 5), (30, 5))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, y3_train = X3[:1040], y3[:1040]\n",
    "X3_val, y3_val = X3[1040:], y3[1040:]\n",
    "X3_test, y3_test = df_to_X_y3(val)\n",
    "X3_train.shape, y3_train.shape, X3_val.shape, y3_val.shape, X3_test.shape, y3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czHWSE2Uv4Br",
    "outputId": "7b192759-b752-4f24-9f24-cf3a089ce7df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m17,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m45\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,485</span> (72.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,485\u001b[0m (72.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,485</span> (72.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,485\u001b[0m (72.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((1, 5)))\n",
    "model5.add(LSTM(64))\n",
    "model5.add(Dense(8, 'relu'))\n",
    "model5.add(Dense(5, 'linear'))\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "HY4LnQYxwDI2"
   },
   "outputs": [],
   "source": [
    "cp5 = ModelCheckpoint('checkpoint.model5.keras', monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model5.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR6NEXeSwF6J",
    "outputId": "63d8ef64-7125-40e9-d3ba-6e0895617e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 1347.0275 - mean_absolute_error: 18.5717\n",
      "Epoch 1: val_loss improved from inf to 2086.01611, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1003.4064 - mean_absolute_error: 15.9271 - val_loss: 2086.0161 - val_mean_absolute_error: 27.4700\n",
      "Epoch 2/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1312.6210 - mean_absolute_error: 18.6370\n",
      "Epoch 2: val_loss improved from 2086.01611 to 2078.70288, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.1716 - mean_absolute_error: 15.9071 - val_loss: 2078.7029 - val_mean_absolute_error: 27.4210\n",
      "Epoch 3/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 654.6089 - mean_absolute_error: 11.4173\n",
      "Epoch 3: val_loss improved from 2078.70288 to 2071.54541, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 904.1064 - mean_absolute_error: 14.8750 - val_loss: 2071.5454 - val_mean_absolute_error: 27.3724\n",
      "Epoch 4/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 495.1107 - mean_absolute_error: 10.7303\n",
      "Epoch 4: val_loss improved from 2071.54541 to 2064.62671, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 914.6492 - mean_absolute_error: 14.9706 - val_loss: 2064.6267 - val_mean_absolute_error: 27.3133\n",
      "Epoch 5/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 965.6597 - mean_absolute_error: 14.7493\n",
      "Epoch 5: val_loss improved from 2064.62671 to 2058.03149, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 922.9093 - mean_absolute_error: 15.0862 - val_loss: 2058.0315 - val_mean_absolute_error: 27.2505\n",
      "Epoch 6/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1062.0164 - mean_absolute_error: 16.3802\n",
      "Epoch 6: val_loss improved from 2058.03149 to 2051.13135, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 980.2885 - mean_absolute_error: 15.6753 - val_loss: 2051.1313 - val_mean_absolute_error: 27.1868\n",
      "Epoch 7/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1459.7949 - mean_absolute_error: 18.4719\n",
      "Epoch 7: val_loss improved from 2051.13135 to 2041.76514, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.6049 - mean_absolute_error: 15.5740 - val_loss: 2041.7651 - val_mean_absolute_error: 27.1069\n",
      "Epoch 8/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1092.5035 - mean_absolute_error: 16.5153\n",
      "Epoch 8: val_loss improved from 2041.76514 to 2030.09985, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 933.5333 - mean_absolute_error: 15.3671 - val_loss: 2030.0999 - val_mean_absolute_error: 27.0123\n",
      "Epoch 9/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1134.4988 - mean_absolute_error: 16.5435\n",
      "Epoch 9: val_loss improved from 2030.09985 to 2017.82092, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 978.6509 - mean_absolute_error: 15.4390 - val_loss: 2017.8209 - val_mean_absolute_error: 26.9120\n",
      "Epoch 10/500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 955.6766 - mean_absolute_error: 15.4770  \n",
      "Epoch 10: val_loss improved from 2017.82092 to 2004.56653, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 952.1671 - mean_absolute_error: 15.4474 - val_loss: 2004.5665 - val_mean_absolute_error: 26.8002\n",
      "Epoch 11/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1407.7604 - mean_absolute_error: 19.2378\n",
      "Epoch 11: val_loss improved from 2004.56653 to 1988.82324, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 971.8495 - mean_absolute_error: 15.7342 - val_loss: 1988.8232 - val_mean_absolute_error: 26.6710\n",
      "Epoch 12/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 613.3121 - mean_absolute_error: 12.5336\n",
      "Epoch 12: val_loss improved from 1988.82324 to 1970.95679, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 856.0474 - mean_absolute_error: 14.7556 - val_loss: 1970.9568 - val_mean_absolute_error: 26.5354\n",
      "Epoch 13/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1099.3492 - mean_absolute_error: 18.5667\n",
      "Epoch 13: val_loss improved from 1970.95679 to 1953.80676, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 944.1871 - mean_absolute_error: 15.4597 - val_loss: 1953.8068 - val_mean_absolute_error: 26.4163\n",
      "Epoch 14/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 911.1991 - mean_absolute_error: 16.1594\n",
      "Epoch 14: val_loss improved from 1953.80676 to 1937.17102, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 887.3170 - mean_absolute_error: 15.2713 - val_loss: 1937.1710 - val_mean_absolute_error: 26.3101\n",
      "Epoch 15/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 629.5703 - mean_absolute_error: 12.7087\n",
      "Epoch 15: val_loss improved from 1937.17102 to 1920.61890, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 852.3065 - mean_absolute_error: 14.7838 - val_loss: 1920.6189 - val_mean_absolute_error: 26.1983\n",
      "Epoch 16/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 769.0737 - mean_absolute_error: 13.9537\n",
      "Epoch 16: val_loss improved from 1920.61890 to 1904.40857, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 876.4573 - mean_absolute_error: 14.8905 - val_loss: 1904.4086 - val_mean_absolute_error: 26.0900\n",
      "Epoch 17/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 925.8961 - mean_absolute_error: 15.7209\n",
      "Epoch 17: val_loss improved from 1904.40857 to 1888.44080, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 902.0292 - mean_absolute_error: 15.2099 - val_loss: 1888.4408 - val_mean_absolute_error: 25.9804\n",
      "Epoch 18/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 887.1047 - mean_absolute_error: 13.3161\n",
      "Epoch 18: val_loss improved from 1888.44080 to 1873.24109, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 903.1668 - mean_absolute_error: 15.0149 - val_loss: 1873.2411 - val_mean_absolute_error: 25.8767\n",
      "Epoch 19/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1021.4178 - mean_absolute_error: 17.5950\n",
      "Epoch 19: val_loss improved from 1873.24109 to 1859.60474, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.8868 - mean_absolute_error: 14.7535 - val_loss: 1859.6047 - val_mean_absolute_error: 25.7820\n",
      "Epoch 20/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 934.9333 - mean_absolute_error: 15.6739\n",
      "Epoch 20: val_loss improved from 1859.60474 to 1846.28528, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.8948 - mean_absolute_error: 14.6268 - val_loss: 1846.2853 - val_mean_absolute_error: 25.6845\n",
      "Epoch 21/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1390.5833 - mean_absolute_error: 20.2231\n",
      "Epoch 21: val_loss improved from 1846.28528 to 1833.48987, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 878.6777 - mean_absolute_error: 15.1849 - val_loss: 1833.4899 - val_mean_absolute_error: 25.5863\n",
      "Epoch 22/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 933.2311 - mean_absolute_error: 16.1867\n",
      "Epoch 22: val_loss improved from 1833.48987 to 1821.82642, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 864.1900 - mean_absolute_error: 15.0235 - val_loss: 1821.8264 - val_mean_absolute_error: 25.4931\n",
      "Epoch 23/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 621.6822 - mean_absolute_error: 12.4933\n",
      "Epoch 23: val_loss improved from 1821.82642 to 1810.67273, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 809.2050 - mean_absolute_error: 14.3042 - val_loss: 1810.6727 - val_mean_absolute_error: 25.4000\n",
      "Epoch 24/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 726.8804 - mean_absolute_error: 13.5485\n",
      "Epoch 24: val_loss improved from 1810.67273 to 1798.95630, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 828.8998 - mean_absolute_error: 14.6220 - val_loss: 1798.9563 - val_mean_absolute_error: 25.3009\n",
      "Epoch 25/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 828.4287 - mean_absolute_error: 15.8188\n",
      "Epoch 25: val_loss improved from 1798.95630 to 1785.64551, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 844.8890 - mean_absolute_error: 14.7366 - val_loss: 1785.6455 - val_mean_absolute_error: 25.1943\n",
      "Epoch 26/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 760.6555 - mean_absolute_error: 14.0921 \n",
      "Epoch 26: val_loss improved from 1785.64551 to 1773.18530, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 769.5037 - mean_absolute_error: 14.1432 - val_loss: 1773.1853 - val_mean_absolute_error: 25.0882\n",
      "Epoch 27/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 770.3225 - mean_absolute_error: 13.4846\n",
      "Epoch 27: val_loss improved from 1773.18530 to 1760.56775, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 779.5544 - mean_absolute_error: 14.1481 - val_loss: 1760.5677 - val_mean_absolute_error: 24.9823\n",
      "Epoch 28/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 616.2548 - mean_absolute_error: 13.5723\n",
      "Epoch 28: val_loss improved from 1760.56775 to 1745.92651, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 810.3097 - mean_absolute_error: 14.6013 - val_loss: 1745.9265 - val_mean_absolute_error: 24.8675\n",
      "Epoch 29/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 774.8067 - mean_absolute_error: 14.4607\n",
      "Epoch 29: val_loss improved from 1745.92651 to 1731.10376, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 769.1060 - mean_absolute_error: 13.8858 - val_loss: 1731.1038 - val_mean_absolute_error: 24.7523\n",
      "Epoch 30/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1033.8955 - mean_absolute_error: 16.2325\n",
      "Epoch 30: val_loss improved from 1731.10376 to 1717.17822, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 827.4070 - mean_absolute_error: 14.4709 - val_loss: 1717.1782 - val_mean_absolute_error: 24.6351\n",
      "Epoch 31/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 822.0981 - mean_absolute_error: 14.8058\n",
      "Epoch 31: val_loss improved from 1717.17822 to 1704.28406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 767.5797 - mean_absolute_error: 14.0063 - val_loss: 1704.2841 - val_mean_absolute_error: 24.5158\n",
      "Epoch 32/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 560.8865 - mean_absolute_error: 11.3093\n",
      "Epoch 32: val_loss improved from 1704.28406 to 1692.07349, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 753.6291 - mean_absolute_error: 13.7321 - val_loss: 1692.0735 - val_mean_absolute_error: 24.3954\n",
      "Epoch 33/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 820.8899 - mean_absolute_error: 13.8024\n",
      "Epoch 33: val_loss improved from 1692.07349 to 1679.88599, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 751.9127 - mean_absolute_error: 13.7245 - val_loss: 1679.8860 - val_mean_absolute_error: 24.2726\n",
      "Epoch 34/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 665.4759 - mean_absolute_error: 13.7806\n",
      "Epoch 34: val_loss improved from 1679.88599 to 1666.22766, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 745.3480 - mean_absolute_error: 13.8571 - val_loss: 1666.2277 - val_mean_absolute_error: 24.1412\n",
      "Epoch 35/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 973.1660 - mean_absolute_error: 15.6495\n",
      "Epoch 35: val_loss improved from 1666.22766 to 1652.98999, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 781.3906 - mean_absolute_error: 13.9248 - val_loss: 1652.9900 - val_mean_absolute_error: 24.0097\n",
      "Epoch 36/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 484.5176 - mean_absolute_error: 11.1286\n",
      "Epoch 36: val_loss improved from 1652.98999 to 1640.85217, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 703.8780 - mean_absolute_error: 13.0555 - val_loss: 1640.8522 - val_mean_absolute_error: 23.8810\n",
      "Epoch 37/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 622.3375 - mean_absolute_error: 12.7953\n",
      "Epoch 37: val_loss improved from 1640.85217 to 1628.24744, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 727.0664 - mean_absolute_error: 13.2087 - val_loss: 1628.2474 - val_mean_absolute_error: 23.7489\n",
      "Epoch 38/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 504.8675 - mean_absolute_error: 11.5574\n",
      "Epoch 38: val_loss improved from 1628.24744 to 1614.14758, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 704.7175 - mean_absolute_error: 13.3139 - val_loss: 1614.1476 - val_mean_absolute_error: 23.6094\n",
      "Epoch 39/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 818.6809 - mean_absolute_error: 14.5101\n",
      "Epoch 39: val_loss improved from 1614.14758 to 1601.54395, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 737.5045 - mean_absolute_error: 13.4131 - val_loss: 1601.5439 - val_mean_absolute_error: 23.4725\n",
      "Epoch 40/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 651.0981 - mean_absolute_error: 11.7707\n",
      "Epoch 40: val_loss improved from 1601.54395 to 1589.39233, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 681.1210 - mean_absolute_error: 12.7306 - val_loss: 1589.3923 - val_mean_absolute_error: 23.3350\n",
      "Epoch 41/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 299.7230 - mean_absolute_error: 8.0090\n",
      "Epoch 41: val_loss improved from 1589.39233 to 1576.91089, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 683.4720 - mean_absolute_error: 12.9188 - val_loss: 1576.9109 - val_mean_absolute_error: 23.1927\n",
      "Epoch 42/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 711.7749 - mean_absolute_error: 12.6190\n",
      "Epoch 42: val_loss improved from 1576.91089 to 1564.24854, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 739.5655 - mean_absolute_error: 13.2959 - val_loss: 1564.2485 - val_mean_absolute_error: 23.0491\n",
      "Epoch 43/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 677.5203 - mean_absolute_error: 12.4119\n",
      "Epoch 43: val_loss improved from 1564.24854 to 1549.64990, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 717.9941 - mean_absolute_error: 13.0737 - val_loss: 1549.6499 - val_mean_absolute_error: 22.8908\n",
      "Epoch 44/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 935.5790 - mean_absolute_error: 15.2003\n",
      "Epoch 44: val_loss improved from 1549.64990 to 1533.11047, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 667.6133 - mean_absolute_error: 12.4574 - val_loss: 1533.1105 - val_mean_absolute_error: 22.7177\n",
      "Epoch 45/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 672.8864 - mean_absolute_error: 13.3479\n",
      "Epoch 45: val_loss improved from 1533.11047 to 1519.22021, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 683.6868 - mean_absolute_error: 12.7489 - val_loss: 1519.2202 - val_mean_absolute_error: 22.5593\n",
      "Epoch 46/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 601.3571 - mean_absolute_error: 12.1055\n",
      "Epoch 46: val_loss improved from 1519.22021 to 1506.07922, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 674.3791 - mean_absolute_error: 12.3888 - val_loss: 1506.0792 - val_mean_absolute_error: 22.4043\n",
      "Epoch 47/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 563.9328 - mean_absolute_error: 11.1112\n",
      "Epoch 47: val_loss improved from 1506.07922 to 1492.79224, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 647.4509 - mean_absolute_error: 12.1127 - val_loss: 1492.7922 - val_mean_absolute_error: 22.2473\n",
      "Epoch 48/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 508.4097 - mean_absolute_error: 10.6232\n",
      "Epoch 48: val_loss improved from 1492.79224 to 1478.74585, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 636.9348 - mean_absolute_error: 12.1741 - val_loss: 1478.7458 - val_mean_absolute_error: 22.0850\n",
      "Epoch 49/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 997.9626 - mean_absolute_error: 16.1718\n",
      "Epoch 49: val_loss improved from 1478.74585 to 1465.59753, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 673.6005 - mean_absolute_error: 12.5366 - val_loss: 1465.5975 - val_mean_absolute_error: 21.9254\n",
      "Epoch 50/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 738.1911 - mean_absolute_error: 13.1421\n",
      "Epoch 50: val_loss improved from 1465.59753 to 1452.65076, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 640.5882 - mean_absolute_error: 12.1282 - val_loss: 1452.6508 - val_mean_absolute_error: 21.7641\n",
      "Epoch 51/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 526.6042 - mean_absolute_error: 10.0707\n",
      "Epoch 51: val_loss improved from 1452.65076 to 1439.71460, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 628.2214 - mean_absolute_error: 11.8089 - val_loss: 1439.7146 - val_mean_absolute_error: 21.5871\n",
      "Epoch 52/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 628.1361 - mean_absolute_error: 11.8554 \n",
      "Epoch 52: val_loss improved from 1439.71460 to 1426.63367, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 626.9277 - mean_absolute_error: 11.8653 - val_loss: 1426.6337 - val_mean_absolute_error: 21.3895\n",
      "Epoch 53/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 549.4530 - mean_absolute_error: 11.0367\n",
      "Epoch 53: val_loss improved from 1426.63367 to 1413.33215, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 641.6171 - mean_absolute_error: 12.0546 - val_loss: 1413.3322 - val_mean_absolute_error: 21.1684\n",
      "Epoch 54/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 529.7632 - mean_absolute_error: 10.5060\n",
      "Epoch 54: val_loss improved from 1413.33215 to 1398.96802, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 596.5375 - mean_absolute_error: 11.5354 - val_loss: 1398.9680 - val_mean_absolute_error: 20.9281\n",
      "Epoch 55/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1035.1028 - mean_absolute_error: 16.2470\n",
      "Epoch 55: val_loss improved from 1398.96802 to 1383.09607, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 654.6578 - mean_absolute_error: 12.0874 - val_loss: 1383.0961 - val_mean_absolute_error: 20.6790\n",
      "Epoch 56/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 493.9279 - mean_absolute_error: 10.1247\n",
      "Epoch 56: val_loss improved from 1383.09607 to 1368.40332, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 572.2053 - mean_absolute_error: 11.2051 - val_loss: 1368.4033 - val_mean_absolute_error: 20.4460\n",
      "Epoch 57/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 796.8234 - mean_absolute_error: 13.7784\n",
      "Epoch 57: val_loss improved from 1368.40332 to 1354.26782, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 619.4476 - mean_absolute_error: 11.5741 - val_loss: 1354.2678 - val_mean_absolute_error: 20.2488\n",
      "Epoch 58/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 696.9294 - mean_absolute_error: 11.7507\n",
      "Epoch 58: val_loss improved from 1354.26782 to 1340.14954, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 576.4254 - mean_absolute_error: 11.1801 - val_loss: 1340.1495 - val_mean_absolute_error: 20.0550\n",
      "Epoch 59/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 751.2955 - mean_absolute_error: 13.0570\n",
      "Epoch 59: val_loss improved from 1340.14954 to 1326.38770, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 629.1741 - mean_absolute_error: 11.7064 - val_loss: 1326.3877 - val_mean_absolute_error: 19.8743\n",
      "Epoch 60/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 651.2635 - mean_absolute_error: 11.1927\n",
      "Epoch 60: val_loss improved from 1326.38770 to 1312.68188, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.0748 - mean_absolute_error: 11.1716 - val_loss: 1312.6819 - val_mean_absolute_error: 19.6998\n",
      "Epoch 61/500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 581.7674 - mean_absolute_error: 11.3190 \n",
      "Epoch 61: val_loss improved from 1312.68188 to 1298.83850, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 579.9667 - mean_absolute_error: 11.2849 - val_loss: 1298.8385 - val_mean_absolute_error: 19.5306\n",
      "Epoch 62/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 577.5050 - mean_absolute_error: 11.5608\n",
      "Epoch 62: val_loss improved from 1298.83850 to 1284.84290, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 554.3073 - mean_absolute_error: 10.9422 - val_loss: 1284.8429 - val_mean_absolute_error: 19.3660\n",
      "Epoch 63/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 467.4366 - mean_absolute_error: 10.0531\n",
      "Epoch 63: val_loss improved from 1284.84290 to 1270.10156, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 535.6125 - mean_absolute_error: 10.8388 - val_loss: 1270.1016 - val_mean_absolute_error: 19.2020\n",
      "Epoch 64/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 467.0262 - mean_absolute_error: 10.7660\n",
      "Epoch 64: val_loss improved from 1270.10156 to 1256.34583, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511.5460 - mean_absolute_error: 10.6068 - val_loss: 1256.3458 - val_mean_absolute_error: 19.0578\n",
      "Epoch 65/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 604.5775 - mean_absolute_error: 11.1931\n",
      "Epoch 65: val_loss improved from 1256.34583 to 1242.68689, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 565.1791 - mean_absolute_error: 11.0111 - val_loss: 1242.6869 - val_mean_absolute_error: 18.9114\n",
      "Epoch 66/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 849.6154 - mean_absolute_error: 13.2025\n",
      "Epoch 66: val_loss improved from 1242.68689 to 1229.64636, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 542.3163 - mean_absolute_error: 10.8775 - val_loss: 1229.6464 - val_mean_absolute_error: 18.7736\n",
      "Epoch 67/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 481.8236 - mean_absolute_error: 11.3600\n",
      "Epoch 67: val_loss improved from 1229.64636 to 1216.52869, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 562.4072 - mean_absolute_error: 11.1682 - val_loss: 1216.5287 - val_mean_absolute_error: 18.6377\n",
      "Epoch 68/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 820.6231 - mean_absolute_error: 14.0315\n",
      "Epoch 68: val_loss improved from 1216.52869 to 1203.91736, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 539.7963 - mean_absolute_error: 10.8307 - val_loss: 1203.9174 - val_mean_absolute_error: 18.5109\n",
      "Epoch 69/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 594.7325 - mean_absolute_error: 11.4027\n",
      "Epoch 69: val_loss improved from 1203.91736 to 1191.45227, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 496.2264 - mean_absolute_error: 10.3826 - val_loss: 1191.4523 - val_mean_absolute_error: 18.3865\n",
      "Epoch 70/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 458.3434 - mean_absolute_error: 11.0739\n",
      "Epoch 70: val_loss improved from 1191.45227 to 1178.57837, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 506.1054 - mean_absolute_error: 10.6497 - val_loss: 1178.5784 - val_mean_absolute_error: 18.2599\n",
      "Epoch 71/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 466.4547 - mean_absolute_error: 10.4674\n",
      "Epoch 71: val_loss improved from 1178.57837 to 1166.15796, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.9341 - mean_absolute_error: 10.7904 - val_loss: 1166.1580 - val_mean_absolute_error: 18.1399\n",
      "Epoch 72/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 666.0217 - mean_absolute_error: 11.5258\n",
      "Epoch 72: val_loss improved from 1166.15796 to 1153.88806, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.9805 - mean_absolute_error: 10.3804 - val_loss: 1153.8881 - val_mean_absolute_error: 18.0229\n",
      "Epoch 73/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 453.7224 - mean_absolute_error: 8.7700\n",
      "Epoch 73: val_loss improved from 1153.88806 to 1141.88464, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.5572 - mean_absolute_error: 10.1812 - val_loss: 1141.8846 - val_mean_absolute_error: 17.9074\n",
      "Epoch 74/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1082.0638 - mean_absolute_error: 15.7164\n",
      "Epoch 74: val_loss improved from 1141.88464 to 1129.48132, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 577.0444 - mean_absolute_error: 10.9069 - val_loss: 1129.4813 - val_mean_absolute_error: 17.7877\n",
      "Epoch 75/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 485.8819 - mean_absolute_error: 9.5295\n",
      "Epoch 75: val_loss improved from 1129.48132 to 1117.35193, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.5724 - mean_absolute_error: 10.1411 - val_loss: 1117.3519 - val_mean_absolute_error: 17.6735\n",
      "Epoch 76/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499.7110 - mean_absolute_error: 10.3491\n",
      "Epoch 76: val_loss improved from 1117.35193 to 1105.15588, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 495.2487 - mean_absolute_error: 10.2874 - val_loss: 1105.1559 - val_mean_absolute_error: 17.5630\n",
      "Epoch 77/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 581.1293 - mean_absolute_error: 10.7199\n",
      "Epoch 77: val_loss improved from 1105.15588 to 1093.42834, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 506.9195 - mean_absolute_error: 10.2788 - val_loss: 1093.4283 - val_mean_absolute_error: 17.4747\n",
      "Epoch 78/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 798.0143 - mean_absolute_error: 13.4307\n",
      "Epoch 78: val_loss improved from 1093.42834 to 1081.38550, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 501.5526 - mean_absolute_error: 10.2364 - val_loss: 1081.3855 - val_mean_absolute_error: 17.3840\n",
      "Epoch 79/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 303.7487 - mean_absolute_error: 9.0405\n",
      "Epoch 79: val_loss improved from 1081.38550 to 1069.60071, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 460.0535 - mean_absolute_error: 9.9174 - val_loss: 1069.6007 - val_mean_absolute_error: 17.2937\n",
      "Epoch 80/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 764.1235 - mean_absolute_error: 12.1540\n",
      "Epoch 80: val_loss improved from 1069.60071 to 1057.89233, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493.5749 - mean_absolute_error: 10.0401 - val_loss: 1057.8923 - val_mean_absolute_error: 17.2046\n",
      "Epoch 81/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 612.4544 - mean_absolute_error: 11.7465\n",
      "Epoch 81: val_loss improved from 1057.89233 to 1045.82983, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 475.8514 - mean_absolute_error: 10.0432 - val_loss: 1045.8298 - val_mean_absolute_error: 17.1113\n",
      "Epoch 82/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 313.0636 - mean_absolute_error: 7.6044\n",
      "Epoch 82: val_loss improved from 1045.82983 to 1034.38586, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.3326 - mean_absolute_error: 9.5620 - val_loss: 1034.3859 - val_mean_absolute_error: 17.0263\n",
      "Epoch 83/500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 424.6111 - mean_absolute_error: 9.2554 \n",
      "Epoch 83: val_loss improved from 1034.38586 to 1022.99420, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 428.4002 - mean_absolute_error: 9.3274 - val_loss: 1022.9942 - val_mean_absolute_error: 16.9423\n",
      "Epoch 84/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 521.6985 - mean_absolute_error: 11.1893\n",
      "Epoch 84: val_loss improved from 1022.99420 to 1011.57117, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.6696 - mean_absolute_error: 9.8038 - val_loss: 1011.5712 - val_mean_absolute_error: 16.8577\n",
      "Epoch 85/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 469.2855 - mean_absolute_error: 10.0918\n",
      "Epoch 85: val_loss improved from 1011.57117 to 999.94220, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.9627 - mean_absolute_error: 9.7416 - val_loss: 999.9422 - val_mean_absolute_error: 16.7729\n",
      "Epoch 86/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 262.2538 - mean_absolute_error: 8.3265\n",
      "Epoch 86: val_loss improved from 999.94220 to 988.67932, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423.4836 - mean_absolute_error: 9.3221 - val_loss: 988.6793 - val_mean_absolute_error: 16.6890\n",
      "Epoch 87/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 555.0571 - mean_absolute_error: 10.2409\n",
      "Epoch 87: val_loss improved from 988.67932 to 977.39264, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 447.8160 - mean_absolute_error: 9.5750 - val_loss: 977.3926 - val_mean_absolute_error: 16.6035\n",
      "Epoch 88/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 478.3521 - mean_absolute_error: 10.8688\n",
      "Epoch 88: val_loss improved from 977.39264 to 966.15912, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.2268 - mean_absolute_error: 9.5939 - val_loss: 966.1591 - val_mean_absolute_error: 16.5180\n",
      "Epoch 89/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 428.5621 - mean_absolute_error: 9.5545\n",
      "Epoch 89: val_loss improved from 966.15912 to 955.20416, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 406.2982 - mean_absolute_error: 9.1999 - val_loss: 955.2042 - val_mean_absolute_error: 16.4334\n",
      "Epoch 90/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 239.8272 - mean_absolute_error: 7.2537\n",
      "Epoch 90: val_loss improved from 955.20416 to 943.87030, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 392.3199 - mean_absolute_error: 9.0699 - val_loss: 943.8703 - val_mean_absolute_error: 16.3467\n",
      "Epoch 91/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 461.2269 - mean_absolute_error: 10.5084\n",
      "Epoch 91: val_loss improved from 943.87030 to 932.85535, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.1664 - mean_absolute_error: 9.0154 - val_loss: 932.8553 - val_mean_absolute_error: 16.2597\n",
      "Epoch 92/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 333.3931 - mean_absolute_error: 8.3251\n",
      "Epoch 92: val_loss improved from 932.85535 to 921.44055, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.5886 - mean_absolute_error: 9.0238 - val_loss: 921.4406 - val_mean_absolute_error: 16.1711\n",
      "Epoch 93/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 356.7810 - mean_absolute_error: 9.7346\n",
      "Epoch 93: val_loss improved from 921.44055 to 910.35229, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 382.9912 - mean_absolute_error: 8.8777 - val_loss: 910.3523 - val_mean_absolute_error: 16.0830\n",
      "Epoch 94/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 540.3047 - mean_absolute_error: 10.2135\n",
      "Epoch 94: val_loss improved from 910.35229 to 898.62085, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 431.6321 - mean_absolute_error: 9.4851 - val_loss: 898.6208 - val_mean_absolute_error: 15.9867\n",
      "Epoch 95/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 280.0973 - mean_absolute_error: 8.2291\n",
      "Epoch 95: val_loss improved from 898.62085 to 888.10590, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.7167 - mean_absolute_error: 8.8696 - val_loss: 888.1059 - val_mean_absolute_error: 15.9002\n",
      "Epoch 96/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.6251 - mean_absolute_error: 8.7291 \n",
      "Epoch 96: val_loss improved from 888.10590 to 876.36182, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 384.2185 - mean_absolute_error: 8.7560 - val_loss: 876.3618 - val_mean_absolute_error: 15.8044\n",
      "Epoch 97/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 241.0645 - mean_absolute_error: 7.3076\n",
      "Epoch 97: val_loss improved from 876.36182 to 865.29803, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 356.7249 - mean_absolute_error: 8.6338 - val_loss: 865.2980 - val_mean_absolute_error: 15.7128\n",
      "Epoch 98/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 560.4562 - mean_absolute_error: 10.9707\n",
      "Epoch 98: val_loss improved from 865.29803 to 853.54584, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.1586 - mean_absolute_error: 9.0310 - val_loss: 853.5458 - val_mean_absolute_error: 15.6172\n",
      "Epoch 99/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 428.2451 - mean_absolute_error: 9.4541\n",
      "Epoch 99: val_loss improved from 853.54584 to 842.47003, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.9733 - mean_absolute_error: 8.9749 - val_loss: 842.4700 - val_mean_absolute_error: 15.5194\n",
      "Epoch 100/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 383.0552 - mean_absolute_error: 9.0641\n",
      "Epoch 100: val_loss improved from 842.47003 to 831.20038, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 363.4416 - mean_absolute_error: 8.6352 - val_loss: 831.2004 - val_mean_absolute_error: 15.4241\n",
      "Epoch 101/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 203.3843 - mean_absolute_error: 6.7016\n",
      "Epoch 101: val_loss improved from 831.20038 to 819.90570, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 341.4447 - mean_absolute_error: 8.2782 - val_loss: 819.9057 - val_mean_absolute_error: 15.3263\n",
      "Epoch 102/500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.0752 - mean_absolute_error: 8.3486 \n",
      "Epoch 102: val_loss improved from 819.90570 to 808.49347, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 353.0165 - mean_absolute_error: 8.3564 - val_loss: 808.4935 - val_mean_absolute_error: 15.2257\n",
      "Epoch 103/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 332.6420 - mean_absolute_error: 8.0789\n",
      "Epoch 103: val_loss improved from 808.49347 to 796.92615, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 367.4616 - mean_absolute_error: 8.6395 - val_loss: 796.9261 - val_mean_absolute_error: 15.1229\n",
      "Epoch 104/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 377.2931 - mean_absolute_error: 8.7105\n",
      "Epoch 104: val_loss improved from 796.92615 to 785.72351, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.9208 - mean_absolute_error: 8.4340 - val_loss: 785.7235 - val_mean_absolute_error: 15.0248\n",
      "Epoch 105/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 465.7315 - mean_absolute_error: 10.9067\n",
      "Epoch 105: val_loss improved from 785.72351 to 774.68726, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.8171 - mean_absolute_error: 8.2493 - val_loss: 774.6873 - val_mean_absolute_error: 14.9231\n",
      "Epoch 106/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 417.3270 - mean_absolute_error: 9.3496\n",
      "Epoch 106: val_loss improved from 774.68726 to 764.06744, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 362.2063 - mean_absolute_error: 8.5733 - val_loss: 764.0674 - val_mean_absolute_error: 14.8254\n",
      "Epoch 107/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 388.9973 - mean_absolute_error: 9.6595\n",
      "Epoch 107: val_loss improved from 764.06744 to 752.38757, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 374.1152 - mean_absolute_error: 8.8096 - val_loss: 752.3876 - val_mean_absolute_error: 14.7230\n",
      "Epoch 108/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 476.0062 - mean_absolute_error: 10.4374\n",
      "Epoch 108: val_loss improved from 752.38757 to 741.89075, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 338.4287 - mean_absolute_error: 8.3484 - val_loss: 741.8907 - val_mean_absolute_error: 14.6256\n",
      "Epoch 109/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 472.3947 - mean_absolute_error: 9.4625\n",
      "Epoch 109: val_loss improved from 741.89075 to 730.75580, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.5012 - mean_absolute_error: 7.9568 - val_loss: 730.7558 - val_mean_absolute_error: 14.5248\n",
      "Epoch 110/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 209.8027 - mean_absolute_error: 6.4255\n",
      "Epoch 110: val_loss improved from 730.75580 to 720.39655, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 301.5515 - mean_absolute_error: 7.8947 - val_loss: 720.3965 - val_mean_absolute_error: 14.4245\n",
      "Epoch 111/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 384.5005 - mean_absolute_error: 9.4044\n",
      "Epoch 111: val_loss improved from 720.39655 to 709.24207, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.2469 - mean_absolute_error: 8.0637 - val_loss: 709.2421 - val_mean_absolute_error: 14.3220\n",
      "Epoch 112/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 368.2902 - mean_absolute_error: 9.2863\n",
      "Epoch 112: val_loss improved from 709.24207 to 698.64740, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302.6126 - mean_absolute_error: 7.9067 - val_loss: 698.6474 - val_mean_absolute_error: 14.2188\n",
      "Epoch 113/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 179.0910 - mean_absolute_error: 6.4119\n",
      "Epoch 113: val_loss improved from 698.64740 to 688.37341, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.5000 - mean_absolute_error: 7.5731 - val_loss: 688.3734 - val_mean_absolute_error: 14.1221\n",
      "Epoch 114/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 340.2474 - mean_absolute_error: 7.8773\n",
      "Epoch 114: val_loss improved from 688.37341 to 677.47192, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 296.8519 - mean_absolute_error: 7.6427 - val_loss: 677.4719 - val_mean_absolute_error: 14.0187\n",
      "Epoch 115/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 279.0793 - mean_absolute_error: 7.2148\n",
      "Epoch 115: val_loss improved from 677.47192 to 667.34088, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 292.6839 - mean_absolute_error: 7.7579 - val_loss: 667.3409 - val_mean_absolute_error: 13.9175\n",
      "Epoch 116/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 444.1502 - mean_absolute_error: 9.5881\n",
      "Epoch 116: val_loss improved from 667.34088 to 656.92523, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.5785 - mean_absolute_error: 7.6221 - val_loss: 656.9252 - val_mean_absolute_error: 13.8176\n",
      "Epoch 117/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 280.1460 - mean_absolute_error: 8.0840\n",
      "Epoch 117: val_loss improved from 656.92523 to 646.82330, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 279.4968 - mean_absolute_error: 7.6543 - val_loss: 646.8233 - val_mean_absolute_error: 13.7164\n",
      "Epoch 118/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 541.6719 - mean_absolute_error: 10.2843\n",
      "Epoch 118: val_loss improved from 646.82330 to 636.77533, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 300.6892 - mean_absolute_error: 7.8434 - val_loss: 636.7753 - val_mean_absolute_error: 13.6179\n",
      "Epoch 119/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 423.5324 - mean_absolute_error: 9.8249\n",
      "Epoch 119: val_loss improved from 636.77533 to 627.17865, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 284.7306 - mean_absolute_error: 7.7210 - val_loss: 627.1786 - val_mean_absolute_error: 13.5237\n",
      "Epoch 120/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 217.7854 - mean_absolute_error: 6.9246\n",
      "Epoch 120: val_loss improved from 627.17865 to 617.07031, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 274.8940 - mean_absolute_error: 7.5341 - val_loss: 617.0703 - val_mean_absolute_error: 13.4319\n",
      "Epoch 121/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 206.7664 - mean_absolute_error: 7.0750\n",
      "Epoch 121: val_loss improved from 617.07031 to 607.89020, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 262.2242 - mean_absolute_error: 7.2397 - val_loss: 607.8902 - val_mean_absolute_error: 13.3400\n",
      "Epoch 122/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 350.9731 - mean_absolute_error: 7.9011\n",
      "Epoch 122: val_loss improved from 607.89020 to 598.18658, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.0287 - mean_absolute_error: 7.3076 - val_loss: 598.1866 - val_mean_absolute_error: 13.2443\n",
      "Epoch 123/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 205.5722 - mean_absolute_error: 6.7334\n",
      "Epoch 123: val_loss improved from 598.18658 to 588.52008, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.5007 - mean_absolute_error: 7.3752 - val_loss: 588.5201 - val_mean_absolute_error: 13.1480\n",
      "Epoch 124/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 196.2169 - mean_absolute_error: 7.2794\n",
      "Epoch 124: val_loss improved from 588.52008 to 579.17493, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.7912 - mean_absolute_error: 7.1541 - val_loss: 579.1749 - val_mean_absolute_error: 13.0657\n",
      "Epoch 125/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 354.4041 - mean_absolute_error: 8.4689\n",
      "Epoch 125: val_loss improved from 579.17493 to 569.38019, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 271.9302 - mean_absolute_error: 7.5081 - val_loss: 569.3802 - val_mean_absolute_error: 12.9692\n",
      "Epoch 126/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 286.5070 - mean_absolute_error: 8.2260\n",
      "Epoch 126: val_loss improved from 569.38019 to 561.36176, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 261.3929 - mean_absolute_error: 7.4267 - val_loss: 561.3618 - val_mean_absolute_error: 12.8860\n",
      "Epoch 127/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 311.3773 - mean_absolute_error: 7.5075\n",
      "Epoch 127: val_loss improved from 561.36176 to 551.11304, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.1285 - mean_absolute_error: 7.3637 - val_loss: 551.1130 - val_mean_absolute_error: 12.7955\n",
      "Epoch 128/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 211.2746 - mean_absolute_error: 5.3967\n",
      "Epoch 128: val_loss improved from 551.11304 to 543.37231, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 242.7133 - mean_absolute_error: 6.9295 - val_loss: 543.3723 - val_mean_absolute_error: 12.7092\n",
      "Epoch 129/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 137.0306 - mean_absolute_error: 5.7296\n",
      "Epoch 129: val_loss improved from 543.37231 to 534.96851, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.0235 - mean_absolute_error: 6.7318 - val_loss: 534.9685 - val_mean_absolute_error: 12.6233\n",
      "Epoch 130/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 509.4305 - mean_absolute_error: 9.4940\n",
      "Epoch 130: val_loss improved from 534.96851 to 526.21912, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 242.9473 - mean_absolute_error: 6.9003 - val_loss: 526.2191 - val_mean_absolute_error: 12.5430\n",
      "Epoch 131/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 267.9376 - mean_absolute_error: 8.8055\n",
      "Epoch 131: val_loss improved from 526.21912 to 517.13593, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 231.2755 - mean_absolute_error: 6.9755 - val_loss: 517.1359 - val_mean_absolute_error: 12.4606\n",
      "Epoch 132/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 219.3454 - mean_absolute_error: 6.1621\n",
      "Epoch 132: val_loss improved from 517.13593 to 508.71469, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.7443 - mean_absolute_error: 6.8069 - val_loss: 508.7147 - val_mean_absolute_error: 12.3803\n",
      "Epoch 133/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 220.2242 - mean_absolute_error: 6.3916\n",
      "Epoch 133: val_loss improved from 508.71469 to 500.93698, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.0193 - mean_absolute_error: 6.7251 - val_loss: 500.9370 - val_mean_absolute_error: 12.3018\n",
      "Epoch 134/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 166.7991 - mean_absolute_error: 5.4664\n",
      "Epoch 134: val_loss improved from 500.93698 to 492.24615, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.3068 - mean_absolute_error: 6.5796 - val_loss: 492.2462 - val_mean_absolute_error: 12.2192\n",
      "Epoch 135/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.3622 - mean_absolute_error: 6.7288 \n",
      "Epoch 135: val_loss improved from 492.24615 to 484.80463, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 229.5144 - mean_absolute_error: 6.7250 - val_loss: 484.8046 - val_mean_absolute_error: 12.1393\n",
      "Epoch 136/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 100.0372 - mean_absolute_error: 5.3442\n",
      "Epoch 136: val_loss improved from 484.80463 to 477.09802, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 208.1282 - mean_absolute_error: 6.5743 - val_loss: 477.0980 - val_mean_absolute_error: 12.0596\n",
      "Epoch 137/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 240.5764 - mean_absolute_error: 7.0775\n",
      "Epoch 137: val_loss improved from 477.09802 to 468.87839, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.7553 - mean_absolute_error: 6.5776 - val_loss: 468.8784 - val_mean_absolute_error: 11.9778\n",
      "Epoch 138/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 245.6610 - mean_absolute_error: 6.3777\n",
      "Epoch 138: val_loss improved from 468.87839 to 460.85547, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.9667 - mean_absolute_error: 6.4901 - val_loss: 460.8555 - val_mean_absolute_error: 11.9010\n",
      "Epoch 139/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 270.0129 - mean_absolute_error: 7.8690\n",
      "Epoch 139: val_loss improved from 460.85547 to 453.69330, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 206.3994 - mean_absolute_error: 6.5513 - val_loss: 453.6933 - val_mean_absolute_error: 11.8235\n",
      "Epoch 140/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 170.7647 - mean_absolute_error: 6.6539\n",
      "Epoch 140: val_loss improved from 453.69330 to 446.14703, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.6363 - mean_absolute_error: 6.2818 - val_loss: 446.1470 - val_mean_absolute_error: 11.7433\n",
      "Epoch 141/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 134.8171 - mean_absolute_error: 5.2710\n",
      "Epoch 141: val_loss improved from 446.14703 to 438.88382, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.0730 - mean_absolute_error: 6.4814 - val_loss: 438.8838 - val_mean_absolute_error: 11.6667\n",
      "Epoch 142/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 213.7024 - mean_absolute_error: 5.9728\n",
      "Epoch 142: val_loss improved from 438.88382 to 431.61069, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.8046 - mean_absolute_error: 6.3842 - val_loss: 431.6107 - val_mean_absolute_error: 11.5891\n",
      "Epoch 143/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 181.2196 - mean_absolute_error: 5.8280\n",
      "Epoch 143: val_loss improved from 431.61069 to 424.73697, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.8746 - mean_absolute_error: 6.2827 - val_loss: 424.7370 - val_mean_absolute_error: 11.5077\n",
      "Epoch 144/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 143.3821 - mean_absolute_error: 5.2824\n",
      "Epoch 144: val_loss improved from 424.73697 to 417.18967, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 199.9388 - mean_absolute_error: 6.3649 - val_loss: 417.1897 - val_mean_absolute_error: 11.4333\n",
      "Epoch 145/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 205.1445 - mean_absolute_error: 7.0970\n",
      "Epoch 145: val_loss improved from 417.18967 to 410.79129, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.3261 - mean_absolute_error: 6.3940 - val_loss: 410.7913 - val_mean_absolute_error: 11.3568\n",
      "Epoch 146/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 106.8205 - mean_absolute_error: 4.7429\n",
      "Epoch 146: val_loss improved from 410.79129 to 403.48807, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.0236 - mean_absolute_error: 6.0550 - val_loss: 403.4881 - val_mean_absolute_error: 11.2832\n",
      "Epoch 147/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 313.2384 - mean_absolute_error: 8.2138\n",
      "Epoch 147: val_loss improved from 403.48807 to 396.74142, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.4370 - mean_absolute_error: 6.3867 - val_loss: 396.7414 - val_mean_absolute_error: 11.2105\n",
      "Epoch 148/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 101.4417 - mean_absolute_error: 4.6618\n",
      "Epoch 148: val_loss improved from 396.74142 to 390.14914, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 174.8228 - mean_absolute_error: 6.0206 - val_loss: 390.1491 - val_mean_absolute_error: 11.1374\n",
      "Epoch 149/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 130.1238 - mean_absolute_error: 5.6581\n",
      "Epoch 149: val_loss improved from 390.14914 to 383.66608, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 180.8407 - mean_absolute_error: 6.1052 - val_loss: 383.6661 - val_mean_absolute_error: 11.0604\n",
      "Epoch 150/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.4188 - mean_absolute_error: 4.0359\n",
      "Epoch 150: val_loss improved from 383.66608 to 377.50281, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 170.6570 - mean_absolute_error: 5.8531 - val_loss: 377.5028 - val_mean_absolute_error: 10.9904\n",
      "Epoch 151/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 191.9908 - mean_absolute_error: 6.2073\n",
      "Epoch 151: val_loss improved from 377.50281 to 372.00623, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 173.9646 - mean_absolute_error: 6.0725 - val_loss: 372.0062 - val_mean_absolute_error: 10.9166\n",
      "Epoch 152/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 104.6671 - mean_absolute_error: 5.1623\n",
      "Epoch 152: val_loss improved from 372.00623 to 365.48669, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 163.5878 - mean_absolute_error: 5.8146 - val_loss: 365.4867 - val_mean_absolute_error: 10.8465\n",
      "Epoch 153/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 101.7361 - mean_absolute_error: 5.4445\n",
      "Epoch 153: val_loss improved from 365.48669 to 359.13071, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159.7242 - mean_absolute_error: 5.8310 - val_loss: 359.1307 - val_mean_absolute_error: 10.7753\n",
      "Epoch 154/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 132.1809 - mean_absolute_error: 4.8847\n",
      "Epoch 154: val_loss improved from 359.13071 to 353.78827, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.4151 - mean_absolute_error: 5.6825 - val_loss: 353.7883 - val_mean_absolute_error: 10.6979\n",
      "Epoch 155/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 152.5706 - mean_absolute_error: 5.4348\n",
      "Epoch 155: val_loss improved from 353.78827 to 348.13141, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 169.4861 - mean_absolute_error: 5.9233 - val_loss: 348.1314 - val_mean_absolute_error: 10.6282\n",
      "Epoch 156/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 275.3640 - mean_absolute_error: 7.3079\n",
      "Epoch 156: val_loss improved from 348.13141 to 343.46310, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 172.6888 - mean_absolute_error: 5.9612 - val_loss: 343.4631 - val_mean_absolute_error: 10.5557\n",
      "Epoch 157/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 125.5747 - mean_absolute_error: 5.0395\n",
      "Epoch 157: val_loss improved from 343.46310 to 337.11575, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134.5976 - mean_absolute_error: 5.2762 - val_loss: 337.1158 - val_mean_absolute_error: 10.4891\n",
      "Epoch 158/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 113.5846 - mean_absolute_error: 5.1439\n",
      "Epoch 158: val_loss improved from 337.11575 to 331.90503, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.3438 - mean_absolute_error: 5.7450 - val_loss: 331.9050 - val_mean_absolute_error: 10.4152\n",
      "Epoch 159/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 216.0615 - mean_absolute_error: 6.2594\n",
      "Epoch 159: val_loss improved from 331.90503 to 327.24097, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.5821 - mean_absolute_error: 5.9237 - val_loss: 327.2410 - val_mean_absolute_error: 10.3458\n",
      "Epoch 160/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 99.6143 - mean_absolute_error: 5.2167\n",
      "Epoch 160: val_loss improved from 327.24097 to 322.35358, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 147.6629 - mean_absolute_error: 5.6470 - val_loss: 322.3536 - val_mean_absolute_error: 10.2791\n",
      "Epoch 161/500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 157.6930 - mean_absolute_error: 5.7815 \n",
      "Epoch 161: val_loss improved from 322.35358 to 316.50854, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157.2372 - mean_absolute_error: 5.7749 - val_loss: 316.5085 - val_mean_absolute_error: 10.2138\n",
      "Epoch 162/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 354.3966 - mean_absolute_error: 8.2204\n",
      "Epoch 162: val_loss improved from 316.50854 to 312.31119, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 163.0148 - mean_absolute_error: 5.7642 - val_loss: 312.3112 - val_mean_absolute_error: 10.1440\n",
      "Epoch 163/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 187.3074 - mean_absolute_error: 5.7797\n",
      "Epoch 163: val_loss improved from 312.31119 to 306.99954, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.8538 - mean_absolute_error: 5.4391 - val_loss: 306.9995 - val_mean_absolute_error: 10.0832\n",
      "Epoch 164/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 174.4528 - mean_absolute_error: 5.5298\n",
      "Epoch 164: val_loss improved from 306.99954 to 302.75513, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.5460 - mean_absolute_error: 5.5171 - val_loss: 302.7551 - val_mean_absolute_error: 10.0215\n",
      "Epoch 165/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 162.5433 - mean_absolute_error: 5.1829\n",
      "Epoch 165: val_loss improved from 302.75513 to 297.55014, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.6824 - mean_absolute_error: 5.5143 - val_loss: 297.5501 - val_mean_absolute_error: 9.9566\n",
      "Epoch 166/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 100.0930 - mean_absolute_error: 4.5860\n",
      "Epoch 166: val_loss improved from 297.55014 to 295.07117, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 128.4267 - mean_absolute_error: 5.2740 - val_loss: 295.0712 - val_mean_absolute_error: 9.8981\n",
      "Epoch 167/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 147.7981 - mean_absolute_error: 4.9489\n",
      "Epoch 167: val_loss improved from 295.07117 to 289.77719, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.5012 - mean_absolute_error: 5.6009 - val_loss: 289.7772 - val_mean_absolute_error: 9.8344\n",
      "Epoch 168/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 92.6588 - mean_absolute_error: 5.2136\n",
      "Epoch 168: val_loss improved from 289.77719 to 285.18549, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.3345 - mean_absolute_error: 5.2592 - val_loss: 285.1855 - val_mean_absolute_error: 9.7752\n",
      "Epoch 169/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 159.0266 - mean_absolute_error: 5.8071\n",
      "Epoch 169: val_loss improved from 285.18549 to 281.50516, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 146.1611 - mean_absolute_error: 5.7183 - val_loss: 281.5052 - val_mean_absolute_error: 9.7137\n",
      "Epoch 170/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 95.2631 - mean_absolute_error: 5.2663\n",
      "Epoch 170: val_loss improved from 281.50516 to 278.42474, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 136.8942 - mean_absolute_error: 5.4840 - val_loss: 278.4247 - val_mean_absolute_error: 9.6554\n",
      "Epoch 171/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 114.1775 - mean_absolute_error: 5.0194\n",
      "Epoch 171: val_loss improved from 278.42474 to 274.41699, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 136.5697 - mean_absolute_error: 5.4268 - val_loss: 274.4170 - val_mean_absolute_error: 9.5958\n",
      "Epoch 172/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 84.2656 - mean_absolute_error: 4.7144\n",
      "Epoch 172: val_loss improved from 274.41699 to 270.98804, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.6720 - mean_absolute_error: 5.1311 - val_loss: 270.9880 - val_mean_absolute_error: 9.5419\n",
      "Epoch 173/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 163.0509 - mean_absolute_error: 4.6210\n",
      "Epoch 173: val_loss improved from 270.98804 to 268.28278, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 131.2610 - mean_absolute_error: 5.2663 - val_loss: 268.2828 - val_mean_absolute_error: 9.4881\n",
      "Epoch 174/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.8548 - mean_absolute_error: 5.2949 \n",
      "Epoch 174: val_loss improved from 268.28278 to 264.43948, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129.1941 - mean_absolute_error: 5.2962 - val_loss: 264.4395 - val_mean_absolute_error: 9.4379\n",
      "Epoch 175/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 126.5710 - mean_absolute_error: 6.2132\n",
      "Epoch 175: val_loss improved from 264.43948 to 258.51685, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.1651 - mean_absolute_error: 5.5046 - val_loss: 258.5168 - val_mean_absolute_error: 9.3961\n",
      "Epoch 176/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 39.2973 - mean_absolute_error: 3.8230\n",
      "Epoch 176: val_loss improved from 258.51685 to 256.89636, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.6149 - mean_absolute_error: 5.0817 - val_loss: 256.8964 - val_mean_absolute_error: 9.3382\n",
      "Epoch 177/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 119.7004 - mean_absolute_error: 5.5096\n",
      "Epoch 177: val_loss improved from 256.89636 to 253.49327, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3291 - mean_absolute_error: 5.2389 - val_loss: 253.4933 - val_mean_absolute_error: 9.2889\n",
      "Epoch 178/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 136.2843 - mean_absolute_error: 5.1900\n",
      "Epoch 178: val_loss improved from 253.49327 to 250.25256, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 122.8961 - mean_absolute_error: 5.1672 - val_loss: 250.2526 - val_mean_absolute_error: 9.2396\n",
      "Epoch 179/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 189.9479 - mean_absolute_error: 6.5467\n",
      "Epoch 179: val_loss improved from 250.25256 to 248.42072, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.9602 - mean_absolute_error: 5.0799 - val_loss: 248.4207 - val_mean_absolute_error: 9.1817\n",
      "Epoch 180/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 78.4187 - mean_absolute_error: 4.1019\n",
      "Epoch 180: val_loss improved from 248.42072 to 243.98357, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.9598 - mean_absolute_error: 5.2557 - val_loss: 243.9836 - val_mean_absolute_error: 9.1377\n",
      "Epoch 181/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.0604 - mean_absolute_error: 4.5367\n",
      "Epoch 181: val_loss improved from 243.98357 to 241.26065, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.4494 - mean_absolute_error: 5.1501 - val_loss: 241.2607 - val_mean_absolute_error: 9.0899\n",
      "Epoch 182/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 103.3916 - mean_absolute_error: 5.0702\n",
      "Epoch 182: val_loss improved from 241.26065 to 237.95625, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.6193 - mean_absolute_error: 5.0286 - val_loss: 237.9563 - val_mean_absolute_error: 9.0455\n",
      "Epoch 183/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 169.0367 - mean_absolute_error: 5.7072\n",
      "Epoch 183: val_loss improved from 237.95625 to 235.98203, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.0454 - mean_absolute_error: 5.0984 - val_loss: 235.9820 - val_mean_absolute_error: 8.9962\n",
      "Epoch 184/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 166.6113 - mean_absolute_error: 6.0037\n",
      "Epoch 184: val_loss improved from 235.98203 to 233.18407, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.8962 - mean_absolute_error: 5.1827 - val_loss: 233.1841 - val_mean_absolute_error: 8.9528\n",
      "Epoch 185/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 94.2888 - mean_absolute_error: 4.7188\n",
      "Epoch 185: val_loss improved from 233.18407 to 230.81145, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.0720 - mean_absolute_error: 5.0215 - val_loss: 230.8114 - val_mean_absolute_error: 8.9098\n",
      "Epoch 186/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 132.2378 - mean_absolute_error: 4.7030\n",
      "Epoch 186: val_loss improved from 230.81145 to 228.41394, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.4076 - mean_absolute_error: 4.9291 - val_loss: 228.4139 - val_mean_absolute_error: 8.8694\n",
      "Epoch 187/500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.6165 - mean_absolute_error: 4.8634\n",
      "Epoch 187: val_loss improved from 228.41394 to 225.32298, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.6856 - mean_absolute_error: 4.8685 - val_loss: 225.3230 - val_mean_absolute_error: 8.8213\n",
      "Epoch 188/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 86.8263 - mean_absolute_error: 4.3317\n",
      "Epoch 188: val_loss improved from 225.32298 to 223.55948, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.9817 - mean_absolute_error: 5.0676 - val_loss: 223.5595 - val_mean_absolute_error: 8.7820\n",
      "Epoch 189/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 134.8859 - mean_absolute_error: 6.0227\n",
      "Epoch 189: val_loss improved from 223.55948 to 221.01320, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.9540 - mean_absolute_error: 5.0268 - val_loss: 221.0132 - val_mean_absolute_error: 8.7435\n",
      "Epoch 190/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 107.3665 - mean_absolute_error: 5.5499\n",
      "Epoch 190: val_loss improved from 221.01320 to 217.65343, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.5450 - mean_absolute_error: 4.9757 - val_loss: 217.6534 - val_mean_absolute_error: 8.7092\n",
      "Epoch 191/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56.1901 - mean_absolute_error: 3.6333\n",
      "Epoch 191: val_loss improved from 217.65343 to 217.57370, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.5428 - mean_absolute_error: 4.8895 - val_loss: 217.5737 - val_mean_absolute_error: 8.6536\n",
      "Epoch 192/500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.0889 - mean_absolute_error: 4.9852 \n",
      "Epoch 192: val_loss improved from 217.57370 to 214.78502, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.6139 - mean_absolute_error: 4.9788 - val_loss: 214.7850 - val_mean_absolute_error: 8.6145\n",
      "Epoch 193/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 31.8039 - mean_absolute_error: 2.8641\n",
      "Epoch 193: val_loss improved from 214.78502 to 212.92599, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.4341 - mean_absolute_error: 4.8556 - val_loss: 212.9260 - val_mean_absolute_error: 8.5704\n",
      "Epoch 194/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 155.5765 - mean_absolute_error: 6.2259\n",
      "Epoch 194: val_loss improved from 212.92599 to 211.29860, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.5034 - mean_absolute_error: 5.1029 - val_loss: 211.2986 - val_mean_absolute_error: 8.5311\n",
      "Epoch 195/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 138.1104 - mean_absolute_error: 5.4477\n",
      "Epoch 195: val_loss improved from 211.29860 to 208.53477, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 103.6775 - mean_absolute_error: 4.8490 - val_loss: 208.5348 - val_mean_absolute_error: 8.5015\n",
      "Epoch 196/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 58.4863 - mean_absolute_error: 4.0960\n",
      "Epoch 196: val_loss improved from 208.53477 to 206.44197, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.8703 - mean_absolute_error: 5.1050 - val_loss: 206.4420 - val_mean_absolute_error: 8.4579\n",
      "Epoch 197/500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.9660 - mean_absolute_error: 5.0744\n",
      "Epoch 197: val_loss improved from 206.44197 to 205.11952, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.5219 - mean_absolute_error: 5.0616 - val_loss: 205.1195 - val_mean_absolute_error: 8.4194\n",
      "Epoch 198/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 115.2029 - mean_absolute_error: 5.4632\n",
      "Epoch 198: val_loss improved from 205.11952 to 201.96759, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 102.8187 - mean_absolute_error: 4.8658 - val_loss: 201.9676 - val_mean_absolute_error: 8.3970\n",
      "Epoch 199/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 46.9253 - mean_absolute_error: 3.8417\n",
      "Epoch 199: val_loss improved from 201.96759 to 199.55852, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.5787 - mean_absolute_error: 4.7899 - val_loss: 199.5585 - val_mean_absolute_error: 8.3619\n",
      "Epoch 200/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.7836 - mean_absolute_error: 4.0923\n",
      "Epoch 200: val_loss improved from 199.55852 to 199.42404, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.0983 - mean_absolute_error: 4.6628 - val_loss: 199.4240 - val_mean_absolute_error: 8.3184\n",
      "Epoch 201/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 81.7686 - mean_absolute_error: 4.8632\n",
      "Epoch 201: val_loss improved from 199.42404 to 197.91316, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.5015 - mean_absolute_error: 4.7291 - val_loss: 197.9132 - val_mean_absolute_error: 8.2834\n",
      "Epoch 202/500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.4584 - mean_absolute_error: 5.1369 \n",
      "Epoch 202: val_loss improved from 197.91316 to 195.44218, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109.6009 - mean_absolute_error: 5.0240 - val_loss: 195.4422 - val_mean_absolute_error: 8.2405\n",
      "Epoch 203/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 77.5230 - mean_absolute_error: 4.4659\n",
      "Epoch 203: val_loss improved from 195.44218 to 193.82465, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.2747 - mean_absolute_error: 4.7823 - val_loss: 193.8246 - val_mean_absolute_error: 8.2139\n",
      "Epoch 204/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 130.5576 - mean_absolute_error: 5.6274\n",
      "Epoch 204: val_loss improved from 193.82465 to 193.24423, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 96.6321 - mean_absolute_error: 4.8221 - val_loss: 193.2442 - val_mean_absolute_error: 8.1762\n",
      "Epoch 205/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 102.6906 - mean_absolute_error: 4.9300\n",
      "Epoch 205: val_loss improved from 193.24423 to 191.93181, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.6546 - mean_absolute_error: 4.7327 - val_loss: 191.9318 - val_mean_absolute_error: 8.1568\n",
      "Epoch 206/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 146.3489 - mean_absolute_error: 5.0917\n",
      "Epoch 206: val_loss improved from 191.93181 to 189.35057, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 96.0303 - mean_absolute_error: 4.7555 - val_loss: 189.3506 - val_mean_absolute_error: 8.1160\n",
      "Epoch 207/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 49.4625 - mean_absolute_error: 3.6123\n",
      "Epoch 207: val_loss improved from 189.35057 to 189.20497, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.2418 - mean_absolute_error: 4.6067 - val_loss: 189.2050 - val_mean_absolute_error: 8.0808\n",
      "Epoch 208/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 137.4290 - mean_absolute_error: 4.9518\n",
      "Epoch 208: val_loss improved from 189.20497 to 188.16461, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95.2187 - mean_absolute_error: 4.6402 - val_loss: 188.1646 - val_mean_absolute_error: 8.0549\n",
      "Epoch 209/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 92.0484 - mean_absolute_error: 4.7705\n",
      "Epoch 209: val_loss improved from 188.16461 to 185.23326, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.3147 - mean_absolute_error: 4.4785 - val_loss: 185.2333 - val_mean_absolute_error: 8.0253\n",
      "Epoch 210/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.6109 - mean_absolute_error: 4.2018\n",
      "Epoch 210: val_loss improved from 185.23326 to 184.24406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.4740 - mean_absolute_error: 4.8045 - val_loss: 184.2441 - val_mean_absolute_error: 7.9878\n",
      "Epoch 211/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 130.2628 - mean_absolute_error: 5.8799\n",
      "Epoch 211: val_loss improved from 184.24406 to 183.03172, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 95.0716 - mean_absolute_error: 4.7816 - val_loss: 183.0317 - val_mean_absolute_error: 7.9661\n",
      "Epoch 212/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 108.2808 - mean_absolute_error: 5.3313\n",
      "Epoch 212: val_loss improved from 183.03172 to 181.01848, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.8887 - mean_absolute_error: 4.7167 - val_loss: 181.0185 - val_mean_absolute_error: 7.9309\n",
      "Epoch 213/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 105.4557 - mean_absolute_error: 5.0954\n",
      "Epoch 213: val_loss improved from 181.01848 to 180.44774, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 90.0388 - mean_absolute_error: 4.7765 - val_loss: 180.4477 - val_mean_absolute_error: 7.9109\n",
      "Epoch 214/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 75.8689 - mean_absolute_error: 4.1509\n",
      "Epoch 214: val_loss improved from 180.44774 to 179.09930, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.2895 - mean_absolute_error: 4.5693 - val_loss: 179.0993 - val_mean_absolute_error: 7.8702\n",
      "Epoch 215/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 90.1791 - mean_absolute_error: 4.5573\n",
      "Epoch 215: val_loss improved from 179.09930 to 178.34013, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.9975 - mean_absolute_error: 4.5560 - val_loss: 178.3401 - val_mean_absolute_error: 7.8598\n",
      "Epoch 216/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 73.1198 - mean_absolute_error: 4.6651\n",
      "Epoch 216: val_loss improved from 178.34013 to 177.49815, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 87.5738 - mean_absolute_error: 4.6194 - val_loss: 177.4982 - val_mean_absolute_error: 7.8279\n",
      "Epoch 217/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 57.2992 - mean_absolute_error: 3.9371\n",
      "Epoch 217: val_loss improved from 177.49815 to 176.61124, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.9710 - mean_absolute_error: 4.7045 - val_loss: 176.6112 - val_mean_absolute_error: 7.8083\n",
      "Epoch 218/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 63.2799 - mean_absolute_error: 4.1464\n",
      "Epoch 218: val_loss improved from 176.61124 to 174.48158, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.8781 - mean_absolute_error: 4.3814 - val_loss: 174.4816 - val_mean_absolute_error: 7.7969\n",
      "Epoch 219/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 105.5044 - mean_absolute_error: 5.4461\n",
      "Epoch 219: val_loss improved from 174.48158 to 174.07712, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.9200 - mean_absolute_error: 4.5122 - val_loss: 174.0771 - val_mean_absolute_error: 7.7692\n",
      "Epoch 220/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41.0805 - mean_absolute_error: 3.2744\n",
      "Epoch 220: val_loss improved from 174.07712 to 172.46373, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.1576 - mean_absolute_error: 4.4877 - val_loss: 172.4637 - val_mean_absolute_error: 7.7644\n",
      "Epoch 221/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 93.8568 - mean_absolute_error: 4.8791\n",
      "Epoch 221: val_loss improved from 172.46373 to 172.17548, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 82.9260 - mean_absolute_error: 4.5468 - val_loss: 172.1755 - val_mean_absolute_error: 7.7403\n",
      "Epoch 222/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 90.7669 - mean_absolute_error: 4.7133\n",
      "Epoch 222: val_loss improved from 172.17548 to 170.42271, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 92.1738 - mean_absolute_error: 4.6845 - val_loss: 170.4227 - val_mean_absolute_error: 7.7241\n",
      "Epoch 223/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 84.2074 - mean_absolute_error: 4.4039\n",
      "Epoch 223: val_loss improved from 170.42271 to 169.32973, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.4429 - mean_absolute_error: 4.4791 - val_loss: 169.3297 - val_mean_absolute_error: 7.7084\n",
      "Epoch 224/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 89.4952 - mean_absolute_error: 5.1498\n",
      "Epoch 224: val_loss improved from 169.32973 to 168.92546, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.7356 - mean_absolute_error: 4.6900 - val_loss: 168.9255 - val_mean_absolute_error: 7.6857\n",
      "Epoch 225/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 78.9541 - mean_absolute_error: 4.3630\n",
      "Epoch 225: val_loss improved from 168.92546 to 166.83113, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 86.8421 - mean_absolute_error: 4.5490 - val_loss: 166.8311 - val_mean_absolute_error: 7.6827\n",
      "Epoch 226/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 69.3820 - mean_absolute_error: 4.4901\n",
      "Epoch 226: val_loss improved from 166.83113 to 166.45967, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.4268 - mean_absolute_error: 4.3387 - val_loss: 166.4597 - val_mean_absolute_error: 7.6635\n",
      "Epoch 227/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 63.7705 - mean_absolute_error: 4.4191\n",
      "Epoch 227: val_loss improved from 166.45967 to 165.81630, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.8283 - mean_absolute_error: 4.3906 - val_loss: 165.8163 - val_mean_absolute_error: 7.6486\n",
      "Epoch 228/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.2434 - mean_absolute_error: 3.9692\n",
      "Epoch 228: val_loss improved from 165.81630 to 164.36316, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.8105 - mean_absolute_error: 4.3732 - val_loss: 164.3632 - val_mean_absolute_error: 7.6283\n",
      "Epoch 229/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 113.1821 - mean_absolute_error: 4.2850\n",
      "Epoch 229: val_loss improved from 164.36316 to 164.35492, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.5057 - mean_absolute_error: 4.4405 - val_loss: 164.3549 - val_mean_absolute_error: 7.6119\n",
      "Epoch 230/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.5894 - mean_absolute_error: 4.4006 \n",
      "Epoch 230: val_loss improved from 164.35492 to 163.02800, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 79.2296 - mean_absolute_error: 4.4147 - val_loss: 163.0280 - val_mean_absolute_error: 7.5987\n",
      "Epoch 231/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 78.3198 - mean_absolute_error: 4.2588\n",
      "Epoch 231: val_loss improved from 163.02800 to 161.78214, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.5909 - mean_absolute_error: 4.4272 - val_loss: 161.7821 - val_mean_absolute_error: 7.6267\n",
      "Epoch 232/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 48.2726 - mean_absolute_error: 3.8298\n",
      "Epoch 232: val_loss did not improve from 161.78214\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.0861 - mean_absolute_error: 4.3455 - val_loss: 163.0245 - val_mean_absolute_error: 7.5563\n",
      "Epoch 233/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 110.5756 - mean_absolute_error: 5.4786\n",
      "Epoch 233: val_loss improved from 161.78214 to 161.01956, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.3098 - mean_absolute_error: 4.5804 - val_loss: 161.0196 - val_mean_absolute_error: 7.5782\n",
      "Epoch 234/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 95.2124 - mean_absolute_error: 4.5883\n",
      "Epoch 234: val_loss improved from 161.01956 to 160.10057, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 80.3622 - mean_absolute_error: 4.4077 - val_loss: 160.1006 - val_mean_absolute_error: 7.5693\n",
      "Epoch 235/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 55.8794 - mean_absolute_error: 3.8105\n",
      "Epoch 235: val_loss improved from 160.10057 to 159.77333, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.1844 - mean_absolute_error: 4.3891 - val_loss: 159.7733 - val_mean_absolute_error: 7.5528\n",
      "Epoch 236/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 107.7816 - mean_absolute_error: 4.0003\n",
      "Epoch 236: val_loss did not improve from 159.77333\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.3928 - mean_absolute_error: 4.3144 - val_loss: 159.8458 - val_mean_absolute_error: 7.5357\n",
      "Epoch 237/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.4600 - mean_absolute_error: 3.8242\n",
      "Epoch 237: val_loss improved from 159.77333 to 158.51340, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.2420 - mean_absolute_error: 4.3704 - val_loss: 158.5134 - val_mean_absolute_error: 7.5402\n",
      "Epoch 238/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 55.0307 - mean_absolute_error: 3.8066\n",
      "Epoch 238: val_loss improved from 158.51340 to 157.82832, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.2989 - mean_absolute_error: 4.4107 - val_loss: 157.8283 - val_mean_absolute_error: 7.5130\n",
      "Epoch 239/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 110.2665 - mean_absolute_error: 4.6367\n",
      "Epoch 239: val_loss improved from 157.82832 to 157.18855, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.5697 - mean_absolute_error: 4.5353 - val_loss: 157.1886 - val_mean_absolute_error: 7.5201\n",
      "Epoch 240/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 147.7254 - mean_absolute_error: 5.2105\n",
      "Epoch 240: val_loss improved from 157.18855 to 156.36574, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.8257 - mean_absolute_error: 4.4918 - val_loss: 156.3657 - val_mean_absolute_error: 7.5172\n",
      "Epoch 241/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 152.5098 - mean_absolute_error: 4.4792\n",
      "Epoch 241: val_loss did not improve from 156.36574\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.3934 - mean_absolute_error: 4.2895 - val_loss: 157.0336 - val_mean_absolute_error: 7.4712\n",
      "Epoch 242/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 106.8142 - mean_absolute_error: 4.9381\n",
      "Epoch 242: val_loss improved from 156.36574 to 155.31326, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.3153 - mean_absolute_error: 4.5522 - val_loss: 155.3133 - val_mean_absolute_error: 7.4980\n",
      "Epoch 243/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 59.3321 - mean_absolute_error: 3.9252\n",
      "Epoch 243: val_loss improved from 155.31326 to 155.18202, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.6159 - mean_absolute_error: 4.3992 - val_loss: 155.1820 - val_mean_absolute_error: 7.4913\n",
      "Epoch 244/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 49.8273 - mean_absolute_error: 4.0296\n",
      "Epoch 244: val_loss improved from 155.18202 to 154.57675, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 78.9712 - mean_absolute_error: 4.3757 - val_loss: 154.5768 - val_mean_absolute_error: 7.4600\n",
      "Epoch 245/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 57.9863 - mean_absolute_error: 3.8436\n",
      "Epoch 245: val_loss improved from 154.57675 to 153.12015, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.9970 - mean_absolute_error: 4.2369 - val_loss: 153.1201 - val_mean_absolute_error: 7.4968\n",
      "Epoch 246/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 43.9719 - mean_absolute_error: 3.4217\n",
      "Epoch 246: val_loss improved from 153.12015 to 152.36971, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.2147 - mean_absolute_error: 4.2898 - val_loss: 152.3697 - val_mean_absolute_error: 7.4830\n",
      "Epoch 247/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 52.4962 - mean_absolute_error: 3.7528\n",
      "Epoch 247: val_loss did not improve from 152.36971\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.9995 - mean_absolute_error: 4.2182 - val_loss: 152.6134 - val_mean_absolute_error: 7.4753\n",
      "Epoch 248/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 98.7445 - mean_absolute_error: 5.1568\n",
      "Epoch 248: val_loss did not improve from 152.36971\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.4052 - mean_absolute_error: 4.2782 - val_loss: 152.4311 - val_mean_absolute_error: 7.4480\n",
      "Epoch 249/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.9206 - mean_absolute_error: 4.0835 \n",
      "Epoch 249: val_loss improved from 152.36971 to 151.21396, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 70.4376 - mean_absolute_error: 4.1349 - val_loss: 151.2140 - val_mean_absolute_error: 7.4561\n",
      "Epoch 250/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 54.0246 - mean_absolute_error: 3.7967\n",
      "Epoch 250: val_loss improved from 151.21396 to 150.83034, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.6238 - mean_absolute_error: 4.3173 - val_loss: 150.8303 - val_mean_absolute_error: 7.4552\n",
      "Epoch 251/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 68.7318 - mean_absolute_error: 4.4476\n",
      "Epoch 251: val_loss did not improve from 150.83034\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.7454 - mean_absolute_error: 4.2610 - val_loss: 150.8326 - val_mean_absolute_error: 7.4280\n",
      "Epoch 252/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 72.7562 - mean_absolute_error: 4.7875\n",
      "Epoch 252: val_loss improved from 150.83034 to 150.34685, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.4158 - mean_absolute_error: 4.3396 - val_loss: 150.3468 - val_mean_absolute_error: 7.4200\n",
      "Epoch 253/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.1800 - mean_absolute_error: 4.0086\n",
      "Epoch 253: val_loss improved from 150.34685 to 149.55406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.1316 - mean_absolute_error: 4.2764 - val_loss: 149.5541 - val_mean_absolute_error: 7.4123\n",
      "Epoch 254/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.9521 - mean_absolute_error: 4.0422 \n",
      "Epoch 254: val_loss did not improve from 149.55406\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 68.5149 - mean_absolute_error: 4.0970 - val_loss: 149.8661 - val_mean_absolute_error: 7.3996\n",
      "Epoch 255/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 85.2029 - mean_absolute_error: 5.0382\n",
      "Epoch 255: val_loss improved from 149.55406 to 148.52519, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.5382 - mean_absolute_error: 4.2713 - val_loss: 148.5252 - val_mean_absolute_error: 7.4093\n",
      "Epoch 256/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 69.0141 - mean_absolute_error: 4.6835\n",
      "Epoch 256: val_loss did not improve from 148.52519\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.1871 - mean_absolute_error: 4.1827 - val_loss: 148.5733 - val_mean_absolute_error: 7.3843\n",
      "Epoch 257/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 73.7281 - mean_absolute_error: 4.5025\n",
      "Epoch 257: val_loss improved from 148.52519 to 148.41389, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.9068 - mean_absolute_error: 4.2105 - val_loss: 148.4139 - val_mean_absolute_error: 7.3641\n",
      "Epoch 258/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 44.9590 - mean_absolute_error: 3.5842\n",
      "Epoch 258: val_loss improved from 148.41389 to 147.60170, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.0540 - mean_absolute_error: 4.1677 - val_loss: 147.6017 - val_mean_absolute_error: 7.3571\n",
      "Epoch 259/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.4663 - mean_absolute_error: 4.2457 \n",
      "Epoch 259: val_loss did not improve from 147.60170\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.0715 - mean_absolute_error: 4.2215 - val_loss: 147.6149 - val_mean_absolute_error: 7.3682\n",
      "Epoch 260/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 88.4148 - mean_absolute_error: 4.6304\n",
      "Epoch 260: val_loss improved from 147.60170 to 146.90292, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.1852 - mean_absolute_error: 4.3139 - val_loss: 146.9029 - val_mean_absolute_error: 7.3424\n",
      "Epoch 261/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.0095 - mean_absolute_error: 3.5577\n",
      "Epoch 261: val_loss improved from 146.90292 to 145.92419, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.6646 - mean_absolute_error: 4.3482 - val_loss: 145.9242 - val_mean_absolute_error: 7.3494\n",
      "Epoch 262/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.4526 - mean_absolute_error: 3.3127\n",
      "Epoch 262: val_loss did not improve from 145.92419\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.6150 - mean_absolute_error: 4.0698 - val_loss: 146.2169 - val_mean_absolute_error: 7.3267\n",
      "Epoch 263/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81.0345 - mean_absolute_error: 4.3819\n",
      "Epoch 263: val_loss did not improve from 145.92419\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.3260 - mean_absolute_error: 4.1791 - val_loss: 146.3219 - val_mean_absolute_error: 7.3271\n",
      "Epoch 264/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.0674 - mean_absolute_error: 4.2823 \n",
      "Epoch 264: val_loss improved from 145.92419 to 145.59181, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 73.2099 - mean_absolute_error: 4.2567 - val_loss: 145.5918 - val_mean_absolute_error: 7.2996\n",
      "Epoch 265/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 39.0531 - mean_absolute_error: 3.2394\n",
      "Epoch 265: val_loss improved from 145.59181 to 144.42331, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.4325 - mean_absolute_error: 3.9409 - val_loss: 144.4233 - val_mean_absolute_error: 7.3341\n",
      "Epoch 266/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.3007 - mean_absolute_error: 4.3235\n",
      "Epoch 266: val_loss improved from 144.42331 to 144.07018, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.9988 - mean_absolute_error: 4.2756 - val_loss: 144.0702 - val_mean_absolute_error: 7.2975\n",
      "Epoch 267/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 70.7790 - mean_absolute_error: 4.5031\n",
      "Epoch 267: val_loss did not improve from 144.07018\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.6059 - mean_absolute_error: 4.2526 - val_loss: 144.3858 - val_mean_absolute_error: 7.2866\n",
      "Epoch 268/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 40.0361 - mean_absolute_error: 3.0236\n",
      "Epoch 268: val_loss did not improve from 144.07018\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.0733 - mean_absolute_error: 4.0837 - val_loss: 144.6802 - val_mean_absolute_error: 7.2595\n",
      "Epoch 269/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 99.9261 - mean_absolute_error: 4.6911\n",
      "Epoch 269: val_loss improved from 144.07018 to 143.23354, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.1054 - mean_absolute_error: 4.2517 - val_loss: 143.2335 - val_mean_absolute_error: 7.3012\n",
      "Epoch 270/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 67.4811 - mean_absolute_error: 3.7480\n",
      "Epoch 270: val_loss did not improve from 143.23354\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.7827 - mean_absolute_error: 3.9308 - val_loss: 143.3396 - val_mean_absolute_error: 7.2547\n",
      "Epoch 271/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 77.3509 - mean_absolute_error: 4.4236\n",
      "Epoch 271: val_loss improved from 143.23354 to 143.09520, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.9810 - mean_absolute_error: 4.1741 - val_loss: 143.0952 - val_mean_absolute_error: 7.2588\n",
      "Epoch 272/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 63.8419 - mean_absolute_error: 4.1776\n",
      "Epoch 272: val_loss improved from 143.09520 to 141.91827, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.5034 - mean_absolute_error: 4.0341 - val_loss: 141.9183 - val_mean_absolute_error: 7.3117\n",
      "Epoch 273/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 82.0423 - mean_absolute_error: 5.4509\n",
      "Epoch 273: val_loss did not improve from 141.91827\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.8828 - mean_absolute_error: 4.0985 - val_loss: 142.0633 - val_mean_absolute_error: 7.2389\n",
      "Epoch 274/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3833 - mean_absolute_error: 3.9513 \n",
      "Epoch 274: val_loss did not improve from 141.91827\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.1165 - mean_absolute_error: 3.9897 - val_loss: 141.9247 - val_mean_absolute_error: 7.2510\n",
      "Epoch 275/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 63.5575 - mean_absolute_error: 4.0020\n",
      "Epoch 275: val_loss improved from 141.91827 to 141.59406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.5670 - mean_absolute_error: 4.0675 - val_loss: 141.5941 - val_mean_absolute_error: 7.2291\n",
      "Epoch 276/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 98.5829 - mean_absolute_error: 4.8424\n",
      "Epoch 276: val_loss improved from 141.59406 to 140.95839, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.1192 - mean_absolute_error: 4.2386 - val_loss: 140.9584 - val_mean_absolute_error: 7.2238\n",
      "Epoch 277/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 48.9844 - mean_absolute_error: 3.4617\n",
      "Epoch 277: val_loss improved from 140.95839 to 140.64085, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.1581 - mean_absolute_error: 4.0042 - val_loss: 140.6409 - val_mean_absolute_error: 7.2160\n",
      "Epoch 278/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.6830 - mean_absolute_error: 3.9686\n",
      "Epoch 278: val_loss improved from 140.64085 to 140.12091, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.5957 - mean_absolute_error: 4.0389 - val_loss: 140.1209 - val_mean_absolute_error: 7.2040\n",
      "Epoch 279/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 27.8826 - mean_absolute_error: 2.9350\n",
      "Epoch 279: val_loss did not improve from 140.12091\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5033 - mean_absolute_error: 3.9044 - val_loss: 140.1770 - val_mean_absolute_error: 7.2083\n",
      "Epoch 280/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.8721 - mean_absolute_error: 3.6762\n",
      "Epoch 280: val_loss improved from 140.12091 to 139.66315, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9998 - mean_absolute_error: 3.8810 - val_loss: 139.6631 - val_mean_absolute_error: 7.2228\n",
      "Epoch 281/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 87.0563 - mean_absolute_error: 4.8778\n",
      "Epoch 281: val_loss improved from 139.66315 to 139.33345, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.4242 - mean_absolute_error: 4.1570 - val_loss: 139.3335 - val_mean_absolute_error: 7.2257\n",
      "Epoch 282/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 65.0957 - mean_absolute_error: 4.1391\n",
      "Epoch 282: val_loss did not improve from 139.33345\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.8079 - mean_absolute_error: 4.0944 - val_loss: 139.6382 - val_mean_absolute_error: 7.1933\n",
      "Epoch 283/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - loss: 91.0501 - mean_absolute_error: 4.8795\n",
      "Epoch 283: val_loss improved from 139.33345 to 139.11131, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2969 - mean_absolute_error: 4.1109 - val_loss: 139.1113 - val_mean_absolute_error: 7.2104\n",
      "Epoch 284/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 67.0955 - mean_absolute_error: 4.6082\n",
      "Epoch 284: val_loss improved from 139.11131 to 138.78073, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3841 - mean_absolute_error: 4.0809 - val_loss: 138.7807 - val_mean_absolute_error: 7.2079\n",
      "Epoch 285/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 99.5957 - mean_absolute_error: 5.3094\n",
      "Epoch 285: val_loss improved from 138.78073 to 138.19164, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.4496 - mean_absolute_error: 3.9857 - val_loss: 138.1916 - val_mean_absolute_error: 7.2326\n",
      "Epoch 286/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 100.2630 - mean_absolute_error: 4.5596\n",
      "Epoch 286: val_loss improved from 138.19164 to 138.03578, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.1396 - mean_absolute_error: 3.9058 - val_loss: 138.0358 - val_mean_absolute_error: 7.2005\n",
      "Epoch 287/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 59.5117 - mean_absolute_error: 4.3070\n",
      "Epoch 287: val_loss did not improve from 138.03578\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.5819 - mean_absolute_error: 4.1142 - val_loss: 138.8715 - val_mean_absolute_error: 7.1487\n",
      "Epoch 288/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 43.0952 - mean_absolute_error: 3.3341\n",
      "Epoch 288: val_loss improved from 138.03578 to 137.84247, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4842 - mean_absolute_error: 4.0955 - val_loss: 137.8425 - val_mean_absolute_error: 7.1586\n",
      "Epoch 289/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.0031 - mean_absolute_error: 3.2201\n",
      "Epoch 289: val_loss did not improve from 137.84247\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8031 - mean_absolute_error: 3.9085 - val_loss: 138.1942 - val_mean_absolute_error: 7.1377\n",
      "Epoch 290/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 57.3867 - mean_absolute_error: 4.0147\n",
      "Epoch 290: val_loss improved from 137.84247 to 137.59436, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 71.1816 - mean_absolute_error: 4.2064 - val_loss: 137.5944 - val_mean_absolute_error: 7.1328\n",
      "Epoch 291/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.2168 - mean_absolute_error: 3.2558\n",
      "Epoch 291: val_loss did not improve from 137.59436\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.2198 - mean_absolute_error: 3.9304 - val_loss: 137.7873 - val_mean_absolute_error: 7.1468\n",
      "Epoch 292/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4904 - mean_absolute_error: 3.9751 \n",
      "Epoch 292: val_loss improved from 137.59436 to 136.49745, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.4979 - mean_absolute_error: 3.9752 - val_loss: 136.4975 - val_mean_absolute_error: 7.1686\n",
      "Epoch 293/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 93.5110 - mean_absolute_error: 5.3092\n",
      "Epoch 293: val_loss did not improve from 136.49745\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.7677 - mean_absolute_error: 4.0741 - val_loss: 136.5283 - val_mean_absolute_error: 7.1544\n",
      "Epoch 294/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72.8344 - mean_absolute_error: 4.4302\n",
      "Epoch 294: val_loss improved from 136.49745 to 136.43736, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.0646 - mean_absolute_error: 4.1232 - val_loss: 136.4374 - val_mean_absolute_error: 7.1668\n",
      "Epoch 295/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.0434 - mean_absolute_error: 4.3915\n",
      "Epoch 295: val_loss did not improve from 136.43736\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.4474 - mean_absolute_error: 4.1138 - val_loss: 136.4642 - val_mean_absolute_error: 7.1287\n",
      "Epoch 296/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 90.4962 - mean_absolute_error: 4.4627\n",
      "Epoch 296: val_loss improved from 136.43736 to 135.71280, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.7878 - mean_absolute_error: 3.9936 - val_loss: 135.7128 - val_mean_absolute_error: 7.1766\n",
      "Epoch 297/500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.2241 - mean_absolute_error: 3.9888 \n",
      "Epoch 297: val_loss did not improve from 135.71280\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 64.2166 - mean_absolute_error: 3.9901 - val_loss: 135.9529 - val_mean_absolute_error: 7.1188\n",
      "Epoch 298/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 70.4444 - mean_absolute_error: 4.2964\n",
      "Epoch 298: val_loss improved from 135.71280 to 135.65855, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.7690 - mean_absolute_error: 4.1169 - val_loss: 135.6586 - val_mean_absolute_error: 7.1858\n",
      "Epoch 299/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.4557 - mean_absolute_error: 3.5290\n",
      "Epoch 299: val_loss did not improve from 135.65855\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.5704 - mean_absolute_error: 3.9335 - val_loss: 136.7348 - val_mean_absolute_error: 7.0788\n",
      "Epoch 300/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 85.7411 - mean_absolute_error: 5.0518\n",
      "Epoch 300: val_loss improved from 135.65855 to 135.14873, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.2179 - mean_absolute_error: 4.1274 - val_loss: 135.1487 - val_mean_absolute_error: 7.1356\n",
      "Epoch 301/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42.0195 - mean_absolute_error: 3.5613\n",
      "Epoch 301: val_loss did not improve from 135.14873\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.7642 - mean_absolute_error: 3.9985 - val_loss: 135.4297 - val_mean_absolute_error: 7.0929\n",
      "Epoch 302/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 69.8105 - mean_absolute_error: 4.2996\n",
      "Epoch 302: val_loss improved from 135.14873 to 135.05344, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 65.2594 - mean_absolute_error: 4.0133 - val_loss: 135.0534 - val_mean_absolute_error: 7.1451\n",
      "Epoch 303/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.7502 - mean_absolute_error: 3.5250\n",
      "Epoch 303: val_loss improved from 135.05344 to 134.47134, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3384 - mean_absolute_error: 3.9660 - val_loss: 134.4713 - val_mean_absolute_error: 7.1299\n",
      "Epoch 304/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 58.7796 - mean_absolute_error: 4.3764\n",
      "Epoch 304: val_loss did not improve from 134.47134\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.2516 - mean_absolute_error: 3.9569 - val_loss: 135.1941 - val_mean_absolute_error: 7.0837\n",
      "Epoch 305/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.8501 - mean_absolute_error: 3.4821\n",
      "Epoch 305: val_loss improved from 134.47134 to 134.27608, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3687 - mean_absolute_error: 4.0100 - val_loss: 134.2761 - val_mean_absolute_error: 7.1113\n",
      "Epoch 306/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 77.3670 - mean_absolute_error: 3.9141\n",
      "Epoch 306: val_loss did not improve from 134.27608\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.8799 - mean_absolute_error: 3.9895 - val_loss: 134.3853 - val_mean_absolute_error: 7.0826\n",
      "Epoch 307/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 26.1286 - mean_absolute_error: 2.8606\n",
      "Epoch 307: val_loss did not improve from 134.27608\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7325 - mean_absolute_error: 3.7545 - val_loss: 134.3635 - val_mean_absolute_error: 7.0732\n",
      "Epoch 308/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 88.0140 - mean_absolute_error: 4.2787\n",
      "Epoch 308: val_loss improved from 134.27608 to 133.47411, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.3744 - mean_absolute_error: 3.9177 - val_loss: 133.4741 - val_mean_absolute_error: 7.0802\n",
      "Epoch 309/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.0695 - mean_absolute_error: 4.4188\n",
      "Epoch 309: val_loss did not improve from 133.47411\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.9866 - mean_absolute_error: 4.0724 - val_loss: 134.0157 - val_mean_absolute_error: 7.0672\n",
      "Epoch 310/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 53.3265 - mean_absolute_error: 3.8350\n",
      "Epoch 310: val_loss did not improve from 133.47411\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.4781 - mean_absolute_error: 3.8468 - val_loss: 133.5531 - val_mean_absolute_error: 7.0848\n",
      "Epoch 311/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 58.1344 - mean_absolute_error: 4.1265\n",
      "Epoch 311: val_loss improved from 133.47411 to 133.36046, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.6728 - mean_absolute_error: 3.9072 - val_loss: 133.3605 - val_mean_absolute_error: 7.0760\n",
      "Epoch 312/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 79.6527 - mean_absolute_error: 4.3673\n",
      "Epoch 312: val_loss improved from 133.36046 to 133.04666, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.8088 - mean_absolute_error: 4.0093 - val_loss: 133.0467 - val_mean_absolute_error: 7.0960\n",
      "Epoch 313/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.1093 - mean_absolute_error: 3.7007\n",
      "Epoch 313: val_loss did not improve from 133.04666\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.5223 - mean_absolute_error: 3.8823 - val_loss: 133.7121 - val_mean_absolute_error: 7.0393\n",
      "Epoch 314/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 36.6802 - mean_absolute_error: 3.3880\n",
      "Epoch 314: val_loss improved from 133.04666 to 133.02498, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7284 - mean_absolute_error: 3.7571 - val_loss: 133.0250 - val_mean_absolute_error: 7.1022\n",
      "Epoch 315/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 68.5532 - mean_absolute_error: 4.2024\n",
      "Epoch 315: val_loss improved from 133.02498 to 132.87370, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.7444 - mean_absolute_error: 3.8071 - val_loss: 132.8737 - val_mean_absolute_error: 7.0558\n",
      "Epoch 316/500\n",
      "\u001b[1m19/33\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.4711 - mean_absolute_error: 3.8312 \n",
      "Epoch 316: val_loss improved from 132.87370 to 132.80159, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 59.0083 - mean_absolute_error: 3.8926 - val_loss: 132.8016 - val_mean_absolute_error: 7.0648\n",
      "Epoch 317/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 35.9568 - mean_absolute_error: 3.0544\n",
      "Epoch 317: val_loss improved from 132.80159 to 132.69008, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.0222 - mean_absolute_error: 3.8805 - val_loss: 132.6901 - val_mean_absolute_error: 7.1013\n",
      "Epoch 318/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 161.8792 - mean_absolute_error: 6.0334\n",
      "Epoch 318: val_loss did not improve from 132.69008\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 72.7192 - mean_absolute_error: 4.2080 - val_loss: 133.2188 - val_mean_absolute_error: 7.0124\n",
      "Epoch 319/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 93.3037 - mean_absolute_error: 4.5329\n",
      "Epoch 319: val_loss improved from 132.69008 to 132.43997, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.8586 - mean_absolute_error: 3.9289 - val_loss: 132.4400 - val_mean_absolute_error: 7.0747\n",
      "Epoch 320/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 63.8420 - mean_absolute_error: 4.5061\n",
      "Epoch 320: val_loss improved from 132.43997 to 132.14778, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.6390 - mean_absolute_error: 4.0242 - val_loss: 132.1478 - val_mean_absolute_error: 7.0264\n",
      "Epoch 321/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 87.3321 - mean_absolute_error: 4.8690\n",
      "Epoch 321: val_loss improved from 132.14778 to 131.66212, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.9972 - mean_absolute_error: 4.0136 - val_loss: 131.6621 - val_mean_absolute_error: 7.0567\n",
      "Epoch 322/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 42.6449 - mean_absolute_error: 3.8017\n",
      "Epoch 322: val_loss did not improve from 131.66212\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5869 - mean_absolute_error: 3.8518 - val_loss: 131.8636 - val_mean_absolute_error: 7.0515\n",
      "Epoch 323/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 59.8745 - mean_absolute_error: 3.9400\n",
      "Epoch 323: val_loss did not improve from 131.66212\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3887 - mean_absolute_error: 4.0195 - val_loss: 131.7213 - val_mean_absolute_error: 7.0613\n",
      "Epoch 324/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 25.6003 - mean_absolute_error: 2.6391\n",
      "Epoch 324: val_loss did not improve from 131.66212\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7524 - mean_absolute_error: 3.8101 - val_loss: 132.0708 - val_mean_absolute_error: 7.1066\n",
      "Epoch 325/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 84.0165 - mean_absolute_error: 4.0607\n",
      "Epoch 325: val_loss improved from 131.66212 to 131.28445, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.4032 - mean_absolute_error: 3.8765 - val_loss: 131.2845 - val_mean_absolute_error: 7.0680\n",
      "Epoch 326/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 27.9559 - mean_absolute_error: 2.9479\n",
      "Epoch 326: val_loss did not improve from 131.28445\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8963 - mean_absolute_error: 3.8400 - val_loss: 131.4366 - val_mean_absolute_error: 6.9976\n",
      "Epoch 327/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 67.2221 - mean_absolute_error: 4.0162\n",
      "Epoch 327: val_loss did not improve from 131.28445\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.1540 - mean_absolute_error: 3.8409 - val_loss: 131.8123 - val_mean_absolute_error: 7.0604\n",
      "Epoch 328/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 74.9948 - mean_absolute_error: 4.7560\n",
      "Epoch 328: val_loss improved from 131.28445 to 131.07152, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.2518 - mean_absolute_error: 3.9996 - val_loss: 131.0715 - val_mean_absolute_error: 7.0690\n",
      "Epoch 329/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 92.0009 - mean_absolute_error: 3.9459\n",
      "Epoch 329: val_loss did not improve from 131.07152\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3098 - mean_absolute_error: 3.8676 - val_loss: 131.1534 - val_mean_absolute_error: 7.0343\n",
      "Epoch 330/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.8574 - mean_absolute_error: 4.2650\n",
      "Epoch 330: val_loss improved from 131.07152 to 130.49612, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.5217 - mean_absolute_error: 3.8360 - val_loss: 130.4961 - val_mean_absolute_error: 7.0281\n",
      "Epoch 331/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.5506 - mean_absolute_error: 3.2566\n",
      "Epoch 331: val_loss did not improve from 130.49612\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.3279 - mean_absolute_error: 3.8556 - val_loss: 130.7242 - val_mean_absolute_error: 7.0258\n",
      "Epoch 332/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 71.4112 - mean_absolute_error: 4.1088\n",
      "Epoch 332: val_loss did not improve from 130.49612\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4078 - mean_absolute_error: 3.8395 - val_loss: 130.7744 - val_mean_absolute_error: 7.0180\n",
      "Epoch 333/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 53.7768 - mean_absolute_error: 3.4539\n",
      "Epoch 333: val_loss did not improve from 130.49612\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.8641 - mean_absolute_error: 3.8578 - val_loss: 130.7438 - val_mean_absolute_error: 6.9846\n",
      "Epoch 334/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 91.2944 - mean_absolute_error: 4.5029\n",
      "Epoch 334: val_loss did not improve from 130.49612\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3780 - mean_absolute_error: 3.9029 - val_loss: 130.9442 - val_mean_absolute_error: 7.0629\n",
      "Epoch 335/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27.3204 - mean_absolute_error: 2.6720\n",
      "Epoch 335: val_loss improved from 130.49612 to 130.49356, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5587 - mean_absolute_error: 3.7935 - val_loss: 130.4936 - val_mean_absolute_error: 6.9734\n",
      "Epoch 336/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 85.3563 - mean_absolute_error: 4.0827\n",
      "Epoch 336: val_loss improved from 130.49356 to 129.91492, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.4387 - mean_absolute_error: 3.8996 - val_loss: 129.9149 - val_mean_absolute_error: 7.0124\n",
      "Epoch 337/500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.0442 - mean_absolute_error: 3.7213 \n",
      "Epoch 337: val_loss did not improve from 129.91492\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.6762 - mean_absolute_error: 3.7422 - val_loss: 129.9910 - val_mean_absolute_error: 6.9727\n",
      "Epoch 338/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 77.3946 - mean_absolute_error: 4.6254\n",
      "Epoch 338: val_loss improved from 129.91492 to 129.89641, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.5093 - mean_absolute_error: 4.0598 - val_loss: 129.8964 - val_mean_absolute_error: 7.0002\n",
      "Epoch 339/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 78.2747 - mean_absolute_error: 4.7984\n",
      "Epoch 339: val_loss did not improve from 129.89641\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.5170 - mean_absolute_error: 3.9616 - val_loss: 130.1977 - val_mean_absolute_error: 7.0347\n",
      "Epoch 340/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 55.7396 - mean_absolute_error: 3.8740\n",
      "Epoch 340: val_loss improved from 129.89641 to 129.68439, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1506 - mean_absolute_error: 3.8492 - val_loss: 129.6844 - val_mean_absolute_error: 6.9832\n",
      "Epoch 341/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.6909 - mean_absolute_error: 3.9221\n",
      "Epoch 341: val_loss improved from 129.68439 to 129.29695, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.6070 - mean_absolute_error: 3.7807 - val_loss: 129.2970 - val_mean_absolute_error: 6.9686\n",
      "Epoch 342/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 133.5960 - mean_absolute_error: 4.9682\n",
      "Epoch 342: val_loss did not improve from 129.29695\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.5054 - mean_absolute_error: 4.0610 - val_loss: 129.5880 - val_mean_absolute_error: 6.9443\n",
      "Epoch 343/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 41.3411 - mean_absolute_error: 3.6587\n",
      "Epoch 343: val_loss did not improve from 129.29695\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8730 - mean_absolute_error: 3.7658 - val_loss: 129.4003 - val_mean_absolute_error: 6.9476\n",
      "Epoch 344/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 42.3470 - mean_absolute_error: 3.3824\n",
      "Epoch 344: val_loss improved from 129.29695 to 129.05589, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.3948 - mean_absolute_error: 3.8364 - val_loss: 129.0559 - val_mean_absolute_error: 7.0154\n",
      "Epoch 345/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 67.5574 - mean_absolute_error: 4.0702\n",
      "Epoch 345: val_loss improved from 129.05589 to 128.69586, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4512 - mean_absolute_error: 3.9731 - val_loss: 128.6959 - val_mean_absolute_error: 7.0177\n",
      "Epoch 346/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 52.3971 - mean_absolute_error: 4.1024\n",
      "Epoch 346: val_loss did not improve from 128.69586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.1423 - mean_absolute_error: 3.9439 - val_loss: 129.1992 - val_mean_absolute_error: 6.9225\n",
      "Epoch 347/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 86.2146 - mean_absolute_error: 4.7090\n",
      "Epoch 347: val_loss did not improve from 128.69586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.2204 - mean_absolute_error: 3.9079 - val_loss: 128.7577 - val_mean_absolute_error: 7.0226\n",
      "Epoch 348/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 37.2765 - mean_absolute_error: 3.1837\n",
      "Epoch 348: val_loss did not improve from 128.69586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1591 - mean_absolute_error: 3.8755 - val_loss: 128.9684 - val_mean_absolute_error: 6.9388\n",
      "Epoch 349/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 54.1804 - mean_absolute_error: 3.3830\n",
      "Epoch 349: val_loss improved from 128.69586 to 128.68010, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.4186 - mean_absolute_error: 3.9000 - val_loss: 128.6801 - val_mean_absolute_error: 6.9861\n",
      "Epoch 350/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.6339 - mean_absolute_error: 4.1976\n",
      "Epoch 350: val_loss improved from 128.68010 to 128.01929, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1704 - mean_absolute_error: 3.8471 - val_loss: 128.0193 - val_mean_absolute_error: 6.9934\n",
      "Epoch 351/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 67.7089 - mean_absolute_error: 3.9734\n",
      "Epoch 351: val_loss improved from 128.01929 to 127.87946, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.1736 - mean_absolute_error: 3.8678 - val_loss: 127.8795 - val_mean_absolute_error: 6.9654\n",
      "Epoch 352/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 92.1651 - mean_absolute_error: 4.6297\n",
      "Epoch 352: val_loss did not improve from 127.87946\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3357 - mean_absolute_error: 4.0094 - val_loss: 128.3699 - val_mean_absolute_error: 6.9042\n",
      "Epoch 353/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.9668 - mean_absolute_error: 3.6997 \n",
      "Epoch 353: val_loss did not improve from 127.87946\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.3512 - mean_absolute_error: 3.7319 - val_loss: 128.4530 - val_mean_absolute_error: 6.9789\n",
      "Epoch 354/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 68.9173 - mean_absolute_error: 4.1487\n",
      "Epoch 354: val_loss did not improve from 127.87946\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0543 - mean_absolute_error: 3.8448 - val_loss: 127.9128 - val_mean_absolute_error: 6.9162\n",
      "Epoch 355/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.7696 - mean_absolute_error: 4.3698\n",
      "Epoch 355: val_loss improved from 127.87946 to 127.76923, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.2331 - mean_absolute_error: 3.8050 - val_loss: 127.7692 - val_mean_absolute_error: 6.9672\n",
      "Epoch 356/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 58.3177 - mean_absolute_error: 3.8128\n",
      "Epoch 356: val_loss improved from 127.76923 to 127.73735, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.0133 - mean_absolute_error: 3.8507 - val_loss: 127.7374 - val_mean_absolute_error: 6.9568\n",
      "Epoch 357/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 91.7335 - mean_absolute_error: 4.9853\n",
      "Epoch 357: val_loss did not improve from 127.73735\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2053 - mean_absolute_error: 3.9388 - val_loss: 127.8203 - val_mean_absolute_error: 6.9567\n",
      "Epoch 358/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 66.7555 - mean_absolute_error: 3.7737\n",
      "Epoch 358: val_loss improved from 127.73735 to 127.52756, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.3211 - mean_absolute_error: 3.7969 - val_loss: 127.5276 - val_mean_absolute_error: 6.9706\n",
      "Epoch 359/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 52.3962 - mean_absolute_error: 3.8534\n",
      "Epoch 359: val_loss improved from 127.52756 to 127.07443, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.3948 - mean_absolute_error: 3.9674 - val_loss: 127.0744 - val_mean_absolute_error: 6.9172\n",
      "Epoch 360/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.7228 - mean_absolute_error: 4.2620\n",
      "Epoch 360: val_loss did not improve from 127.07443\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8138 - mean_absolute_error: 3.7708 - val_loss: 127.2561 - val_mean_absolute_error: 6.9401\n",
      "Epoch 361/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 57.2112 - mean_absolute_error: 3.8579\n",
      "Epoch 361: val_loss did not improve from 127.07443\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.5291 - mean_absolute_error: 3.7119 - val_loss: 127.4381 - val_mean_absolute_error: 6.9701\n",
      "Epoch 362/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 55.6005 - mean_absolute_error: 3.7328\n",
      "Epoch 362: val_loss improved from 127.07443 to 127.06866, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1934 - mean_absolute_error: 3.7738 - val_loss: 127.0687 - val_mean_absolute_error: 6.9587\n",
      "Epoch 363/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 37.7728 - mean_absolute_error: 3.0937\n",
      "Epoch 363: val_loss did not improve from 127.06866\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.2828 - mean_absolute_error: 3.8629 - val_loss: 127.1831 - val_mean_absolute_error: 6.9950\n",
      "Epoch 364/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 42.2284 - mean_absolute_error: 3.5699\n",
      "Epoch 364: val_loss did not improve from 127.06866\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.4209 - mean_absolute_error: 3.7011 - val_loss: 127.1671 - val_mean_absolute_error: 6.9320\n",
      "Epoch 365/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 40.2160 - mean_absolute_error: 3.2541\n",
      "Epoch 365: val_loss improved from 127.06866 to 126.83032, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4225 - mean_absolute_error: 3.8359 - val_loss: 126.8303 - val_mean_absolute_error: 6.9124\n",
      "Epoch 366/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 67.3113 - mean_absolute_error: 3.9324\n",
      "Epoch 366: val_loss did not improve from 126.83032\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.2135 - mean_absolute_error: 3.7727 - val_loss: 127.1857 - val_mean_absolute_error: 6.9583\n",
      "Epoch 367/500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4775 - mean_absolute_error: 3.8239 \n",
      "Epoch 367: val_loss did not improve from 126.83032\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.4846 - mean_absolute_error: 3.8245 - val_loss: 126.9199 - val_mean_absolute_error: 6.9309\n",
      "Epoch 368/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 107.0923 - mean_absolute_error: 5.0836\n",
      "Epoch 368: val_loss did not improve from 126.83032\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.2077 - mean_absolute_error: 3.9381 - val_loss: 126.8899 - val_mean_absolute_error: 6.9239\n",
      "Epoch 369/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 45.0114 - mean_absolute_error: 3.3541\n",
      "Epoch 369: val_loss did not improve from 126.83032\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9586 - mean_absolute_error: 3.9093 - val_loss: 127.0840 - val_mean_absolute_error: 6.8767\n",
      "Epoch 370/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 95.9802 - mean_absolute_error: 5.0392\n",
      "Epoch 370: val_loss improved from 126.83032 to 126.53671, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1529 - mean_absolute_error: 3.8801 - val_loss: 126.5367 - val_mean_absolute_error: 6.9128\n",
      "Epoch 371/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 40.5029 - mean_absolute_error: 3.5088\n",
      "Epoch 371: val_loss improved from 126.53671 to 126.33549, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8963 - mean_absolute_error: 3.6992 - val_loss: 126.3355 - val_mean_absolute_error: 6.9272\n",
      "Epoch 372/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 44.8418 - mean_absolute_error: 3.6869\n",
      "Epoch 372: val_loss did not improve from 126.33549\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9969 - mean_absolute_error: 3.7540 - val_loss: 126.3508 - val_mean_absolute_error: 6.8847\n",
      "Epoch 373/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 53.1150 - mean_absolute_error: 3.7451\n",
      "Epoch 373: val_loss improved from 126.33549 to 126.19383, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4174 - mean_absolute_error: 3.7402 - val_loss: 126.1938 - val_mean_absolute_error: 6.9132\n",
      "Epoch 374/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 47.2629 - mean_absolute_error: 3.4323\n",
      "Epoch 374: val_loss did not improve from 126.19383\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4408 - mean_absolute_error: 3.7718 - val_loss: 126.5724 - val_mean_absolute_error: 6.9535\n",
      "Epoch 375/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 34.4937 - mean_absolute_error: 3.4151\n",
      "Epoch 375: val_loss improved from 126.19383 to 126.08487, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2058 - mean_absolute_error: 3.7618 - val_loss: 126.0849 - val_mean_absolute_error: 6.8824\n",
      "Epoch 376/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9782 - mean_absolute_error: 3.7808 \n",
      "Epoch 376: val_loss did not improve from 126.08487\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.8476 - mean_absolute_error: 3.7983 - val_loss: 126.5157 - val_mean_absolute_error: 6.9135\n",
      "Epoch 377/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.2129 - mean_absolute_error: 4.1319\n",
      "Epoch 377: val_loss improved from 126.08487 to 125.84986, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5954 - mean_absolute_error: 3.8869 - val_loss: 125.8499 - val_mean_absolute_error: 6.8719\n",
      "Epoch 378/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32.3963 - mean_absolute_error: 3.1882\n",
      "Epoch 378: val_loss did not improve from 125.84986\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.6658 - mean_absolute_error: 3.9035 - val_loss: 126.2050 - val_mean_absolute_error: 6.8660\n",
      "Epoch 379/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 36.3196 - mean_absolute_error: 3.2621\n",
      "Epoch 379: val_loss did not improve from 125.84986\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9324 - mean_absolute_error: 3.8219 - val_loss: 126.2969 - val_mean_absolute_error: 6.9467\n",
      "Epoch 380/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.1166 - mean_absolute_error: 4.0408\n",
      "Epoch 380: val_loss did not improve from 125.84986\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3010 - mean_absolute_error: 3.9161 - val_loss: 126.2982 - val_mean_absolute_error: 6.9666\n",
      "Epoch 381/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 66.6304 - mean_absolute_error: 4.1630\n",
      "Epoch 381: val_loss did not improve from 125.84986\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0894 - mean_absolute_error: 3.8611 - val_loss: 127.3124 - val_mean_absolute_error: 6.8009\n",
      "Epoch 382/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56.9281 - mean_absolute_error: 3.9111\n",
      "Epoch 382: val_loss improved from 125.84986 to 125.67209, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.4744 - mean_absolute_error: 3.8855 - val_loss: 125.6721 - val_mean_absolute_error: 6.9233\n",
      "Epoch 383/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 89.7469 - mean_absolute_error: 4.6009\n",
      "Epoch 383: val_loss did not improve from 125.67209\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5434 - mean_absolute_error: 3.8597 - val_loss: 125.8150 - val_mean_absolute_error: 6.8973\n",
      "Epoch 384/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.7764 - mean_absolute_error: 3.8032\n",
      "Epoch 384: val_loss did not improve from 125.67209\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4244 - mean_absolute_error: 3.7948 - val_loss: 126.4450 - val_mean_absolute_error: 6.9841\n",
      "Epoch 385/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 64.3873 - mean_absolute_error: 3.7990\n",
      "Epoch 385: val_loss did not improve from 125.67209\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.0949 - mean_absolute_error: 3.9004 - val_loss: 125.8982 - val_mean_absolute_error: 6.9109\n",
      "Epoch 386/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 32.4582 - mean_absolute_error: 3.2292\n",
      "Epoch 386: val_loss improved from 125.67209 to 125.40353, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0328 - mean_absolute_error: 3.8443 - val_loss: 125.4035 - val_mean_absolute_error: 6.8802\n",
      "Epoch 387/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.7107 - mean_absolute_error: 2.9703\n",
      "Epoch 387: val_loss did not improve from 125.40353\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.5950 - mean_absolute_error: 3.7148 - val_loss: 125.5762 - val_mean_absolute_error: 6.9048\n",
      "Epoch 388/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.7848 - mean_absolute_error: 4.2763\n",
      "Epoch 388: val_loss improved from 125.40353 to 125.20010, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7970 - mean_absolute_error: 3.7640 - val_loss: 125.2001 - val_mean_absolute_error: 6.8579\n",
      "Epoch 389/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 66.6705 - mean_absolute_error: 4.0895\n",
      "Epoch 389: val_loss improved from 125.20010 to 124.81539, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.3614 - mean_absolute_error: 3.8170 - val_loss: 124.8154 - val_mean_absolute_error: 6.8909\n",
      "Epoch 390/500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.1315 - mean_absolute_error: 3.5744 \n",
      "Epoch 390: val_loss improved from 124.81539 to 124.81184, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.1409 - mean_absolute_error: 3.6648 - val_loss: 124.8118 - val_mean_absolute_error: 6.8331\n",
      "Epoch 391/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 74.4593 - mean_absolute_error: 4.3842\n",
      "Epoch 391: val_loss did not improve from 124.81184\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6254 - mean_absolute_error: 3.8133 - val_loss: 127.3703 - val_mean_absolute_error: 7.0328\n",
      "Epoch 392/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 29.1461 - mean_absolute_error: 2.9223\n",
      "Epoch 392: val_loss did not improve from 124.81184\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.8880 - mean_absolute_error: 3.6450 - val_loss: 124.9868 - val_mean_absolute_error: 6.8291\n",
      "Epoch 393/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 61.5974 - mean_absolute_error: 4.1272\n",
      "Epoch 393: val_loss did not improve from 124.81184\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2542 - mean_absolute_error: 3.7675 - val_loss: 125.8328 - val_mean_absolute_error: 6.9563\n",
      "Epoch 394/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 44.5555 - mean_absolute_error: 3.8320\n",
      "Epoch 394: val_loss improved from 124.81184 to 124.71859, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.0607 - mean_absolute_error: 3.7961 - val_loss: 124.7186 - val_mean_absolute_error: 6.8194\n",
      "Epoch 395/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.4866 - mean_absolute_error: 3.8521 \n",
      "Epoch 395: val_loss did not improve from 124.71859\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.6785 - mean_absolute_error: 3.8433 - val_loss: 125.1870 - val_mean_absolute_error: 6.9057\n",
      "Epoch 396/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 37.0641 - mean_absolute_error: 3.4411\n",
      "Epoch 396: val_loss improved from 124.71859 to 124.53051, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5639 - mean_absolute_error: 3.8310 - val_loss: 124.5305 - val_mean_absolute_error: 6.8084\n",
      "Epoch 397/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 53.0175 - mean_absolute_error: 3.7973\n",
      "Epoch 397: val_loss did not improve from 124.53051\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.7872 - mean_absolute_error: 3.6697 - val_loss: 124.6192 - val_mean_absolute_error: 6.8540\n",
      "Epoch 398/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.5212 - mean_absolute_error: 4.1569\n",
      "Epoch 398: val_loss did not improve from 124.53051\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.4694 - mean_absolute_error: 3.9041 - val_loss: 125.2754 - val_mean_absolute_error: 6.9035\n",
      "Epoch 399/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.1642 - mean_absolute_error: 4.3002\n",
      "Epoch 399: val_loss improved from 124.53051 to 124.47099, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2739 - mean_absolute_error: 3.8152 - val_loss: 124.4710 - val_mean_absolute_error: 6.8291\n",
      "Epoch 400/500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2766 - mean_absolute_error: 3.7463 \n",
      "Epoch 400: val_loss improved from 124.47099 to 124.33572, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.6526 - mean_absolute_error: 3.7678 - val_loss: 124.3357 - val_mean_absolute_error: 6.8504\n",
      "Epoch 401/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 71.6669 - mean_absolute_error: 4.1010\n",
      "Epoch 401: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8545 - mean_absolute_error: 3.6805 - val_loss: 124.3389 - val_mean_absolute_error: 6.8368\n",
      "Epoch 402/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 29.5252 - mean_absolute_error: 3.1097\n",
      "Epoch 402: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1621 - mean_absolute_error: 3.7876 - val_loss: 124.6831 - val_mean_absolute_error: 6.8024\n",
      "Epoch 403/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 40.9372 - mean_absolute_error: 2.9862\n",
      "Epoch 403: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.0776 - mean_absolute_error: 3.7388 - val_loss: 124.5458 - val_mean_absolute_error: 6.8782\n",
      "Epoch 404/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 52.8203 - mean_absolute_error: 3.6612\n",
      "Epoch 404: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.5057 - mean_absolute_error: 3.6679 - val_loss: 124.5404 - val_mean_absolute_error: 6.8511\n",
      "Epoch 405/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72.9816 - mean_absolute_error: 4.4151\n",
      "Epoch 405: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.9969 - mean_absolute_error: 3.9096 - val_loss: 124.4395 - val_mean_absolute_error: 6.8409\n",
      "Epoch 406/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 42.8442 - mean_absolute_error: 2.8752\n",
      "Epoch 406: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9119 - mean_absolute_error: 3.6626 - val_loss: 124.4836 - val_mean_absolute_error: 6.7680\n",
      "Epoch 407/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 35.5191 - mean_absolute_error: 3.1166\n",
      "Epoch 407: val_loss did not improve from 124.33572\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6382 - mean_absolute_error: 3.8045 - val_loss: 125.4874 - val_mean_absolute_error: 6.9717\n",
      "Epoch 408/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.0960 - mean_absolute_error: 4.0383\n",
      "Epoch 408: val_loss improved from 124.33572 to 123.96725, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.6304 - mean_absolute_error: 3.8932 - val_loss: 123.9672 - val_mean_absolute_error: 6.8300\n",
      "Epoch 409/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 43.7008 - mean_absolute_error: 3.2553\n",
      "Epoch 409: val_loss did not improve from 123.96725\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.8808 - mean_absolute_error: 3.7439 - val_loss: 124.4127 - val_mean_absolute_error: 6.8508\n",
      "Epoch 410/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59.8636 - mean_absolute_error: 4.1415\n",
      "Epoch 410: val_loss did not improve from 123.96725\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1509 - mean_absolute_error: 3.7922 - val_loss: 124.1772 - val_mean_absolute_error: 6.7946\n",
      "Epoch 411/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4796 - mean_absolute_error: 3.7196 \n",
      "Epoch 411: val_loss did not improve from 123.96725\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.9841 - mean_absolute_error: 3.7361 - val_loss: 124.3365 - val_mean_absolute_error: 6.8572\n",
      "Epoch 412/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 64.2058 - mean_absolute_error: 3.7140\n",
      "Epoch 412: val_loss improved from 123.96725 to 123.68092, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3256 - mean_absolute_error: 3.6835 - val_loss: 123.6809 - val_mean_absolute_error: 6.8441\n",
      "Epoch 413/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 31.5686 - mean_absolute_error: 2.9393\n",
      "Epoch 413: val_loss did not improve from 123.68092\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.7778 - mean_absolute_error: 3.6276 - val_loss: 124.0299 - val_mean_absolute_error: 6.7824\n",
      "Epoch 414/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.4202 - mean_absolute_error: 4.4749\n",
      "Epoch 414: val_loss improved from 123.68092 to 123.25262, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0869 - mean_absolute_error: 3.8088 - val_loss: 123.2526 - val_mean_absolute_error: 6.8081\n",
      "Epoch 415/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 110.9864 - mean_absolute_error: 4.9707\n",
      "Epoch 415: val_loss did not improve from 123.25262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3668 - mean_absolute_error: 3.9480 - val_loss: 123.6340 - val_mean_absolute_error: 6.7965\n",
      "Epoch 416/500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.6810 - mean_absolute_error: 3.8841 \n",
      "Epoch 416: val_loss did not improve from 123.25262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.0838 - mean_absolute_error: 3.8658 - val_loss: 123.9581 - val_mean_absolute_error: 6.7378\n",
      "Epoch 417/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 49.3029 - mean_absolute_error: 3.1847\n",
      "Epoch 417: val_loss did not improve from 123.25262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6582 - mean_absolute_error: 3.7287 - val_loss: 124.1293 - val_mean_absolute_error: 6.9227\n",
      "Epoch 418/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 49.5851 - mean_absolute_error: 3.7630\n",
      "Epoch 418: val_loss did not improve from 123.25262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2627 - mean_absolute_error: 3.7882 - val_loss: 123.4040 - val_mean_absolute_error: 6.8147\n",
      "Epoch 419/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 84.6215 - mean_absolute_error: 4.4269\n",
      "Epoch 419: val_loss improved from 123.25262 to 123.16591, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.7687 - mean_absolute_error: 3.8712 - val_loss: 123.1659 - val_mean_absolute_error: 6.8013\n",
      "Epoch 420/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40.0776 - mean_absolute_error: 3.1527\n",
      "Epoch 420: val_loss did not improve from 123.16591\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.3918 - mean_absolute_error: 3.6848 - val_loss: 123.7558 - val_mean_absolute_error: 6.8345\n",
      "Epoch 421/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.0681 - mean_absolute_error: 3.1435\n",
      "Epoch 421: val_loss improved from 123.16591 to 123.11781, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 52.4062 - mean_absolute_error: 3.6522 - val_loss: 123.1178 - val_mean_absolute_error: 6.8290\n",
      "Epoch 422/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 49.1821 - mean_absolute_error: 3.2776\n",
      "Epoch 422: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1761 - mean_absolute_error: 3.7023 - val_loss: 123.4654 - val_mean_absolute_error: 6.8486\n",
      "Epoch 423/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.1840 - mean_absolute_error: 3.4772\n",
      "Epoch 423: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.5168 - mean_absolute_error: 3.8778 - val_loss: 123.2808 - val_mean_absolute_error: 6.7563\n",
      "Epoch 424/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.4346 - mean_absolute_error: 4.1878\n",
      "Epoch 424: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.0621 - mean_absolute_error: 3.7901 - val_loss: 123.6542 - val_mean_absolute_error: 6.8009\n",
      "Epoch 425/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 35.2425 - mean_absolute_error: 3.0203\n",
      "Epoch 425: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49.5631 - mean_absolute_error: 3.5664 - val_loss: 123.3331 - val_mean_absolute_error: 6.7845\n",
      "Epoch 426/500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4092 - mean_absolute_error: 3.8005 \n",
      "Epoch 426: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.5779 - mean_absolute_error: 3.7900 - val_loss: 123.4791 - val_mean_absolute_error: 6.8040\n",
      "Epoch 427/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 61.8050 - mean_absolute_error: 4.0216\n",
      "Epoch 427: val_loss did not improve from 123.11781\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8025 - mean_absolute_error: 3.8011 - val_loss: 123.4070 - val_mean_absolute_error: 6.7595\n",
      "Epoch 428/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.5150 - mean_absolute_error: 3.6823\n",
      "Epoch 428: val_loss improved from 123.11781 to 122.89632, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8116 - mean_absolute_error: 3.6973 - val_loss: 122.8963 - val_mean_absolute_error: 6.7802\n",
      "Epoch 429/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 101.0020 - mean_absolute_error: 4.1395\n",
      "Epoch 429: val_loss did not improve from 122.89632\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5119 - mean_absolute_error: 3.8145 - val_loss: 123.0823 - val_mean_absolute_error: 6.8593\n",
      "Epoch 430/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 56.6875 - mean_absolute_error: 3.9686\n",
      "Epoch 430: val_loss did not improve from 122.89632\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8368 - mean_absolute_error: 3.9273 - val_loss: 122.9644 - val_mean_absolute_error: 6.8274\n",
      "Epoch 431/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.5503 - mean_absolute_error: 3.5613\n",
      "Epoch 431: val_loss did not improve from 122.89632\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9270 - mean_absolute_error: 3.8737 - val_loss: 122.9637 - val_mean_absolute_error: 6.7693\n",
      "Epoch 432/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 47.4886 - mean_absolute_error: 3.4738\n",
      "Epoch 432: val_loss did not improve from 122.89632\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8153 - mean_absolute_error: 3.7865 - val_loss: 123.2331 - val_mean_absolute_error: 6.8376\n",
      "Epoch 433/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.9072 - mean_absolute_error: 3.7141\n",
      "Epoch 433: val_loss did not improve from 122.89632\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6361 - mean_absolute_error: 3.8942 - val_loss: 122.9586 - val_mean_absolute_error: 6.7942\n",
      "Epoch 434/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 100.3069 - mean_absolute_error: 4.7644\n",
      "Epoch 434: val_loss improved from 122.89632 to 122.83163, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.7003 - mean_absolute_error: 3.9827 - val_loss: 122.8316 - val_mean_absolute_error: 6.8290\n",
      "Epoch 435/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 82.8476 - mean_absolute_error: 5.4107\n",
      "Epoch 435: val_loss did not improve from 122.83163\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1702 - mean_absolute_error: 3.8842 - val_loss: 123.2529 - val_mean_absolute_error: 6.8407\n",
      "Epoch 436/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 68.4078 - mean_absolute_error: 4.2022\n",
      "Epoch 436: val_loss improved from 122.83163 to 122.64904, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9157 - mean_absolute_error: 3.9931 - val_loss: 122.6490 - val_mean_absolute_error: 6.7993\n",
      "Epoch 437/500\n",
      "\u001b[1m23/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5910 - mean_absolute_error: 3.8121  \n",
      "Epoch 437: val_loss did not improve from 122.64904\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 57.5390 - mean_absolute_error: 3.7811 - val_loss: 123.6084 - val_mean_absolute_error: 6.8726\n",
      "Epoch 438/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 53.7650 - mean_absolute_error: 3.6572\n",
      "Epoch 438: val_loss did not improve from 122.64904\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4334 - mean_absolute_error: 3.7722 - val_loss: 123.2967 - val_mean_absolute_error: 6.8575\n",
      "Epoch 439/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 42.6054 - mean_absolute_error: 3.3043\n",
      "Epoch 439: val_loss did not improve from 122.64904\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1806 - mean_absolute_error: 3.7852 - val_loss: 122.7543 - val_mean_absolute_error: 6.7161\n",
      "Epoch 440/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 57.9382 - mean_absolute_error: 3.6549\n",
      "Epoch 440: val_loss did not improve from 122.64904\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7208 - mean_absolute_error: 3.7143 - val_loss: 123.2521 - val_mean_absolute_error: 6.8549\n",
      "Epoch 441/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 46.3230 - mean_absolute_error: 3.4097\n",
      "Epoch 441: val_loss improved from 122.64904 to 122.56318, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.3091 - mean_absolute_error: 3.6496 - val_loss: 122.5632 - val_mean_absolute_error: 6.7131\n",
      "Epoch 442/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 67.9467 - mean_absolute_error: 4.2960\n",
      "Epoch 442: val_loss did not improve from 122.56318\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8304 - mean_absolute_error: 3.8493 - val_loss: 122.7749 - val_mean_absolute_error: 6.8122\n",
      "Epoch 443/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.4497 - mean_absolute_error: 3.7086 \n",
      "Epoch 443: val_loss did not improve from 122.56318\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.1202 - mean_absolute_error: 3.7219 - val_loss: 122.6500 - val_mean_absolute_error: 6.7917\n",
      "Epoch 444/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.3001 - mean_absolute_error: 3.3320\n",
      "Epoch 444: val_loss improved from 122.56318 to 122.44740, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.7644 - mean_absolute_error: 3.6523 - val_loss: 122.4474 - val_mean_absolute_error: 6.7987\n",
      "Epoch 445/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 49.5512 - mean_absolute_error: 3.6363\n",
      "Epoch 445: val_loss improved from 122.44740 to 122.28302, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6756 - mean_absolute_error: 3.8162 - val_loss: 122.2830 - val_mean_absolute_error: 6.7430\n",
      "Epoch 446/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 66.3843 - mean_absolute_error: 3.9362\n",
      "Epoch 446: val_loss improved from 122.28302 to 122.03975, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.1581 - mean_absolute_error: 3.6393 - val_loss: 122.0397 - val_mean_absolute_error: 6.7482\n",
      "Epoch 447/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 51.5961 - mean_absolute_error: 3.9044\n",
      "Epoch 447: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.4078 - mean_absolute_error: 3.9284 - val_loss: 122.1625 - val_mean_absolute_error: 6.7774\n",
      "Epoch 448/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 37.1157 - mean_absolute_error: 3.3351\n",
      "Epoch 448: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.2183 - mean_absolute_error: 3.7168 - val_loss: 122.7803 - val_mean_absolute_error: 6.8145\n",
      "Epoch 449/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 28.2164 - mean_absolute_error: 2.7779\n",
      "Epoch 449: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0472 - mean_absolute_error: 3.7126 - val_loss: 122.0876 - val_mean_absolute_error: 6.7714\n",
      "Epoch 450/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 43.2727 - mean_absolute_error: 3.4880\n",
      "Epoch 450: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2650 - mean_absolute_error: 3.7022 - val_loss: 122.1923 - val_mean_absolute_error: 6.7768\n",
      "Epoch 451/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.6560 - mean_absolute_error: 3.3048\n",
      "Epoch 451: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8063 - mean_absolute_error: 3.8077 - val_loss: 122.0956 - val_mean_absolute_error: 6.7332\n",
      "Epoch 452/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 45.9147 - mean_absolute_error: 3.6561\n",
      "Epoch 452: val_loss did not improve from 122.03975\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0187 - mean_absolute_error: 3.8610 - val_loss: 122.2132 - val_mean_absolute_error: 6.7844\n",
      "Epoch 453/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 41.9935 - mean_absolute_error: 3.3687\n",
      "Epoch 453: val_loss improved from 122.03975 to 121.68504, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.8738 - mean_absolute_error: 3.7558 - val_loss: 121.6850 - val_mean_absolute_error: 6.7829\n",
      "Epoch 454/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 41.7587 - mean_absolute_error: 3.1554\n",
      "Epoch 454: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.8884 - mean_absolute_error: 3.6345 - val_loss: 122.0292 - val_mean_absolute_error: 6.7782\n",
      "Epoch 455/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 65.1633 - mean_absolute_error: 3.8686\n",
      "Epoch 455: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.4169 - mean_absolute_error: 3.9478 - val_loss: 122.5076 - val_mean_absolute_error: 6.6769\n",
      "Epoch 456/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 42.0602 - mean_absolute_error: 3.5474\n",
      "Epoch 456: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7079 - mean_absolute_error: 3.7793 - val_loss: 121.9854 - val_mean_absolute_error: 6.8099\n",
      "Epoch 457/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81.0134 - mean_absolute_error: 4.1140\n",
      "Epoch 457: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2046 - mean_absolute_error: 3.9287 - val_loss: 122.6565 - val_mean_absolute_error: 6.8603\n",
      "Epoch 458/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 80.8485 - mean_absolute_error: 4.3776\n",
      "Epoch 458: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9424 - mean_absolute_error: 3.8631 - val_loss: 123.1919 - val_mean_absolute_error: 6.8897\n",
      "Epoch 459/500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0469 - mean_absolute_error: 3.8096 \n",
      "Epoch 459: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.7060 - mean_absolute_error: 3.8070 - val_loss: 122.3175 - val_mean_absolute_error: 6.6852\n",
      "Epoch 460/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 49.4195 - mean_absolute_error: 3.8286\n",
      "Epoch 460: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.3678 - mean_absolute_error: 3.6608 - val_loss: 122.1572 - val_mean_absolute_error: 6.7621\n",
      "Epoch 461/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 33.9403 - mean_absolute_error: 2.9665\n",
      "Epoch 461: val_loss did not improve from 121.68504\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6624 - mean_absolute_error: 3.6683 - val_loss: 122.8010 - val_mean_absolute_error: 6.8367\n",
      "Epoch 462/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.7792 - mean_absolute_error: 3.5552\n",
      "Epoch 462: val_loss improved from 121.68504 to 121.59705, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2404 - mean_absolute_error: 3.7033 - val_loss: 121.5971 - val_mean_absolute_error: 6.7120\n",
      "Epoch 463/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 58.3357 - mean_absolute_error: 3.8280\n",
      "Epoch 463: val_loss did not improve from 121.59705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.4931 - mean_absolute_error: 3.6880 - val_loss: 121.6717 - val_mean_absolute_error: 6.7332\n",
      "Epoch 464/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 94.4257 - mean_absolute_error: 4.0596\n",
      "Epoch 464: val_loss did not improve from 121.59705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6504 - mean_absolute_error: 3.6826 - val_loss: 121.7787 - val_mean_absolute_error: 6.7825\n",
      "Epoch 465/500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 47.2493 - mean_absolute_error: 3.4162 \n",
      "Epoch 465: val_loss did not improve from 121.59705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.4369 - mean_absolute_error: 3.4613 - val_loss: 121.7363 - val_mean_absolute_error: 6.7689\n",
      "Epoch 466/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 86.8524 - mean_absolute_error: 4.8057\n",
      "Epoch 466: val_loss did not improve from 121.59705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5037 - mean_absolute_error: 3.8194 - val_loss: 122.3545 - val_mean_absolute_error: 6.8270\n",
      "Epoch 467/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 64.4306 - mean_absolute_error: 3.8538\n",
      "Epoch 467: val_loss improved from 121.59705 to 121.47630, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.0108 - mean_absolute_error: 3.7051 - val_loss: 121.4763 - val_mean_absolute_error: 6.7435\n",
      "Epoch 468/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 70.7775 - mean_absolute_error: 4.4168\n",
      "Epoch 468: val_loss did not improve from 121.47630\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.0127 - mean_absolute_error: 3.7092 - val_loss: 121.8829 - val_mean_absolute_error: 6.8119\n",
      "Epoch 469/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.9564 - mean_absolute_error: 3.3241\n",
      "Epoch 469: val_loss improved from 121.47630 to 121.41200, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.4048 - mean_absolute_error: 3.6471 - val_loss: 121.4120 - val_mean_absolute_error: 6.7442\n",
      "Epoch 470/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 58.8132 - mean_absolute_error: 4.6159\n",
      "Epoch 470: val_loss improved from 121.41200 to 121.18877, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.4459 - mean_absolute_error: 3.9782 - val_loss: 121.1888 - val_mean_absolute_error: 6.7145\n",
      "Epoch 471/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.1357 - mean_absolute_error: 3.1072\n",
      "Epoch 471: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1824 - mean_absolute_error: 3.6889 - val_loss: 121.3453 - val_mean_absolute_error: 6.7730\n",
      "Epoch 472/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 103.8274 - mean_absolute_error: 5.1976\n",
      "Epoch 472: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7668 - mean_absolute_error: 3.7670 - val_loss: 121.3200 - val_mean_absolute_error: 6.7489\n",
      "Epoch 473/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 19.5978 - mean_absolute_error: 2.5941\n",
      "Epoch 473: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1568 - mean_absolute_error: 3.8264 - val_loss: 121.8652 - val_mean_absolute_error: 6.7933\n",
      "Epoch 474/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 63.9923 - mean_absolute_error: 4.1592\n",
      "Epoch 474: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1102 - mean_absolute_error: 3.7711 - val_loss: 121.7206 - val_mean_absolute_error: 6.7695\n",
      "Epoch 475/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 38.1922 - mean_absolute_error: 2.9388\n",
      "Epoch 475: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0437 - mean_absolute_error: 3.6980 - val_loss: 121.4125 - val_mean_absolute_error: 6.7729\n",
      "Epoch 476/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 35.3370 - mean_absolute_error: 3.2409\n",
      "Epoch 476: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.7792 - mean_absolute_error: 3.7491 - val_loss: 121.4278 - val_mean_absolute_error: 6.7630\n",
      "Epoch 477/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 38.9438 - mean_absolute_error: 3.1986\n",
      "Epoch 477: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5205 - mean_absolute_error: 3.7947 - val_loss: 121.2499 - val_mean_absolute_error: 6.7488\n",
      "Epoch 478/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 29.7011 - mean_absolute_error: 3.0244\n",
      "Epoch 478: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5758 - mean_absolute_error: 3.6835 - val_loss: 122.1502 - val_mean_absolute_error: 6.8203\n",
      "Epoch 479/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 77.1321 - mean_absolute_error: 4.4622\n",
      "Epoch 479: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8170 - mean_absolute_error: 3.7977 - val_loss: 121.4166 - val_mean_absolute_error: 6.7498\n",
      "Epoch 480/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65.1243 - mean_absolute_error: 4.0598\n",
      "Epoch 480: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0464 - mean_absolute_error: 3.7945 - val_loss: 121.2419 - val_mean_absolute_error: 6.7830\n",
      "Epoch 481/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 35.5375 - mean_absolute_error: 3.2099\n",
      "Epoch 481: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.9166 - mean_absolute_error: 3.7256 - val_loss: 121.2620 - val_mean_absolute_error: 6.7081\n",
      "Epoch 482/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 57.8897 - mean_absolute_error: 4.1454\n",
      "Epoch 482: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.1665 - mean_absolute_error: 3.7432 - val_loss: 121.5465 - val_mean_absolute_error: 6.6924\n",
      "Epoch 483/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 49.4679 - mean_absolute_error: 3.4246\n",
      "Epoch 483: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8510 - mean_absolute_error: 3.6794 - val_loss: 121.2918 - val_mean_absolute_error: 6.7532\n",
      "Epoch 484/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 73.6762 - mean_absolute_error: 4.7232\n",
      "Epoch 484: val_loss did not improve from 121.18877\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.0075 - mean_absolute_error: 3.9283 - val_loss: 121.6983 - val_mean_absolute_error: 6.7765\n",
      "Epoch 485/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24.4284 - mean_absolute_error: 2.7948\n",
      "Epoch 485: val_loss improved from 121.18877 to 121.11880, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.6480 - mean_absolute_error: 3.5909 - val_loss: 121.1188 - val_mean_absolute_error: 6.6820\n",
      "Epoch 486/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32.6567 - mean_absolute_error: 2.9007\n",
      "Epoch 486: val_loss did not improve from 121.11880\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.6704 - mean_absolute_error: 3.5987 - val_loss: 121.4088 - val_mean_absolute_error: 6.7648\n",
      "Epoch 487/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 46.1290 - mean_absolute_error: 3.9320\n",
      "Epoch 487: val_loss did not improve from 121.11880\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8959 - mean_absolute_error: 3.7155 - val_loss: 121.3063 - val_mean_absolute_error: 6.8031\n",
      "Epoch 488/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 43.0893 - mean_absolute_error: 3.2648\n",
      "Epoch 488: val_loss did not improve from 121.11880\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9774 - mean_absolute_error: 3.7967 - val_loss: 121.2184 - val_mean_absolute_error: 6.7173\n",
      "Epoch 489/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 14.9703 - mean_absolute_error: 2.2023\n",
      "Epoch 489: val_loss improved from 121.11880 to 120.86363, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.3338 - mean_absolute_error: 3.7029 - val_loss: 120.8636 - val_mean_absolute_error: 6.7142\n",
      "Epoch 490/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 69.8283 - mean_absolute_error: 4.1226\n",
      "Epoch 490: val_loss did not improve from 120.86363\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1511 - mean_absolute_error: 3.7670 - val_loss: 121.0785 - val_mean_absolute_error: 6.7373\n",
      "Epoch 491/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 63.4857 - mean_absolute_error: 3.7374\n",
      "Epoch 491: val_loss did not improve from 120.86363\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.3666 - mean_absolute_error: 3.6564 - val_loss: 121.0818 - val_mean_absolute_error: 6.7329\n",
      "Epoch 492/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 97.2568 - mean_absolute_error: 4.7197\n",
      "Epoch 492: val_loss did not improve from 120.86363\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8090 - mean_absolute_error: 3.8362 - val_loss: 121.0595 - val_mean_absolute_error: 6.7322\n",
      "Epoch 493/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 53.0942 - mean_absolute_error: 3.9110\n",
      "Epoch 493: val_loss improved from 120.86363 to 120.54805, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.0103 - mean_absolute_error: 3.5446 - val_loss: 120.5480 - val_mean_absolute_error: 6.7136\n",
      "Epoch 494/500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.7463 - mean_absolute_error: 3.6230 \n",
      "Epoch 494: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.1620 - mean_absolute_error: 3.6678 - val_loss: 121.2211 - val_mean_absolute_error: 6.7668\n",
      "Epoch 495/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.7751 - mean_absolute_error: 2.6787\n",
      "Epoch 495: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.6573 - mean_absolute_error: 3.6431 - val_loss: 120.8239 - val_mean_absolute_error: 6.7021\n",
      "Epoch 496/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79.5502 - mean_absolute_error: 4.2585\n",
      "Epoch 496: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1790 - mean_absolute_error: 3.7239 - val_loss: 121.0326 - val_mean_absolute_error: 6.7582\n",
      "Epoch 497/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 71.0397 - mean_absolute_error: 4.0798\n",
      "Epoch 497: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.2157 - mean_absolute_error: 3.8329 - val_loss: 120.5663 - val_mean_absolute_error: 6.7208\n",
      "Epoch 498/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 85.6039 - mean_absolute_error: 3.9917\n",
      "Epoch 498: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.0043 - mean_absolute_error: 3.9735 - val_loss: 120.8474 - val_mean_absolute_error: 6.7183\n",
      "Epoch 499/500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3493 - mean_absolute_error: 3.7154 \n",
      "Epoch 499: val_loss did not improve from 120.54805\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.7750 - mean_absolute_error: 3.7287 - val_loss: 121.2733 - val_mean_absolute_error: 6.7906\n",
      "Epoch 500/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 60.6700 - mean_absolute_error: 4.1626\n",
      "Epoch 500: val_loss improved from 120.54805 to 120.39770, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4932 - mean_absolute_error: 3.8127 - val_loss: 120.3977 - val_mean_absolute_error: 6.6810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e645009780>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=500, callbacks=[cp5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "AzIN93E2xRjE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1, 5)\n",
      "(31, 5)\n"
     ]
    }
   ],
   "source": [
    "def mae(true, pred):\n",
    "    return np.mean(np.abs(true - pred))\n",
    "\n",
    "def plot_predictions2(model, X, y, cols, start=0, end=100):\n",
    "    predictions = model.predict(X)-15\n",
    "    df = pd.DataFrame(data=predictions)\n",
    "    df.columns=cols\n",
    "    org = pd.DataFrame(data=y)\n",
    "    org.columns = cols\n",
    "    plt.plot(df['PM2.5 (µg/m³)'][start:end])\n",
    "    plt.plot(org['PM2.5 (µg/m³)'][start:end])\n",
    "    a = org.astype('float32')\n",
    "    print(predictions[:,-1].dtype)\n",
    "    ma = mae(a['PM2.5 (µg/m³)'],df['PM2.5 (µg/m³)'])\n",
    "    return df[start:end], org, ma\n",
    "x_test_start = df_corr.values[-1]\n",
    "x_test_start = np.reshape(x_test_start,(1,1,5))\n",
    "y_test_start = val.values[0]\n",
    "x_test_9 = np.vstack((x_test_start, X2_test))\n",
    "print(x_test_9.shape)\n",
    "y_test_9 = np.vstack((y_test_start, y3_test))\n",
    "print(y_test_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((1, 5)))\n",
    "model5.add(LSTM(64))\n",
    "model5.add(Dense(8, 'relu'))\n",
    "model5.add(Dense(5, 'linear'))\n",
    "\n",
    "# Load the previously saved weights\n",
    "model5.load_weights('checkpoint.model5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "QzXcewu_zy2k",
    "outputId": "0f520f7f-6aa3-4079-edf5-4c5ff4626258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 21 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E648931360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "float32\n",
      "mean absolute error:  17.777107\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5, org_5, mae_5 = plot_predictions2(model5, x_test_9, y_test_9,cols)\n",
    "print(\"mean absolute error: \",mae_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14.044580</td>\n",
       "      <td>0.042932</td>\n",
       "      <td>-0.391599</td>\n",
       "      <td>-8.160532</td>\n",
       "      <td>81.732109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.922686</td>\n",
       "      <td>-0.751628</td>\n",
       "      <td>-3.020547</td>\n",
       "      <td>-5.847861</td>\n",
       "      <td>107.857010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.879909</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>-1.804182</td>\n",
       "      <td>-5.073488</td>\n",
       "      <td>116.795715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.858078</td>\n",
       "      <td>0.926347</td>\n",
       "      <td>-1.462164</td>\n",
       "      <td>-4.745018</td>\n",
       "      <td>120.813309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.862978</td>\n",
       "      <td>0.811635</td>\n",
       "      <td>-1.569119</td>\n",
       "      <td>-4.829928</td>\n",
       "      <td>119.794922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-13.927787</td>\n",
       "      <td>-1.090693</td>\n",
       "      <td>-3.325070</td>\n",
       "      <td>-6.015124</td>\n",
       "      <td>106.021652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-13.948682</td>\n",
       "      <td>-1.412595</td>\n",
       "      <td>-3.782443</td>\n",
       "      <td>-5.900223</td>\n",
       "      <td>109.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-13.957657</td>\n",
       "      <td>-1.630406</td>\n",
       "      <td>-4.023920</td>\n",
       "      <td>-5.976585</td>\n",
       "      <td>108.559586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-13.892078</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>-2.427933</td>\n",
       "      <td>-4.996915</td>\n",
       "      <td>119.371140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-13.999179</td>\n",
       "      <td>-3.105399</td>\n",
       "      <td>-5.359859</td>\n",
       "      <td>-6.832769</td>\n",
       "      <td>98.666779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-13.957663</td>\n",
       "      <td>-1.651193</td>\n",
       "      <td>-4.033565</td>\n",
       "      <td>-5.999639</td>\n",
       "      <td>108.207184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-13.911394</td>\n",
       "      <td>-0.337497</td>\n",
       "      <td>-2.731099</td>\n",
       "      <td>-5.361880</td>\n",
       "      <td>114.584854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-13.975742</td>\n",
       "      <td>-2.416509</td>\n",
       "      <td>-4.765733</td>\n",
       "      <td>-6.399688</td>\n",
       "      <td>104.064941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-13.864279</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>-2.006577</td>\n",
       "      <td>-4.719903</td>\n",
       "      <td>122.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-13.877506</td>\n",
       "      <td>0.254918</td>\n",
       "      <td>-2.184926</td>\n",
       "      <td>-4.847987</td>\n",
       "      <td>121.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-13.940034</td>\n",
       "      <td>-1.144633</td>\n",
       "      <td>-3.558591</td>\n",
       "      <td>-5.718190</td>\n",
       "      <td>111.364563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-13.939836</td>\n",
       "      <td>-1.101327</td>\n",
       "      <td>-3.523223</td>\n",
       "      <td>-5.687986</td>\n",
       "      <td>111.734718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-13.887912</td>\n",
       "      <td>0.374057</td>\n",
       "      <td>-1.962008</td>\n",
       "      <td>-5.168463</td>\n",
       "      <td>115.453445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-13.970956</td>\n",
       "      <td>-1.845229</td>\n",
       "      <td>-4.328621</td>\n",
       "      <td>-5.931868</td>\n",
       "      <td>110.125977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-14.035223</td>\n",
       "      <td>-3.605145</td>\n",
       "      <td>-6.109564</td>\n",
       "      <td>-6.816096</td>\n",
       "      <td>101.479202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-13.968641</td>\n",
       "      <td>-1.943690</td>\n",
       "      <td>-4.432746</td>\n",
       "      <td>-5.938340</td>\n",
       "      <td>110.340378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-14.005427</td>\n",
       "      <td>-3.224574</td>\n",
       "      <td>-5.699047</td>\n",
       "      <td>-6.567777</td>\n",
       "      <td>104.160461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-13.956037</td>\n",
       "      <td>-1.648751</td>\n",
       "      <td>-4.168511</td>\n",
       "      <td>-5.725085</td>\n",
       "      <td>112.940605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-13.949145</td>\n",
       "      <td>-1.512073</td>\n",
       "      <td>-4.033280</td>\n",
       "      <td>-5.640465</td>\n",
       "      <td>113.876266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-13.905341</td>\n",
       "      <td>-0.367469</td>\n",
       "      <td>-2.819573</td>\n",
       "      <td>-5.144751</td>\n",
       "      <td>118.075119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-13.931246</td>\n",
       "      <td>-0.778058</td>\n",
       "      <td>-3.214587</td>\n",
       "      <td>-5.450503</td>\n",
       "      <td>114.387421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-13.850389</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>-1.948302</td>\n",
       "      <td>-4.633296</td>\n",
       "      <td>123.672668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-13.927417</td>\n",
       "      <td>-0.662448</td>\n",
       "      <td>-3.109132</td>\n",
       "      <td>-5.379183</td>\n",
       "      <td>115.221130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-13.908126</td>\n",
       "      <td>-0.539128</td>\n",
       "      <td>-3.026167</td>\n",
       "      <td>-5.159271</td>\n",
       "      <td>118.488724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-13.974477</td>\n",
       "      <td>-1.991485</td>\n",
       "      <td>-4.505232</td>\n",
       "      <td>-5.919620</td>\n",
       "      <td>110.776268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-13.969846</td>\n",
       "      <td>-1.904105</td>\n",
       "      <td>-4.415961</td>\n",
       "      <td>-5.871246</td>\n",
       "      <td>111.282578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "0   -14.044580         0.042932        -0.391599          -8.160532   \n",
       "1   -13.922686        -0.751628        -3.020547          -5.847861   \n",
       "2   -13.879909         0.572469        -1.804182          -5.073488   \n",
       "3   -13.858078         0.926347        -1.462164          -4.745018   \n",
       "4   -13.862978         0.811635        -1.569119          -4.829928   \n",
       "5   -13.927787        -1.090693        -3.325070          -6.015124   \n",
       "6   -13.948682        -1.412595        -3.782443          -5.900223   \n",
       "7   -13.957657        -1.630406        -4.023920          -5.976585   \n",
       "8   -13.892078         0.019107        -2.427933          -4.996915   \n",
       "9   -13.999179        -3.105399        -5.359859          -6.832769   \n",
       "10  -13.957663        -1.651193        -4.033565          -5.999639   \n",
       "11  -13.911394        -0.337497        -2.731099          -5.361880   \n",
       "12  -13.975742        -2.416509        -4.765733          -6.399688   \n",
       "13  -13.864279         0.426480        -2.006577          -4.719903   \n",
       "14  -13.877506         0.254918        -2.184926          -4.847987   \n",
       "15  -13.940034        -1.144633        -3.558591          -5.718190   \n",
       "16  -13.939836        -1.101327        -3.523223          -5.687986   \n",
       "17  -13.887912         0.374057        -1.962008          -5.168463   \n",
       "18  -13.970956        -1.845229        -4.328621          -5.931868   \n",
       "19  -14.035223        -3.605145        -6.109564          -6.816096   \n",
       "20  -13.968641        -1.943690        -4.432746          -5.938340   \n",
       "21  -14.005427        -3.224574        -5.699047          -6.567777   \n",
       "22  -13.956037        -1.648751        -4.168511          -5.725085   \n",
       "23  -13.949145        -1.512073        -4.033280          -5.640465   \n",
       "24  -13.905341        -0.367469        -2.819573          -5.144751   \n",
       "25  -13.931246        -0.778058        -3.214587          -5.450503   \n",
       "26  -13.850389         0.476476        -1.948302          -4.633296   \n",
       "27  -13.927417        -0.662448        -3.109132          -5.379183   \n",
       "28  -13.908126        -0.539128        -3.026167          -5.159271   \n",
       "29  -13.974477        -1.991485        -4.505232          -5.919620   \n",
       "30  -13.969846        -1.904105        -4.415961          -5.871246   \n",
       "\n",
       "    PM2.5 (µg/m³)  \n",
       "0       81.732109  \n",
       "1      107.857010  \n",
       "2      116.795715  \n",
       "3      120.813309  \n",
       "4      119.794922  \n",
       "5      106.021652  \n",
       "6      109.031311  \n",
       "7      108.559586  \n",
       "8      119.371140  \n",
       "9       98.666779  \n",
       "10     108.207184  \n",
       "11     114.584854  \n",
       "12     104.064941  \n",
       "13     122.476562  \n",
       "14     121.000702  \n",
       "15     111.364563  \n",
       "16     111.734718  \n",
       "17     115.453445  \n",
       "18     110.125977  \n",
       "19     101.479202  \n",
       "20     110.340378  \n",
       "21     104.160461  \n",
       "22     112.940605  \n",
       "23     113.876266  \n",
       "24     118.075119  \n",
       "25     114.387421  \n",
       "26     123.672668  \n",
       "27     115.221130  \n",
       "28     118.488724  \n",
       "29     110.776268  \n",
       "30     111.282578  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.72</td>\n",
       "      <td>12.11</td>\n",
       "      <td>14.22</td>\n",
       "      <td>3.39</td>\n",
       "      <td>102.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.59</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.29</td>\n",
       "      <td>3.70</td>\n",
       "      <td>97.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>25.69</td>\n",
       "      <td>26.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>93.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.29</td>\n",
       "      <td>33.04</td>\n",
       "      <td>37.91</td>\n",
       "      <td>6.67</td>\n",
       "      <td>105.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.69</td>\n",
       "      <td>46.25</td>\n",
       "      <td>52.63</td>\n",
       "      <td>8.25</td>\n",
       "      <td>119.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.22</td>\n",
       "      <td>35.99</td>\n",
       "      <td>41.19</td>\n",
       "      <td>6.63</td>\n",
       "      <td>112.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.89</td>\n",
       "      <td>15.05</td>\n",
       "      <td>18.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.78</td>\n",
       "      <td>19.89</td>\n",
       "      <td>18.80</td>\n",
       "      <td>3.11</td>\n",
       "      <td>127.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.89</td>\n",
       "      <td>17.63</td>\n",
       "      <td>22.93</td>\n",
       "      <td>4.56</td>\n",
       "      <td>109.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.29</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93</td>\n",
       "      <td>8.45</td>\n",
       "      <td>9.61</td>\n",
       "      <td>2.13</td>\n",
       "      <td>110.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.63</td>\n",
       "      <td>20.17</td>\n",
       "      <td>16.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>103.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.87</td>\n",
       "      <td>29.41</td>\n",
       "      <td>25.56</td>\n",
       "      <td>5.12</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.83</td>\n",
       "      <td>23.18</td>\n",
       "      <td>16.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>158.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.88</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.42</td>\n",
       "      <td>2.49</td>\n",
       "      <td>139.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.87</td>\n",
       "      <td>18.28</td>\n",
       "      <td>18.18</td>\n",
       "      <td>2.90</td>\n",
       "      <td>116.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.79</td>\n",
       "      <td>20.19</td>\n",
       "      <td>17.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>99.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.67</td>\n",
       "      <td>23.28</td>\n",
       "      <td>18.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>103.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.67</td>\n",
       "      <td>22.01</td>\n",
       "      <td>16.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.01</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>124.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.17</td>\n",
       "      <td>7.95</td>\n",
       "      <td>9.64</td>\n",
       "      <td>3.04</td>\n",
       "      <td>147.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.80</td>\n",
       "      <td>17.72</td>\n",
       "      <td>25.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>137.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.00</td>\n",
       "      <td>48.52</td>\n",
       "      <td>35.87</td>\n",
       "      <td>7.43</td>\n",
       "      <td>132.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.90</td>\n",
       "      <td>112.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.16</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.77</td>\n",
       "      <td>4.85</td>\n",
       "      <td>109.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.00</td>\n",
       "      <td>14.63</td>\n",
       "      <td>16.32</td>\n",
       "      <td>2.84</td>\n",
       "      <td>129.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.11</td>\n",
       "      <td>23.37</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.01</td>\n",
       "      <td>98.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.20</td>\n",
       "      <td>17.96</td>\n",
       "      <td>21.13</td>\n",
       "      <td>4.96</td>\n",
       "      <td>115.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.76</td>\n",
       "      <td>7.69</td>\n",
       "      <td>12.57</td>\n",
       "      <td>4.12</td>\n",
       "      <td>98.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.43</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>69.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.40</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.31</td>\n",
       "      <td>58.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "0         0.72            12.11            14.22               3.39   \n",
       "1         0.59            20.14            18.29               3.70   \n",
       "2         0.90            25.69            26.01               4.84   \n",
       "3         1.29            33.04            37.91               6.67   \n",
       "4         1.69            46.25            52.63               8.25   \n",
       "5         1.22            35.99            41.19               6.63   \n",
       "6         0.89            15.05            18.83               3.50   \n",
       "7         0.78            19.89            18.80               3.11   \n",
       "8         0.89            17.63            22.93               4.56   \n",
       "9         1.29             9.63             9.78               3.15   \n",
       "10        0.93             8.45             9.61               2.13   \n",
       "11        0.63            20.17            16.97               3.30   \n",
       "12        0.87            29.41            25.56               5.12   \n",
       "13        0.83            23.18            16.01               4.27   \n",
       "14        0.88            17.00            12.42               2.49   \n",
       "15        0.87            18.28            18.18               2.90   \n",
       "16        0.79            20.19            17.60               3.45   \n",
       "17        0.67            23.28            18.44               3.34   \n",
       "18        0.67            22.01            16.51               3.90   \n",
       "19        1.01             4.31             5.05               1.91   \n",
       "20        1.17             7.95             9.64               3.04   \n",
       "21        0.80            17.72            25.21               4.37   \n",
       "22        1.00            48.52            35.87               7.43   \n",
       "23        0.60            14.06            11.83               2.90   \n",
       "24        1.16            23.24            22.77               4.85   \n",
       "25        1.00            14.63            16.32               2.84   \n",
       "26        1.11            23.37            19.88               4.01   \n",
       "27        1.20            17.96            21.13               4.96   \n",
       "28        0.76             7.69            12.57               4.12   \n",
       "29        0.43             4.27             4.29               1.23   \n",
       "30        0.40             4.01             7.87               1.31   \n",
       "\n",
       "    PM2.5 (µg/m³)  \n",
       "0          102.58  \n",
       "1           97.01  \n",
       "2           93.04  \n",
       "3          105.41  \n",
       "4          119.15  \n",
       "5          112.77  \n",
       "6          125.58  \n",
       "7          127.41  \n",
       "8          109.73  \n",
       "9          111.51  \n",
       "10         110.29  \n",
       "11         103.24  \n",
       "12         123.00  \n",
       "13         158.87  \n",
       "14         139.88  \n",
       "15         116.59  \n",
       "16          99.03  \n",
       "17         103.19  \n",
       "18          91.11  \n",
       "19         124.94  \n",
       "20         147.98  \n",
       "21         137.20  \n",
       "22         132.69  \n",
       "23         112.50  \n",
       "24         109.74  \n",
       "25         129.29  \n",
       "26          98.85  \n",
       "27         115.18  \n",
       "28          98.28  \n",
       "29          69.20  \n",
       "30          58.32  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.777107"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.index = val.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>-14.044580</td>\n",
       "      <td>0.042932</td>\n",
       "      <td>-0.391599</td>\n",
       "      <td>-8.160532</td>\n",
       "      <td>81.732109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>-13.922686</td>\n",
       "      <td>-0.751628</td>\n",
       "      <td>-3.020547</td>\n",
       "      <td>-5.847861</td>\n",
       "      <td>107.857010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>-13.879909</td>\n",
       "      <td>0.572469</td>\n",
       "      <td>-1.804182</td>\n",
       "      <td>-5.073488</td>\n",
       "      <td>116.795715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>-13.858078</td>\n",
       "      <td>0.926347</td>\n",
       "      <td>-1.462164</td>\n",
       "      <td>-4.745018</td>\n",
       "      <td>120.813309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>-13.862978</td>\n",
       "      <td>0.811635</td>\n",
       "      <td>-1.569119</td>\n",
       "      <td>-4.829928</td>\n",
       "      <td>119.794922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>-13.927787</td>\n",
       "      <td>-1.090693</td>\n",
       "      <td>-3.325070</td>\n",
       "      <td>-6.015124</td>\n",
       "      <td>106.021652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>-13.948682</td>\n",
       "      <td>-1.412595</td>\n",
       "      <td>-3.782443</td>\n",
       "      <td>-5.900223</td>\n",
       "      <td>109.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>-13.957657</td>\n",
       "      <td>-1.630406</td>\n",
       "      <td>-4.023920</td>\n",
       "      <td>-5.976585</td>\n",
       "      <td>108.559586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>-13.892078</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>-2.427933</td>\n",
       "      <td>-4.996915</td>\n",
       "      <td>119.371140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>-13.999179</td>\n",
       "      <td>-3.105399</td>\n",
       "      <td>-5.359859</td>\n",
       "      <td>-6.832769</td>\n",
       "      <td>98.666779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>-13.957663</td>\n",
       "      <td>-1.651193</td>\n",
       "      <td>-4.033565</td>\n",
       "      <td>-5.999639</td>\n",
       "      <td>108.207184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>-13.911394</td>\n",
       "      <td>-0.337497</td>\n",
       "      <td>-2.731099</td>\n",
       "      <td>-5.361880</td>\n",
       "      <td>114.584854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>-13.975742</td>\n",
       "      <td>-2.416509</td>\n",
       "      <td>-4.765733</td>\n",
       "      <td>-6.399688</td>\n",
       "      <td>104.064941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>-13.864279</td>\n",
       "      <td>0.426480</td>\n",
       "      <td>-2.006577</td>\n",
       "      <td>-4.719903</td>\n",
       "      <td>122.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>-13.877506</td>\n",
       "      <td>0.254918</td>\n",
       "      <td>-2.184926</td>\n",
       "      <td>-4.847987</td>\n",
       "      <td>121.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>-13.940034</td>\n",
       "      <td>-1.144633</td>\n",
       "      <td>-3.558591</td>\n",
       "      <td>-5.718190</td>\n",
       "      <td>111.364563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>-13.939836</td>\n",
       "      <td>-1.101327</td>\n",
       "      <td>-3.523223</td>\n",
       "      <td>-5.687986</td>\n",
       "      <td>111.734718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>-13.887912</td>\n",
       "      <td>0.374057</td>\n",
       "      <td>-1.962008</td>\n",
       "      <td>-5.168463</td>\n",
       "      <td>115.453445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>-13.970956</td>\n",
       "      <td>-1.845229</td>\n",
       "      <td>-4.328621</td>\n",
       "      <td>-5.931868</td>\n",
       "      <td>110.125977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>-14.035223</td>\n",
       "      <td>-3.605145</td>\n",
       "      <td>-6.109564</td>\n",
       "      <td>-6.816096</td>\n",
       "      <td>101.479202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>-13.968641</td>\n",
       "      <td>-1.943690</td>\n",
       "      <td>-4.432746</td>\n",
       "      <td>-5.938340</td>\n",
       "      <td>110.340378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>-14.005427</td>\n",
       "      <td>-3.224574</td>\n",
       "      <td>-5.699047</td>\n",
       "      <td>-6.567777</td>\n",
       "      <td>104.160461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>-13.956037</td>\n",
       "      <td>-1.648751</td>\n",
       "      <td>-4.168511</td>\n",
       "      <td>-5.725085</td>\n",
       "      <td>112.940605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>-13.949145</td>\n",
       "      <td>-1.512073</td>\n",
       "      <td>-4.033280</td>\n",
       "      <td>-5.640465</td>\n",
       "      <td>113.876266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>-13.905341</td>\n",
       "      <td>-0.367469</td>\n",
       "      <td>-2.819573</td>\n",
       "      <td>-5.144751</td>\n",
       "      <td>118.075119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>-13.931246</td>\n",
       "      <td>-0.778058</td>\n",
       "      <td>-3.214587</td>\n",
       "      <td>-5.450503</td>\n",
       "      <td>114.387421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>-13.850389</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>-1.948302</td>\n",
       "      <td>-4.633296</td>\n",
       "      <td>123.672668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>-13.927417</td>\n",
       "      <td>-0.662448</td>\n",
       "      <td>-3.109132</td>\n",
       "      <td>-5.379183</td>\n",
       "      <td>115.221130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>-13.908126</td>\n",
       "      <td>-0.539128</td>\n",
       "      <td>-3.026167</td>\n",
       "      <td>-5.159271</td>\n",
       "      <td>118.488724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>-13.974477</td>\n",
       "      <td>-1.991485</td>\n",
       "      <td>-4.505232</td>\n",
       "      <td>-5.919620</td>\n",
       "      <td>110.776268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>-13.969846</td>\n",
       "      <td>-1.904105</td>\n",
       "      <td>-4.415961</td>\n",
       "      <td>-5.871246</td>\n",
       "      <td>111.282578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2024-01-01  -14.044580         0.042932        -0.391599          -8.160532   \n",
       "2024-01-02  -13.922686        -0.751628        -3.020547          -5.847861   \n",
       "2024-01-03  -13.879909         0.572469        -1.804182          -5.073488   \n",
       "2024-01-04  -13.858078         0.926347        -1.462164          -4.745018   \n",
       "2024-01-05  -13.862978         0.811635        -1.569119          -4.829928   \n",
       "2024-01-06  -13.927787        -1.090693        -3.325070          -6.015124   \n",
       "2024-01-07  -13.948682        -1.412595        -3.782443          -5.900223   \n",
       "2024-01-08  -13.957657        -1.630406        -4.023920          -5.976585   \n",
       "2024-01-09  -13.892078         0.019107        -2.427933          -4.996915   \n",
       "2024-01-10  -13.999179        -3.105399        -5.359859          -6.832769   \n",
       "2024-01-11  -13.957663        -1.651193        -4.033565          -5.999639   \n",
       "2024-01-12  -13.911394        -0.337497        -2.731099          -5.361880   \n",
       "2024-01-13  -13.975742        -2.416509        -4.765733          -6.399688   \n",
       "2024-01-14  -13.864279         0.426480        -2.006577          -4.719903   \n",
       "2024-01-15  -13.877506         0.254918        -2.184926          -4.847987   \n",
       "2024-01-16  -13.940034        -1.144633        -3.558591          -5.718190   \n",
       "2024-01-17  -13.939836        -1.101327        -3.523223          -5.687986   \n",
       "2024-01-18  -13.887912         0.374057        -1.962008          -5.168463   \n",
       "2024-01-19  -13.970956        -1.845229        -4.328621          -5.931868   \n",
       "2024-01-20  -14.035223        -3.605145        -6.109564          -6.816096   \n",
       "2024-01-21  -13.968641        -1.943690        -4.432746          -5.938340   \n",
       "2024-01-22  -14.005427        -3.224574        -5.699047          -6.567777   \n",
       "2024-01-23  -13.956037        -1.648751        -4.168511          -5.725085   \n",
       "2024-01-24  -13.949145        -1.512073        -4.033280          -5.640465   \n",
       "2024-01-25  -13.905341        -0.367469        -2.819573          -5.144751   \n",
       "2024-01-26  -13.931246        -0.778058        -3.214587          -5.450503   \n",
       "2024-01-27  -13.850389         0.476476        -1.948302          -4.633296   \n",
       "2024-01-28  -13.927417        -0.662448        -3.109132          -5.379183   \n",
       "2024-01-29  -13.908126        -0.539128        -3.026167          -5.159271   \n",
       "2024-01-30  -13.974477        -1.991485        -4.505232          -5.919620   \n",
       "2024-01-31  -13.969846        -1.904105        -4.415961          -5.871246   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2024-01-01      81.732109  \n",
       "2024-01-02     107.857010  \n",
       "2024-01-03     116.795715  \n",
       "2024-01-04     120.813309  \n",
       "2024-01-05     119.794922  \n",
       "2024-01-06     106.021652  \n",
       "2024-01-07     109.031311  \n",
       "2024-01-08     108.559586  \n",
       "2024-01-09     119.371140  \n",
       "2024-01-10      98.666779  \n",
       "2024-01-11     108.207184  \n",
       "2024-01-12     114.584854  \n",
       "2024-01-13     104.064941  \n",
       "2024-01-14     122.476562  \n",
       "2024-01-15     121.000702  \n",
       "2024-01-16     111.364563  \n",
       "2024-01-17     111.734718  \n",
       "2024-01-18     115.453445  \n",
       "2024-01-19     110.125977  \n",
       "2024-01-20     101.479202  \n",
       "2024-01-21     110.340378  \n",
       "2024-01-22     104.160461  \n",
       "2024-01-23     112.940605  \n",
       "2024-01-24     113.876266  \n",
       "2024-01-25     118.075119  \n",
       "2024-01-26     114.387421  \n",
       "2024-01-27     123.672668  \n",
       "2024-01-28     115.221130  \n",
       "2024-01-29     118.488724  \n",
       "2024-01-30     110.776268  \n",
       "2024-01-31     111.282578  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2021-01-01    122.910000\n",
       "2021-01-02    202.910000\n",
       "2021-01-03    201.110000\n",
       "2021-01-04    140.190000\n",
       "2021-01-05    100.690000\n",
       "                 ...    \n",
       "2024-01-27    138.672668\n",
       "2024-01-28    130.221130\n",
       "2024-01-29    133.488724\n",
       "2024-01-30    125.776268\n",
       "2024-01-31    126.282578\n",
       "Name: PM2.5 (µg/m³), Length: 1126, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>1.260000</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>122.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>1.700000</td>\n",
       "      <td>25.950000</td>\n",
       "      <td>19.630000</td>\n",
       "      <td>22.480000</td>\n",
       "      <td>202.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>2.160000</td>\n",
       "      <td>28.370000</td>\n",
       "      <td>31.630000</td>\n",
       "      <td>36.370000</td>\n",
       "      <td>201.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>1.730000</td>\n",
       "      <td>31.910000</td>\n",
       "      <td>26.230000</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>140.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>1.310000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>29.060000</td>\n",
       "      <td>100.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.885035</td>\n",
       "      <td>20.609687</td>\n",
       "      <td>34.589965</td>\n",
       "      <td>8.392951</td>\n",
       "      <td>102.056818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>1.105486</td>\n",
       "      <td>33.510139</td>\n",
       "      <td>43.237812</td>\n",
       "      <td>9.463750</td>\n",
       "      <td>100.370486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.921493</td>\n",
       "      <td>28.611215</td>\n",
       "      <td>38.746319</td>\n",
       "      <td>8.066528</td>\n",
       "      <td>94.957639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.611042</td>\n",
       "      <td>21.844757</td>\n",
       "      <td>25.318819</td>\n",
       "      <td>6.948403</td>\n",
       "      <td>94.909722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0.552535</td>\n",
       "      <td>11.527847</td>\n",
       "      <td>14.190799</td>\n",
       "      <td>3.571285</td>\n",
       "      <td>95.374306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2021-01-01    1.260000        20.270000        18.400000          20.600000   \n",
       "2021-01-02    1.700000        25.950000        19.630000          22.480000   \n",
       "2021-01-03    2.160000        28.370000        31.630000          36.370000   \n",
       "2021-01-04    1.730000        31.910000        26.230000          30.920000   \n",
       "2021-01-05    1.310000        27.000000        25.750000          29.060000   \n",
       "...                ...              ...              ...                ...   \n",
       "2023-12-27    0.885035        20.609687        34.589965           8.392951   \n",
       "2023-12-28    1.105486        33.510139        43.237812           9.463750   \n",
       "2023-12-29    0.921493        28.611215        38.746319           8.066528   \n",
       "2023-12-30    0.611042        21.844757        25.318819           6.948403   \n",
       "2023-12-31    0.552535        11.527847        14.190799           3.571285   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2021-01-01     122.910000  \n",
       "2021-01-02     202.910000  \n",
       "2021-01-03     201.110000  \n",
       "2021-01-04     140.190000  \n",
       "2021-01-05     100.690000  \n",
       "...                   ...  \n",
       "2023-12-27     102.056818  \n",
       "2023-12-28     100.370486  \n",
       "2023-12-29      94.957639  \n",
       "2023-12-30      94.909722  \n",
       "2023-12-31      95.374306  \n",
       "\n",
       "[1095 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO (mg/m³)</th>\n",
       "      <th>Benzene (µg/m³)</th>\n",
       "      <th>Toluene (µg/m³)</th>\n",
       "      <th>MP-Xylene (µg/m³)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.72</td>\n",
       "      <td>12.11</td>\n",
       "      <td>14.22</td>\n",
       "      <td>3.39</td>\n",
       "      <td>102.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.59</td>\n",
       "      <td>20.14</td>\n",
       "      <td>18.29</td>\n",
       "      <td>3.70</td>\n",
       "      <td>97.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.90</td>\n",
       "      <td>25.69</td>\n",
       "      <td>26.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>93.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>1.29</td>\n",
       "      <td>33.04</td>\n",
       "      <td>37.91</td>\n",
       "      <td>6.67</td>\n",
       "      <td>105.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>1.69</td>\n",
       "      <td>46.25</td>\n",
       "      <td>52.63</td>\n",
       "      <td>8.25</td>\n",
       "      <td>119.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>1.22</td>\n",
       "      <td>35.99</td>\n",
       "      <td>41.19</td>\n",
       "      <td>6.63</td>\n",
       "      <td>112.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.89</td>\n",
       "      <td>15.05</td>\n",
       "      <td>18.83</td>\n",
       "      <td>3.50</td>\n",
       "      <td>125.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.78</td>\n",
       "      <td>19.89</td>\n",
       "      <td>18.80</td>\n",
       "      <td>3.11</td>\n",
       "      <td>127.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.89</td>\n",
       "      <td>17.63</td>\n",
       "      <td>22.93</td>\n",
       "      <td>4.56</td>\n",
       "      <td>109.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>1.29</td>\n",
       "      <td>9.63</td>\n",
       "      <td>9.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.93</td>\n",
       "      <td>8.45</td>\n",
       "      <td>9.61</td>\n",
       "      <td>2.13</td>\n",
       "      <td>110.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.63</td>\n",
       "      <td>20.17</td>\n",
       "      <td>16.97</td>\n",
       "      <td>3.30</td>\n",
       "      <td>103.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.87</td>\n",
       "      <td>29.41</td>\n",
       "      <td>25.56</td>\n",
       "      <td>5.12</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.83</td>\n",
       "      <td>23.18</td>\n",
       "      <td>16.01</td>\n",
       "      <td>4.27</td>\n",
       "      <td>158.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.88</td>\n",
       "      <td>17.00</td>\n",
       "      <td>12.42</td>\n",
       "      <td>2.49</td>\n",
       "      <td>139.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.87</td>\n",
       "      <td>18.28</td>\n",
       "      <td>18.18</td>\n",
       "      <td>2.90</td>\n",
       "      <td>116.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.79</td>\n",
       "      <td>20.19</td>\n",
       "      <td>17.60</td>\n",
       "      <td>3.45</td>\n",
       "      <td>99.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.67</td>\n",
       "      <td>23.28</td>\n",
       "      <td>18.44</td>\n",
       "      <td>3.34</td>\n",
       "      <td>103.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.67</td>\n",
       "      <td>22.01</td>\n",
       "      <td>16.51</td>\n",
       "      <td>3.90</td>\n",
       "      <td>91.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>1.01</td>\n",
       "      <td>4.31</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.91</td>\n",
       "      <td>124.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>1.17</td>\n",
       "      <td>7.95</td>\n",
       "      <td>9.64</td>\n",
       "      <td>3.04</td>\n",
       "      <td>147.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.80</td>\n",
       "      <td>17.72</td>\n",
       "      <td>25.21</td>\n",
       "      <td>4.37</td>\n",
       "      <td>137.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>1.00</td>\n",
       "      <td>48.52</td>\n",
       "      <td>35.87</td>\n",
       "      <td>7.43</td>\n",
       "      <td>132.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.90</td>\n",
       "      <td>112.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>1.16</td>\n",
       "      <td>23.24</td>\n",
       "      <td>22.77</td>\n",
       "      <td>4.85</td>\n",
       "      <td>109.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>1.00</td>\n",
       "      <td>14.63</td>\n",
       "      <td>16.32</td>\n",
       "      <td>2.84</td>\n",
       "      <td>129.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>1.11</td>\n",
       "      <td>23.37</td>\n",
       "      <td>19.88</td>\n",
       "      <td>4.01</td>\n",
       "      <td>98.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>1.20</td>\n",
       "      <td>17.96</td>\n",
       "      <td>21.13</td>\n",
       "      <td>4.96</td>\n",
       "      <td>115.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.76</td>\n",
       "      <td>7.69</td>\n",
       "      <td>12.57</td>\n",
       "      <td>4.12</td>\n",
       "      <td>98.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.43</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>69.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.40</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7.87</td>\n",
       "      <td>1.31</td>\n",
       "      <td>58.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            CO (mg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  MP-Xylene (µg/m³)  \\\n",
       "Timestamp                                                                     \n",
       "2024-01-01        0.72            12.11            14.22               3.39   \n",
       "2024-01-02        0.59            20.14            18.29               3.70   \n",
       "2024-01-03        0.90            25.69            26.01               4.84   \n",
       "2024-01-04        1.29            33.04            37.91               6.67   \n",
       "2024-01-05        1.69            46.25            52.63               8.25   \n",
       "2024-01-06        1.22            35.99            41.19               6.63   \n",
       "2024-01-07        0.89            15.05            18.83               3.50   \n",
       "2024-01-08        0.78            19.89            18.80               3.11   \n",
       "2024-01-09        0.89            17.63            22.93               4.56   \n",
       "2024-01-10        1.29             9.63             9.78               3.15   \n",
       "2024-01-11        0.93             8.45             9.61               2.13   \n",
       "2024-01-12        0.63            20.17            16.97               3.30   \n",
       "2024-01-13        0.87            29.41            25.56               5.12   \n",
       "2024-01-14        0.83            23.18            16.01               4.27   \n",
       "2024-01-15        0.88            17.00            12.42               2.49   \n",
       "2024-01-16        0.87            18.28            18.18               2.90   \n",
       "2024-01-17        0.79            20.19            17.60               3.45   \n",
       "2024-01-18        0.67            23.28            18.44               3.34   \n",
       "2024-01-19        0.67            22.01            16.51               3.90   \n",
       "2024-01-20        1.01             4.31             5.05               1.91   \n",
       "2024-01-21        1.17             7.95             9.64               3.04   \n",
       "2024-01-22        0.80            17.72            25.21               4.37   \n",
       "2024-01-23        1.00            48.52            35.87               7.43   \n",
       "2024-01-24        0.60            14.06            11.83               2.90   \n",
       "2024-01-25        1.16            23.24            22.77               4.85   \n",
       "2024-01-26        1.00            14.63            16.32               2.84   \n",
       "2024-01-27        1.11            23.37            19.88               4.01   \n",
       "2024-01-28        1.20            17.96            21.13               4.96   \n",
       "2024-01-29        0.76             7.69            12.57               4.12   \n",
       "2024-01-30        0.43             4.27             4.29               1.23   \n",
       "2024-01-31        0.40             4.01             7.87               1.31   \n",
       "\n",
       "            PM2.5 (µg/m³)  \n",
       "Timestamp                  \n",
       "2024-01-01         102.58  \n",
       "2024-01-02          97.01  \n",
       "2024-01-03          93.04  \n",
       "2024-01-04         105.41  \n",
       "2024-01-05         119.15  \n",
       "2024-01-06         112.77  \n",
       "2024-01-07         125.58  \n",
       "2024-01-08         127.41  \n",
       "2024-01-09         109.73  \n",
       "2024-01-10         111.51  \n",
       "2024-01-11         110.29  \n",
       "2024-01-12         103.24  \n",
       "2024-01-13         123.00  \n",
       "2024-01-14         158.87  \n",
       "2024-01-15         139.88  \n",
       "2024-01-16         116.59  \n",
       "2024-01-17          99.03  \n",
       "2024-01-18         103.19  \n",
       "2024-01-19          91.11  \n",
       "2024-01-20         124.94  \n",
       "2024-01-21         147.98  \n",
       "2024-01-22         137.20  \n",
       "2024-01-23         132.69  \n",
       "2024-01-24         112.50  \n",
       "2024-01-25         109.74  \n",
       "2024-01-26         129.29  \n",
       "2024-01-27          98.85  \n",
       "2024-01-28         115.18  \n",
       "2024-01-29          98.28  \n",
       "2024-01-30          69.20  \n",
       "2024-01-31          58.32  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_5['PM2.5 (µg/m³)']])\n",
    "org_5.index = val.index\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], org_5['PM2.5 (µg/m³)']])\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train_last_samples')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction')\n",
    "plt.plot(df_org.index[1095:],df_org[1095:],color='green',label='actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmwCnsUj2B8A",
    "outputId": "475af39f-a4f9-40cd-bcfe-ce080d8539f1"
   },
   "source": [
    "model6 = Sequential()\n",
    "model6.add(InputLayer((1, 5)))\n",
    "model6.add(LSTM(32, return_sequences=True))\n",
    "model6.add(LSTM(64))\n",
    "model6.add(Dense(8, 'relu'))\n",
    "model6.add(Dense(5, 'linear'))\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWepnsFE2Tnl"
   },
   "source": [
    "cp6 = ModelCheckpoint('checkpoints.model6.keras', save_best_only=True)\n",
    "model6.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "7XnlR3om2aiA",
    "outputId": "404ce81e-7255-4c09-9e43-12057dc4d980"
   },
   "source": [
    "model6.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=200, callbacks=[cp6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fy6pKacl2bOW",
    "outputId": "fb3aad92-2323-421e-bc68-956bc39107f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m45\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">949</span> (3.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m949\u001b[0m (3.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">949</span> (3.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m949\u001b[0m (3.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(InputLayer((1, 5)))\n",
    "model7.add(Conv1D(64, kernel_size=1, activation='relu'))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(8, 'relu'))\n",
    "model7.add(Dense(5, 'linear'))\n",
    "model7.summary()\n",
    "\n",
    "cp7 = ModelCheckpoint('checkpoints.model7.keras', monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model7.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMRDXuFY27JA",
    "outputId": "54fa8a3f-ae81-4567-a40a-7652a7ec274f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 682ms/step - loss: 702.3685 - mean_absolute_error: 13.1346\n",
      "Epoch 1: val_loss improved from inf to 2052.70898, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1002.6993 - mean_absolute_error: 15.8387 - val_loss: 2052.7090 - val_mean_absolute_error: 26.0970\n",
      "Epoch 2/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1089.2332 - mean_absolute_error: 15.4084\n",
      "Epoch 2: val_loss improved from 2052.70898 to 1978.74744, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 961.3106 - mean_absolute_error: 15.1275 - val_loss: 1978.7474 - val_mean_absolute_error: 25.4304\n",
      "Epoch 3/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 833.5038 - mean_absolute_error: 14.1366\n",
      "Epoch 3: val_loss improved from 1978.74744 to 1916.24048, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 894.1050 - mean_absolute_error: 14.6377 - val_loss: 1916.2405 - val_mean_absolute_error: 25.0595\n",
      "Epoch 4/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 769.9520 - mean_absolute_error: 14.1166\n",
      "Epoch 4: val_loss improved from 1916.24048 to 1861.59985, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 876.9630 - mean_absolute_error: 14.4830 - val_loss: 1861.5999 - val_mean_absolute_error: 24.8175\n",
      "Epoch 5/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 845.0087 - mean_absolute_error: 14.3986\n",
      "Epoch 5: val_loss improved from 1861.59985 to 1813.04773, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 882.0446 - mean_absolute_error: 14.4291 - val_loss: 1813.0477 - val_mean_absolute_error: 24.7478\n",
      "Epoch 6/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 978.8109 - mean_absolute_error: 14.5888\n",
      "Epoch 6: val_loss improved from 1813.04773 to 1769.74292, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 813.6797 - mean_absolute_error: 13.7890 - val_loss: 1769.7429 - val_mean_absolute_error: 24.8285\n",
      "Epoch 7/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1144.9204 - mean_absolute_error: 17.2728\n",
      "Epoch 7: val_loss improved from 1769.74292 to 1727.46301, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839.0073 - mean_absolute_error: 14.4435 - val_loss: 1727.4630 - val_mean_absolute_error: 24.8964\n",
      "Epoch 8/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 962.6727 - mean_absolute_error: 16.7205\n",
      "Epoch 8: val_loss improved from 1727.46301 to 1686.98230, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.3437 - mean_absolute_error: 14.3110 - val_loss: 1686.9823 - val_mean_absolute_error: 24.9530\n",
      "Epoch 9/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1020.2963 - mean_absolute_error: 16.7727\n",
      "Epoch 9: val_loss improved from 1686.98230 to 1647.18176, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 834.4631 - mean_absolute_error: 14.5834 - val_loss: 1647.1818 - val_mean_absolute_error: 24.9128\n",
      "Epoch 10/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 892.0220 - mean_absolute_error: 15.2878\n",
      "Epoch 10: val_loss improved from 1647.18176 to 1610.07898, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 759.4326 - mean_absolute_error: 14.1416 - val_loss: 1610.0790 - val_mean_absolute_error: 24.8209\n",
      "Epoch 11/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 563.5646 - mean_absolute_error: 12.8727\n",
      "Epoch 11: val_loss improved from 1610.07898 to 1571.82336, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 686.4833 - mean_absolute_error: 13.5989 - val_loss: 1571.8234 - val_mean_absolute_error: 24.7396\n",
      "Epoch 12/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 429.2674 - mean_absolute_error: 10.3564\n",
      "Epoch 12: val_loss improved from 1571.82336 to 1530.41382, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 679.9763 - mean_absolute_error: 13.4217 - val_loss: 1530.4138 - val_mean_absolute_error: 24.5845\n",
      "Epoch 13/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 786.5123 - mean_absolute_error: 13.6107\n",
      "Epoch 13: val_loss improved from 1530.41382 to 1486.44849, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 705.5320 - mean_absolute_error: 13.7651 - val_loss: 1486.4485 - val_mean_absolute_error: 24.3171\n",
      "Epoch 14/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 754.5365 - mean_absolute_error: 14.7758\n",
      "Epoch 14: val_loss improved from 1486.44849 to 1439.87842, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 643.2505 - mean_absolute_error: 13.2161 - val_loss: 1439.8784 - val_mean_absolute_error: 23.9680\n",
      "Epoch 15/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 599.4665 - mean_absolute_error: 12.8569\n",
      "Epoch 15: val_loss improved from 1439.87842 to 1388.53760, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 644.5630 - mean_absolute_error: 13.1340 - val_loss: 1388.5376 - val_mean_absolute_error: 23.5837\n",
      "Epoch 16/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 818.2612 - mean_absolute_error: 15.2098\n",
      "Epoch 16: val_loss improved from 1388.53760 to 1334.94385, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 628.9088 - mean_absolute_error: 12.9611 - val_loss: 1334.9438 - val_mean_absolute_error: 23.0889\n",
      "Epoch 17/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 367.7126 - mean_absolute_error: 9.8626\n",
      "Epoch 17: val_loss improved from 1334.94385 to 1277.86047, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 559.4341 - mean_absolute_error: 12.3000 - val_loss: 1277.8605 - val_mean_absolute_error: 22.5145\n",
      "Epoch 18/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 548.6458 - mean_absolute_error: 11.6840\n",
      "Epoch 18: val_loss improved from 1277.86047 to 1207.00305, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.5695 - mean_absolute_error: 12.0105 - val_loss: 1207.0031 - val_mean_absolute_error: 21.8548\n",
      "Epoch 19/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 346.9175 - mean_absolute_error: 10.0536\n",
      "Epoch 19: val_loss improved from 1207.00305 to 1042.64172, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493.0865 - mean_absolute_error: 11.7740 - val_loss: 1042.6417 - val_mean_absolute_error: 20.5166\n",
      "Epoch 20/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 541.1286 - mean_absolute_error: 13.5449\n",
      "Epoch 20: val_loss improved from 1042.64172 to 802.62445, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450.0340 - mean_absolute_error: 11.4001 - val_loss: 802.6245 - val_mean_absolute_error: 18.3079\n",
      "Epoch 21/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 229.3596 - mean_absolute_error: 8.2206\n",
      "Epoch 21: val_loss improved from 802.62445 to 637.93817, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.8110 - mean_absolute_error: 9.6080 - val_loss: 637.9382 - val_mean_absolute_error: 16.3945\n",
      "Epoch 22/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 174.3117 - mean_absolute_error: 7.3303\n",
      "Epoch 22: val_loss improved from 637.93817 to 511.21082, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.1543 - mean_absolute_error: 8.9689 - val_loss: 511.2108 - val_mean_absolute_error: 14.6385\n",
      "Epoch 23/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 210.9782 - mean_absolute_error: 8.6579\n",
      "Epoch 23: val_loss improved from 511.21082 to 417.05591, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.0980 - mean_absolute_error: 8.0767 - val_loss: 417.0559 - val_mean_absolute_error: 13.0810\n",
      "Epoch 24/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 242.1460 - mean_absolute_error: 8.6679\n",
      "Epoch 24: val_loss improved from 417.05591 to 342.23712, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 184.4328 - mean_absolute_error: 7.3225 - val_loss: 342.2371 - val_mean_absolute_error: 11.7361\n",
      "Epoch 25/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 166.7362 - mean_absolute_error: 6.9721\n",
      "Epoch 25: val_loss improved from 342.23712 to 285.78384, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 143.8000 - mean_absolute_error: 6.4795 - val_loss: 285.7838 - val_mean_absolute_error: 10.7089\n",
      "Epoch 26/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 185.1675 - mean_absolute_error: 6.7744\n",
      "Epoch 26: val_loss improved from 285.78384 to 243.09795, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 141.0975 - mean_absolute_error: 6.3256 - val_loss: 243.0979 - val_mean_absolute_error: 9.8590\n",
      "Epoch 27/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 121.5904 - mean_absolute_error: 6.1998\n",
      "Epoch 27: val_loss improved from 243.09795 to 213.71523, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.0780 - mean_absolute_error: 5.9440 - val_loss: 213.7152 - val_mean_absolute_error: 9.2511\n",
      "Epoch 28/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 154.8427 - mean_absolute_error: 6.2812\n",
      "Epoch 28: val_loss improved from 213.71523 to 192.80846, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.0636 - mean_absolute_error: 5.6675 - val_loss: 192.8085 - val_mean_absolute_error: 8.7619\n",
      "Epoch 29/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.8124 - mean_absolute_error: 5.0333\n",
      "Epoch 29: val_loss improved from 192.80846 to 177.21205, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.2782 - mean_absolute_error: 5.2620 - val_loss: 177.2121 - val_mean_absolute_error: 8.3762\n",
      "Epoch 30/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 106.2977 - mean_absolute_error: 5.5614\n",
      "Epoch 30: val_loss improved from 177.21205 to 167.25409, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.7876 - mean_absolute_error: 5.2167 - val_loss: 167.2541 - val_mean_absolute_error: 8.1700\n",
      "Epoch 31/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80.5580 - mean_absolute_error: 4.5564\n",
      "Epoch 31: val_loss improved from 167.25409 to 159.15515, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.6337 - mean_absolute_error: 4.9628 - val_loss: 159.1552 - val_mean_absolute_error: 7.9993\n",
      "Epoch 32/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 81.7288 - mean_absolute_error: 5.1919\n",
      "Epoch 32: val_loss improved from 159.15515 to 154.41153, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.9001 - mean_absolute_error: 4.8737 - val_loss: 154.4115 - val_mean_absolute_error: 7.9064\n",
      "Epoch 33/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 77.8275 - mean_absolute_error: 5.1306\n",
      "Epoch 33: val_loss improved from 154.41153 to 150.27490, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.5526 - mean_absolute_error: 4.9203 - val_loss: 150.2749 - val_mean_absolute_error: 7.8473\n",
      "Epoch 34/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 56.5602 - mean_absolute_error: 4.7377\n",
      "Epoch 34: val_loss improved from 150.27490 to 146.80621, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.3275 - mean_absolute_error: 4.8016 - val_loss: 146.8062 - val_mean_absolute_error: 7.7776\n",
      "Epoch 35/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 101.2916 - mean_absolute_error: 5.3436\n",
      "Epoch 35: val_loss improved from 146.80621 to 144.68336, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.1405 - mean_absolute_error: 4.8542 - val_loss: 144.6834 - val_mean_absolute_error: 7.7394\n",
      "Epoch 36/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 84.0338 - mean_absolute_error: 5.0257\n",
      "Epoch 36: val_loss improved from 144.68336 to 142.47391, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 72.0348 - mean_absolute_error: 4.7869 - val_loss: 142.4739 - val_mean_absolute_error: 7.7105\n",
      "Epoch 37/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 83.7826 - mean_absolute_error: 5.1981\n",
      "Epoch 37: val_loss improved from 142.47391 to 140.65294, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 71.0814 - mean_absolute_error: 4.7059 - val_loss: 140.6529 - val_mean_absolute_error: 7.6641\n",
      "Epoch 38/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 128.2283 - mean_absolute_error: 6.1786\n",
      "Epoch 38: val_loss improved from 140.65294 to 138.82184, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.8592 - mean_absolute_error: 4.9710 - val_loss: 138.8218 - val_mean_absolute_error: 7.6160\n",
      "Epoch 39/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 76.5403 - mean_absolute_error: 4.8042\n",
      "Epoch 39: val_loss improved from 138.82184 to 137.65504, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.3199 - mean_absolute_error: 4.6167 - val_loss: 137.6550 - val_mean_absolute_error: 7.5740\n",
      "Epoch 40/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 39.2892 - mean_absolute_error: 3.9024\n",
      "Epoch 40: val_loss improved from 137.65504 to 136.68645, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.2401 - mean_absolute_error: 4.4008 - val_loss: 136.6864 - val_mean_absolute_error: 7.5584\n",
      "Epoch 41/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.1838 - mean_absolute_error: 4.6772\n",
      "Epoch 41: val_loss improved from 136.68645 to 135.75980, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.6235 - mean_absolute_error: 4.4465 - val_loss: 135.7598 - val_mean_absolute_error: 7.5200\n",
      "Epoch 42/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 75.9109 - mean_absolute_error: 5.1538\n",
      "Epoch 42: val_loss improved from 135.75980 to 134.63734, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.7057 - mean_absolute_error: 4.6010 - val_loss: 134.6373 - val_mean_absolute_error: 7.4710\n",
      "Epoch 43/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 71.8826 - mean_absolute_error: 4.9854\n",
      "Epoch 43: val_loss improved from 134.63734 to 134.38229, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.2215 - mean_absolute_error: 4.6212 - val_loss: 134.3823 - val_mean_absolute_error: 7.4667\n",
      "Epoch 44/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 57.6337 - mean_absolute_error: 4.4362\n",
      "Epoch 44: val_loss improved from 134.38229 to 133.36598, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.0378 - mean_absolute_error: 4.4992 - val_loss: 133.3660 - val_mean_absolute_error: 7.4145\n",
      "Epoch 45/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 90.9260 - mean_absolute_error: 5.4760\n",
      "Epoch 45: val_loss improved from 133.36598 to 132.74435, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.2064 - mean_absolute_error: 4.6288 - val_loss: 132.7444 - val_mean_absolute_error: 7.3874\n",
      "Epoch 46/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 101.4786 - mean_absolute_error: 5.8005\n",
      "Epoch 46: val_loss improved from 132.74435 to 132.60373, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.8390 - mean_absolute_error: 4.6612 - val_loss: 132.6037 - val_mean_absolute_error: 7.3740\n",
      "Epoch 47/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 51.0491 - mean_absolute_error: 3.8263\n",
      "Epoch 47: val_loss improved from 132.60373 to 131.65889, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8647 - mean_absolute_error: 4.2753 - val_loss: 131.6589 - val_mean_absolute_error: 7.3168\n",
      "Epoch 48/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.3703 - mean_absolute_error: 4.1348\n",
      "Epoch 48: val_loss improved from 131.65889 to 131.51633, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6235 - mean_absolute_error: 4.2407 - val_loss: 131.5163 - val_mean_absolute_error: 7.3024\n",
      "Epoch 49/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 47.1367 - mean_absolute_error: 4.1000\n",
      "Epoch 49: val_loss did not improve from 131.51633\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.1613 - mean_absolute_error: 4.3628 - val_loss: 131.7132 - val_mean_absolute_error: 7.3099\n",
      "Epoch 50/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.0384 - mean_absolute_error: 3.5458\n",
      "Epoch 50: val_loss improved from 131.51633 to 131.00970, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.3022 - mean_absolute_error: 4.2882 - val_loss: 131.0097 - val_mean_absolute_error: 7.2596\n",
      "Epoch 51/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 42.4217 - mean_absolute_error: 3.5091\n",
      "Epoch 51: val_loss improved from 131.00970 to 130.83961, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.8077 - mean_absolute_error: 4.2398 - val_loss: 130.8396 - val_mean_absolute_error: 7.2485\n",
      "Epoch 52/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 88.7045 - mean_absolute_error: 5.1056\n",
      "Epoch 52: val_loss improved from 130.83961 to 130.80374, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.9593 - mean_absolute_error: 4.3196 - val_loss: 130.8037 - val_mean_absolute_error: 7.2381\n",
      "Epoch 53/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 72.7381 - mean_absolute_error: 3.8958\n",
      "Epoch 53: val_loss improved from 130.80374 to 130.61667, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.7941 - mean_absolute_error: 4.2503 - val_loss: 130.6167 - val_mean_absolute_error: 7.2145\n",
      "Epoch 54/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.7914 - mean_absolute_error: 3.7298\n",
      "Epoch 54: val_loss improved from 130.61667 to 130.40443, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2888 - mean_absolute_error: 4.1794 - val_loss: 130.4044 - val_mean_absolute_error: 7.2034\n",
      "Epoch 55/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 77.5185 - mean_absolute_error: 5.2293\n",
      "Epoch 55: val_loss improved from 130.40443 to 130.09125, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.7259 - mean_absolute_error: 4.1685 - val_loss: 130.0912 - val_mean_absolute_error: 7.1704\n",
      "Epoch 56/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 31.9464 - mean_absolute_error: 3.5905\n",
      "Epoch 56: val_loss did not improve from 130.09125\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.1766 - mean_absolute_error: 4.1512 - val_loss: 130.3927 - val_mean_absolute_error: 7.1861\n",
      "Epoch 57/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 69.2999 - mean_absolute_error: 3.6221\n",
      "Epoch 57: val_loss improved from 130.09125 to 130.02995, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.5503 - mean_absolute_error: 4.0687 - val_loss: 130.0300 - val_mean_absolute_error: 7.1629\n",
      "Epoch 58/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 42.0569 - mean_absolute_error: 3.5661\n",
      "Epoch 58: val_loss did not improve from 130.02995\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.7835 - mean_absolute_error: 4.0066 - val_loss: 130.0933 - val_mean_absolute_error: 7.1595\n",
      "Epoch 59/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 69.6504 - mean_absolute_error: 4.4931\n",
      "Epoch 59: val_loss did not improve from 130.02995\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.3114 - mean_absolute_error: 4.2366 - val_loss: 130.1006 - val_mean_absolute_error: 7.1498\n",
      "Epoch 60/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 54.1649 - mean_absolute_error: 3.6851\n",
      "Epoch 60: val_loss did not improve from 130.02995\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.6197 - mean_absolute_error: 4.2994 - val_loss: 130.0514 - val_mean_absolute_error: 7.1457\n",
      "Epoch 61/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 46.4959 - mean_absolute_error: 3.7013\n",
      "Epoch 61: val_loss improved from 130.02995 to 129.91223, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2862 - mean_absolute_error: 3.9398 - val_loss: 129.9122 - val_mean_absolute_error: 7.1429\n",
      "Epoch 62/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.5638 - mean_absolute_error: 3.8605\n",
      "Epoch 62: val_loss did not improve from 129.91223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.7297 - mean_absolute_error: 4.1379 - val_loss: 130.2467 - val_mean_absolute_error: 7.1456\n",
      "Epoch 63/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 50.5214 - mean_absolute_error: 3.8449\n",
      "Epoch 63: val_loss did not improve from 129.91223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.3715 - mean_absolute_error: 4.1412 - val_loss: 130.1885 - val_mean_absolute_error: 7.1457\n",
      "Epoch 64/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81.1925 - mean_absolute_error: 4.3038\n",
      "Epoch 64: val_loss improved from 129.91223 to 129.65009, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.7824 - mean_absolute_error: 4.1893 - val_loss: 129.6501 - val_mean_absolute_error: 7.1136\n",
      "Epoch 65/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.8346 - mean_absolute_error: 4.3329\n",
      "Epoch 65: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3185 - mean_absolute_error: 4.1178 - val_loss: 130.1211 - val_mean_absolute_error: 7.1429\n",
      "Epoch 66/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59.6646 - mean_absolute_error: 4.1699\n",
      "Epoch 66: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.6557 - mean_absolute_error: 4.0569 - val_loss: 130.1037 - val_mean_absolute_error: 7.1361\n",
      "Epoch 67/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 40.2193 - mean_absolute_error: 3.1669\n",
      "Epoch 67: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.4056 - mean_absolute_error: 3.8467 - val_loss: 129.9953 - val_mean_absolute_error: 7.1308\n",
      "Epoch 68/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.1982 - mean_absolute_error: 3.9949\n",
      "Epoch 68: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.5303 - mean_absolute_error: 4.0874 - val_loss: 129.6675 - val_mean_absolute_error: 7.1092\n",
      "Epoch 69/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 44.4330 - mean_absolute_error: 3.3973\n",
      "Epoch 69: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.0260 - mean_absolute_error: 4.0215 - val_loss: 129.9180 - val_mean_absolute_error: 7.1284\n",
      "Epoch 70/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 86.1428 - mean_absolute_error: 4.5813\n",
      "Epoch 70: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8605 - mean_absolute_error: 4.0048 - val_loss: 129.7397 - val_mean_absolute_error: 7.1111\n",
      "Epoch 71/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 90.9632 - mean_absolute_error: 4.5199\n",
      "Epoch 71: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.7144 - mean_absolute_error: 4.1093 - val_loss: 130.1255 - val_mean_absolute_error: 7.1289\n",
      "Epoch 72/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 67.8312 - mean_absolute_error: 4.0744\n",
      "Epoch 72: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8060 - mean_absolute_error: 4.0178 - val_loss: 130.0004 - val_mean_absolute_error: 7.1240\n",
      "Epoch 73/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.9386 - mean_absolute_error: 3.7013\n",
      "Epoch 73: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8660 - mean_absolute_error: 3.9630 - val_loss: 129.7618 - val_mean_absolute_error: 7.1057\n",
      "Epoch 74/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.8785 - mean_absolute_error: 3.7205\n",
      "Epoch 74: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.7542 - mean_absolute_error: 3.9894 - val_loss: 130.1503 - val_mean_absolute_error: 7.1360\n",
      "Epoch 75/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 42.3528 - mean_absolute_error: 3.6600\n",
      "Epoch 75: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7785 - mean_absolute_error: 3.9544 - val_loss: 129.7169 - val_mean_absolute_error: 7.1007\n",
      "Epoch 76/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 88.8074 - mean_absolute_error: 4.2784\n",
      "Epoch 76: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9673 - mean_absolute_error: 3.8881 - val_loss: 129.9700 - val_mean_absolute_error: 7.1186\n",
      "Epoch 77/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 75.5177 - mean_absolute_error: 4.9785\n",
      "Epoch 77: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5477 - mean_absolute_error: 3.9929 - val_loss: 130.0789 - val_mean_absolute_error: 7.1200\n",
      "Epoch 78/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41.4501 - mean_absolute_error: 3.5296\n",
      "Epoch 78: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8521 - mean_absolute_error: 3.8952 - val_loss: 129.9576 - val_mean_absolute_error: 7.1220\n",
      "Epoch 79/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 43.8220 - mean_absolute_error: 3.6912\n",
      "Epoch 79: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1941 - mean_absolute_error: 3.9053 - val_loss: 130.0402 - val_mean_absolute_error: 7.1175\n",
      "Epoch 80/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 88.6064 - mean_absolute_error: 4.6445\n",
      "Epoch 80: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.7002 - mean_absolute_error: 3.9038 - val_loss: 130.0547 - val_mean_absolute_error: 7.1262\n",
      "Epoch 81/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 45.4827 - mean_absolute_error: 3.2773\n",
      "Epoch 81: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5753 - mean_absolute_error: 3.9158 - val_loss: 130.2660 - val_mean_absolute_error: 7.1291\n",
      "Epoch 82/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 69.5129 - mean_absolute_error: 4.2012\n",
      "Epoch 82: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.4028 - mean_absolute_error: 3.9172 - val_loss: 130.0563 - val_mean_absolute_error: 7.1231\n",
      "Epoch 83/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 43.7146 - mean_absolute_error: 3.3692\n",
      "Epoch 83: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9263 - mean_absolute_error: 3.9405 - val_loss: 130.0950 - val_mean_absolute_error: 7.1312\n",
      "Epoch 84/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 57.8275 - mean_absolute_error: 3.6481\n",
      "Epoch 84: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.7439 - mean_absolute_error: 3.8445 - val_loss: 130.1853 - val_mean_absolute_error: 7.1298\n",
      "Epoch 85/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 52.7220 - mean_absolute_error: 3.8670\n",
      "Epoch 85: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9180 - mean_absolute_error: 3.8891 - val_loss: 129.8955 - val_mean_absolute_error: 7.1031\n",
      "Epoch 86/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.7467 - mean_absolute_error: 3.8271\n",
      "Epoch 86: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.5959 - mean_absolute_error: 4.0046 - val_loss: 130.1611 - val_mean_absolute_error: 7.1259\n",
      "Epoch 87/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 48.6322 - mean_absolute_error: 3.7752\n",
      "Epoch 87: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1493 - mean_absolute_error: 3.8702 - val_loss: 130.0630 - val_mean_absolute_error: 7.1168\n",
      "Epoch 88/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 50.8459 - mean_absolute_error: 3.6406\n",
      "Epoch 88: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6253 - mean_absolute_error: 3.9191 - val_loss: 130.3039 - val_mean_absolute_error: 7.1244\n",
      "Epoch 89/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 35.2717 - mean_absolute_error: 2.9550\n",
      "Epoch 89: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.3152 - mean_absolute_error: 3.7157 - val_loss: 129.9073 - val_mean_absolute_error: 7.0941\n",
      "Epoch 90/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 41.2908 - mean_absolute_error: 3.6257\n",
      "Epoch 90: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1732 - mean_absolute_error: 3.9024 - val_loss: 130.0716 - val_mean_absolute_error: 7.1114\n",
      "Epoch 91/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.2739 - mean_absolute_error: 3.8491\n",
      "Epoch 91: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.9847 - mean_absolute_error: 3.7002 - val_loss: 130.3411 - val_mean_absolute_error: 7.1248\n",
      "Epoch 92/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 92.1346 - mean_absolute_error: 4.9064\n",
      "Epoch 92: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5922 - mean_absolute_error: 3.9220 - val_loss: 130.0215 - val_mean_absolute_error: 7.1149\n",
      "Epoch 93/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 34.3088 - mean_absolute_error: 3.0588\n",
      "Epoch 93: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.3417 - mean_absolute_error: 3.8357 - val_loss: 129.9965 - val_mean_absolute_error: 7.1049\n",
      "Epoch 94/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 80.8795 - mean_absolute_error: 4.3142\n",
      "Epoch 94: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.6967 - mean_absolute_error: 4.0067 - val_loss: 130.1228 - val_mean_absolute_error: 7.1113\n",
      "Epoch 95/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59.2586 - mean_absolute_error: 3.7257\n",
      "Epoch 95: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9799 - mean_absolute_error: 3.8715 - val_loss: 129.9583 - val_mean_absolute_error: 7.0986\n",
      "Epoch 96/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 62.0869 - mean_absolute_error: 3.8934\n",
      "Epoch 96: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.4057 - mean_absolute_error: 3.8074 - val_loss: 130.2451 - val_mean_absolute_error: 7.1171\n",
      "Epoch 97/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 46.9318 - mean_absolute_error: 3.4376\n",
      "Epoch 97: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8743 - mean_absolute_error: 3.9558 - val_loss: 129.9733 - val_mean_absolute_error: 7.0978\n",
      "Epoch 98/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 104.3412 - mean_absolute_error: 5.1119\n",
      "Epoch 98: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.8089 - mean_absolute_error: 4.0059 - val_loss: 130.1179 - val_mean_absolute_error: 7.0999\n",
      "Epoch 99/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 102.1199 - mean_absolute_error: 5.0977\n",
      "Epoch 99: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.8288 - mean_absolute_error: 3.9367 - val_loss: 129.7833 - val_mean_absolute_error: 7.0798\n",
      "Epoch 100/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 116.1748 - mean_absolute_error: 5.7512\n",
      "Epoch 100: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.2444 - mean_absolute_error: 4.0816 - val_loss: 130.0259 - val_mean_absolute_error: 7.0995\n",
      "Epoch 101/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28.4590 - mean_absolute_error: 2.7161\n",
      "Epoch 101: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0988 - mean_absolute_error: 3.7898 - val_loss: 130.1397 - val_mean_absolute_error: 7.1004\n",
      "Epoch 102/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 40.8681 - mean_absolute_error: 3.3827\n",
      "Epoch 102: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8949 - mean_absolute_error: 3.8857 - val_loss: 130.0060 - val_mean_absolute_error: 7.0922\n",
      "Epoch 103/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 68.4943 - mean_absolute_error: 3.9284\n",
      "Epoch 103: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8107 - mean_absolute_error: 3.8839 - val_loss: 129.9021 - val_mean_absolute_error: 7.0844\n",
      "Epoch 104/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 108.2762 - mean_absolute_error: 5.6575\n",
      "Epoch 104: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.4192 - mean_absolute_error: 4.0772 - val_loss: 129.9589 - val_mean_absolute_error: 7.0876\n",
      "Epoch 105/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 50.3907 - mean_absolute_error: 3.7217\n",
      "Epoch 105: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7102 - mean_absolute_error: 3.7528 - val_loss: 130.0566 - val_mean_absolute_error: 7.0932\n",
      "Epoch 106/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 38.8232 - mean_absolute_error: 3.1776\n",
      "Epoch 106: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2980 - mean_absolute_error: 3.8002 - val_loss: 130.1259 - val_mean_absolute_error: 7.0956\n",
      "Epoch 107/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 30.8438 - mean_absolute_error: 3.3004\n",
      "Epoch 107: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3391 - mean_absolute_error: 3.9355 - val_loss: 129.6510 - val_mean_absolute_error: 7.0563\n",
      "Epoch 108/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 37.6339 - mean_absolute_error: 3.2243\n",
      "Epoch 108: val_loss did not improve from 129.65009\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.7087 - mean_absolute_error: 3.7881 - val_loss: 129.8471 - val_mean_absolute_error: 7.0748\n",
      "Epoch 109/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 58.8115 - mean_absolute_error: 3.6991\n",
      "Epoch 109: val_loss improved from 129.65009 to 129.64275, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.4007 - mean_absolute_error: 3.7823 - val_loss: 129.6427 - val_mean_absolute_error: 7.0603\n",
      "Epoch 110/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 42.1428 - mean_absolute_error: 3.1523\n",
      "Epoch 110: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7141 - mean_absolute_error: 3.7329 - val_loss: 129.9666 - val_mean_absolute_error: 7.0828\n",
      "Epoch 111/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 75.5909 - mean_absolute_error: 4.1480\n",
      "Epoch 111: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4148 - mean_absolute_error: 3.7965 - val_loss: 129.8935 - val_mean_absolute_error: 7.0686\n",
      "Epoch 112/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.5156 - mean_absolute_error: 3.1735\n",
      "Epoch 112: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2463 - mean_absolute_error: 3.8311 - val_loss: 130.2356 - val_mean_absolute_error: 7.0834\n",
      "Epoch 113/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.0351 - mean_absolute_error: 4.3041\n",
      "Epoch 113: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9887 - mean_absolute_error: 3.8322 - val_loss: 129.9326 - val_mean_absolute_error: 7.0716\n",
      "Epoch 114/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 86.4501 - mean_absolute_error: 4.3940\n",
      "Epoch 114: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.7783 - mean_absolute_error: 3.8730 - val_loss: 129.8773 - val_mean_absolute_error: 7.0638\n",
      "Epoch 115/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 21.8309 - mean_absolute_error: 2.3864\n",
      "Epoch 115: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3425 - mean_absolute_error: 3.8281 - val_loss: 129.8735 - val_mean_absolute_error: 7.0626\n",
      "Epoch 116/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 40.9385 - mean_absolute_error: 3.1783\n",
      "Epoch 116: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3245 - mean_absolute_error: 3.9055 - val_loss: 129.7451 - val_mean_absolute_error: 7.0518\n",
      "Epoch 117/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 45.6251 - mean_absolute_error: 3.3362\n",
      "Epoch 117: val_loss did not improve from 129.64275\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6947 - mean_absolute_error: 3.7651 - val_loss: 129.7059 - val_mean_absolute_error: 7.0532\n",
      "Epoch 118/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 67.1996 - mean_absolute_error: 3.8949\n",
      "Epoch 118: val_loss improved from 129.64275 to 129.58420, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.2772 - mean_absolute_error: 3.7582 - val_loss: 129.5842 - val_mean_absolute_error: 7.0389\n",
      "Epoch 119/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 58.5575 - mean_absolute_error: 4.3705\n",
      "Epoch 119: val_loss did not improve from 129.58420\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8658 - mean_absolute_error: 3.7379 - val_loss: 129.7388 - val_mean_absolute_error: 7.0482\n",
      "Epoch 120/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 53.0881 - mean_absolute_error: 3.5207\n",
      "Epoch 120: val_loss did not improve from 129.58420\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4487 - mean_absolute_error: 3.7531 - val_loss: 129.6774 - val_mean_absolute_error: 7.0465\n",
      "Epoch 121/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 43.5756 - mean_absolute_error: 3.6555\n",
      "Epoch 121: val_loss did not improve from 129.58420\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3964 - mean_absolute_error: 3.7310 - val_loss: 130.0590 - val_mean_absolute_error: 7.0720\n",
      "Epoch 122/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 72.5487 - mean_absolute_error: 4.6387\n",
      "Epoch 122: val_loss did not improve from 129.58420\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.5962 - mean_absolute_error: 3.9729 - val_loss: 129.9091 - val_mean_absolute_error: 7.0593\n",
      "Epoch 123/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 36.1872 - mean_absolute_error: 3.0832\n",
      "Epoch 123: val_loss did not improve from 129.58420\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.6249 - mean_absolute_error: 3.8576 - val_loss: 129.5980 - val_mean_absolute_error: 7.0325\n",
      "Epoch 124/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 25.2738 - mean_absolute_error: 3.0809\n",
      "Epoch 124: val_loss improved from 129.58420 to 129.58401, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 59.4671 - mean_absolute_error: 3.8436 - val_loss: 129.5840 - val_mean_absolute_error: 7.0333\n",
      "Epoch 125/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 21.4927 - mean_absolute_error: 2.8001\n",
      "Epoch 125: val_loss did not improve from 129.58401\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1620 - mean_absolute_error: 3.7377 - val_loss: 129.9771 - val_mean_absolute_error: 7.0602\n",
      "Epoch 126/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 79.4631 - mean_absolute_error: 4.4757\n",
      "Epoch 126: val_loss improved from 129.58401 to 129.52161, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 62.4648 - mean_absolute_error: 3.9507 - val_loss: 129.5216 - val_mean_absolute_error: 7.0221\n",
      "Epoch 127/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.8676 - mean_absolute_error: 3.1687\n",
      "Epoch 127: val_loss did not improve from 129.52161\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6065 - mean_absolute_error: 3.7313 - val_loss: 129.9245 - val_mean_absolute_error: 7.0480\n",
      "Epoch 128/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.7632 - mean_absolute_error: 3.6959\n",
      "Epoch 128: val_loss improved from 129.52161 to 129.37561, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9247 - mean_absolute_error: 3.8750 - val_loss: 129.3756 - val_mean_absolute_error: 7.0141\n",
      "Epoch 129/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 41.9798 - mean_absolute_error: 3.2865\n",
      "Epoch 129: val_loss did not improve from 129.37561\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.2422 - mean_absolute_error: 3.7369 - val_loss: 129.6046 - val_mean_absolute_error: 7.0259\n",
      "Epoch 130/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 56.1358 - mean_absolute_error: 3.6648\n",
      "Epoch 130: val_loss did not improve from 129.37561\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7102 - mean_absolute_error: 3.6517 - val_loss: 129.4745 - val_mean_absolute_error: 7.0223\n",
      "Epoch 131/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 52.7978 - mean_absolute_error: 3.5780\n",
      "Epoch 131: val_loss did not improve from 129.37561\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5150 - mean_absolute_error: 3.7907 - val_loss: 129.5186 - val_mean_absolute_error: 7.0202\n",
      "Epoch 132/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 71.8102 - mean_absolute_error: 4.6496\n",
      "Epoch 132: val_loss did not improve from 129.37561\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9222 - mean_absolute_error: 3.8222 - val_loss: 129.4800 - val_mean_absolute_error: 7.0099\n",
      "Epoch 133/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 69.0551 - mean_absolute_error: 4.1239\n",
      "Epoch 133: val_loss improved from 129.37561 to 129.29552, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9379 - mean_absolute_error: 3.8369 - val_loss: 129.2955 - val_mean_absolute_error: 7.0044\n",
      "Epoch 134/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 39.7537 - mean_absolute_error: 3.0340\n",
      "Epoch 134: val_loss did not improve from 129.29552\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6676 - mean_absolute_error: 3.7130 - val_loss: 129.5692 - val_mean_absolute_error: 7.0145\n",
      "Epoch 135/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 66.9971 - mean_absolute_error: 4.0313\n",
      "Epoch 135: val_loss improved from 129.29552 to 129.28044, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.6276 - mean_absolute_error: 3.8120 - val_loss: 129.2804 - val_mean_absolute_error: 6.9943\n",
      "Epoch 136/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 48.3798 - mean_absolute_error: 3.4805\n",
      "Epoch 136: val_loss did not improve from 129.28044\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5745 - mean_absolute_error: 3.6135 - val_loss: 129.3792 - val_mean_absolute_error: 6.9977\n",
      "Epoch 137/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 49.4205 - mean_absolute_error: 3.2832\n",
      "Epoch 137: val_loss did not improve from 129.28044\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8222 - mean_absolute_error: 3.5946 - val_loss: 129.4967 - val_mean_absolute_error: 7.0047\n",
      "Epoch 138/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.0483 - mean_absolute_error: 3.2286\n",
      "Epoch 138: val_loss improved from 129.28044 to 129.26047, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.0092 - mean_absolute_error: 3.8341 - val_loss: 129.2605 - val_mean_absolute_error: 6.9923\n",
      "Epoch 139/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 74.6864 - mean_absolute_error: 4.5841\n",
      "Epoch 139: val_loss improved from 129.26047 to 129.25821, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.2750 - mean_absolute_error: 3.9094 - val_loss: 129.2582 - val_mean_absolute_error: 6.9902\n",
      "Epoch 140/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 88.9082 - mean_absolute_error: 4.0249\n",
      "Epoch 140: val_loss improved from 129.25821 to 129.05722, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8697 - mean_absolute_error: 3.8052 - val_loss: 129.0572 - val_mean_absolute_error: 6.9724\n",
      "Epoch 141/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79.4136 - mean_absolute_error: 3.3087\n",
      "Epoch 141: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6485 - mean_absolute_error: 3.7625 - val_loss: 129.2373 - val_mean_absolute_error: 6.9847\n",
      "Epoch 142/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 41.6954 - mean_absolute_error: 3.0456\n",
      "Epoch 142: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.7466 - mean_absolute_error: 3.7312 - val_loss: 129.3579 - val_mean_absolute_error: 6.9912\n",
      "Epoch 143/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 89.8351 - mean_absolute_error: 3.7080\n",
      "Epoch 143: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1120 - mean_absolute_error: 3.7545 - val_loss: 129.4765 - val_mean_absolute_error: 6.9948\n",
      "Epoch 144/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 61.8564 - mean_absolute_error: 3.7792\n",
      "Epoch 144: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3343 - mean_absolute_error: 3.7970 - val_loss: 129.4421 - val_mean_absolute_error: 6.9987\n",
      "Epoch 145/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 111.2649 - mean_absolute_error: 4.8420\n",
      "Epoch 145: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9870 - mean_absolute_error: 3.7817 - val_loss: 129.3478 - val_mean_absolute_error: 6.9808\n",
      "Epoch 146/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 70.7326 - mean_absolute_error: 4.0199\n",
      "Epoch 146: val_loss did not improve from 129.05722\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5384 - mean_absolute_error: 3.7500 - val_loss: 129.3227 - val_mean_absolute_error: 6.9848\n",
      "Epoch 147/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 59.9273 - mean_absolute_error: 3.6213\n",
      "Epoch 147: val_loss improved from 129.05722 to 128.92462, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7047 - mean_absolute_error: 3.6836 - val_loss: 128.9246 - val_mean_absolute_error: 6.9560\n",
      "Epoch 148/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.2349 - mean_absolute_error: 3.8066\n",
      "Epoch 148: val_loss did not improve from 128.92462\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9143 - mean_absolute_error: 3.6251 - val_loss: 129.3843 - val_mean_absolute_error: 6.9824\n",
      "Epoch 149/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 54.9071 - mean_absolute_error: 3.8288\n",
      "Epoch 149: val_loss improved from 128.92462 to 128.75171, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.0813 - mean_absolute_error: 3.8362 - val_loss: 128.7517 - val_mean_absolute_error: 6.9454\n",
      "Epoch 150/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.4568 - mean_absolute_error: 3.1744\n",
      "Epoch 150: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8920 - mean_absolute_error: 3.8119 - val_loss: 129.3062 - val_mean_absolute_error: 6.9778\n",
      "Epoch 151/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 54.2793 - mean_absolute_error: 3.9441\n",
      "Epoch 151: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7423 - mean_absolute_error: 3.6741 - val_loss: 129.0308 - val_mean_absolute_error: 6.9503\n",
      "Epoch 152/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.6906 - mean_absolute_error: 3.8475\n",
      "Epoch 152: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9304 - mean_absolute_error: 3.7487 - val_loss: 128.9466 - val_mean_absolute_error: 6.9522\n",
      "Epoch 153/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 47.8205 - mean_absolute_error: 3.5622\n",
      "Epoch 153: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7859 - mean_absolute_error: 3.8304 - val_loss: 129.1639 - val_mean_absolute_error: 6.9625\n",
      "Epoch 154/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 29.6315 - mean_absolute_error: 2.8681\n",
      "Epoch 154: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9509 - mean_absolute_error: 3.7228 - val_loss: 128.7796 - val_mean_absolute_error: 6.9322\n",
      "Epoch 155/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 67.3577 - mean_absolute_error: 3.5054\n",
      "Epoch 155: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.0481 - mean_absolute_error: 3.7715 - val_loss: 129.1100 - val_mean_absolute_error: 6.9633\n",
      "Epoch 156/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.0830 - mean_absolute_error: 3.7650\n",
      "Epoch 156: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.2082 - mean_absolute_error: 3.7102 - val_loss: 129.2317 - val_mean_absolute_error: 6.9610\n",
      "Epoch 157/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 51.4815 - mean_absolute_error: 3.5435\n",
      "Epoch 157: val_loss did not improve from 128.75171\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5955 - mean_absolute_error: 3.7407 - val_loss: 129.0241 - val_mean_absolute_error: 6.9481\n",
      "Epoch 158/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 90.2691 - mean_absolute_error: 4.7093\n",
      "Epoch 158: val_loss improved from 128.75171 to 128.71951, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9549 - mean_absolute_error: 3.7619 - val_loss: 128.7195 - val_mean_absolute_error: 6.9245\n",
      "Epoch 159/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 82.3828 - mean_absolute_error: 4.0820\n",
      "Epoch 159: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2390 - mean_absolute_error: 3.7053 - val_loss: 128.8753 - val_mean_absolute_error: 6.9395\n",
      "Epoch 160/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 103.5794 - mean_absolute_error: 5.6497\n",
      "Epoch 160: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3420 - mean_absolute_error: 3.8374 - val_loss: 129.1619 - val_mean_absolute_error: 6.9510\n",
      "Epoch 161/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30.0936 - mean_absolute_error: 2.5198\n",
      "Epoch 161: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.7193 - mean_absolute_error: 3.8178 - val_loss: 129.1646 - val_mean_absolute_error: 6.9556\n",
      "Epoch 162/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.4388 - mean_absolute_error: 4.3594\n",
      "Epoch 162: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8598 - mean_absolute_error: 3.8376 - val_loss: 128.7571 - val_mean_absolute_error: 6.9124\n",
      "Epoch 163/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 126.3229 - mean_absolute_error: 4.9017\n",
      "Epoch 163: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.1730 - mean_absolute_error: 3.9316 - val_loss: 128.8534 - val_mean_absolute_error: 6.9297\n",
      "Epoch 164/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 51.3903 - mean_absolute_error: 3.7851\n",
      "Epoch 164: val_loss did not improve from 128.71951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.0805 - mean_absolute_error: 3.7863 - val_loss: 128.7398 - val_mean_absolute_error: 6.9154\n",
      "Epoch 165/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 45.3047 - mean_absolute_error: 3.5837\n",
      "Epoch 165: val_loss improved from 128.71951 to 128.71230, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1125 - mean_absolute_error: 3.6508 - val_loss: 128.7123 - val_mean_absolute_error: 6.9167\n",
      "Epoch 166/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 49.7640 - mean_absolute_error: 3.3076\n",
      "Epoch 166: val_loss improved from 128.71230 to 128.71223, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1259 - mean_absolute_error: 3.6467 - val_loss: 128.7122 - val_mean_absolute_error: 6.9160\n",
      "Epoch 167/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 78.8907 - mean_absolute_error: 4.3354\n",
      "Epoch 167: val_loss did not improve from 128.71223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3526 - mean_absolute_error: 3.7319 - val_loss: 129.2329 - val_mean_absolute_error: 6.9533\n",
      "Epoch 168/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 54.4808 - mean_absolute_error: 3.9452\n",
      "Epoch 168: val_loss did not improve from 128.71223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6554 - mean_absolute_error: 3.6525 - val_loss: 129.1158 - val_mean_absolute_error: 6.9376\n",
      "Epoch 169/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 113.8261 - mean_absolute_error: 5.2871\n",
      "Epoch 169: val_loss did not improve from 128.71223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.0789 - mean_absolute_error: 3.9510 - val_loss: 128.8993 - val_mean_absolute_error: 6.9160\n",
      "Epoch 170/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 114.4916 - mean_absolute_error: 4.9948\n",
      "Epoch 170: val_loss did not improve from 128.71223\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.1827 - mean_absolute_error: 3.8095 - val_loss: 128.7404 - val_mean_absolute_error: 6.9126\n",
      "Epoch 171/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 36.1175 - mean_absolute_error: 3.0996\n",
      "Epoch 171: val_loss improved from 128.71223 to 128.60854, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.3357 - mean_absolute_error: 3.5180 - val_loss: 128.6085 - val_mean_absolute_error: 6.9101\n",
      "Epoch 172/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.2078 - mean_absolute_error: 3.0615\n",
      "Epoch 172: val_loss did not improve from 128.60854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0378 - mean_absolute_error: 3.5931 - val_loss: 129.0202 - val_mean_absolute_error: 6.9124\n",
      "Epoch 173/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 31.8235 - mean_absolute_error: 2.9878\n",
      "Epoch 173: val_loss did not improve from 128.60854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8349 - mean_absolute_error: 3.5884 - val_loss: 128.9056 - val_mean_absolute_error: 6.9002\n",
      "Epoch 174/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 37.7031 - mean_absolute_error: 3.2923\n",
      "Epoch 174: val_loss did not improve from 128.60854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4419 - mean_absolute_error: 3.7440 - val_loss: 128.8680 - val_mean_absolute_error: 6.9130\n",
      "Epoch 175/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 53.4466 - mean_absolute_error: 3.4565\n",
      "Epoch 175: val_loss did not improve from 128.60854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1738 - mean_absolute_error: 3.6985 - val_loss: 128.8833 - val_mean_absolute_error: 6.8954\n",
      "Epoch 176/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 86.9230 - mean_absolute_error: 4.1047\n",
      "Epoch 176: val_loss did not improve from 128.60854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9640 - mean_absolute_error: 3.7264 - val_loss: 128.8104 - val_mean_absolute_error: 6.9083\n",
      "Epoch 177/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 82.5180 - mean_absolute_error: 4.3156\n",
      "Epoch 177: val_loss improved from 128.60854 to 128.40402, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8862 - mean_absolute_error: 3.7352 - val_loss: 128.4040 - val_mean_absolute_error: 6.8904\n",
      "Epoch 178/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 25.5248 - mean_absolute_error: 2.9119\n",
      "Epoch 178: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.2083 - mean_absolute_error: 3.5803 - val_loss: 128.7193 - val_mean_absolute_error: 6.9082\n",
      "Epoch 179/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.4107 - mean_absolute_error: 3.8576\n",
      "Epoch 179: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6929 - mean_absolute_error: 3.8036 - val_loss: 128.6342 - val_mean_absolute_error: 6.8851\n",
      "Epoch 180/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40.0533 - mean_absolute_error: 3.0308\n",
      "Epoch 180: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.2765 - mean_absolute_error: 3.5717 - val_loss: 128.7900 - val_mean_absolute_error: 6.8931\n",
      "Epoch 181/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 64.0993 - mean_absolute_error: 3.6438\n",
      "Epoch 181: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5069 - mean_absolute_error: 3.7276 - val_loss: 128.5562 - val_mean_absolute_error: 6.8811\n",
      "Epoch 182/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 53.0282 - mean_absolute_error: 3.9839\n",
      "Epoch 182: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5634 - mean_absolute_error: 3.7392 - val_loss: 128.5870 - val_mean_absolute_error: 6.8825\n",
      "Epoch 183/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 44.8610 - mean_absolute_error: 3.5619\n",
      "Epoch 183: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9888 - mean_absolute_error: 3.6711 - val_loss: 128.5913 - val_mean_absolute_error: 6.8896\n",
      "Epoch 184/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 50.6345 - mean_absolute_error: 3.2074\n",
      "Epoch 184: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9636 - mean_absolute_error: 3.6136 - val_loss: 128.6613 - val_mean_absolute_error: 6.8765\n",
      "Epoch 185/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 41.0788 - mean_absolute_error: 3.0184\n",
      "Epoch 185: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9624 - mean_absolute_error: 3.6243 - val_loss: 128.6324 - val_mean_absolute_error: 6.8836\n",
      "Epoch 186/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41.2590 - mean_absolute_error: 2.8627\n",
      "Epoch 186: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8861 - mean_absolute_error: 3.6308 - val_loss: 128.4457 - val_mean_absolute_error: 6.8705\n",
      "Epoch 187/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 76.1479 - mean_absolute_error: 4.8818\n",
      "Epoch 187: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3622 - mean_absolute_error: 3.8563 - val_loss: 128.8810 - val_mean_absolute_error: 6.8920\n",
      "Epoch 188/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 48.5150 - mean_absolute_error: 3.0923\n",
      "Epoch 188: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4738 - mean_absolute_error: 3.6158 - val_loss: 128.4265 - val_mean_absolute_error: 6.8667\n",
      "Epoch 189/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 53.7876 - mean_absolute_error: 3.6441\n",
      "Epoch 189: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2889 - mean_absolute_error: 3.6671 - val_loss: 128.4769 - val_mean_absolute_error: 6.8784\n",
      "Epoch 190/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 72.8599 - mean_absolute_error: 3.9083\n",
      "Epoch 190: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.4529 - mean_absolute_error: 3.7428 - val_loss: 128.9866 - val_mean_absolute_error: 6.8815\n",
      "Epoch 191/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 52.3870 - mean_absolute_error: 3.4377\n",
      "Epoch 191: val_loss did not improve from 128.40402\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9125 - mean_absolute_error: 3.5631 - val_loss: 128.4117 - val_mean_absolute_error: 6.8653\n",
      "Epoch 192/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 105.5111 - mean_absolute_error: 4.8984\n",
      "Epoch 192: val_loss improved from 128.40402 to 128.36819, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.4456 - mean_absolute_error: 3.8589 - val_loss: 128.3682 - val_mean_absolute_error: 6.8606\n",
      "Epoch 193/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 34.6856 - mean_absolute_error: 3.0798\n",
      "Epoch 193: val_loss did not improve from 128.36819\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.8433 - mean_absolute_error: 3.6036 - val_loss: 128.4769 - val_mean_absolute_error: 6.8623\n",
      "Epoch 194/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 33.1453 - mean_absolute_error: 2.8702\n",
      "Epoch 194: val_loss did not improve from 128.36819\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.7450 - mean_absolute_error: 3.5887 - val_loss: 128.8598 - val_mean_absolute_error: 6.8842\n",
      "Epoch 195/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 41.0239 - mean_absolute_error: 3.1139\n",
      "Epoch 195: val_loss did not improve from 128.36819\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.7606 - mean_absolute_error: 3.5607 - val_loss: 128.6302 - val_mean_absolute_error: 6.8687\n",
      "Epoch 196/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 69.6747 - mean_absolute_error: 3.8142\n",
      "Epoch 196: val_loss did not improve from 128.36819\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8778 - mean_absolute_error: 3.7345 - val_loss: 128.6058 - val_mean_absolute_error: 6.8684\n",
      "Epoch 197/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 27.5944 - mean_absolute_error: 2.6400\n",
      "Epoch 197: val_loss did not improve from 128.36819\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.2291 - mean_absolute_error: 3.4081 - val_loss: 128.4208 - val_mean_absolute_error: 6.8687\n",
      "Epoch 198/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 70.8898 - mean_absolute_error: 4.3555\n",
      "Epoch 198: val_loss improved from 128.36819 to 128.36095, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5091 - mean_absolute_error: 3.7787 - val_loss: 128.3609 - val_mean_absolute_error: 6.8492\n",
      "Epoch 199/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 73.1678 - mean_absolute_error: 3.4901\n",
      "Epoch 199: val_loss did not improve from 128.36095\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.3686 - mean_absolute_error: 3.7203 - val_loss: 128.5679 - val_mean_absolute_error: 6.8516\n",
      "Epoch 200/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 29.5573 - mean_absolute_error: 2.9571\n",
      "Epoch 200: val_loss did not improve from 128.36095\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5317 - mean_absolute_error: 3.7038 - val_loss: 128.3744 - val_mean_absolute_error: 6.8391\n",
      "Epoch 201/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79.1967 - mean_absolute_error: 3.2336\n",
      "Epoch 201: val_loss did not improve from 128.36095\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.2365 - mean_absolute_error: 3.6568 - val_loss: 128.3868 - val_mean_absolute_error: 6.8688\n",
      "Epoch 202/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 96.4747 - mean_absolute_error: 4.4313\n",
      "Epoch 202: val_loss improved from 128.36095 to 128.22557, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.9029 - mean_absolute_error: 3.8372 - val_loss: 128.2256 - val_mean_absolute_error: 6.8321\n",
      "Epoch 203/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 33.6223 - mean_absolute_error: 2.9572\n",
      "Epoch 203: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.2791 - mean_absolute_error: 3.5891 - val_loss: 128.3921 - val_mean_absolute_error: 6.8406\n",
      "Epoch 204/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 29.9688 - mean_absolute_error: 2.3146\n",
      "Epoch 204: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0253 - mean_absolute_error: 3.5595 - val_loss: 128.5356 - val_mean_absolute_error: 6.8637\n",
      "Epoch 205/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 77.1537 - mean_absolute_error: 4.4781\n",
      "Epoch 205: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.7028 - mean_absolute_error: 3.8210 - val_loss: 128.2397 - val_mean_absolute_error: 6.8210\n",
      "Epoch 206/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 84.8980 - mean_absolute_error: 3.8974\n",
      "Epoch 206: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.2797 - mean_absolute_error: 3.7332 - val_loss: 128.6096 - val_mean_absolute_error: 6.8483\n",
      "Epoch 207/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.5038 - mean_absolute_error: 4.2613\n",
      "Epoch 207: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.7809 - mean_absolute_error: 3.8846 - val_loss: 128.3755 - val_mean_absolute_error: 6.8455\n",
      "Epoch 208/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59.8832 - mean_absolute_error: 4.0783\n",
      "Epoch 208: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8144 - mean_absolute_error: 3.5341 - val_loss: 128.2491 - val_mean_absolute_error: 6.8377\n",
      "Epoch 209/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 62.3790 - mean_absolute_error: 3.6156\n",
      "Epoch 209: val_loss did not improve from 128.22557\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.4565 - mean_absolute_error: 3.5261 - val_loss: 128.4223 - val_mean_absolute_error: 6.8512\n",
      "Epoch 210/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 97.8500 - mean_absolute_error: 4.4517\n",
      "Epoch 210: val_loss improved from 128.22557 to 128.22453, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 54.4117 - mean_absolute_error: 3.5734 - val_loss: 128.2245 - val_mean_absolute_error: 6.8295\n",
      "Epoch 211/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.9931 - mean_absolute_error: 3.7616\n",
      "Epoch 211: val_loss did not improve from 128.22453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.3646 - mean_absolute_error: 3.5291 - val_loss: 128.6059 - val_mean_absolute_error: 6.8434\n",
      "Epoch 212/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 71.7500 - mean_absolute_error: 4.0906\n",
      "Epoch 212: val_loss did not improve from 128.22453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.0113 - mean_absolute_error: 3.8041 - val_loss: 128.3017 - val_mean_absolute_error: 6.8126\n",
      "Epoch 213/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 42.9802 - mean_absolute_error: 3.3446\n",
      "Epoch 213: val_loss did not improve from 128.22453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9133 - mean_absolute_error: 3.5798 - val_loss: 128.4653 - val_mean_absolute_error: 6.8398\n",
      "Epoch 214/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.3084 - mean_absolute_error: 3.7443\n",
      "Epoch 214: val_loss did not improve from 128.22453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0853 - mean_absolute_error: 3.5945 - val_loss: 128.5481 - val_mean_absolute_error: 6.8377\n",
      "Epoch 215/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 80.9462 - mean_absolute_error: 3.8950\n",
      "Epoch 215: val_loss improved from 128.22453 to 128.19273, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2371 - mean_absolute_error: 3.5092 - val_loss: 128.1927 - val_mean_absolute_error: 6.8105\n",
      "Epoch 216/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 50.0665 - mean_absolute_error: 3.7179\n",
      "Epoch 216: val_loss did not improve from 128.19273\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9090 - mean_absolute_error: 3.5980 - val_loss: 128.3524 - val_mean_absolute_error: 6.8270\n",
      "Epoch 217/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 53.5312 - mean_absolute_error: 3.7903\n",
      "Epoch 217: val_loss did not improve from 128.19273\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5965 - mean_absolute_error: 3.5784 - val_loss: 128.1944 - val_mean_absolute_error: 6.8208\n",
      "Epoch 218/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 45.4218 - mean_absolute_error: 3.6615\n",
      "Epoch 218: val_loss improved from 128.19273 to 128.14059, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.7616 - mean_absolute_error: 3.6815 - val_loss: 128.1406 - val_mean_absolute_error: 6.7971\n",
      "Epoch 219/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 54.3544 - mean_absolute_error: 3.9230\n",
      "Epoch 219: val_loss did not improve from 128.14059\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8966 - mean_absolute_error: 3.7042 - val_loss: 128.3988 - val_mean_absolute_error: 6.8416\n",
      "Epoch 220/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 88.4704 - mean_absolute_error: 4.0404\n",
      "Epoch 220: val_loss improved from 128.14059 to 128.13104, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6941 - mean_absolute_error: 3.6205 - val_loss: 128.1310 - val_mean_absolute_error: 6.7977\n",
      "Epoch 221/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 58.4973 - mean_absolute_error: 3.3884\n",
      "Epoch 221: val_loss did not improve from 128.13104\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5433 - mean_absolute_error: 3.5608 - val_loss: 128.3768 - val_mean_absolute_error: 6.8354\n",
      "Epoch 222/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 30.6670 - mean_absolute_error: 2.9192\n",
      "Epoch 222: val_loss did not improve from 128.13104\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2524 - mean_absolute_error: 3.5435 - val_loss: 128.4455 - val_mean_absolute_error: 6.8363\n",
      "Epoch 223/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 26.3539 - mean_absolute_error: 2.8217\n",
      "Epoch 223: val_loss improved from 128.13104 to 127.97580, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6951 - mean_absolute_error: 3.6339 - val_loss: 127.9758 - val_mean_absolute_error: 6.7850\n",
      "Epoch 224/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 75.8291 - mean_absolute_error: 4.1752\n",
      "Epoch 224: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.5641 - mean_absolute_error: 3.7869 - val_loss: 128.6963 - val_mean_absolute_error: 6.8342\n",
      "Epoch 225/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 75.5756 - mean_absolute_error: 4.0198\n",
      "Epoch 225: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.6587 - mean_absolute_error: 3.7249 - val_loss: 128.5068 - val_mean_absolute_error: 6.8269\n",
      "Epoch 226/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 69.9232 - mean_absolute_error: 4.3576\n",
      "Epoch 226: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.4978 - mean_absolute_error: 3.7337 - val_loss: 128.3418 - val_mean_absolute_error: 6.8105\n",
      "Epoch 227/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 64.3667 - mean_absolute_error: 3.8342\n",
      "Epoch 227: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4952 - mean_absolute_error: 3.6444 - val_loss: 128.3873 - val_mean_absolute_error: 6.8179\n",
      "Epoch 228/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 45.2751 - mean_absolute_error: 3.5524\n",
      "Epoch 228: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.0748 - mean_absolute_error: 3.5844 - val_loss: 128.4687 - val_mean_absolute_error: 6.8011\n",
      "Epoch 229/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 65.1461 - mean_absolute_error: 3.9093\n",
      "Epoch 229: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9106 - mean_absolute_error: 3.7476 - val_loss: 127.9955 - val_mean_absolute_error: 6.7991\n",
      "Epoch 230/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72.4024 - mean_absolute_error: 3.9027\n",
      "Epoch 230: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3696 - mean_absolute_error: 3.6438 - val_loss: 128.1810 - val_mean_absolute_error: 6.8065\n",
      "Epoch 231/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 86.0064 - mean_absolute_error: 4.5320\n",
      "Epoch 231: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9200 - mean_absolute_error: 3.6962 - val_loss: 128.3993 - val_mean_absolute_error: 6.8117\n",
      "Epoch 232/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 69.8512 - mean_absolute_error: 4.2246\n",
      "Epoch 232: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6100 - mean_absolute_error: 3.7003 - val_loss: 128.2886 - val_mean_absolute_error: 6.8092\n",
      "Epoch 233/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 42.9581 - mean_absolute_error: 3.2466\n",
      "Epoch 233: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.1262 - mean_absolute_error: 3.6122 - val_loss: 128.1816 - val_mean_absolute_error: 6.7868\n",
      "Epoch 234/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 31.9111 - mean_absolute_error: 2.9862\n",
      "Epoch 234: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6361 - mean_absolute_error: 3.5983 - val_loss: 128.7241 - val_mean_absolute_error: 6.8107\n",
      "Epoch 235/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 64.5684 - mean_absolute_error: 3.2300\n",
      "Epoch 235: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.7928 - mean_absolute_error: 3.7646 - val_loss: 128.1478 - val_mean_absolute_error: 6.7798\n",
      "Epoch 236/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 91.0927 - mean_absolute_error: 4.1220\n",
      "Epoch 236: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.4244 - mean_absolute_error: 3.5902 - val_loss: 128.0889 - val_mean_absolute_error: 6.7865\n",
      "Epoch 237/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 21.4772 - mean_absolute_error: 2.5379\n",
      "Epoch 237: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2348 - mean_absolute_error: 3.5351 - val_loss: 128.4165 - val_mean_absolute_error: 6.7910\n",
      "Epoch 238/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 41.0174 - mean_absolute_error: 3.3025\n",
      "Epoch 238: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.9501 - mean_absolute_error: 3.5186 - val_loss: 128.2188 - val_mean_absolute_error: 6.8041\n",
      "Epoch 239/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 109.9856 - mean_absolute_error: 5.2261\n",
      "Epoch 239: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.1197 - mean_absolute_error: 3.6670 - val_loss: 128.2558 - val_mean_absolute_error: 6.7730\n",
      "Epoch 240/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 61.6565 - mean_absolute_error: 4.0700\n",
      "Epoch 240: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8991 - mean_absolute_error: 3.7028 - val_loss: 128.1054 - val_mean_absolute_error: 6.7827\n",
      "Epoch 241/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 144.0014 - mean_absolute_error: 5.4007\n",
      "Epoch 241: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.6455 - mean_absolute_error: 3.7915 - val_loss: 128.1960 - val_mean_absolute_error: 6.7796\n",
      "Epoch 242/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62.5607 - mean_absolute_error: 3.8022\n",
      "Epoch 242: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.7839 - mean_absolute_error: 3.7429 - val_loss: 128.3456 - val_mean_absolute_error: 6.7948\n",
      "Epoch 243/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 44.5535 - mean_absolute_error: 3.1122\n",
      "Epoch 243: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8983 - mean_absolute_error: 3.6833 - val_loss: 128.5361 - val_mean_absolute_error: 6.8025\n",
      "Epoch 244/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 37.2774 - mean_absolute_error: 2.9763\n",
      "Epoch 244: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.1027 - mean_absolute_error: 3.7464 - val_loss: 128.1433 - val_mean_absolute_error: 6.7587\n",
      "Epoch 245/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 107.4776 - mean_absolute_error: 4.6472\n",
      "Epoch 245: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.5355 - mean_absolute_error: 3.7700 - val_loss: 128.2110 - val_mean_absolute_error: 6.7964\n",
      "Epoch 246/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 33.5160 - mean_absolute_error: 2.7793\n",
      "Epoch 246: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.7542 - mean_absolute_error: 3.5245 - val_loss: 128.4057 - val_mean_absolute_error: 6.7868\n",
      "Epoch 247/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 55.4120 - mean_absolute_error: 3.7419\n",
      "Epoch 247: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1544 - mean_absolute_error: 3.6294 - val_loss: 128.2541 - val_mean_absolute_error: 6.7827\n",
      "Epoch 248/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 40.2595 - mean_absolute_error: 3.2461\n",
      "Epoch 248: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.3410 - mean_absolute_error: 3.5425 - val_loss: 128.0887 - val_mean_absolute_error: 6.7770\n",
      "Epoch 249/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 36.8664 - mean_absolute_error: 3.0036\n",
      "Epoch 249: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7701 - mean_absolute_error: 3.5997 - val_loss: 128.2225 - val_mean_absolute_error: 6.7729\n",
      "Epoch 250/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 47.7041 - mean_absolute_error: 3.4972\n",
      "Epoch 250: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0110 - mean_absolute_error: 3.5671 - val_loss: 128.0464 - val_mean_absolute_error: 6.7521\n",
      "Epoch 251/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 46.1331 - mean_absolute_error: 3.0465\n",
      "Epoch 251: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6800 - mean_absolute_error: 3.4810 - val_loss: 128.1555 - val_mean_absolute_error: 6.7658\n",
      "Epoch 252/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 97.0276 - mean_absolute_error: 4.2333\n",
      "Epoch 252: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3005 - mean_absolute_error: 3.5600 - val_loss: 128.1456 - val_mean_absolute_error: 6.7638\n",
      "Epoch 253/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25.6410 - mean_absolute_error: 2.7955\n",
      "Epoch 253: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.4738 - mean_absolute_error: 3.5412 - val_loss: 128.0701 - val_mean_absolute_error: 6.7573\n",
      "Epoch 254/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.0784 - mean_absolute_error: 3.6365\n",
      "Epoch 254: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6339 - mean_absolute_error: 3.6384 - val_loss: 128.1372 - val_mean_absolute_error: 6.7849\n",
      "Epoch 255/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.9676 - mean_absolute_error: 3.8469\n",
      "Epoch 255: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.6208 - mean_absolute_error: 3.6437 - val_loss: 128.0711 - val_mean_absolute_error: 6.7582\n",
      "Epoch 256/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 54.2096 - mean_absolute_error: 3.7934\n",
      "Epoch 256: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.7624 - mean_absolute_error: 3.6570 - val_loss: 128.2247 - val_mean_absolute_error: 6.7615\n",
      "Epoch 257/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 55.8105 - mean_absolute_error: 3.8866\n",
      "Epoch 257: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2473 - mean_absolute_error: 3.5675 - val_loss: 128.0795 - val_mean_absolute_error: 6.7584\n",
      "Epoch 258/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 73.2322 - mean_absolute_error: 4.1171\n",
      "Epoch 258: val_loss did not improve from 127.97580\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8667 - mean_absolute_error: 3.5774 - val_loss: 128.1050 - val_mean_absolute_error: 6.7493\n",
      "Epoch 259/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56.6415 - mean_absolute_error: 3.9062\n",
      "Epoch 259: val_loss improved from 127.97580 to 127.92329, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6693 - mean_absolute_error: 3.6376 - val_loss: 127.9233 - val_mean_absolute_error: 6.7422\n",
      "Epoch 260/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 121.5405 - mean_absolute_error: 4.7813\n",
      "Epoch 260: val_loss did not improve from 127.92329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.0061 - mean_absolute_error: 3.6561 - val_loss: 128.3490 - val_mean_absolute_error: 6.7583\n",
      "Epoch 261/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 63.5126 - mean_absolute_error: 3.7419\n",
      "Epoch 261: val_loss did not improve from 127.92329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.7361 - mean_absolute_error: 3.5328 - val_loss: 128.4866 - val_mean_absolute_error: 6.7744\n",
      "Epoch 262/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 54.6652 - mean_absolute_error: 3.5858\n",
      "Epoch 262: val_loss did not improve from 127.92329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1461 - mean_absolute_error: 3.6319 - val_loss: 127.9907 - val_mean_absolute_error: 6.7609\n",
      "Epoch 263/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 61.1822 - mean_absolute_error: 3.5715\n",
      "Epoch 263: val_loss did not improve from 127.92329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9791 - mean_absolute_error: 3.5992 - val_loss: 128.1221 - val_mean_absolute_error: 6.7546\n",
      "Epoch 264/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.8439 - mean_absolute_error: 3.3224\n",
      "Epoch 264: val_loss did not improve from 127.92329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.2436 - mean_absolute_error: 3.6412 - val_loss: 128.3458 - val_mean_absolute_error: 6.7502\n",
      "Epoch 265/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 54.9710 - mean_absolute_error: 3.6433\n",
      "Epoch 265: val_loss improved from 127.92329 to 127.83169, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9801 - mean_absolute_error: 3.5062 - val_loss: 127.8317 - val_mean_absolute_error: 6.7378\n",
      "Epoch 266/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 30.2991 - mean_absolute_error: 2.6751\n",
      "Epoch 266: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1316 - mean_absolute_error: 3.5223 - val_loss: 128.5889 - val_mean_absolute_error: 6.7590\n",
      "Epoch 267/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 29.7289 - mean_absolute_error: 2.9445\n",
      "Epoch 267: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.8338 - mean_absolute_error: 3.4957 - val_loss: 128.0334 - val_mean_absolute_error: 6.7325\n",
      "Epoch 268/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 79.1147 - mean_absolute_error: 4.2229\n",
      "Epoch 268: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.1500 - mean_absolute_error: 3.7428 - val_loss: 128.6361 - val_mean_absolute_error: 6.7662\n",
      "Epoch 269/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 59.4796 - mean_absolute_error: 3.5740\n",
      "Epoch 269: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8579 - mean_absolute_error: 3.6424 - val_loss: 128.3423 - val_mean_absolute_error: 6.7393\n",
      "Epoch 270/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 48.9279 - mean_absolute_error: 3.6805\n",
      "Epoch 270: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4769 - mean_absolute_error: 3.6435 - val_loss: 127.8900 - val_mean_absolute_error: 6.7331\n",
      "Epoch 271/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 30.2197 - mean_absolute_error: 2.7418\n",
      "Epoch 271: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6660 - mean_absolute_error: 3.5434 - val_loss: 128.1613 - val_mean_absolute_error: 6.7454\n",
      "Epoch 272/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 46.8270 - mean_absolute_error: 3.1752\n",
      "Epoch 272: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.5905 - mean_absolute_error: 3.4877 - val_loss: 127.9622 - val_mean_absolute_error: 6.7212\n",
      "Epoch 273/500\n",
      "\u001b[1m17/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.8182 - mean_absolute_error: 3.7724 \n",
      "Epoch 273: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 61.3648 - mean_absolute_error: 3.7174 - val_loss: 128.1988 - val_mean_absolute_error: 6.7427\n",
      "Epoch 274/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 62.6240 - mean_absolute_error: 3.6860\n",
      "Epoch 274: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8525 - mean_absolute_error: 3.6180 - val_loss: 127.9405 - val_mean_absolute_error: 6.7227\n",
      "Epoch 275/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 43.9262 - mean_absolute_error: 3.0331\n",
      "Epoch 275: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5734 - mean_absolute_error: 3.6761 - val_loss: 128.0978 - val_mean_absolute_error: 6.7474\n",
      "Epoch 276/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 45.5520 - mean_absolute_error: 3.3487\n",
      "Epoch 276: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3182 - mean_absolute_error: 3.6434 - val_loss: 128.1613 - val_mean_absolute_error: 6.7397\n",
      "Epoch 277/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 61.9896 - mean_absolute_error: 3.3964\n",
      "Epoch 277: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9575 - mean_absolute_error: 3.6277 - val_loss: 127.9459 - val_mean_absolute_error: 6.7281\n",
      "Epoch 278/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 47.1739 - mean_absolute_error: 3.5074\n",
      "Epoch 278: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.7659 - mean_absolute_error: 3.6061 - val_loss: 128.1893 - val_mean_absolute_error: 6.7183\n",
      "Epoch 279/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 37.8942 - mean_absolute_error: 3.3467\n",
      "Epoch 279: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8309 - mean_absolute_error: 3.5842 - val_loss: 128.5190 - val_mean_absolute_error: 6.7352\n",
      "Epoch 280/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 49.8066 - mean_absolute_error: 3.6379\n",
      "Epoch 280: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.9307 - mean_absolute_error: 3.5092 - val_loss: 128.1354 - val_mean_absolute_error: 6.7332\n",
      "Epoch 281/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 44.0241 - mean_absolute_error: 3.5828\n",
      "Epoch 281: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.4711 - mean_absolute_error: 3.6238 - val_loss: 128.1931 - val_mean_absolute_error: 6.7413\n",
      "Epoch 282/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 59.5863 - mean_absolute_error: 3.3369\n",
      "Epoch 282: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4593 - mean_absolute_error: 3.5568 - val_loss: 127.9610 - val_mean_absolute_error: 6.7307\n",
      "Epoch 283/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 64.6322 - mean_absolute_error: 3.4151\n",
      "Epoch 283: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1157 - mean_absolute_error: 3.5782 - val_loss: 128.3052 - val_mean_absolute_error: 6.7225\n",
      "Epoch 284/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 95.0935 - mean_absolute_error: 4.3272\n",
      "Epoch 284: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8800 - mean_absolute_error: 3.6483 - val_loss: 128.1378 - val_mean_absolute_error: 6.7256\n",
      "Epoch 285/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 29.3980 - mean_absolute_error: 2.6214\n",
      "Epoch 285: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.4464 - mean_absolute_error: 3.4721 - val_loss: 128.1561 - val_mean_absolute_error: 6.7253\n",
      "Epoch 286/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 61.7500 - mean_absolute_error: 4.0650\n",
      "Epoch 286: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2681 - mean_absolute_error: 3.7430 - val_loss: 128.1612 - val_mean_absolute_error: 6.7185\n",
      "Epoch 287/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 56.9737 - mean_absolute_error: 3.2495\n",
      "Epoch 287: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.2985 - mean_absolute_error: 3.5845 - val_loss: 128.1405 - val_mean_absolute_error: 6.7414\n",
      "Epoch 288/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 69.8772 - mean_absolute_error: 4.1483\n",
      "Epoch 288: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.7502 - mean_absolute_error: 3.6801 - val_loss: 127.8657 - val_mean_absolute_error: 6.7118\n",
      "Epoch 289/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 51.7266 - mean_absolute_error: 3.7913\n",
      "Epoch 289: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8928 - mean_absolute_error: 3.6866 - val_loss: 128.1207 - val_mean_absolute_error: 6.7076\n",
      "Epoch 290/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61.3247 - mean_absolute_error: 3.8296\n",
      "Epoch 290: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6627 - mean_absolute_error: 3.6824 - val_loss: 128.0837 - val_mean_absolute_error: 6.7290\n",
      "Epoch 291/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 53.7585 - mean_absolute_error: 3.0531\n",
      "Epoch 291: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3253 - mean_absolute_error: 3.6047 - val_loss: 128.1290 - val_mean_absolute_error: 6.7104\n",
      "Epoch 292/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 69.7334 - mean_absolute_error: 4.2136\n",
      "Epoch 292: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.4053 - mean_absolute_error: 3.6098 - val_loss: 128.2527 - val_mean_absolute_error: 6.7345\n",
      "Epoch 293/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 76.6939 - mean_absolute_error: 4.1366\n",
      "Epoch 293: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.4932 - mean_absolute_error: 3.7062 - val_loss: 128.2318 - val_mean_absolute_error: 6.7214\n",
      "Epoch 294/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 67.9509 - mean_absolute_error: 4.1263\n",
      "Epoch 294: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9461 - mean_absolute_error: 3.7089 - val_loss: 128.4778 - val_mean_absolute_error: 6.7406\n",
      "Epoch 295/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 78.0333 - mean_absolute_error: 4.2308\n",
      "Epoch 295: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8558 - mean_absolute_error: 3.6787 - val_loss: 128.1270 - val_mean_absolute_error: 6.7042\n",
      "Epoch 296/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.5927 - mean_absolute_error: 3.1484\n",
      "Epoch 296: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.6908 - mean_absolute_error: 3.5739 - val_loss: 128.5025 - val_mean_absolute_error: 6.7391\n",
      "Epoch 297/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 47.5429 - mean_absolute_error: 2.9663\n",
      "Epoch 297: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9639 - mean_absolute_error: 3.5430 - val_loss: 128.1579 - val_mean_absolute_error: 6.7094\n",
      "Epoch 298/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 52.2553 - mean_absolute_error: 3.8335\n",
      "Epoch 298: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9136 - mean_absolute_error: 3.6805 - val_loss: 128.4143 - val_mean_absolute_error: 6.7484\n",
      "Epoch 299/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 50.6133 - mean_absolute_error: 3.5613\n",
      "Epoch 299: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6644 - mean_absolute_error: 3.6166 - val_loss: 128.0994 - val_mean_absolute_error: 6.7109\n",
      "Epoch 300/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 29.8765 - mean_absolute_error: 2.8999\n",
      "Epoch 300: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.3395 - mean_absolute_error: 3.4907 - val_loss: 128.1715 - val_mean_absolute_error: 6.7124\n",
      "Epoch 301/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 57.8665 - mean_absolute_error: 3.5316\n",
      "Epoch 301: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.1440 - mean_absolute_error: 3.7061 - val_loss: 128.0614 - val_mean_absolute_error: 6.6966\n",
      "Epoch 302/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 43.2396 - mean_absolute_error: 3.4435\n",
      "Epoch 302: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1849 - mean_absolute_error: 3.6417 - val_loss: 128.2170 - val_mean_absolute_error: 6.7388\n",
      "Epoch 303/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 51.6112 - mean_absolute_error: 3.1119\n",
      "Epoch 303: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9268 - mean_absolute_error: 3.7038 - val_loss: 128.2987 - val_mean_absolute_error: 6.7230\n",
      "Epoch 304/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 86.0786 - mean_absolute_error: 4.7297\n",
      "Epoch 304: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0918 - mean_absolute_error: 3.6897 - val_loss: 127.9771 - val_mean_absolute_error: 6.7055\n",
      "Epoch 305/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 53.3324 - mean_absolute_error: 3.7730\n",
      "Epoch 305: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9700 - mean_absolute_error: 3.6361 - val_loss: 128.2574 - val_mean_absolute_error: 6.7032\n",
      "Epoch 306/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 30.8253 - mean_absolute_error: 2.8492\n",
      "Epoch 306: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1803 - mean_absolute_error: 3.5179 - val_loss: 128.0782 - val_mean_absolute_error: 6.7233\n",
      "Epoch 307/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 64.4597 - mean_absolute_error: 4.1671\n",
      "Epoch 307: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.5400 - mean_absolute_error: 3.5795 - val_loss: 128.4272 - val_mean_absolute_error: 6.7042\n",
      "Epoch 308/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17.4752 - mean_absolute_error: 2.1766\n",
      "Epoch 308: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.8853 - mean_absolute_error: 3.4396 - val_loss: 128.2887 - val_mean_absolute_error: 6.7003\n",
      "Epoch 309/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 43.7752 - mean_absolute_error: 3.4032\n",
      "Epoch 309: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4497 - mean_absolute_error: 3.6210 - val_loss: 128.1389 - val_mean_absolute_error: 6.6993\n",
      "Epoch 310/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.6500 - mean_absolute_error: 3.7493\n",
      "Epoch 310: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5555 - mean_absolute_error: 3.6055 - val_loss: 128.4222 - val_mean_absolute_error: 6.6840\n",
      "Epoch 311/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 21.5362 - mean_absolute_error: 2.1491\n",
      "Epoch 311: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.9594 - mean_absolute_error: 3.4784 - val_loss: 128.2177 - val_mean_absolute_error: 6.7100\n",
      "Epoch 312/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 61.7776 - mean_absolute_error: 4.0373\n",
      "Epoch 312: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9505 - mean_absolute_error: 3.5818 - val_loss: 128.1412 - val_mean_absolute_error: 6.7067\n",
      "Epoch 313/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 75.4584 - mean_absolute_error: 4.2024\n",
      "Epoch 313: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.9944 - mean_absolute_error: 3.7439 - val_loss: 128.6451 - val_mean_absolute_error: 6.7181\n",
      "Epoch 314/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81.8689 - mean_absolute_error: 4.2566\n",
      "Epoch 314: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.3664 - mean_absolute_error: 3.7008 - val_loss: 128.0745 - val_mean_absolute_error: 6.6933\n",
      "Epoch 315/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 54.5358 - mean_absolute_error: 3.5346\n",
      "Epoch 315: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9600 - mean_absolute_error: 3.5361 - val_loss: 128.0310 - val_mean_absolute_error: 6.6963\n",
      "Epoch 316/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 37.6428 - mean_absolute_error: 3.2316\n",
      "Epoch 316: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.0573 - mean_absolute_error: 3.3493 - val_loss: 128.3276 - val_mean_absolute_error: 6.7007\n",
      "Epoch 317/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 38.9321 - mean_absolute_error: 3.2362\n",
      "Epoch 317: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2774 - mean_absolute_error: 3.6035 - val_loss: 128.1359 - val_mean_absolute_error: 6.6983\n",
      "Epoch 318/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 28.2374 - mean_absolute_error: 2.8261\n",
      "Epoch 318: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.9286 - mean_absolute_error: 3.4397 - val_loss: 128.0662 - val_mean_absolute_error: 6.6946\n",
      "Epoch 319/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 53.9935 - mean_absolute_error: 3.2138\n",
      "Epoch 319: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.5559 - mean_absolute_error: 3.5803 - val_loss: 128.3678 - val_mean_absolute_error: 6.7173\n",
      "Epoch 320/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.1721 - mean_absolute_error: 3.6731\n",
      "Epoch 320: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.2605 - mean_absolute_error: 3.4823 - val_loss: 128.3711 - val_mean_absolute_error: 6.7177\n",
      "Epoch 321/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 112.2673 - mean_absolute_error: 4.1968\n",
      "Epoch 321: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3937 - mean_absolute_error: 3.6809 - val_loss: 128.2755 - val_mean_absolute_error: 6.6999\n",
      "Epoch 322/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 46.1402 - mean_absolute_error: 3.2666\n",
      "Epoch 322: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3880 - mean_absolute_error: 3.7417 - val_loss: 128.1180 - val_mean_absolute_error: 6.6967\n",
      "Epoch 323/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 85.1565 - mean_absolute_error: 4.5436\n",
      "Epoch 323: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.9645 - mean_absolute_error: 3.5012 - val_loss: 128.0753 - val_mean_absolute_error: 6.6884\n",
      "Epoch 324/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 37.9858 - mean_absolute_error: 3.2218\n",
      "Epoch 324: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8828 - mean_absolute_error: 3.6309 - val_loss: 128.4930 - val_mean_absolute_error: 6.6917\n",
      "Epoch 325/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 63.4331 - mean_absolute_error: 3.4441\n",
      "Epoch 325: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9732 - mean_absolute_error: 3.6589 - val_loss: 128.2002 - val_mean_absolute_error: 6.6912\n",
      "Epoch 326/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 78.2472 - mean_absolute_error: 4.3022\n",
      "Epoch 326: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6791 - mean_absolute_error: 3.5782 - val_loss: 128.3855 - val_mean_absolute_error: 6.7139\n",
      "Epoch 327/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.0198 - mean_absolute_error: 4.0021\n",
      "Epoch 327: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9778 - mean_absolute_error: 3.6229 - val_loss: 128.1889 - val_mean_absolute_error: 6.6844\n",
      "Epoch 328/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.0722 - mean_absolute_error: 3.9159\n",
      "Epoch 328: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.9033 - mean_absolute_error: 3.3846 - val_loss: 128.3664 - val_mean_absolute_error: 6.6907\n",
      "Epoch 329/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 89.6395 - mean_absolute_error: 4.7263\n",
      "Epoch 329: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63.8220 - mean_absolute_error: 3.8008 - val_loss: 128.1362 - val_mean_absolute_error: 6.6920\n",
      "Epoch 330/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 88.0990 - mean_absolute_error: 5.0465\n",
      "Epoch 330: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.0585 - mean_absolute_error: 3.7385 - val_loss: 128.5301 - val_mean_absolute_error: 6.7050\n",
      "Epoch 331/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.9058 - mean_absolute_error: 3.8133\n",
      "Epoch 331: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3973 - mean_absolute_error: 3.5565 - val_loss: 128.2555 - val_mean_absolute_error: 6.6811\n",
      "Epoch 332/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 61.7585 - mean_absolute_error: 4.1069\n",
      "Epoch 332: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6618 - mean_absolute_error: 3.4715 - val_loss: 128.1328 - val_mean_absolute_error: 6.6896\n",
      "Epoch 333/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.9789 - mean_absolute_error: 2.9507\n",
      "Epoch 333: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6805 - mean_absolute_error: 3.5865 - val_loss: 128.0038 - val_mean_absolute_error: 6.6765\n",
      "Epoch 334/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 49.5054 - mean_absolute_error: 3.0149\n",
      "Epoch 334: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9683 - mean_absolute_error: 3.5488 - val_loss: 128.2161 - val_mean_absolute_error: 6.6971\n",
      "Epoch 335/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.2192 - mean_absolute_error: 3.9545\n",
      "Epoch 335: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.2504 - mean_absolute_error: 3.7267 - val_loss: 128.3216 - val_mean_absolute_error: 6.6899\n",
      "Epoch 336/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 50.9784 - mean_absolute_error: 3.3707\n",
      "Epoch 336: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.4061 - mean_absolute_error: 3.4762 - val_loss: 128.2937 - val_mean_absolute_error: 6.6856\n",
      "Epoch 337/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 67.4861 - mean_absolute_error: 3.7064\n",
      "Epoch 337: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6806 - mean_absolute_error: 3.5566 - val_loss: 128.1571 - val_mean_absolute_error: 6.6841\n",
      "Epoch 338/500\n",
      "\u001b[1m21/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.5037 - mean_absolute_error: 3.5923 \n",
      "Epoch 338: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 56.1036 - mean_absolute_error: 3.6061 - val_loss: 128.5551 - val_mean_absolute_error: 6.7081\n",
      "Epoch 339/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 46.5771 - mean_absolute_error: 3.3722\n",
      "Epoch 339: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.9674 - mean_absolute_error: 3.5921 - val_loss: 128.5119 - val_mean_absolute_error: 6.6917\n",
      "Epoch 340/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 59.6851 - mean_absolute_error: 3.6266\n",
      "Epoch 340: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.2770 - mean_absolute_error: 3.5846 - val_loss: 128.3125 - val_mean_absolute_error: 6.6888\n",
      "Epoch 341/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 44.3801 - mean_absolute_error: 3.3695\n",
      "Epoch 341: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.3101 - mean_absolute_error: 3.4401 - val_loss: 128.1130 - val_mean_absolute_error: 6.6703\n",
      "Epoch 342/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.9838 - mean_absolute_error: 3.4710\n",
      "Epoch 342: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3611 - mean_absolute_error: 3.5753 - val_loss: 128.4145 - val_mean_absolute_error: 6.6903\n",
      "Epoch 343/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 49.6428 - mean_absolute_error: 3.5318\n",
      "Epoch 343: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0146 - mean_absolute_error: 3.6017 - val_loss: 128.1839 - val_mean_absolute_error: 6.6847\n",
      "Epoch 344/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 54.4898 - mean_absolute_error: 3.7606\n",
      "Epoch 344: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.2970 - mean_absolute_error: 3.7304 - val_loss: 128.3978 - val_mean_absolute_error: 6.6932\n",
      "Epoch 345/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 68.2587 - mean_absolute_error: 3.9568\n",
      "Epoch 345: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3160 - mean_absolute_error: 3.6840 - val_loss: 128.0432 - val_mean_absolute_error: 6.6713\n",
      "Epoch 346/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 34.2495 - mean_absolute_error: 3.1812\n",
      "Epoch 346: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8752 - mean_absolute_error: 3.6227 - val_loss: 128.3469 - val_mean_absolute_error: 6.6977\n",
      "Epoch 347/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 98.1511 - mean_absolute_error: 4.4592\n",
      "Epoch 347: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7318 - mean_absolute_error: 3.6193 - val_loss: 128.3976 - val_mean_absolute_error: 6.6678\n",
      "Epoch 348/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 31.7121 - mean_absolute_error: 2.8185\n",
      "Epoch 348: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8570 - mean_absolute_error: 3.5175 - val_loss: 127.9508 - val_mean_absolute_error: 6.6821\n",
      "Epoch 349/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 50.5392 - mean_absolute_error: 3.5734\n",
      "Epoch 349: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6748 - mean_absolute_error: 3.5769 - val_loss: 128.3318 - val_mean_absolute_error: 6.6848\n",
      "Epoch 350/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.2371 - mean_absolute_error: 3.5671\n",
      "Epoch 350: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9770 - mean_absolute_error: 3.5190 - val_loss: 128.2438 - val_mean_absolute_error: 6.6794\n",
      "Epoch 351/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79.8375 - mean_absolute_error: 4.3465\n",
      "Epoch 351: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4675 - mean_absolute_error: 3.6888 - val_loss: 128.2738 - val_mean_absolute_error: 6.6747\n",
      "Epoch 352/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 84.0259 - mean_absolute_error: 4.2465\n",
      "Epoch 352: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2552 - mean_absolute_error: 3.7378 - val_loss: 128.4861 - val_mean_absolute_error: 6.6851\n",
      "Epoch 353/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 80.1078 - mean_absolute_error: 3.4919\n",
      "Epoch 353: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9339 - mean_absolute_error: 3.6022 - val_loss: 128.0797 - val_mean_absolute_error: 6.6682\n",
      "Epoch 354/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 32.7694 - mean_absolute_error: 2.6157\n",
      "Epoch 354: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5215 - mean_absolute_error: 3.6200 - val_loss: 128.7864 - val_mean_absolute_error: 6.7008\n",
      "Epoch 355/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 72.6318 - mean_absolute_error: 3.8337\n",
      "Epoch 355: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9388 - mean_absolute_error: 3.5835 - val_loss: 128.2305 - val_mean_absolute_error: 6.6804\n",
      "Epoch 356/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 45.9374 - mean_absolute_error: 2.9901\n",
      "Epoch 356: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.3271 - mean_absolute_error: 3.4583 - val_loss: 128.4595 - val_mean_absolute_error: 6.6799\n",
      "Epoch 357/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 55.3731 - mean_absolute_error: 3.4920\n",
      "Epoch 357: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4228 - mean_absolute_error: 3.6422 - val_loss: 128.2499 - val_mean_absolute_error: 6.6757\n",
      "Epoch 358/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 47.7629 - mean_absolute_error: 3.1181\n",
      "Epoch 358: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.3337 - mean_absolute_error: 3.5633 - val_loss: 128.2064 - val_mean_absolute_error: 6.6700\n",
      "Epoch 359/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 32.7929 - mean_absolute_error: 3.2349\n",
      "Epoch 359: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9301 - mean_absolute_error: 3.6516 - val_loss: 128.3079 - val_mean_absolute_error: 6.6513\n",
      "Epoch 360/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 60.7749 - mean_absolute_error: 3.3443\n",
      "Epoch 360: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.9812 - mean_absolute_error: 3.5409 - val_loss: 128.0981 - val_mean_absolute_error: 6.6517\n",
      "Epoch 361/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 49.0690 - mean_absolute_error: 3.5668\n",
      "Epoch 361: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9274 - mean_absolute_error: 3.7071 - val_loss: 128.4055 - val_mean_absolute_error: 6.6893\n",
      "Epoch 362/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 12.1733 - mean_absolute_error: 2.0560\n",
      "Epoch 362: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.0718 - mean_absolute_error: 3.4011 - val_loss: 128.3513 - val_mean_absolute_error: 6.6617\n",
      "Epoch 363/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81.6556 - mean_absolute_error: 4.4393\n",
      "Epoch 363: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6439 - mean_absolute_error: 3.7096 - val_loss: 128.2729 - val_mean_absolute_error: 6.6611\n",
      "Epoch 364/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 33.7083 - mean_absolute_error: 2.5810\n",
      "Epoch 364: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.1950 - mean_absolute_error: 3.3597 - val_loss: 128.2906 - val_mean_absolute_error: 6.6756\n",
      "Epoch 365/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 31.7657 - mean_absolute_error: 2.7693\n",
      "Epoch 365: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8269 - mean_absolute_error: 3.6821 - val_loss: 128.6498 - val_mean_absolute_error: 6.6680\n",
      "Epoch 366/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 30.2694 - mean_absolute_error: 2.5989\n",
      "Epoch 366: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.9255 - mean_absolute_error: 3.3930 - val_loss: 128.4707 - val_mean_absolute_error: 6.6771\n",
      "Epoch 367/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 57.8676 - mean_absolute_error: 3.6173\n",
      "Epoch 367: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3820 - mean_absolute_error: 3.5142 - val_loss: 128.2960 - val_mean_absolute_error: 6.6599\n",
      "Epoch 368/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 110.5193 - mean_absolute_error: 5.3587\n",
      "Epoch 368: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.0144 - mean_absolute_error: 3.7914 - val_loss: 128.5951 - val_mean_absolute_error: 6.6894\n",
      "Epoch 369/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 92.9337 - mean_absolute_error: 4.8107\n",
      "Epoch 369: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64.0291 - mean_absolute_error: 3.7964 - val_loss: 128.1128 - val_mean_absolute_error: 6.6476\n",
      "Epoch 370/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.9999 - mean_absolute_error: 3.7142\n",
      "Epoch 370: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.0732 - mean_absolute_error: 3.7290 - val_loss: 128.5525 - val_mean_absolute_error: 6.6954\n",
      "Epoch 371/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 97.5364 - mean_absolute_error: 4.7240\n",
      "Epoch 371: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8927 - mean_absolute_error: 3.6294 - val_loss: 128.0578 - val_mean_absolute_error: 6.6609\n",
      "Epoch 372/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 58.9976 - mean_absolute_error: 3.5530\n",
      "Epoch 372: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5444 - mean_absolute_error: 3.6207 - val_loss: 128.6107 - val_mean_absolute_error: 6.6811\n",
      "Epoch 373/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 68.1465 - mean_absolute_error: 4.3957\n",
      "Epoch 373: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9626 - mean_absolute_error: 3.7038 - val_loss: 128.2457 - val_mean_absolute_error: 6.6593\n",
      "Epoch 374/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 39.6211 - mean_absolute_error: 3.1673\n",
      "Epoch 374: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.9618 - mean_absolute_error: 3.5484 - val_loss: 128.4825 - val_mean_absolute_error: 6.6618\n",
      "Epoch 375/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 55.9739 - mean_absolute_error: 3.5637\n",
      "Epoch 375: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6178 - mean_absolute_error: 3.5483 - val_loss: 128.2872 - val_mean_absolute_error: 6.6560\n",
      "Epoch 376/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.7196 - mean_absolute_error: 2.7707\n",
      "Epoch 376: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8611 - mean_absolute_error: 3.6970 - val_loss: 128.0585 - val_mean_absolute_error: 6.6551\n",
      "Epoch 377/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 51.7684 - mean_absolute_error: 3.6519\n",
      "Epoch 377: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8451 - mean_absolute_error: 3.5636 - val_loss: 128.2711 - val_mean_absolute_error: 6.6520\n",
      "Epoch 378/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 48.0364 - mean_absolute_error: 3.4624\n",
      "Epoch 378: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48.5452 - mean_absolute_error: 3.4232 - val_loss: 128.0583 - val_mean_absolute_error: 6.6578\n",
      "Epoch 379/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 49.9110 - mean_absolute_error: 2.8266\n",
      "Epoch 379: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.6486 - mean_absolute_error: 3.6829 - val_loss: 128.0429 - val_mean_absolute_error: 6.6560\n",
      "Epoch 380/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 46.6974 - mean_absolute_error: 2.8589\n",
      "Epoch 380: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.3465 - mean_absolute_error: 3.5172 - val_loss: 128.1630 - val_mean_absolute_error: 6.6620\n",
      "Epoch 381/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.1320 - mean_absolute_error: 2.8751\n",
      "Epoch 381: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6409 - mean_absolute_error: 3.5054 - val_loss: 128.1752 - val_mean_absolute_error: 6.6516\n",
      "Epoch 382/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 70.1090 - mean_absolute_error: 4.1285\n",
      "Epoch 382: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.6334 - mean_absolute_error: 3.5561 - val_loss: 128.0601 - val_mean_absolute_error: 6.6507\n",
      "Epoch 383/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 48.8212 - mean_absolute_error: 3.3974\n",
      "Epoch 383: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8648 - mean_absolute_error: 3.5392 - val_loss: 128.8200 - val_mean_absolute_error: 6.6875\n",
      "Epoch 384/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 77.4895 - mean_absolute_error: 3.9749\n",
      "Epoch 384: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.5672 - mean_absolute_error: 3.7133 - val_loss: 128.1225 - val_mean_absolute_error: 6.6531\n",
      "Epoch 385/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 34.1117 - mean_absolute_error: 3.0093\n",
      "Epoch 385: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.1451 - mean_absolute_error: 3.6215 - val_loss: 128.4055 - val_mean_absolute_error: 6.6623\n",
      "Epoch 386/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 33.6202 - mean_absolute_error: 2.9681\n",
      "Epoch 386: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.3855 - mean_absolute_error: 3.4443 - val_loss: 128.3935 - val_mean_absolute_error: 6.6555\n",
      "Epoch 387/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 49.7369 - mean_absolute_error: 3.5647\n",
      "Epoch 387: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.8037 - mean_absolute_error: 3.6132 - val_loss: 128.0831 - val_mean_absolute_error: 6.6615\n",
      "Epoch 388/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 18.6201 - mean_absolute_error: 2.2356\n",
      "Epoch 388: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8412 - mean_absolute_error: 3.4878 - val_loss: 128.1069 - val_mean_absolute_error: 6.6550\n",
      "Epoch 389/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 89.2296 - mean_absolute_error: 4.1859\n",
      "Epoch 389: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62.8219 - mean_absolute_error: 3.7122 - val_loss: 127.9457 - val_mean_absolute_error: 6.6436\n",
      "Epoch 390/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 75.8342 - mean_absolute_error: 3.9885\n",
      "Epoch 390: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.1797 - mean_absolute_error: 3.6456 - val_loss: 128.0678 - val_mean_absolute_error: 6.6390\n",
      "Epoch 391/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 39.6933 - mean_absolute_error: 3.2725\n",
      "Epoch 391: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2824 - mean_absolute_error: 3.5705 - val_loss: 128.1498 - val_mean_absolute_error: 6.6420\n",
      "Epoch 392/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 41.8261 - mean_absolute_error: 3.1039\n",
      "Epoch 392: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.7849 - mean_absolute_error: 3.4968 - val_loss: 128.0320 - val_mean_absolute_error: 6.6331\n",
      "Epoch 393/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.1792 - mean_absolute_error: 3.7751\n",
      "Epoch 393: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1275 - mean_absolute_error: 3.6326 - val_loss: 127.9413 - val_mean_absolute_error: 6.6451\n",
      "Epoch 394/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 57.6561 - mean_absolute_error: 3.6139\n",
      "Epoch 394: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.9014 - mean_absolute_error: 3.5296 - val_loss: 128.0890 - val_mean_absolute_error: 6.6377\n",
      "Epoch 395/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 50.7739 - mean_absolute_error: 3.4622\n",
      "Epoch 395: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6201 - mean_absolute_error: 3.5270 - val_loss: 128.3272 - val_mean_absolute_error: 6.6473\n",
      "Epoch 396/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41.3000 - mean_absolute_error: 3.2013\n",
      "Epoch 396: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.0142 - mean_absolute_error: 3.5431 - val_loss: 128.0918 - val_mean_absolute_error: 6.6564\n",
      "Epoch 397/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.3743 - mean_absolute_error: 3.9317\n",
      "Epoch 397: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5394 - mean_absolute_error: 3.5645 - val_loss: 127.9045 - val_mean_absolute_error: 6.6466\n",
      "Epoch 398/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.3236 - mean_absolute_error: 3.8896\n",
      "Epoch 398: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.4941 - mean_absolute_error: 3.7527 - val_loss: 128.3309 - val_mean_absolute_error: 6.6468\n",
      "Epoch 399/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 36.2554 - mean_absolute_error: 3.2376\n",
      "Epoch 399: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2688 - mean_absolute_error: 3.5604 - val_loss: 128.3748 - val_mean_absolute_error: 6.6604\n",
      "Epoch 400/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.7484 - mean_absolute_error: 3.2903\n",
      "Epoch 400: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.1955 - mean_absolute_error: 3.5412 - val_loss: 128.3687 - val_mean_absolute_error: 6.6596\n",
      "Epoch 401/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 72.7910 - mean_absolute_error: 4.0762\n",
      "Epoch 401: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2364 - mean_absolute_error: 3.7392 - val_loss: 127.8670 - val_mean_absolute_error: 6.6339\n",
      "Epoch 402/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.2766 - mean_absolute_error: 3.6243\n",
      "Epoch 402: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.8762 - mean_absolute_error: 3.6601 - val_loss: 128.1339 - val_mean_absolute_error: 6.6381\n",
      "Epoch 403/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 37.3052 - mean_absolute_error: 2.9676\n",
      "Epoch 403: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.1193 - mean_absolute_error: 3.4725 - val_loss: 128.4113 - val_mean_absolute_error: 6.6653\n",
      "Epoch 404/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.2041 - mean_absolute_error: 3.6856\n",
      "Epoch 404: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.0966 - mean_absolute_error: 3.6293 - val_loss: 127.9344 - val_mean_absolute_error: 6.6463\n",
      "Epoch 405/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 35.9737 - mean_absolute_error: 3.0698\n",
      "Epoch 405: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.4518 - mean_absolute_error: 3.6232 - val_loss: 128.0987 - val_mean_absolute_error: 6.6467\n",
      "Epoch 406/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79.7757 - mean_absolute_error: 4.3026\n",
      "Epoch 406: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.5935 - mean_absolute_error: 3.7227 - val_loss: 128.1460 - val_mean_absolute_error: 6.6489\n",
      "Epoch 407/500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49.7894 - mean_absolute_error: 3.3605 \n",
      "Epoch 407: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 50.9196 - mean_absolute_error: 3.3991 - val_loss: 127.8799 - val_mean_absolute_error: 6.6249\n",
      "Epoch 408/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 37.1988 - mean_absolute_error: 2.9671\n",
      "Epoch 408: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.0949 - mean_absolute_error: 3.4881 - val_loss: 128.1901 - val_mean_absolute_error: 6.6377\n",
      "Epoch 409/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 57.3801 - mean_absolute_error: 3.3080\n",
      "Epoch 409: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.9240 - mean_absolute_error: 3.4719 - val_loss: 128.4483 - val_mean_absolute_error: 6.6494\n",
      "Epoch 410/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 58.0461 - mean_absolute_error: 3.5768\n",
      "Epoch 410: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.3329 - mean_absolute_error: 3.5803 - val_loss: 128.2449 - val_mean_absolute_error: 6.6528\n",
      "Epoch 411/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 35.3120 - mean_absolute_error: 3.2130\n",
      "Epoch 411: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.1982 - mean_absolute_error: 3.5133 - val_loss: 128.3645 - val_mean_absolute_error: 6.6504\n",
      "Epoch 412/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 67.6909 - mean_absolute_error: 3.9224\n",
      "Epoch 412: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3800 - mean_absolute_error: 3.6356 - val_loss: 128.2521 - val_mean_absolute_error: 6.6541\n",
      "Epoch 413/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 79.7728 - mean_absolute_error: 4.0292\n",
      "Epoch 413: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.3979 - mean_absolute_error: 3.7137 - val_loss: 128.2138 - val_mean_absolute_error: 6.6518\n",
      "Epoch 414/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 45.4221 - mean_absolute_error: 3.3774\n",
      "Epoch 414: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.7895 - mean_absolute_error: 3.6290 - val_loss: 128.3393 - val_mean_absolute_error: 6.6438\n",
      "Epoch 415/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 76.8027 - mean_absolute_error: 4.2760\n",
      "Epoch 415: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.2287 - mean_absolute_error: 3.6803 - val_loss: 128.3294 - val_mean_absolute_error: 6.6371\n",
      "Epoch 416/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 55.5925 - mean_absolute_error: 3.6436\n",
      "Epoch 416: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5264 - mean_absolute_error: 3.6570 - val_loss: 127.9522 - val_mean_absolute_error: 6.6246\n",
      "Epoch 417/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 60.6302 - mean_absolute_error: 3.4665\n",
      "Epoch 417: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0252 - mean_absolute_error: 3.4717 - val_loss: 127.8635 - val_mean_absolute_error: 6.6367\n",
      "Epoch 418/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60.6424 - mean_absolute_error: 3.5588\n",
      "Epoch 418: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5158 - mean_absolute_error: 3.6262 - val_loss: 128.0121 - val_mean_absolute_error: 6.6269\n",
      "Epoch 419/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 34.4375 - mean_absolute_error: 2.9399\n",
      "Epoch 419: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8987 - mean_absolute_error: 3.6853 - val_loss: 127.9902 - val_mean_absolute_error: 6.6203\n",
      "Epoch 420/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.9700 - mean_absolute_error: 3.4377\n",
      "Epoch 420: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5064 - mean_absolute_error: 3.6594 - val_loss: 128.5429 - val_mean_absolute_error: 6.6552\n",
      "Epoch 421/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 69.3603 - mean_absolute_error: 3.6425\n",
      "Epoch 421: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9229 - mean_absolute_error: 3.6434 - val_loss: 128.0647 - val_mean_absolute_error: 6.6333\n",
      "Epoch 422/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 66.3910 - mean_absolute_error: 4.3498\n",
      "Epoch 422: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8606 - mean_absolute_error: 3.6342 - val_loss: 128.0095 - val_mean_absolute_error: 6.6404\n",
      "Epoch 423/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 51.1812 - mean_absolute_error: 3.3780\n",
      "Epoch 423: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.0763 - mean_absolute_error: 3.6127 - val_loss: 128.3308 - val_mean_absolute_error: 6.6421\n",
      "Epoch 424/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 65.3984 - mean_absolute_error: 4.1055\n",
      "Epoch 424: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.5460 - mean_absolute_error: 3.6744 - val_loss: 128.4302 - val_mean_absolute_error: 6.6382\n",
      "Epoch 425/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 34.4160 - mean_absolute_error: 2.7694\n",
      "Epoch 425: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.5091 - mean_absolute_error: 3.5956 - val_loss: 128.1170 - val_mean_absolute_error: 6.6391\n",
      "Epoch 426/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42.5292 - mean_absolute_error: 3.2190\n",
      "Epoch 426: val_loss did not improve from 127.83169\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.8881 - mean_absolute_error: 3.6315 - val_loss: 128.1981 - val_mean_absolute_error: 6.6365\n",
      "Epoch 427/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24.7648 - mean_absolute_error: 2.6875\n",
      "Epoch 427: val_loss improved from 127.83169 to 127.80247, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 51.7229 - mean_absolute_error: 3.4238 - val_loss: 127.8025 - val_mean_absolute_error: 6.6228\n",
      "Epoch 428/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 49.9412 - mean_absolute_error: 3.6096\n",
      "Epoch 428: val_loss did not improve from 127.80247\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8402 - mean_absolute_error: 3.6457 - val_loss: 128.0000 - val_mean_absolute_error: 6.6295\n",
      "Epoch 429/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 66.6825 - mean_absolute_error: 3.6036\n",
      "Epoch 429: val_loss did not improve from 127.80247\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.8216 - mean_absolute_error: 3.6671 - val_loss: 128.2147 - val_mean_absolute_error: 6.6402\n",
      "Epoch 430/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27.6717 - mean_absolute_error: 2.5670\n",
      "Epoch 430: val_loss did not improve from 127.80247\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6262 - mean_absolute_error: 3.5355 - val_loss: 127.8501 - val_mean_absolute_error: 6.6348\n",
      "Epoch 431/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 74.7666 - mean_absolute_error: 4.6498\n",
      "Epoch 431: val_loss did not improve from 127.80247\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.3018 - mean_absolute_error: 3.7865 - val_loss: 127.8681 - val_mean_absolute_error: 6.6167\n",
      "Epoch 432/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 86.3035 - mean_absolute_error: 4.3475\n",
      "Epoch 432: val_loss improved from 127.80247 to 127.76662, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.6361 - mean_absolute_error: 3.5842 - val_loss: 127.7666 - val_mean_absolute_error: 6.6139\n",
      "Epoch 433/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 53.7323 - mean_absolute_error: 3.3375\n",
      "Epoch 433: val_loss did not improve from 127.76662\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0869 - mean_absolute_error: 3.6570 - val_loss: 127.9019 - val_mean_absolute_error: 6.6286\n",
      "Epoch 434/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 38.2868 - mean_absolute_error: 3.2902\n",
      "Epoch 434: val_loss did not improve from 127.76662\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.3532 - mean_absolute_error: 3.5276 - val_loss: 127.9221 - val_mean_absolute_error: 6.6462\n",
      "Epoch 435/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.8269 - mean_absolute_error: 3.8311\n",
      "Epoch 435: val_loss did not improve from 127.76662\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.4947 - mean_absolute_error: 3.5485 - val_loss: 128.0237 - val_mean_absolute_error: 6.6539\n",
      "Epoch 436/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.2960 - mean_absolute_error: 3.2055\n",
      "Epoch 436: val_loss did not improve from 127.76662\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.3138 - mean_absolute_error: 3.5067 - val_loss: 128.2078 - val_mean_absolute_error: 6.6458\n",
      "Epoch 437/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.0719 - mean_absolute_error: 3.3169\n",
      "Epoch 437: val_loss did not improve from 127.76662\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.6981 - mean_absolute_error: 3.5486 - val_loss: 128.1239 - val_mean_absolute_error: 6.6447\n",
      "Epoch 438/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 55.3757 - mean_absolute_error: 3.3307\n",
      "Epoch 438: val_loss improved from 127.76662 to 127.73026, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6620 - mean_absolute_error: 3.5739 - val_loss: 127.7303 - val_mean_absolute_error: 6.6186\n",
      "Epoch 439/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 38.0643 - mean_absolute_error: 2.8525\n",
      "Epoch 439: val_loss improved from 127.73026 to 127.61236, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.3298 - mean_absolute_error: 3.5127 - val_loss: 127.6124 - val_mean_absolute_error: 6.6302\n",
      "Epoch 440/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 54.0819 - mean_absolute_error: 3.4722\n",
      "Epoch 440: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.8946 - mean_absolute_error: 3.4833 - val_loss: 128.1785 - val_mean_absolute_error: 6.6275\n",
      "Epoch 441/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 58.7583 - mean_absolute_error: 3.6753\n",
      "Epoch 441: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6848 - mean_absolute_error: 3.5885 - val_loss: 127.6701 - val_mean_absolute_error: 6.6362\n",
      "Epoch 442/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 34.6649 - mean_absolute_error: 2.7647\n",
      "Epoch 442: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4529 - mean_absolute_error: 3.5886 - val_loss: 127.9618 - val_mean_absolute_error: 6.6212\n",
      "Epoch 443/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.9966 - mean_absolute_error: 3.4122\n",
      "Epoch 443: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9011 - mean_absolute_error: 3.5491 - val_loss: 127.9478 - val_mean_absolute_error: 6.6279\n",
      "Epoch 444/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 53.4989 - mean_absolute_error: 3.6367\n",
      "Epoch 444: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.2368 - mean_absolute_error: 3.6864 - val_loss: 127.8265 - val_mean_absolute_error: 6.6213\n",
      "Epoch 445/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 29.5377 - mean_absolute_error: 2.6699\n",
      "Epoch 445: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6341 - mean_absolute_error: 3.5156 - val_loss: 128.0228 - val_mean_absolute_error: 6.6494\n",
      "Epoch 446/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 45.8487 - mean_absolute_error: 3.2867\n",
      "Epoch 446: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.9342 - mean_absolute_error: 3.6407 - val_loss: 127.8252 - val_mean_absolute_error: 6.6027\n",
      "Epoch 447/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 67.7270 - mean_absolute_error: 4.1632\n",
      "Epoch 447: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.8766 - mean_absolute_error: 3.5843 - val_loss: 127.9073 - val_mean_absolute_error: 6.6536\n",
      "Epoch 448/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 43.0627 - mean_absolute_error: 3.4225\n",
      "Epoch 448: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.0412 - mean_absolute_error: 3.5463 - val_loss: 128.0498 - val_mean_absolute_error: 6.6324\n",
      "Epoch 449/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 93.0173 - mean_absolute_error: 3.9447\n",
      "Epoch 449: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.1353 - mean_absolute_error: 3.6294 - val_loss: 127.7822 - val_mean_absolute_error: 6.6261\n",
      "Epoch 450/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15.2575 - mean_absolute_error: 2.0215\n",
      "Epoch 450: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.1154 - mean_absolute_error: 3.4183 - val_loss: 127.9425 - val_mean_absolute_error: 6.6353\n",
      "Epoch 451/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.3680 - mean_absolute_error: 2.7986\n",
      "Epoch 451: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.5176 - mean_absolute_error: 3.4560 - val_loss: 127.8790 - val_mean_absolute_error: 6.6098\n",
      "Epoch 452/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56.7099 - mean_absolute_error: 3.6666\n",
      "Epoch 452: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1894 - mean_absolute_error: 3.5492 - val_loss: 127.7399 - val_mean_absolute_error: 6.6196\n",
      "Epoch 453/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 64.8532 - mean_absolute_error: 3.7346\n",
      "Epoch 453: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.4464 - mean_absolute_error: 3.6205 - val_loss: 127.9439 - val_mean_absolute_error: 6.6299\n",
      "Epoch 454/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 86.9124 - mean_absolute_error: 4.2290\n",
      "Epoch 454: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8377 - mean_absolute_error: 3.6390 - val_loss: 127.8150 - val_mean_absolute_error: 6.6154\n",
      "Epoch 455/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 104.9807 - mean_absolute_error: 4.8726\n",
      "Epoch 455: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.8189 - mean_absolute_error: 3.6971 - val_loss: 127.8936 - val_mean_absolute_error: 6.6131\n",
      "Epoch 456/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 35.8620 - mean_absolute_error: 3.0798\n",
      "Epoch 456: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49.9013 - mean_absolute_error: 3.3950 - val_loss: 127.7420 - val_mean_absolute_error: 6.6167\n",
      "Epoch 457/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 54.6521 - mean_absolute_error: 3.4584\n",
      "Epoch 457: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.6093 - mean_absolute_error: 3.4748 - val_loss: 127.9673 - val_mean_absolute_error: 6.6405\n",
      "Epoch 458/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 38.7404 - mean_absolute_error: 3.1442\n",
      "Epoch 458: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2266 - mean_absolute_error: 3.4902 - val_loss: 127.7550 - val_mean_absolute_error: 6.6089\n",
      "Epoch 459/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 33.7130 - mean_absolute_error: 2.9198\n",
      "Epoch 459: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.0056 - mean_absolute_error: 3.4645 - val_loss: 128.0361 - val_mean_absolute_error: 6.6441\n",
      "Epoch 460/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 57.3585 - mean_absolute_error: 4.0757\n",
      "Epoch 460: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.9558 - mean_absolute_error: 3.6265 - val_loss: 127.6582 - val_mean_absolute_error: 6.6100\n",
      "Epoch 461/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 31.0204 - mean_absolute_error: 2.6797\n",
      "Epoch 461: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.1389 - mean_absolute_error: 3.5615 - val_loss: 127.9343 - val_mean_absolute_error: 6.6179\n",
      "Epoch 462/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 48.8303 - mean_absolute_error: 3.5109\n",
      "Epoch 462: val_loss did not improve from 127.61236\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1419 - mean_absolute_error: 3.5435 - val_loss: 127.6872 - val_mean_absolute_error: 6.6174\n",
      "Epoch 463/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 136.3648 - mean_absolute_error: 5.5460\n",
      "Epoch 463: val_loss improved from 127.61236 to 127.46246, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.7872 - mean_absolute_error: 3.7787 - val_loss: 127.4625 - val_mean_absolute_error: 6.6247\n",
      "Epoch 464/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 51.6009 - mean_absolute_error: 3.5046\n",
      "Epoch 464: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.9251 - mean_absolute_error: 3.6810 - val_loss: 127.8736 - val_mean_absolute_error: 6.6223\n",
      "Epoch 465/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38.4771 - mean_absolute_error: 2.8520\n",
      "Epoch 465: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.8454 - mean_absolute_error: 3.4417 - val_loss: 127.7097 - val_mean_absolute_error: 6.5947\n",
      "Epoch 466/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65.8515 - mean_absolute_error: 3.7886\n",
      "Epoch 466: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.7354 - mean_absolute_error: 3.5573 - val_loss: 127.9608 - val_mean_absolute_error: 6.6281\n",
      "Epoch 467/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 46.8666 - mean_absolute_error: 3.7199\n",
      "Epoch 467: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.4395 - mean_absolute_error: 3.6689 - val_loss: 127.8958 - val_mean_absolute_error: 6.6119\n",
      "Epoch 468/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 39.4075 - mean_absolute_error: 2.9915\n",
      "Epoch 468: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.7315 - mean_absolute_error: 3.5094 - val_loss: 127.6699 - val_mean_absolute_error: 6.6145\n",
      "Epoch 469/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 21.5521 - mean_absolute_error: 2.6017\n",
      "Epoch 469: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.6612 - mean_absolute_error: 3.4970 - val_loss: 128.0347 - val_mean_absolute_error: 6.6355\n",
      "Epoch 470/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 135.3137 - mean_absolute_error: 5.6409\n",
      "Epoch 470: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65.1898 - mean_absolute_error: 3.8415 - val_loss: 127.6187 - val_mean_absolute_error: 6.6152\n",
      "Epoch 471/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 78.5284 - mean_absolute_error: 3.9878\n",
      "Epoch 471: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.5458 - mean_absolute_error: 3.5290 - val_loss: 127.7359 - val_mean_absolute_error: 6.6236\n",
      "Epoch 472/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 39.3219 - mean_absolute_error: 2.8669\n",
      "Epoch 472: val_loss did not improve from 127.46246\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.3324 - mean_absolute_error: 3.4085 - val_loss: 128.4601 - val_mean_absolute_error: 6.6248\n",
      "Epoch 473/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 65.5578 - mean_absolute_error: 3.7525\n",
      "Epoch 473: val_loss improved from 127.46246 to 127.31538, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.0255 - mean_absolute_error: 3.5777 - val_loss: 127.3154 - val_mean_absolute_error: 6.6014\n",
      "Epoch 474/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 94.5459 - mean_absolute_error: 4.2861\n",
      "Epoch 474: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0142 - mean_absolute_error: 3.6166 - val_loss: 127.6531 - val_mean_absolute_error: 6.6096\n",
      "Epoch 475/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 26.5833 - mean_absolute_error: 2.5848\n",
      "Epoch 475: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53.7859 - mean_absolute_error: 3.5012 - val_loss: 127.6233 - val_mean_absolute_error: 6.5998\n",
      "Epoch 476/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 27.0411 - mean_absolute_error: 2.7782\n",
      "Epoch 476: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.3873 - mean_absolute_error: 3.4562 - val_loss: 128.1197 - val_mean_absolute_error: 6.6152\n",
      "Epoch 477/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 108.9942 - mean_absolute_error: 4.5231\n",
      "Epoch 477: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61.8448 - mean_absolute_error: 3.6961 - val_loss: 127.4829 - val_mean_absolute_error: 6.5896\n",
      "Epoch 478/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48.0241 - mean_absolute_error: 3.6345\n",
      "Epoch 478: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0333 - mean_absolute_error: 3.6920 - val_loss: 127.8323 - val_mean_absolute_error: 6.6276\n",
      "Epoch 479/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 62.2996 - mean_absolute_error: 3.9481\n",
      "Epoch 479: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.6364 - mean_absolute_error: 3.5765 - val_loss: 128.2192 - val_mean_absolute_error: 6.6276\n",
      "Epoch 480/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42.1273 - mean_absolute_error: 3.1283\n",
      "Epoch 480: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.9979 - mean_absolute_error: 3.4406 - val_loss: 127.4714 - val_mean_absolute_error: 6.6144\n",
      "Epoch 481/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43.2983 - mean_absolute_error: 3.3849\n",
      "Epoch 481: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.5216 - mean_absolute_error: 3.5699 - val_loss: 127.7155 - val_mean_absolute_error: 6.6108\n",
      "Epoch 482/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 47.0171 - mean_absolute_error: 2.9864\n",
      "Epoch 482: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0032 - mean_absolute_error: 3.5521 - val_loss: 127.9738 - val_mean_absolute_error: 6.5850\n",
      "Epoch 483/500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.3055 - mean_absolute_error: 3.5841 \n",
      "Epoch 483: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 55.4576 - mean_absolute_error: 3.5855 - val_loss: 127.6789 - val_mean_absolute_error: 6.6152\n",
      "Epoch 484/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 35.4986 - mean_absolute_error: 3.0780\n",
      "Epoch 484: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.9448 - mean_absolute_error: 3.4114 - val_loss: 127.7838 - val_mean_absolute_error: 6.6148\n",
      "Epoch 485/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 28.0476 - mean_absolute_error: 2.7403\n",
      "Epoch 485: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.2485 - mean_absolute_error: 3.3774 - val_loss: 127.6701 - val_mean_absolute_error: 6.6017\n",
      "Epoch 486/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 60.4361 - mean_absolute_error: 3.6177\n",
      "Epoch 486: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5545 - mean_absolute_error: 3.5581 - val_loss: 127.8961 - val_mean_absolute_error: 6.6291\n",
      "Epoch 487/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59.2442 - mean_absolute_error: 3.4762\n",
      "Epoch 487: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.2698 - mean_absolute_error: 3.6743 - val_loss: 127.3833 - val_mean_absolute_error: 6.5861\n",
      "Epoch 488/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41.2402 - mean_absolute_error: 3.0250\n",
      "Epoch 488: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.5016 - mean_absolute_error: 3.5513 - val_loss: 127.8865 - val_mean_absolute_error: 6.6174\n",
      "Epoch 489/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 50.4173 - mean_absolute_error: 3.3902\n",
      "Epoch 489: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60.9778 - mean_absolute_error: 3.7579 - val_loss: 127.3530 - val_mean_absolute_error: 6.5820\n",
      "Epoch 490/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 30.4486 - mean_absolute_error: 2.5666\n",
      "Epoch 490: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.2692 - mean_absolute_error: 3.4918 - val_loss: 127.8297 - val_mean_absolute_error: 6.6165\n",
      "Epoch 491/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58.0479 - mean_absolute_error: 3.6842\n",
      "Epoch 491: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58.0761 - mean_absolute_error: 3.6588 - val_loss: 127.6309 - val_mean_absolute_error: 6.6155\n",
      "Epoch 492/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 39.1849 - mean_absolute_error: 3.0580\n",
      "Epoch 492: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.4259 - mean_absolute_error: 3.4386 - val_loss: 127.8397 - val_mean_absolute_error: 6.6099\n",
      "Epoch 493/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 44.0968 - mean_absolute_error: 3.3631\n",
      "Epoch 493: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59.9285 - mean_absolute_error: 3.6952 - val_loss: 127.5806 - val_mean_absolute_error: 6.6126\n",
      "Epoch 494/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 58.5657 - mean_absolute_error: 3.6268\n",
      "Epoch 494: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55.0856 - mean_absolute_error: 3.5537 - val_loss: 127.7659 - val_mean_absolute_error: 6.6071\n",
      "Epoch 495/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 74.1929 - mean_absolute_error: 4.5149\n",
      "Epoch 495: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.2742 - mean_absolute_error: 3.6837 - val_loss: 127.4093 - val_mean_absolute_error: 6.5901\n",
      "Epoch 496/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24.5252 - mean_absolute_error: 2.5172\n",
      "Epoch 496: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.4482 - mean_absolute_error: 3.4808 - val_loss: 128.2972 - val_mean_absolute_error: 6.6288\n",
      "Epoch 497/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 44.6944 - mean_absolute_error: 3.4657\n",
      "Epoch 497: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52.6684 - mean_absolute_error: 3.5084 - val_loss: 127.8681 - val_mean_absolute_error: 6.5960\n",
      "Epoch 498/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 58.9623 - mean_absolute_error: 4.0838\n",
      "Epoch 498: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56.1498 - mean_absolute_error: 3.6014 - val_loss: 127.6966 - val_mean_absolute_error: 6.6066\n",
      "Epoch 499/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 71.4267 - mean_absolute_error: 3.5691\n",
      "Epoch 499: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.7900 - mean_absolute_error: 3.4611 - val_loss: 127.6909 - val_mean_absolute_error: 6.5961\n",
      "Epoch 500/500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 76.0677 - mean_absolute_error: 4.4891\n",
      "Epoch 500: val_loss did not improve from 127.31538\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3660 - mean_absolute_error: 3.6712 - val_loss: 127.6528 - val_mean_absolute_error: 6.6028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e648cf6530>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=500, callbacks=[cp7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(InputLayer((1, 5)))\n",
    "model7.add(Conv1D(64, kernel_size=1, activation='relu'))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(8, 'relu'))\n",
    "model7.add(Dense(5, 'linear'))\n",
    "model7.load_weights('checkpoints.model7.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions3(model, X, y, cols, start=0, end=100):\n",
    "    predictions = model.predict(X)-80\n",
    "    df = pd.DataFrame(data=predictions)\n",
    "    df.columns=cols\n",
    "    org = pd.DataFrame(data=y)\n",
    "    org.columns = cols\n",
    "    plt.plot(df['PM2.5 (µg/m³)'][start:end])\n",
    "    plt.plot(org['PM2.5 (µg/m³)'][start:end])\n",
    "    a = org.astype('float32')\n",
    "    print(predictions[:,-1].dtype)\n",
    "    ma = mae(a['PM2.5 (µg/m³)'],df['PM2.5 (µg/m³)'])\n",
    "    return df[start:end], org, ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_7, org_7, mae_7 = plot_predictions3(model7, x_test_9, y_test_9,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.231552"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df_7.index = val.index\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_7['PM2.5 (µg/m³)']])\n",
    "org_7.index = val.index\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], org_7['PM2.5 (µg/m³)']])\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction')\n",
    "plt.plot(df_org.index[len(df_corr['PM2.5 (µg/m³)']):],df_org[len(df_corr['PM2.5 (µg/m³)']):],color='green',label='actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
