{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "EbrFD1vMR_qS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ls sub -26, cn -39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "RRVN-4QOSKAx",
    "outputId": "0fae4e16-1266-4d53-81fe-2ef0c08efb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     PM2.5 (µg/m³)  PM10 (µg/m³)  NO (µg/m³)  NO2 (µg/m³)  \\\n",
      "PM2.5 (µg/m³)             1.000000      0.859977    0.492519     0.467814   \n",
      "PM10 (µg/m³)              0.859977      1.000000    0.584055     0.509675   \n",
      "NO (µg/m³)                0.492519      0.584055    1.000000     0.629851   \n",
      "NO2 (µg/m³)               0.467814      0.509675    0.629851     1.000000   \n",
      "NOx (ppb)                 0.521376      0.606035    0.951826     0.827521   \n",
      "NH3 (µg/m³)               0.507318      0.526585    0.481089     0.510274   \n",
      "SO2 (µg/m³)               0.207822      0.198121    0.097967     0.064959   \n",
      "CO (mg/m³)                0.367459      0.505559    0.442598     0.236357   \n",
      "Ozone (µg/m³)             0.078025      0.061609   -0.138730    -0.091195   \n",
      "Benzene (µg/m³)           0.439359      0.511498    0.445780     0.434731   \n",
      "Toluene (µg/m³)           0.345766      0.470154    0.489967     0.403619   \n",
      "Eth-Benzene (µg/m³)       0.360241      0.477562    0.474254     0.334586   \n",
      "MP-Xylene (µg/m³)         0.314345      0.434956    0.432510     0.283098   \n",
      "RH (%)                   -0.046565     -0.185141   -0.027752    -0.144242   \n",
      "WS (m/s)                 -0.524779     -0.474433   -0.334477    -0.300488   \n",
      "WD (deg)                  0.134968      0.168010    0.035243     0.185809   \n",
      "SR (W/mt2)               -0.286794     -0.225924   -0.182650    -0.232199   \n",
      "VWS (m/s)                -0.011533     -0.022226   -0.081529    -0.094850   \n",
      "\n",
      "                     NOx (ppb)  NH3 (µg/m³)  SO2 (µg/m³)  CO (mg/m³)  \\\n",
      "PM2.5 (µg/m³)         0.521376     0.507318     0.207822    0.367459   \n",
      "PM10 (µg/m³)          0.606035     0.526585     0.198121    0.505559   \n",
      "NO (µg/m³)            0.951826     0.481089     0.097967    0.442598   \n",
      "NO2 (µg/m³)           0.827521     0.510274     0.064959    0.236357   \n",
      "NOx (ppb)             1.000000     0.537695     0.096694    0.396965   \n",
      "NH3 (µg/m³)           0.537695     1.000000     0.185126    0.317417   \n",
      "SO2 (µg/m³)           0.096694     0.185126     1.000000   -0.052107   \n",
      "CO (mg/m³)            0.396965     0.317417    -0.052107    1.000000   \n",
      "Ozone (µg/m³)        -0.135090     0.055435     0.195217   -0.114237   \n",
      "Benzene (µg/m³)       0.486515     0.490234     0.010080    0.405390   \n",
      "Toluene (µg/m³)       0.511816     0.448337    -0.000633    0.418526   \n",
      "Eth-Benzene (µg/m³)   0.471667     0.471091     0.073816    0.524031   \n",
      "MP-Xylene (µg/m³)     0.422529     0.420648     0.018287    0.544793   \n",
      "RH (%)               -0.081387    -0.146311    -0.164353    0.048932   \n",
      "WS (m/s)             -0.341115    -0.294962    -0.073760   -0.286213   \n",
      "WD (deg)              0.097000     0.095900    -0.011007    0.003783   \n",
      "SR (W/mt2)           -0.219190    -0.221125    -0.088748   -0.096969   \n",
      "VWS (m/s)            -0.094296    -0.016239    -0.032397   -0.004727   \n",
      "\n",
      "                     Ozone (µg/m³)  Benzene (µg/m³)  Toluene (µg/m³)  \\\n",
      "PM2.5 (µg/m³)             0.078025         0.439359         0.345766   \n",
      "PM10 (µg/m³)              0.061609         0.511498         0.470154   \n",
      "NO (µg/m³)               -0.138730         0.445780         0.489967   \n",
      "NO2 (µg/m³)              -0.091195         0.434731         0.403619   \n",
      "NOx (ppb)                -0.135090         0.486515         0.511816   \n",
      "NH3 (µg/m³)               0.055435         0.490234         0.448337   \n",
      "SO2 (µg/m³)               0.195217         0.010080        -0.000633   \n",
      "CO (mg/m³)               -0.114237         0.405390         0.418526   \n",
      "Ozone (µg/m³)             1.000000        -0.130130        -0.166124   \n",
      "Benzene (µg/m³)          -0.130130         1.000000         0.879310   \n",
      "Toluene (µg/m³)          -0.166124         0.879310         1.000000   \n",
      "Eth-Benzene (µg/m³)      -0.100715         0.807990         0.890183   \n",
      "MP-Xylene (µg/m³)        -0.100726         0.785401         0.853799   \n",
      "RH (%)                   -0.330812        -0.007645        -0.099462   \n",
      "WS (m/s)                 -0.005168        -0.286395        -0.241916   \n",
      "WD (deg)                 -0.086142         0.124267         0.107111   \n",
      "SR (W/mt2)                0.103521        -0.220357        -0.187921   \n",
      "VWS (m/s)                -0.020510        -0.047669        -0.082249   \n",
      "\n",
      "                     Eth-Benzene (µg/m³)  MP-Xylene (µg/m³)    RH (%)  \\\n",
      "PM2.5 (µg/m³)                   0.360241           0.314345 -0.046565   \n",
      "PM10 (µg/m³)                    0.477562           0.434956 -0.185141   \n",
      "NO (µg/m³)                      0.474254           0.432510 -0.027752   \n",
      "NO2 (µg/m³)                     0.334586           0.283098 -0.144242   \n",
      "NOx (ppb)                       0.471667           0.422529 -0.081387   \n",
      "NH3 (µg/m³)                     0.471091           0.420648 -0.146311   \n",
      "SO2 (µg/m³)                     0.073816           0.018287 -0.164353   \n",
      "CO (mg/m³)                      0.524031           0.544793  0.048932   \n",
      "Ozone (µg/m³)                  -0.100715          -0.100726 -0.330812   \n",
      "Benzene (µg/m³)                 0.807990           0.785401 -0.007645   \n",
      "Toluene (µg/m³)                 0.890183           0.853799 -0.099462   \n",
      "Eth-Benzene (µg/m³)             1.000000           0.951079 -0.051597   \n",
      "MP-Xylene (µg/m³)               0.951079           1.000000 -0.048709   \n",
      "RH (%)                         -0.051597          -0.048709  1.000000   \n",
      "WS (m/s)                       -0.270008          -0.234108 -0.087384   \n",
      "WD (deg)                        0.054012           0.027077 -0.295626   \n",
      "SR (W/mt2)                     -0.169430          -0.117799 -0.281979   \n",
      "VWS (m/s)                      -0.076582          -0.078685  0.049842   \n",
      "\n",
      "                     WS (m/s)  WD (deg)  SR (W/mt2)  VWS (m/s)  \n",
      "PM2.5 (µg/m³)       -0.524779  0.134968   -0.286794  -0.011533  \n",
      "PM10 (µg/m³)        -0.474433  0.168010   -0.225924  -0.022226  \n",
      "NO (µg/m³)          -0.334477  0.035243   -0.182650  -0.081529  \n",
      "NO2 (µg/m³)         -0.300488  0.185809   -0.232199  -0.094850  \n",
      "NOx (ppb)           -0.341115  0.097000   -0.219190  -0.094296  \n",
      "NH3 (µg/m³)         -0.294962  0.095900   -0.221125  -0.016239  \n",
      "SO2 (µg/m³)         -0.073760 -0.011007   -0.088748  -0.032397  \n",
      "CO (mg/m³)          -0.286213  0.003783   -0.096969  -0.004727  \n",
      "Ozone (µg/m³)       -0.005168 -0.086142    0.103521  -0.020510  \n",
      "Benzene (µg/m³)     -0.286395  0.124267   -0.220357  -0.047669  \n",
      "Toluene (µg/m³)     -0.241916  0.107111   -0.187921  -0.082249  \n",
      "Eth-Benzene (µg/m³) -0.270008  0.054012   -0.169430  -0.076582  \n",
      "MP-Xylene (µg/m³)   -0.234108  0.027077   -0.117799  -0.078685  \n",
      "RH (%)              -0.087384 -0.295626   -0.281979   0.049842  \n",
      "WS (m/s)             1.000000 -0.199317    0.119269  -0.061950  \n",
      "WD (deg)            -0.199317  1.000000    0.047724  -0.048472  \n",
      "SR (W/mt2)           0.119269  0.047724    1.000000   0.014303  \n",
      "VWS (m/s)           -0.061950 -0.048472    0.014303   1.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\DHAN RAJ\\\\Downloads\\\\btp_forecast_preprocessed_data\\\\delhi\\\\daily\\\\imputed_daily_delhi_data.csv')\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "data = df.drop(columns=['Timestamp'])\n",
    "# Assuming df is your DataFrame\n",
    "correlation_matrix = data.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correlation threshold\n",
    "threshold = 0.2\n",
    "\n",
    "# Find pairs with correlation above threshold\n",
    "highly_correlated_pairs = [(column1, 'PM2.5 (µg/m³)') for column1 in correlation_matrix.columns if abs(correlation_matrix[column1]['PM2.5 (µg/m³)']) > threshold and column1 != 'PM2.5 (µg/m³)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality Test for pair ('PM10 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=3.7076  , p=0.0544  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=3.7178  , p=0.0538  , df=1\n",
      "likelihood ratio test: chi2=3.7115  , p=0.0540  , df=1\n",
      "parameter F test:         F=3.7076  , p=0.0544  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=7.9713  , p=0.0004  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=16.0159 , p=0.0003  , df=2\n",
      "likelihood ratio test: chi2=15.8997 , p=0.0004  , df=2\n",
      "parameter F test:         F=7.9713  , p=0.0004  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.4106  , p=0.0170  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=10.2979 , p=0.0162  , df=3\n",
      "likelihood ratio test: chi2=10.2497 , p=0.0166  , df=3\n",
      "parameter F test:         F=3.4106  , p=0.0170  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.5909  , p=0.0353  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=10.4500 , p=0.0335  , df=4\n",
      "likelihood ratio test: chi2=10.4002 , p=0.0342  , df=4\n",
      "parameter F test:         F=2.5909  , p=0.0353  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.7642  , p=0.1174  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=8.9108  , p=0.1127  , df=5\n",
      "likelihood ratio test: chi2=8.8746  , p=0.1142  , df=5\n",
      "parameter F test:         F=1.7642  , p=0.1174  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.1785  , p=0.0428  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=13.2292 , p=0.0395  , df=6\n",
      "likelihood ratio test: chi2=13.1495 , p=0.0407  , df=6\n",
      "parameter F test:         F=2.1785  , p=0.0428  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.7264  , p=0.0991  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=12.2537 , p=0.0925  , df=7\n",
      "likelihood ratio test: chi2=12.1852 , p=0.0946  , df=7\n",
      "parameter F test:         F=1.7264  , p=0.0991  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.4930  , p=0.1552  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=12.1341 , p=0.1453  , df=8\n",
      "likelihood ratio test: chi2=12.0669 , p=0.1482  , df=8\n",
      "parameter F test:         F=1.4930  , p=0.1552  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.0203  , p=0.0342  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=18.5064 , p=0.0297  , df=9\n",
      "likelihood ratio test: chi2=18.3505 , p=0.0313  , df=9\n",
      "parameter F test:         F=2.0203  , p=0.0342  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.7060  , p=0.0746  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=17.3969 , p=0.0660  , df=10\n",
      "likelihood ratio test: chi2=17.2589 , p=0.0688  , df=10\n",
      "parameter F test:         F=1.7060  , p=0.0746  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NO (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=10.7762 , p=0.0011  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=10.8059 , p=0.0010  , df=1\n",
      "likelihood ratio test: chi2=10.7528 , p=0.0010  , df=1\n",
      "parameter F test:         F=10.7762 , p=0.0011  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=4.1549  , p=0.0159  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=8.3480  , p=0.0154  , df=2\n",
      "likelihood ratio test: chi2=8.3163  , p=0.0156  , df=2\n",
      "parameter F test:         F=4.1549  , p=0.0159  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.1577  , p=0.0914  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=6.5149  , p=0.0891  , df=3\n",
      "likelihood ratio test: chi2=6.4955  , p=0.0898  , df=3\n",
      "parameter F test:         F=2.1577  , p=0.0914  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.8214  , p=0.1224  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=7.3461  , p=0.1187  , df=4\n",
      "likelihood ratio test: chi2=7.3215  , p=0.1198  , df=4\n",
      "parameter F test:         F=1.8214  , p=0.1224  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.9798  , p=0.0791  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=9.9999  , p=0.0752  , df=5\n",
      "likelihood ratio test: chi2=9.9543  , p=0.0765  , df=5\n",
      "parameter F test:         F=1.9798  , p=0.0791  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.8299  , p=0.0097  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=17.1848 , p=0.0086  , df=6\n",
      "likelihood ratio test: chi2=17.0506 , p=0.0091  , df=6\n",
      "parameter F test:         F=2.8299  , p=0.0097  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.5742  , p=0.1391  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=11.1734 , p=0.1312  , df=7\n",
      "likelihood ratio test: chi2=11.1164 , p=0.1336  , df=7\n",
      "parameter F test:         F=1.5742  , p=0.1391  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.4051  , p=0.1899  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=11.4197 , p=0.1790  , df=8\n",
      "likelihood ratio test: chi2=11.3601 , p=0.1821  , df=8\n",
      "parameter F test:         F=1.4051  , p=0.1899  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.2326  , p=0.2708  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=11.2906 , p=0.2563  , df=9\n",
      "likelihood ratio test: chi2=11.2323 , p=0.2601  , df=9\n",
      "parameter F test:         F=1.2326  , p=0.2708  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.4315  , p=0.1609  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=14.5971 , p=0.1475  , df=10\n",
      "likelihood ratio test: chi2=14.4998 , p=0.1514  , df=10\n",
      "parameter F test:         F=1.4315  , p=0.1609  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NO2 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.0823  , p=0.7743  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=0.0825  , p=0.7739  , df=1\n",
      "likelihood ratio test: chi2=0.0825  , p=0.7739  , df=1\n",
      "parameter F test:         F=0.0823  , p=0.7743  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=4.1015  , p=0.0168  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=8.2406  , p=0.0162  , df=2\n",
      "likelihood ratio test: chi2=8.2097  , p=0.0165  , df=2\n",
      "parameter F test:         F=4.1015  , p=0.0168  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.1605  , p=0.0239  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=9.5426  , p=0.0229  , df=3\n",
      "likelihood ratio test: chi2=9.5012  , p=0.0233  , df=3\n",
      "parameter F test:         F=3.1605  , p=0.0239  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.3456  , p=0.0529  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=9.4606  , p=0.0506  , df=4\n",
      "likelihood ratio test: chi2=9.4198  , p=0.0514  , df=4\n",
      "parameter F test:         F=2.3456  , p=0.0529  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=2.0826  , p=0.0652  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=10.5193 , p=0.0618  , df=5\n",
      "likelihood ratio test: chi2=10.4689 , p=0.0630  , df=5\n",
      "parameter F test:         F=2.0826  , p=0.0652  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.7878  , p=0.0107  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=16.9287 , p=0.0095  , df=6\n",
      "likelihood ratio test: chi2=16.7985 , p=0.0101  , df=6\n",
      "parameter F test:         F=2.7878  , p=0.0107  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.5844  , p=0.0121  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=18.3438 , p=0.0105  , df=7\n",
      "likelihood ratio test: chi2=18.1909 , p=0.0111  , df=7\n",
      "parameter F test:         F=2.5844  , p=0.0121  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.2134  , p=0.0243  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=17.9884 , p=0.0213  , df=8\n",
      "likelihood ratio test: chi2=17.8411 , p=0.0224  , df=8\n",
      "parameter F test:         F=2.2134  , p=0.0243  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.9986  , p=0.0364  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=18.3074 , p=0.0318  , df=9\n",
      "likelihood ratio test: chi2=18.1548 , p=0.0334  , df=9\n",
      "parameter F test:         F=1.9986  , p=0.0364  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.8372  , p=0.0504  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=18.7344 , p=0.0438  , df=10\n",
      "likelihood ratio test: chi2=18.5745 , p=0.0460  , df=10\n",
      "parameter F test:         F=1.8372  , p=0.0504  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NOx (ppb)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=3.0346  , p=0.0818  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=3.0429  , p=0.0811  , df=1\n",
      "likelihood ratio test: chi2=3.0387  , p=0.0813  , df=1\n",
      "parameter F test:         F=3.0346  , p=0.0818  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.0401  , p=0.1305  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=4.0991  , p=0.1288  , df=2\n",
      "likelihood ratio test: chi2=4.0914  , p=0.1293  , df=2\n",
      "parameter F test:         F=2.0401  , p=0.1305  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.6018  , p=0.6139  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=1.8170  , p=0.6112  , df=3\n",
      "likelihood ratio test: chi2=1.8155  , p=0.6116  , df=3\n",
      "parameter F test:         F=0.6018  , p=0.6139  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.8011  , p=0.5245  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=3.2310  , p=0.5199  , df=4\n",
      "likelihood ratio test: chi2=3.2263  , p=0.5207  , df=4\n",
      "parameter F test:         F=0.8011  , p=0.5245  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.7930  , p=0.5548  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=4.0052  , p=0.5487  , df=5\n",
      "likelihood ratio test: chi2=3.9979  , p=0.5497  , df=5\n",
      "parameter F test:         F=0.7930  , p=0.5548  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.1844  , p=0.0422  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=13.2645 , p=0.0390  , df=6\n",
      "likelihood ratio test: chi2=13.1844 , p=0.0402  , df=6\n",
      "parameter F test:         F=2.1844  , p=0.0422  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.5666  , p=0.1414  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=11.1198 , p=0.1335  , df=7\n",
      "likelihood ratio test: chi2=11.0634 , p=0.1359  , df=7\n",
      "parameter F test:         F=1.5666  , p=0.1414  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.5105  , p=0.1490  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=12.2757 , p=0.1393  , df=8\n",
      "likelihood ratio test: chi2=12.2069 , p=0.1422  , df=8\n",
      "parameter F test:         F=1.5105  , p=0.1490  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.2392  , p=0.2668  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=11.3512 , p=0.2524  , df=9\n",
      "likelihood ratio test: chi2=11.2922 , p=0.2562  , df=9\n",
      "parameter F test:         F=1.2392  , p=0.2668  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.3846  , p=0.1819  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=14.1198 , p=0.1676  , df=10\n",
      "likelihood ratio test: chi2=14.0287 , p=0.1717  , df=10\n",
      "parameter F test:         F=1.3846  , p=0.1819  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('NH3 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=8.1706  , p=0.0043  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=8.1931  , p=0.0042  , df=1\n",
      "likelihood ratio test: chi2=8.1625  , p=0.0043  , df=1\n",
      "parameter F test:         F=8.1706  , p=0.0043  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=4.1521  , p=0.0160  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=8.3424  , p=0.0154  , df=2\n",
      "likelihood ratio test: chi2=8.3108  , p=0.0157  , df=2\n",
      "parameter F test:         F=4.1521  , p=0.0160  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.0350  , p=0.0284  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=9.1637  , p=0.0272  , df=3\n",
      "likelihood ratio test: chi2=9.1255  , p=0.0277  , df=3\n",
      "parameter F test:         F=3.0350  , p=0.0284  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=2.1744  , p=0.0699  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=8.7699  , p=0.0671  , df=4\n",
      "likelihood ratio test: chi2=8.7349  , p=0.0681  , df=4\n",
      "parameter F test:         F=2.1744  , p=0.0699  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.6982  , p=0.1322  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=8.5773  , p=0.1272  , df=5\n",
      "likelihood ratio test: chi2=8.5438  , p=0.1287  , df=5\n",
      "parameter F test:         F=1.6982  , p=0.1322  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.9399  , p=0.0715  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=11.7803 , p=0.0671  , df=6\n",
      "likelihood ratio test: chi2=11.7170 , p=0.0686  , df=6\n",
      "parameter F test:         F=1.9399  , p=0.0715  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.1910  , p=0.0328  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=15.5511 , p=0.0295  , df=7\n",
      "likelihood ratio test: chi2=15.4410 , p=0.0307  , df=7\n",
      "parameter F test:         F=2.1910  , p=0.0328  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.8583  , p=0.0630  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=15.1027 , p=0.0572  , df=8\n",
      "likelihood ratio test: chi2=14.9987 , p=0.0592  , df=8\n",
      "parameter F test:         F=1.8583  , p=0.0630  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.6211  , p=0.1044  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=14.8500 , p=0.0951  , df=9\n",
      "likelihood ratio test: chi2=14.7494 , p=0.0981  , df=9\n",
      "parameter F test:         F=1.6211  , p=0.1044  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.4751  , p=0.1432  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=15.0422 , p=0.1305  , df=10\n",
      "likelihood ratio test: chi2=14.9389 , p=0.1343  , df=10\n",
      "parameter F test:         F=1.4751  , p=0.1432  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('SO2 (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.1436  , p=0.7048  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=0.1440  , p=0.7044  , df=1\n",
      "likelihood ratio test: chi2=0.1440  , p=0.7044  , df=1\n",
      "parameter F test:         F=0.1436  , p=0.7048  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.0522  , p=0.9492  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=0.1048  , p=0.9489  , df=2\n",
      "likelihood ratio test: chi2=0.1048  , p=0.9489  , df=2\n",
      "parameter F test:         F=0.0522  , p=0.9492  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.7142  , p=0.5436  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=2.1563  , p=0.5406  , df=3\n",
      "likelihood ratio test: chi2=2.1542  , p=0.5410  , df=3\n",
      "parameter F test:         F=0.7142  , p=0.5436  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.4435  , p=0.7772  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=1.7887  , p=0.7746  , df=4\n",
      "likelihood ratio test: chi2=1.7872  , p=0.7748  , df=4\n",
      "parameter F test:         F=0.4435  , p=0.7772  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.3354  , p=0.8917  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=1.6940  , p=0.8897  , df=5\n",
      "likelihood ratio test: chi2=1.6927  , p=0.8898  , df=5\n",
      "parameter F test:         F=0.3354  , p=0.8917  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.2920  , p=0.9409  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=1.7731  , p=0.9393  , df=6\n",
      "likelihood ratio test: chi2=1.7717  , p=0.9395  , df=6\n",
      "parameter F test:         F=0.2920  , p=0.9409  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=0.2928  , p=0.9569  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=2.0781  , p=0.9554  , df=7\n",
      "likelihood ratio test: chi2=2.0761  , p=0.9555  , df=7\n",
      "parameter F test:         F=0.2928  , p=0.9569  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=0.2733  , p=0.9746  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=2.2215  , p=0.9735  , df=8\n",
      "likelihood ratio test: chi2=2.2192  , p=0.9735  , df=8\n",
      "parameter F test:         F=0.2733  , p=0.9746  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=0.3388  , p=0.9621  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=3.1036  , p=0.9600  , df=9\n",
      "likelihood ratio test: chi2=3.0992  , p=0.9602  , df=9\n",
      "parameter F test:         F=0.3388  , p=0.9621  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=0.4858  , p=0.9000  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=4.9537  , p=0.8942  , df=10\n",
      "likelihood ratio test: chi2=4.9424  , p=0.8950  , df=10\n",
      "parameter F test:         F=0.4858  , p=0.9000  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('CO (mg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=3.0208  , p=0.0825  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=3.0291  , p=0.0818  , df=1\n",
      "likelihood ratio test: chi2=3.0249  , p=0.0820  , df=1\n",
      "parameter F test:         F=3.0208  , p=0.0825  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.6923  , p=0.1846  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=3.4002  , p=0.1827  , df=2\n",
      "likelihood ratio test: chi2=3.3949  , p=0.1832  , df=2\n",
      "parameter F test:         F=1.6923  , p=0.1846  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.5027  , p=0.2122  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=4.5372  , p=0.2090  , df=3\n",
      "likelihood ratio test: chi2=4.5278  , p=0.2098  , df=3\n",
      "parameter F test:         F=1.5027  , p=0.2122  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.9266  , p=0.1038  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=7.7705  , p=0.1004  , df=4\n",
      "likelihood ratio test: chi2=7.7429  , p=0.1015  , df=4\n",
      "parameter F test:         F=1.9266  , p=0.1038  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=2.0682  , p=0.0670  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=10.4464 , p=0.0635  , df=5\n",
      "likelihood ratio test: chi2=10.3967 , p=0.0647  , df=5\n",
      "parameter F test:         F=2.0682  , p=0.0670  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=2.1429  , p=0.0462  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=13.0128 , p=0.0428  , df=6\n",
      "likelihood ratio test: chi2=12.9356 , p=0.0441  , df=6\n",
      "parameter F test:         F=2.1429  , p=0.0462  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.7309  , p=0.0981  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=12.2857 , p=0.0915  , df=7\n",
      "likelihood ratio test: chi2=12.2169 , p=0.0936  , df=7\n",
      "parameter F test:         F=1.7309  , p=0.0981  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.8315  , p=0.0676  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=14.8845 , p=0.0614  , df=8\n",
      "likelihood ratio test: chi2=14.7835 , p=0.0635  , df=8\n",
      "parameter F test:         F=1.8315  , p=0.0676  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=1.6918  , p=0.0864  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=15.4974 , p=0.0781  , df=9\n",
      "likelihood ratio test: chi2=15.3879 , p=0.0808  , df=9\n",
      "parameter F test:         F=1.6918  , p=0.0864  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.4976  , p=0.1347  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=15.2714 , p=0.1225  , df=10\n",
      "likelihood ratio test: chi2=15.1649 , p=0.1262  , df=10\n",
      "parameter F test:         F=1.4976  , p=0.1347  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Benzene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=6.3081  , p=0.0122  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=6.3254  , p=0.0119  , df=1\n",
      "likelihood ratio test: chi2=6.3072  , p=0.0120  , df=1\n",
      "parameter F test:         F=6.3081  , p=0.0122  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.8223  , p=0.0599  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=5.6705  , p=0.0587  , df=2\n",
      "likelihood ratio test: chi2=5.6558  , p=0.0591  , df=2\n",
      "parameter F test:         F=2.8223  , p=0.0599  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.3659  , p=0.2517  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=4.1242  , p=0.2484  , df=3\n",
      "likelihood ratio test: chi2=4.1164  , p=0.2492  , df=3\n",
      "parameter F test:         F=1.3659  , p=0.2517  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.4908  , p=0.2027  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=6.0128  , p=0.1982  , df=4\n",
      "likelihood ratio test: chi2=5.9963  , p=0.1994  , df=4\n",
      "parameter F test:         F=1.4908  , p=0.2027  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=1.4788  , p=0.1939  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=7.4695  , p=0.1880  , df=5\n",
      "likelihood ratio test: chi2=7.4440  , p=0.1897  , df=5\n",
      "parameter F test:         F=1.4788  , p=0.1939  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.4553  , p=0.1904  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=8.8372  , p=0.1829  , df=6\n",
      "likelihood ratio test: chi2=8.8016  , p=0.1850  , df=6\n",
      "parameter F test:         F=1.4553  , p=0.1904  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.7155  , p=0.1016  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=12.1761 , p=0.0949  , df=7\n",
      "likelihood ratio test: chi2=12.1084 , p=0.0970  , df=7\n",
      "parameter F test:         F=1.7155  , p=0.1016  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.9909  , p=0.0445  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=16.1800 , p=0.0399  , df=8\n",
      "likelihood ratio test: chi2=16.0607 , p=0.0415  , df=8\n",
      "parameter F test:         F=1.9909  , p=0.0445  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.6255  , p=0.0053  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=24.0500 , p=0.0042  , df=9\n",
      "likelihood ratio test: chi2=23.7876 , p=0.0047  , df=9\n",
      "parameter F test:         F=2.6255  , p=0.0053  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.3627  , p=0.0092  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=24.0934 , p=0.0074  , df=10\n",
      "likelihood ratio test: chi2=23.8298 , p=0.0081  , df=10\n",
      "parameter F test:         F=2.3627  , p=0.0092  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Toluene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.4502  , p=0.5024  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=0.4515  , p=0.5016  , df=1\n",
      "likelihood ratio test: chi2=0.4514  , p=0.5017  , df=1\n",
      "parameter F test:         F=0.4502  , p=0.5024  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.2480  , p=0.7804  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=0.4983  , p=0.7795  , df=2\n",
      "likelihood ratio test: chi2=0.4982  , p=0.7795  , df=2\n",
      "parameter F test:         F=0.2480  , p=0.7804  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.1461  , p=0.9322  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=0.4411  , p=0.9316  , df=3\n",
      "likelihood ratio test: chi2=0.4410  , p=0.9316  , df=3\n",
      "parameter F test:         F=0.1461  , p=0.9322  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.7551  , p=0.5546  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=3.0456  , p=0.5502  , df=4\n",
      "likelihood ratio test: chi2=3.0414  , p=0.5509  , df=4\n",
      "parameter F test:         F=0.7551  , p=0.5546  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.5774  , p=0.7174  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=2.9164  , p=0.7129  , df=5\n",
      "likelihood ratio test: chi2=2.9125  , p=0.7135  , df=5\n",
      "parameter F test:         F=0.5774  , p=0.7174  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.7407  , p=0.6169  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=4.4977  , p=0.6096  , df=6\n",
      "likelihood ratio test: chi2=4.4884  , p=0.6109  , df=6\n",
      "parameter F test:         F=0.7407  , p=0.6169  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.3343  , p=0.2304  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=9.4706  , p=0.2206  , df=7\n",
      "likelihood ratio test: chi2=9.4296  , p=0.2233  , df=7\n",
      "parameter F test:         F=1.3343  , p=0.2304  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=1.8624  , p=0.0624  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=15.1359 , p=0.0566  , df=8\n",
      "likelihood ratio test: chi2=15.0315 , p=0.0585  , df=8\n",
      "parameter F test:         F=1.8624  , p=0.0624  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.2540  , p=0.0169  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=20.6472 , p=0.0143  , df=9\n",
      "likelihood ratio test: chi2=20.4534 , p=0.0153  , df=9\n",
      "parameter F test:         F=2.2540  , p=0.0169  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.2027  , p=0.0157  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=22.4613 , p=0.0129  , df=10\n",
      "likelihood ratio test: chi2=22.2320 , p=0.0140  , df=10\n",
      "parameter F test:         F=2.2027  , p=0.0157  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('Eth-Benzene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.4625  , p=0.2268  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=1.4666  , p=0.2259  , df=1\n",
      "likelihood ratio test: chi2=1.4656  , p=0.2260  , df=1\n",
      "parameter F test:         F=1.4625  , p=0.2268  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.8031  , p=0.4482  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=1.6136  , p=0.4463  , df=2\n",
      "likelihood ratio test: chi2=1.6124  , p=0.4466  , df=2\n",
      "parameter F test:         F=0.8031  , p=0.4482  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.7628  , p=0.5150  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=2.3032  , p=0.5119  , df=3\n",
      "likelihood ratio test: chi2=2.3008  , p=0.5124  , df=3\n",
      "parameter F test:         F=0.7628  , p=0.5150  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=1.1519  , p=0.3306  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=4.6458  , p=0.3256  , df=4\n",
      "likelihood ratio test: chi2=4.6359  , p=0.3267  , df=4\n",
      "parameter F test:         F=1.1519  , p=0.3306  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.8551  , p=0.5108  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=4.3192  , p=0.5044  , df=5\n",
      "likelihood ratio test: chi2=4.3106  , p=0.5056  , df=5\n",
      "parameter F test:         F=0.8551  , p=0.5108  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.7108  , p=0.6410  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=4.3162  , p=0.6340  , df=6\n",
      "likelihood ratio test: chi2=4.3077  , p=0.6351  , df=6\n",
      "parameter F test:         F=0.7108  , p=0.6410  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.0286  , p=0.4091  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=7.3008  , p=0.3982  , df=7\n",
      "likelihood ratio test: chi2=7.2765  , p=0.4007  , df=7\n",
      "parameter F test:         F=1.0286  , p=0.4091  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.3646  , p=0.0159  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=19.2175 , p=0.0137  , df=8\n",
      "likelihood ratio test: chi2=19.0496 , p=0.0146  , df=8\n",
      "parameter F test:         F=2.3646  , p=0.0159  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.3195  , p=0.0138  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=21.2475 , p=0.0116  , df=9\n",
      "likelihood ratio test: chi2=21.0423 , p=0.0125  , df=9\n",
      "parameter F test:         F=2.3195  , p=0.0138  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.5266  , p=0.0052  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=25.7650 , p=0.0041  , df=10\n",
      "likelihood ratio test: chi2=25.4638 , p=0.0045  , df=10\n",
      "parameter F test:         F=2.5266  , p=0.0052  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('MP-Xylene (µg/m³)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.4606  , p=0.4975  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=0.4619  , p=0.4967  , df=1\n",
      "likelihood ratio test: chi2=0.4618  , p=0.4968  , df=1\n",
      "parameter F test:         F=0.4606  , p=0.4975  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.2786  , p=0.7569  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=0.5598  , p=0.7559  , df=2\n",
      "likelihood ratio test: chi2=0.5596  , p=0.7559  , df=2\n",
      "parameter F test:         F=0.2786  , p=0.7569  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.1514  , p=0.9288  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=0.4572  , p=0.9282  , df=3\n",
      "likelihood ratio test: chi2=0.4571  , p=0.9282  , df=3\n",
      "parameter F test:         F=0.1514  , p=0.9288  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=0.7675  , p=0.5464  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=3.0955  , p=0.5420  , df=4\n",
      "likelihood ratio test: chi2=3.0912  , p=0.5427  , df=4\n",
      "parameter F test:         F=0.7675  , p=0.5464  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=0.5797  , p=0.7156  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=2.9280  , p=0.7111  , df=5\n",
      "likelihood ratio test: chi2=2.9240  , p=0.7117  , df=5\n",
      "parameter F test:         F=0.5797  , p=0.7156  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=0.5890  , p=0.7393  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=3.5767  , p=0.7337  , df=6\n",
      "likelihood ratio test: chi2=3.5709  , p=0.7345  , df=6\n",
      "parameter F test:         F=0.5890  , p=0.7393  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=1.2334  , p=0.2812  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=8.7543  , p=0.2708  , df=7\n",
      "likelihood ratio test: chi2=8.7192  , p=0.2734  , df=7\n",
      "parameter F test:         F=1.2334  , p=0.2812  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.7213  , p=0.0057  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=22.1162 , p=0.0047  , df=8\n",
      "likelihood ratio test: chi2=21.8942 , p=0.0051  , df=8\n",
      "parameter F test:         F=2.7213  , p=0.0057  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.7197  , p=0.0039  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=24.9129 , p=0.0031  , df=9\n",
      "likelihood ratio test: chi2=24.6314 , p=0.0034  , df=9\n",
      "parameter F test:         F=2.7197  , p=0.0039  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=2.7383  , p=0.0025  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=27.9235 , p=0.0019  , df=10\n",
      "likelihood ratio test: chi2=27.5702 , p=0.0021  , df=10\n",
      "parameter F test:         F=2.7383  , p=0.0025  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('WS (m/s)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=23.9907 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=24.0567 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=23.7960 , p=0.0000  , df=1\n",
      "parameter F test:         F=23.9907 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=17.1689 , p=0.0000  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=34.4955 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=33.9624 , p=0.0000  , df=2\n",
      "parameter F test:         F=17.1689 , p=0.0000  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=8.8920  , p=0.0000  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=26.8482 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=26.5235 , p=0.0000  , df=3\n",
      "parameter F test:         F=8.8920  , p=0.0000  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=5.2577  , p=0.0003  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=21.2057 , p=0.0003  , df=4\n",
      "likelihood ratio test: chi2=21.0022 , p=0.0003  , df=4\n",
      "parameter F test:         F=5.2577  , p=0.0003  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.9811  , p=0.0014  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=20.1086 , p=0.0012  , df=5\n",
      "likelihood ratio test: chi2=19.9253 , p=0.0013  , df=5\n",
      "parameter F test:         F=3.9811  , p=0.0014  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=1.8191  , p=0.0922  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=11.0466 , p=0.0869  , df=6\n",
      "likelihood ratio test: chi2=10.9909 , p=0.0887  , df=6\n",
      "parameter F test:         F=1.8191  , p=0.0922  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.8336  , p=0.0063  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=20.1126 , p=0.0053  , df=7\n",
      "likelihood ratio test: chi2=19.9289 , p=0.0057  , df=7\n",
      "parameter F test:         F=2.8336  , p=0.0063  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.2654  , p=0.0211  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=18.4113 , p=0.0183  , df=8\n",
      "likelihood ratio test: chi2=18.2571 , p=0.0194  , df=8\n",
      "parameter F test:         F=2.2654  , p=0.0211  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.1106  , p=0.0261  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=19.3332 , p=0.0225  , df=9\n",
      "likelihood ratio test: chi2=19.1631 , p=0.0238  , df=9\n",
      "parameter F test:         F=2.1106  , p=0.0261  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.8209  , p=0.0529  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=18.5686 , p=0.0461  , df=10\n",
      "likelihood ratio test: chi2=18.4115 , p=0.0484  , df=10\n",
      "parameter F test:         F=1.8209  , p=0.0529  , df_denom=1064, df_num=10\n",
      "\n",
      "Granger Causality Test for pair ('SR (W/mt2)', 'PM2.5 (µg/m³)'):\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=22.1739 , p=0.0000  , df_denom=1091, df_num=1\n",
      "ssr based chi2 test:   chi2=22.2349 , p=0.0000  , df=1\n",
      "likelihood ratio test: chi2=22.0119 , p=0.0000  , df=1\n",
      "parameter F test:         F=22.1739 , p=0.0000  , df_denom=1091, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=9.9717  , p=0.0001  , df_denom=1088, df_num=2\n",
      "ssr based chi2 test:   chi2=20.0350 , p=0.0000  , df=2\n",
      "likelihood ratio test: chi2=19.8536 , p=0.0000  , df=2\n",
      "parameter F test:         F=9.9717  , p=0.0001  , df_denom=1088, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=5.8696  , p=0.0006  , df_denom=1085, df_num=3\n",
      "ssr based chi2 test:   chi2=17.7223 , p=0.0005  , df=3\n",
      "likelihood ratio test: chi2=17.5800 , p=0.0005  , df=3\n",
      "parameter F test:         F=5.8696  , p=0.0006  , df_denom=1085, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 4\n",
      "ssr based F test:         F=4.1888  , p=0.0023  , df_denom=1082, df_num=4\n",
      "ssr based chi2 test:   chi2=16.8944 , p=0.0020  , df=4\n",
      "likelihood ratio test: chi2=16.7649 , p=0.0021  , df=4\n",
      "parameter F test:         F=4.1888  , p=0.0023  , df_denom=1082, df_num=4\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 5\n",
      "ssr based F test:         F=3.2825  , p=0.0060  , df_denom=1079, df_num=5\n",
      "ssr based chi2 test:   chi2=16.5796 , p=0.0054  , df=5\n",
      "likelihood ratio test: chi2=16.4548 , p=0.0057  , df=5\n",
      "parameter F test:         F=3.2825  , p=0.0060  , df_denom=1079, df_num=5\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 6\n",
      "ssr based F test:         F=3.2688  , p=0.0034  , df_denom=1076, df_num=6\n",
      "ssr based chi2 test:   chi2=19.8499 , p=0.0029  , df=6\n",
      "likelihood ratio test: chi2=19.6711 , p=0.0032  , df=6\n",
      "parameter F test:         F=3.2688  , p=0.0034  , df_denom=1076, df_num=6\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 7\n",
      "ssr based F test:         F=2.6702  , p=0.0096  , df_denom=1073, df_num=7\n",
      "ssr based chi2 test:   chi2=18.9529 , p=0.0083  , df=7\n",
      "likelihood ratio test: chi2=18.7897 , p=0.0089  , df=7\n",
      "parameter F test:         F=2.6702  , p=0.0096  , df_denom=1073, df_num=7\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 8\n",
      "ssr based F test:         F=2.3406  , p=0.0171  , df_denom=1070, df_num=8\n",
      "ssr based chi2 test:   chi2=19.0225 , p=0.0147  , df=8\n",
      "likelihood ratio test: chi2=18.8580 , p=0.0156  , df=8\n",
      "parameter F test:         F=2.3406  , p=0.0171  , df_denom=1070, df_num=8\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 9\n",
      "ssr based F test:         F=2.1099  , p=0.0262  , df_denom=1067, df_num=9\n",
      "ssr based chi2 test:   chi2=19.3269 , p=0.0226  , df=9\n",
      "likelihood ratio test: chi2=19.1569 , p=0.0239  , df=9\n",
      "parameter F test:         F=2.1099  , p=0.0262  , df_denom=1067, df_num=9\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 10\n",
      "ssr based F test:         F=1.8335  , p=0.0509  , df_denom=1064, df_num=10\n",
      "ssr based chi2 test:   chi2=18.6970 , p=0.0443  , df=10\n",
      "likelihood ratio test: chi2=18.5377 , p=0.0465  , df=10\n",
      "parameter F test:         F=1.8335  , p=0.0509  , df_denom=1064, df_num=10\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Apply Granger's Causality Test\n",
    "for pair in highly_correlated_pairs:\n",
    "    print()\n",
    "    print(f\"Granger Causality Test for pair {pair}:\")\n",
    "    granger_test_result = grangercausalitytests(df[list(pair)], maxlag=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WS (m/s)', 'SR (W/mt2)', 'PM2.5 (µg/m³)']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['WS (m/s)','SR (W/mt2)','PM2.5 (µg/m³)']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15136004, 0.04265012, 0.00514282])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr = df[cols]\n",
    "df_corr.index = df['Timestamp']\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "johan_test_temp = df_corr\n",
    "coint_johansen(johan_test_temp,-1,1).eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.51</td>\n",
       "      <td>74.96</td>\n",
       "      <td>159.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.50</td>\n",
       "      <td>81.38</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.45</td>\n",
       "      <td>64.66</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>0.48</td>\n",
       "      <td>56.41</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>0.38</td>\n",
       "      <td>48.90</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>0.51</td>\n",
       "      <td>67.82</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.40</td>\n",
       "      <td>102.06</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.29</td>\n",
       "      <td>86.84</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.53</td>\n",
       "      <td>65.92</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>0.75</td>\n",
       "      <td>79.49</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>103.14</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>109.45</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.36</td>\n",
       "      <td>102.28</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.40</td>\n",
       "      <td>106.05</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.43</td>\n",
       "      <td>113.21</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.71</td>\n",
       "      <td>99.30</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.63</td>\n",
       "      <td>101.43</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.42</td>\n",
       "      <td>91.86</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.66</td>\n",
       "      <td>79.06</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>0.31</td>\n",
       "      <td>76.87</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>0.56</td>\n",
       "      <td>81.75</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.52</td>\n",
       "      <td>95.49</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>0.59</td>\n",
       "      <td>90.75</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.49</td>\n",
       "      <td>98.08</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>0.34</td>\n",
       "      <td>115.67</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>0.19</td>\n",
       "      <td>119.65</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>0.51</td>\n",
       "      <td>124.78</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>0.65</td>\n",
       "      <td>88.99</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.44</td>\n",
       "      <td>111.66</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.33</td>\n",
       "      <td>93.28</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.52</td>\n",
       "      <td>78.51</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                      \n",
       "2024-01-01      0.51       74.96         159.49\n",
       "2024-01-02      0.50       81.38         201.22\n",
       "2024-01-03      0.45       64.66         235.04\n",
       "2024-01-04      0.48       56.41         223.36\n",
       "2024-01-05      0.38       48.90         153.35\n",
       "2024-01-06      0.51       67.82         176.58\n",
       "2024-01-07      0.40      102.06         179.29\n",
       "2024-01-08      0.29       86.84         260.26\n",
       "2024-01-09      0.53       65.92         144.39\n",
       "2024-01-10      0.75       79.49         176.85\n",
       "2024-01-11      0.50      103.14         200.03\n",
       "2024-01-12      0.50      109.45         161.85\n",
       "2024-01-13      0.36      102.28         324.88\n",
       "2024-01-14      0.40      106.05         285.11\n",
       "2024-01-15      0.43      113.21         191.13\n",
       "2024-01-16      0.71       99.30         194.15\n",
       "2024-01-17      0.63      101.43         188.70\n",
       "2024-01-18      0.42       91.86         201.74\n",
       "2024-01-19      0.66       79.06         174.39\n",
       "2024-01-20      0.31       76.87         206.83\n",
       "2024-01-21      0.56       81.75         181.35\n",
       "2024-01-22      0.52       95.49         234.13\n",
       "2024-01-23      0.59       90.75         244.36\n",
       "2024-01-24      0.49       98.08         252.99\n",
       "2024-01-25      0.34      115.67         212.36\n",
       "2024-01-26      0.19      119.65         401.43\n",
       "2024-01-27      0.51      124.78         220.10\n",
       "2024-01-28      0.65       88.99         284.35\n",
       "2024-01-29      0.44      111.66         216.37\n",
       "2024-01-30      0.33       93.28         219.25\n",
       "2024-01-31      0.52       78.51         204.15"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colums = [i.split()[0] for i in cols]\n",
    "val = pd.read_excel(\"C:/Users/DHAN RAJ/Downloads/Delhi_daily_Jan.xlsx\")\n",
    "origin = '2021-01-01'\n",
    "start = '2024-01-01'\n",
    "end = '2024-01-31'\n",
    "time_period = pd.date_range(start,end)\n",
    "val['Timestamp'] = time_period\n",
    "val = val.drop(columns=['From Date'])\n",
    "val.set_index('Timestamp', inplace=True)\n",
    "val = val[colums]\n",
    "val.columns = cols\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
      "Timestamp                                      \n",
      "2024-01-01      0.51       74.96         159.49\n",
      "2024-01-02      0.50       81.38         201.22\n",
      "2024-01-03      0.45       64.66         235.04\n",
      "2024-01-04      0.48       56.41         223.36\n",
      "2024-01-05      0.38       48.90         153.35\n",
      "2024-01-06      0.51       67.82         176.58\n",
      "2024-01-07      0.40      102.06         179.29\n",
      "2024-01-08      0.29       86.84         260.26\n",
      "2024-01-09      0.53       65.92         144.39\n",
      "2024-01-10      0.75       79.49         176.85\n",
      "2024-01-11      0.50      103.14         200.03\n",
      "2024-01-12      0.50      109.45         161.85\n",
      "2024-01-13      0.36      102.28         324.88\n",
      "2024-01-14      0.40      106.05         285.11\n",
      "2024-01-15      0.43      113.21         191.13\n",
      "2024-01-16      0.71       99.30         194.15\n",
      "2024-01-17      0.63      101.43         188.70\n",
      "2024-01-18      0.42       91.86         201.74\n",
      "2024-01-19      0.66       79.06         174.39\n",
      "2024-01-20      0.31       76.87         206.83\n",
      "2024-01-21      0.56       81.75         181.35\n",
      "2024-01-22      0.52       95.49         234.13\n",
      "2024-01-23      0.59       90.75         244.36\n",
      "2024-01-24      0.49       98.08         252.99\n",
      "2024-01-25      0.34      115.67         212.36\n",
      "2024-01-26      0.19      119.65         401.43\n",
      "2024-01-27      0.51      124.78         220.10\n",
      "2024-01-28      0.65       88.99         284.35\n",
      "2024-01-29      0.44      111.66         216.37\n",
      "2024-01-30      0.33       93.28         219.25\n",
      "2024-01-31      0.52       78.51         204.15\n"
     ]
    }
   ],
   "source": [
    "val[cols]= val[cols].fillna(val[cols].rolling(8,min_periods=1).mean())\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "Db8BJQONjbAT"
   },
   "outputs": [],
   "source": [
    "def df_to_X_y2(df, window_size=1):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size][2]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJhF1cIDleQ1",
    "outputId": "f571aa4c-d18c-41ef-d9c2-652ab09f9b3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1094, 1, 3), (1094,))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2, y2 = df_to_X_y2(df_corr)\n",
    "X2.shape, y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMOArQgyoTnq",
    "outputId": "405a6dfd-4335-4d27-de23-a2fed6e08f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1040, 1, 3), (1040,), (54, 1, 3), (54,), (30, 1, 3), (30,))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train, y2_train = X2[:1040], y2[:1040]\n",
    "X2_val, y2_val = X2[1040:], y2[1040:]\n",
    "X2_test, y2_test = df_to_X_y2(val)\n",
    "X2_train.shape, y2_train.shape, X2_val.shape, y2_val.shape, X2_test.shape, y2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpFVgXYJqbt8",
    "outputId": "4696c3ab-a8cb-45e1-c691-faed44ba0086"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m17,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,937</span> (70.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,937\u001b[0m (70.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,937</span> (70.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,937\u001b[0m (70.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model4 = Sequential()\n",
    "model4.add(InputLayer((1, 3)))\n",
    "model4.add(LSTM(64))\n",
    "model4.add(Dense(8, 'relu'))\n",
    "model4.add(Dense(1, 'linear'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "3RD8D_SXqkk8"
   },
   "outputs": [],
   "source": [
    "cp4 = ModelCheckpoint('checkpoint.model4.keras',monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model4.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GB5aik6bqogC",
    "outputId": "cfabcd42-c96b-4336-a89e-e51352dd6d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 2s/step - loss: 14182.9219 - mean_absolute_error: 98.4537\n",
      "Epoch 1: val_loss improved from inf to 37793.76562, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 12743.0088 - mean_absolute_error: 92.2152 - val_loss: 37793.7656 - val_mean_absolute_error: 185.9707\n",
      "Epoch 2/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10787.2793 - mean_absolute_error: 86.8482\n",
      "Epoch 2: val_loss improved from 37793.76562 to 37764.88281, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12190.7744 - mean_absolute_error: 90.0572 - val_loss: 37764.8828 - val_mean_absolute_error: 185.8889\n",
      "Epoch 3/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15255.3281 - mean_absolute_error: 103.0765\n",
      "Epoch 3: val_loss improved from 37764.88281 to 37736.70312, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12680.8574 - mean_absolute_error: 92.0075 - val_loss: 37736.7031 - val_mean_absolute_error: 185.8113\n",
      "Epoch 4/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10308.0762 - mean_absolute_error: 82.5529\n",
      "Epoch 4: val_loss improved from 37736.70312 to 37710.12109, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11635.0771 - mean_absolute_error: 87.5489 - val_loss: 37710.1211 - val_mean_absolute_error: 185.7372\n",
      "Epoch 5/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10213.2354 - mean_absolute_error: 78.9300\n",
      "Epoch 5: val_loss improved from 37710.12109 to 37679.66406, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12075.2725 - mean_absolute_error: 88.9830 - val_loss: 37679.6641 - val_mean_absolute_error: 185.6481\n",
      "Epoch 6/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8065.9565 - mean_absolute_error: 76.6791\n",
      "Epoch 6: val_loss improved from 37679.66406 to 37631.17578, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11822.0859 - mean_absolute_error: 88.7048 - val_loss: 37631.1758 - val_mean_absolute_error: 185.5053\n",
      "Epoch 7/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9994.6504 - mean_absolute_error: 84.1297\n",
      "Epoch 7: val_loss improved from 37631.17578 to 37554.80469, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11307.0322 - mean_absolute_error: 86.3818 - val_loss: 37554.8047 - val_mean_absolute_error: 185.2921\n",
      "Epoch 8/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8322.9033 - mean_absolute_error: 67.3690\n",
      "Epoch 8: val_loss improved from 37554.80469 to 37412.58984, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11076.0430 - mean_absolute_error: 84.7738 - val_loss: 37412.5898 - val_mean_absolute_error: 184.8942\n",
      "Epoch 9/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12826.8711 - mean_absolute_error: 90.2828\n",
      "Epoch 9: val_loss improved from 37412.58984 to 37233.97266, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11851.7168 - mean_absolute_error: 88.1629 - val_loss: 37233.9727 - val_mean_absolute_error: 184.3965\n",
      "Epoch 10/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10016.8174 - mean_absolute_error: 86.1345\n",
      "Epoch 10: val_loss improved from 37233.97266 to 37057.28516, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11925.8945 - mean_absolute_error: 89.2707 - val_loss: 37057.2852 - val_mean_absolute_error: 183.8964\n",
      "Epoch 11/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11535.1680 - mean_absolute_error: 87.9628\n",
      "Epoch 11: val_loss improved from 37057.28516 to 36882.74609, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11484.5322 - mean_absolute_error: 86.4240 - val_loss: 36882.7461 - val_mean_absolute_error: 183.3932\n",
      "Epoch 12/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11992.2646 - mean_absolute_error: 75.9958\n",
      "Epoch 12: val_loss improved from 36882.74609 to 36635.44141, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11361.1689 - mean_absolute_error: 84.3308 - val_loss: 36635.4414 - val_mean_absolute_error: 182.6952\n",
      "Epoch 13/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11403.0703 - mean_absolute_error: 82.8297\n",
      "Epoch 13: val_loss improved from 36635.44141 to 36391.57422, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11559.0957 - mean_absolute_error: 85.3391 - val_loss: 36391.5742 - val_mean_absolute_error: 182.0001\n",
      "Epoch 14/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9316.4395 - mean_absolute_error: 78.0647\n",
      "Epoch 14: val_loss improved from 36391.57422 to 36095.76953, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11617.6396 - mean_absolute_error: 85.9521 - val_loss: 36095.7695 - val_mean_absolute_error: 181.1786\n",
      "Epoch 15/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11105.3682 - mean_absolute_error: 80.9853\n",
      "Epoch 15: val_loss improved from 36095.76953 to 35781.49609, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11794.0371 - mean_absolute_error: 87.2453 - val_loss: 35781.4961 - val_mean_absolute_error: 180.2925\n",
      "Epoch 16/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12549.9121 - mean_absolute_error: 89.8920\n",
      "Epoch 16: val_loss improved from 35781.49609 to 35461.34766, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10712.7773 - mean_absolute_error: 82.1587 - val_loss: 35461.3477 - val_mean_absolute_error: 179.3933\n",
      "Epoch 17/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9401.2988 - mean_absolute_error: 74.8468\n",
      "Epoch 17: val_loss improved from 35461.34766 to 35063.48828, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10934.5693 - mean_absolute_error: 83.5914 - val_loss: 35063.4883 - val_mean_absolute_error: 178.3025\n",
      "Epoch 18/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6245.2437 - mean_absolute_error: 68.3569\n",
      "Epoch 18: val_loss improved from 35063.48828 to 34721.98438, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10634.2979 - mean_absolute_error: 82.0491 - val_loss: 34721.9844 - val_mean_absolute_error: 177.3643\n",
      "Epoch 19/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14322.2188 - mean_absolute_error: 91.2155\n",
      "Epoch 19: val_loss improved from 34721.98438 to 34398.98047, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11367.0381 - mean_absolute_error: 82.7217 - val_loss: 34398.9805 - val_mean_absolute_error: 176.4563\n",
      "Epoch 20/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6872.1270 - mean_absolute_error: 66.1485\n",
      "Epoch 20: val_loss improved from 34398.98047 to 34061.16797, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10263.1045 - mean_absolute_error: 80.1834 - val_loss: 34061.1680 - val_mean_absolute_error: 175.5187\n",
      "Epoch 21/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14857.5020 - mean_absolute_error: 86.4773\n",
      "Epoch 21: val_loss improved from 34061.16797 to 33728.89453, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10524.0508 - mean_absolute_error: 79.5422 - val_loss: 33728.8945 - val_mean_absolute_error: 174.5835\n",
      "Epoch 22/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 13341.1768 - mean_absolute_error: 91.0038\n",
      "Epoch 22: val_loss improved from 33728.89453 to 33335.35156, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10148.9512 - mean_absolute_error: 79.3478 - val_loss: 33335.3516 - val_mean_absolute_error: 173.4707\n",
      "Epoch 23/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11210.7783 - mean_absolute_error: 90.5704\n",
      "Epoch 23: val_loss improved from 33335.35156 to 33005.67188, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10193.8350 - mean_absolute_error: 78.1138 - val_loss: 33005.6719 - val_mean_absolute_error: 172.5364\n",
      "Epoch 24/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9076.0898 - mean_absolute_error: 77.3111\n",
      "Epoch 24: val_loss improved from 33005.67188 to 32737.17188, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9399.3535 - mean_absolute_error: 75.5834 - val_loss: 32737.1719 - val_mean_absolute_error: 171.7709\n",
      "Epoch 25/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9100.9590 - mean_absolute_error: 73.8574\n",
      "Epoch 25: val_loss improved from 32737.17188 to 32485.33984, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9643.7373 - mean_absolute_error: 74.9336 - val_loss: 32485.3398 - val_mean_absolute_error: 171.0498\n",
      "Epoch 26/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8923.5068 - mean_absolute_error: 72.9269 \n",
      "Epoch 26: val_loss improved from 32485.33984 to 32246.00195, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9058.0225 - mean_absolute_error: 73.2905 - val_loss: 32246.0020 - val_mean_absolute_error: 170.3631\n",
      "Epoch 27/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13277.3398 - mean_absolute_error: 93.1257\n",
      "Epoch 27: val_loss improved from 32246.00195 to 31956.63867, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10104.7871 - mean_absolute_error: 76.6084 - val_loss: 31956.6387 - val_mean_absolute_error: 169.5282\n",
      "Epoch 28/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6957.3057 - mean_absolute_error: 59.9263\n",
      "Epoch 28: val_loss improved from 31956.63867 to 31691.01367, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9367.3369 - mean_absolute_error: 72.8542 - val_loss: 31691.0137 - val_mean_absolute_error: 168.7456\n",
      "Epoch 29/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12669.6670 - mean_absolute_error: 87.0878\n",
      "Epoch 29: val_loss improved from 31691.01367 to 31438.83398, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9312.2949 - mean_absolute_error: 72.6655 - val_loss: 31438.8340 - val_mean_absolute_error: 167.9773\n",
      "Epoch 30/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10844.6445 - mean_absolute_error: 84.6001\n",
      "Epoch 30: val_loss improved from 31438.83398 to 31059.64258, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9753.1865 - mean_absolute_error: 74.7651 - val_loss: 31059.6426 - val_mean_absolute_error: 166.8545\n",
      "Epoch 31/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5592.3096 - mean_absolute_error: 59.0563\n",
      "Epoch 31: val_loss improved from 31059.64258 to 30669.16602, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8673.2471 - mean_absolute_error: 69.7812 - val_loss: 30669.1660 - val_mean_absolute_error: 165.6783\n",
      "Epoch 32/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8101.2744 - mean_absolute_error: 58.8584\n",
      "Epoch 32: val_loss improved from 30669.16602 to 30198.80078, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9328.8633 - mean_absolute_error: 68.7091 - val_loss: 30198.8008 - val_mean_absolute_error: 164.2493\n",
      "Epoch 33/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11960.3018 - mean_absolute_error: 85.8700\n",
      "Epoch 33: val_loss improved from 30198.80078 to 29807.34766, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8891.0049 - mean_absolute_error: 68.6816 - val_loss: 29807.3477 - val_mean_absolute_error: 163.0632\n",
      "Epoch 34/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8867.6973 - mean_absolute_error: 62.1789\n",
      "Epoch 34: val_loss improved from 29807.34766 to 29484.25000, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8114.7241 - mean_absolute_error: 65.7362 - val_loss: 29484.2500 - val_mean_absolute_error: 162.0651\n",
      "Epoch 35/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6106.6592 - mean_absolute_error: 57.7971\n",
      "Epoch 35: val_loss improved from 29484.25000 to 29186.64844, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7789.0225 - mean_absolute_error: 64.8769 - val_loss: 29186.6484 - val_mean_absolute_error: 161.1585\n",
      "Epoch 36/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5880.5034 - mean_absolute_error: 58.0646\n",
      "Epoch 36: val_loss improved from 29186.64844 to 28839.86328, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7844.6543 - mean_absolute_error: 63.8936 - val_loss: 28839.8633 - val_mean_absolute_error: 160.0755\n",
      "Epoch 37/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6649.1763 - mean_absolute_error: 55.7744\n",
      "Epoch 37: val_loss improved from 28839.86328 to 28466.94531, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8187.6924 - mean_absolute_error: 64.2829 - val_loss: 28466.9453 - val_mean_absolute_error: 158.9221\n",
      "Epoch 38/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6115.4639 - mean_absolute_error: 64.4065\n",
      "Epoch 38: val_loss improved from 28466.94531 to 28205.52344, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7706.2119 - mean_absolute_error: 64.3092 - val_loss: 28205.5234 - val_mean_absolute_error: 158.1022\n",
      "Epoch 39/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10321.5371 - mean_absolute_error: 72.8988\n",
      "Epoch 39: val_loss improved from 28205.52344 to 27951.54492, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8116.7563 - mean_absolute_error: 63.9051 - val_loss: 27951.5449 - val_mean_absolute_error: 157.3065\n",
      "Epoch 40/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9134.7070 - mean_absolute_error: 75.1322\n",
      "Epoch 40: val_loss improved from 27951.54492 to 27705.98438, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8148.9531 - mean_absolute_error: 65.7521 - val_loss: 27705.9844 - val_mean_absolute_error: 156.5299\n",
      "Epoch 41/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12009.1133 - mean_absolute_error: 77.4497\n",
      "Epoch 41: val_loss improved from 27705.98438 to 27473.75391, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7614.6069 - mean_absolute_error: 61.0050 - val_loss: 27473.7539 - val_mean_absolute_error: 155.7887\n",
      "Epoch 42/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4750.5239 - mean_absolute_error: 46.0737\n",
      "Epoch 42: val_loss improved from 27473.75391 to 27239.00977, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7559.3525 - mean_absolute_error: 61.0593 - val_loss: 27239.0098 - val_mean_absolute_error: 155.0365\n",
      "Epoch 43/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5927.1465 - mean_absolute_error: 50.3237\n",
      "Epoch 43: val_loss improved from 27239.00977 to 27013.10352, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7852.0640 - mean_absolute_error: 61.4610 - val_loss: 27013.1035 - val_mean_absolute_error: 154.3071\n",
      "Epoch 44/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10902.7529 - mean_absolute_error: 67.3228\n",
      "Epoch 44: val_loss improved from 27013.10352 to 26789.02344, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7604.0356 - mean_absolute_error: 59.9872 - val_loss: 26789.0234 - val_mean_absolute_error: 153.5817\n",
      "Epoch 45/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4818.3389 - mean_absolute_error: 50.3604\n",
      "Epoch 45: val_loss improved from 26789.02344 to 26562.91211, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7353.7026 - mean_absolute_error: 59.8390 - val_loss: 26562.9121 - val_mean_absolute_error: 152.8460\n",
      "Epoch 46/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7631.2090 - mean_absolute_error: 58.8903\n",
      "Epoch 46: val_loss improved from 26562.91211 to 26342.40234, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7302.6514 - mean_absolute_error: 59.8239 - val_loss: 26342.4023 - val_mean_absolute_error: 152.1244\n",
      "Epoch 47/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7612.6543 - mean_absolute_error: 56.5965\n",
      "Epoch 47: val_loss improved from 26342.40234 to 26124.00781, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6993.2490 - mean_absolute_error: 58.4355 - val_loss: 26124.0078 - val_mean_absolute_error: 151.4070\n",
      "Epoch 48/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7235.6553 - mean_absolute_error: 57.0923\n",
      "Epoch 48: val_loss improved from 26124.00781 to 25897.22070, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7075.2402 - mean_absolute_error: 58.0763 - val_loss: 25897.2207 - val_mean_absolute_error: 150.6609\n",
      "Epoch 49/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3906.5923 - mean_absolute_error: 36.9825\n",
      "Epoch 49: val_loss improved from 25897.22070 to 25665.08984, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6827.7007 - mean_absolute_error: 56.7962 - val_loss: 25665.0898 - val_mean_absolute_error: 149.8889\n",
      "Epoch 50/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2653.3494 - mean_absolute_error: 40.5737\n",
      "Epoch 50: val_loss improved from 25665.08984 to 25437.42969, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6510.7612 - mean_absolute_error: 56.0490 - val_loss: 25437.4297 - val_mean_absolute_error: 149.1265\n",
      "Epoch 51/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5743.0308 - mean_absolute_error: 52.4222\n",
      "Epoch 51: val_loss improved from 25437.42969 to 25213.99023, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6728.9443 - mean_absolute_error: 57.7925 - val_loss: 25213.9902 - val_mean_absolute_error: 148.3750\n",
      "Epoch 52/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8647.8291 - mean_absolute_error: 60.8652\n",
      "Epoch 52: val_loss improved from 25213.99023 to 24995.99609, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7337.1089 - mean_absolute_error: 57.8524 - val_loss: 24995.9961 - val_mean_absolute_error: 147.6375\n",
      "Epoch 53/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4777.2520 - mean_absolute_error: 47.4800\n",
      "Epoch 53: val_loss improved from 24995.99609 to 24784.35352, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6342.0493 - mean_absolute_error: 53.1690 - val_loss: 24784.3535 - val_mean_absolute_error: 146.9163\n",
      "Epoch 54/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8295.4746 - mean_absolute_error: 70.1491\n",
      "Epoch 54: val_loss improved from 24784.35352 to 24565.55078, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6936.8008 - mean_absolute_error: 58.6624 - val_loss: 24565.5508 - val_mean_absolute_error: 146.1693\n",
      "Epoch 55/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4968.7500 - mean_absolute_error: 50.9857\n",
      "Epoch 55: val_loss improved from 24565.55078 to 24354.36328, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6282.2275 - mean_absolute_error: 54.8398 - val_loss: 24354.3633 - val_mean_absolute_error: 145.4449\n",
      "Epoch 56/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6932.6729 - mean_absolute_error: 56.8634\n",
      "Epoch 56: val_loss improved from 24354.36328 to 24146.12891, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6275.1548 - mean_absolute_error: 53.9053 - val_loss: 24146.1289 - val_mean_absolute_error: 144.7269\n",
      "Epoch 57/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5527.7422 - mean_absolute_error: 50.7923\n",
      "Epoch 57: val_loss improved from 24146.12891 to 23940.20312, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5544.6230 - mean_absolute_error: 51.0505 - val_loss: 23940.2031 - val_mean_absolute_error: 144.0135\n",
      "Epoch 58/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3510.5957 - mean_absolute_error: 44.2460\n",
      "Epoch 58: val_loss improved from 23940.20312 to 23734.19531, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5801.6846 - mean_absolute_error: 52.7955 - val_loss: 23734.1953 - val_mean_absolute_error: 143.2964\n",
      "Epoch 59/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7087.4277 - mean_absolute_error: 57.1118\n",
      "Epoch 59: val_loss improved from 23734.19531 to 23528.73242, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6308.2891 - mean_absolute_error: 53.9312 - val_loss: 23528.7324 - val_mean_absolute_error: 142.5776\n",
      "Epoch 60/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6497.6973 - mean_absolute_error: 56.0124\n",
      "Epoch 60: val_loss improved from 23528.73242 to 23323.43555, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6164.9653 - mean_absolute_error: 52.9129 - val_loss: 23323.4355 - val_mean_absolute_error: 141.8556\n",
      "Epoch 61/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5069.5312 - mean_absolute_error: 52.0252\n",
      "Epoch 61: val_loss improved from 23323.43555 to 23120.62109, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6040.6479 - mean_absolute_error: 52.9686 - val_loss: 23120.6211 - val_mean_absolute_error: 141.1387\n",
      "Epoch 62/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2902.3945 - mean_absolute_error: 39.1180\n",
      "Epoch 62: val_loss improved from 23120.62109 to 22923.14258, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5531.8794 - mean_absolute_error: 49.0933 - val_loss: 22923.1426 - val_mean_absolute_error: 140.4373\n",
      "Epoch 63/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5844.3008 - mean_absolute_error: 53.5017\n",
      "Epoch 63: val_loss improved from 22923.14258 to 22718.15430, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5657.6875 - mean_absolute_error: 50.3646 - val_loss: 22718.1543 - val_mean_absolute_error: 139.7055\n",
      "Epoch 64/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6954.7021 - mean_absolute_error: 56.0560\n",
      "Epoch 64: val_loss improved from 22718.15430 to 22520.14258, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6126.3774 - mean_absolute_error: 53.2285 - val_loss: 22520.1426 - val_mean_absolute_error: 138.9950\n",
      "Epoch 65/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5909.4414 - mean_absolute_error: 49.2404\n",
      "Epoch 65: val_loss improved from 22520.14258 to 22325.06641, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6163.0908 - mean_absolute_error: 51.5676 - val_loss: 22325.0664 - val_mean_absolute_error: 138.2915\n",
      "Epoch 66/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4817.4331 - mean_absolute_error: 49.9359\n",
      "Epoch 66: val_loss improved from 22325.06641 to 22127.63477, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5655.2144 - mean_absolute_error: 51.1604 - val_loss: 22127.6348 - val_mean_absolute_error: 137.5760\n",
      "Epoch 67/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5077.5093 - mean_absolute_error: 50.4392\n",
      "Epoch 67: val_loss improved from 22127.63477 to 21930.14062, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5648.2305 - mean_absolute_error: 50.8219 - val_loss: 21930.1406 - val_mean_absolute_error: 136.8565\n",
      "Epoch 68/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7159.8877 - mean_absolute_error: 60.8197\n",
      "Epoch 68: val_loss improved from 21930.14062 to 21733.15820, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5774.5024 - mean_absolute_error: 50.5650 - val_loss: 21733.1582 - val_mean_absolute_error: 136.1349\n",
      "Epoch 69/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4335.7549 - mean_absolute_error: 42.2837\n",
      "Epoch 69: val_loss improved from 21733.15820 to 21539.23828, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5816.1821 - mean_absolute_error: 50.2895 - val_loss: 21539.2383 - val_mean_absolute_error: 135.4209\n",
      "Epoch 70/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4081.6318 - mean_absolute_error: 39.2193\n",
      "Epoch 70: val_loss improved from 21539.23828 to 21352.27148, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5003.2739 - mean_absolute_error: 45.5172 - val_loss: 21352.2715 - val_mean_absolute_error: 134.7291\n",
      "Epoch 71/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7200.9941 - mean_absolute_error: 55.7184\n",
      "Epoch 71: val_loss improved from 21352.27148 to 21155.40820, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5868.0972 - mean_absolute_error: 50.4992 - val_loss: 21155.4082 - val_mean_absolute_error: 133.9970\n",
      "Epoch 72/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6719.3286 - mean_absolute_error: 50.3733\n",
      "Epoch 72: val_loss improved from 21155.40820 to 20967.02344, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5063.9058 - mean_absolute_error: 46.5888 - val_loss: 20967.0234 - val_mean_absolute_error: 133.2928\n",
      "Epoch 73/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2985.0530 - mean_absolute_error: 37.9456\n",
      "Epoch 73: val_loss improved from 20967.02344 to 20776.04883, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4805.8828 - mean_absolute_error: 45.7037 - val_loss: 20776.0488 - val_mean_absolute_error: 132.5754\n",
      "Epoch 74/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6853.5088 - mean_absolute_error: 55.9624\n",
      "Epoch 74: val_loss improved from 20776.04883 to 20582.34766, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5628.0684 - mean_absolute_error: 49.3284 - val_loss: 20582.3477 - val_mean_absolute_error: 131.8424\n",
      "Epoch 75/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5224.8730 - mean_absolute_error: 45.9603\n",
      "Epoch 75: val_loss improved from 20582.34766 to 20392.80078, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5236.4707 - mean_absolute_error: 47.6754 - val_loss: 20392.8008 - val_mean_absolute_error: 131.1212\n",
      "Epoch 76/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9179.3965 - mean_absolute_error: 62.4007\n",
      "Epoch 76: val_loss improved from 20392.80078 to 20206.66211, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5262.8223 - mean_absolute_error: 47.8768 - val_loss: 20206.6621 - val_mean_absolute_error: 130.4098\n",
      "Epoch 77/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4636.2158 - mean_absolute_error: 45.3473 \n",
      "Epoch 77: val_loss improved from 20206.66211 to 20020.48828, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4685.8779 - mean_absolute_error: 45.4858 - val_loss: 20020.4883 - val_mean_absolute_error: 129.6943\n",
      "Epoch 78/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9437.5039 - mean_absolute_error: 61.6735\n",
      "Epoch 78: val_loss improved from 20020.48828 to 19832.84570, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5231.1333 - mean_absolute_error: 46.4699 - val_loss: 19832.8457 - val_mean_absolute_error: 128.9695\n",
      "Epoch 79/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12211.4785 - mean_absolute_error: 79.3034\n",
      "Epoch 79: val_loss improved from 19832.84570 to 19643.40820, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5719.7104 - mean_absolute_error: 49.5260 - val_loss: 19643.4082 - val_mean_absolute_error: 128.2334\n",
      "Epoch 80/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3543.6523 - mean_absolute_error: 41.5442\n",
      "Epoch 80: val_loss improved from 19643.40820 to 19462.48828, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4601.8794 - mean_absolute_error: 44.5650 - val_loss: 19462.4883 - val_mean_absolute_error: 127.5269\n",
      "Epoch 81/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5492.1924 - mean_absolute_error: 51.3085\n",
      "Epoch 81: val_loss improved from 19462.48828 to 19279.86719, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4665.4897 - mean_absolute_error: 44.9202 - val_loss: 19279.8672 - val_mean_absolute_error: 126.8085\n",
      "Epoch 82/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5784.5400 - mean_absolute_error: 49.9307\n",
      "Epoch 82: val_loss improved from 19279.86719 to 19096.99023, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4985.1650 - mean_absolute_error: 46.0074 - val_loss: 19096.9902 - val_mean_absolute_error: 126.0864\n",
      "Epoch 83/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5002.1592 - mean_absolute_error: 50.4598\n",
      "Epoch 83: val_loss improved from 19096.99023 to 18912.65039, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4958.8682 - mean_absolute_error: 46.5052 - val_loss: 18912.6504 - val_mean_absolute_error: 125.3535\n",
      "Epoch 84/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3977.0068 - mean_absolute_error: 45.3410\n",
      "Epoch 84: val_loss improved from 18912.65039 to 18737.59570, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4553.0513 - mean_absolute_error: 43.6289 - val_loss: 18737.5957 - val_mean_absolute_error: 124.6559\n",
      "Epoch 85/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4251.4126 - mean_absolute_error: 42.3774\n",
      "Epoch 85: val_loss improved from 18737.59570 to 18553.00391, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5089.7993 - mean_absolute_error: 45.5848 - val_loss: 18553.0039 - val_mean_absolute_error: 123.9119\n",
      "Epoch 86/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6413.5068 - mean_absolute_error: 54.9635\n",
      "Epoch 86: val_loss improved from 18553.00391 to 18375.96680, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5235.5684 - mean_absolute_error: 46.6520 - val_loss: 18375.9668 - val_mean_absolute_error: 123.1988\n",
      "Epoch 87/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4487.2876 - mean_absolute_error: 44.3684\n",
      "Epoch 87: val_loss improved from 18375.96680 to 18203.11719, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4506.8999 - mean_absolute_error: 43.0927 - val_loss: 18203.1172 - val_mean_absolute_error: 122.4945\n",
      "Epoch 88/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7268.1118 - mean_absolute_error: 55.3181\n",
      "Epoch 88: val_loss improved from 18203.11719 to 18025.81250, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4873.4897 - mean_absolute_error: 44.5507 - val_loss: 18025.8125 - val_mean_absolute_error: 121.7729\n",
      "Epoch 89/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6035.4375 - mean_absolute_error: 51.6861\n",
      "Epoch 89: val_loss improved from 18025.81250 to 17851.22266, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4364.6562 - mean_absolute_error: 42.2054 - val_loss: 17851.2227 - val_mean_absolute_error: 121.0532\n",
      "Epoch 90/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4344.4385 - mean_absolute_error: 37.9001\n",
      "Epoch 90: val_loss improved from 17851.22266 to 17678.84180, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4143.0581 - mean_absolute_error: 40.4829 - val_loss: 17678.8418 - val_mean_absolute_error: 120.3377\n",
      "Epoch 91/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4931.9492 - mean_absolute_error: 48.9570\n",
      "Epoch 91: val_loss improved from 17678.84180 to 17501.50195, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4425.0352 - mean_absolute_error: 43.5463 - val_loss: 17501.5020 - val_mean_absolute_error: 119.6039\n",
      "Epoch 92/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4552.4419 - mean_absolute_error: 44.8465\n",
      "Epoch 92: val_loss improved from 17501.50195 to 17326.97266, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4187.6562 - mean_absolute_error: 41.4297 - val_loss: 17326.9727 - val_mean_absolute_error: 118.8698\n",
      "Epoch 93/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2758.4839 - mean_absolute_error: 32.3161\n",
      "Epoch 93: val_loss improved from 17326.97266 to 17158.48828, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4396.5049 - mean_absolute_error: 40.7854 - val_loss: 17158.4883 - val_mean_absolute_error: 118.1632\n",
      "Epoch 94/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3207.6245 - mean_absolute_error: 35.1112\n",
      "Epoch 94: val_loss improved from 17158.48828 to 16987.61328, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4008.8406 - mean_absolute_error: 39.6608 - val_loss: 16987.6133 - val_mean_absolute_error: 117.4381\n",
      "Epoch 95/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7709.1445 - mean_absolute_error: 47.6503\n",
      "Epoch 95: val_loss improved from 16987.61328 to 16813.84766, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4437.4395 - mean_absolute_error: 41.4184 - val_loss: 16813.8477 - val_mean_absolute_error: 116.6981\n",
      "Epoch 96/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3305.1931 - mean_absolute_error: 33.3772\n",
      "Epoch 96: val_loss improved from 16813.84766 to 16643.71680, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4162.6255 - mean_absolute_error: 40.8826 - val_loss: 16643.7168 - val_mean_absolute_error: 115.9699\n",
      "Epoch 97/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3166.7126 - mean_absolute_error: 29.4950\n",
      "Epoch 97: val_loss improved from 16643.71680 to 16473.79883, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4057.8879 - mean_absolute_error: 40.5347 - val_loss: 16473.7988 - val_mean_absolute_error: 115.2358\n",
      "Epoch 98/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1809.6597 - mean_absolute_error: 30.6624\n",
      "Epoch 98: val_loss improved from 16473.79883 to 16310.52930, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3717.2107 - mean_absolute_error: 39.6158 - val_loss: 16310.5293 - val_mean_absolute_error: 114.5271\n",
      "Epoch 99/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5960.5430 - mean_absolute_error: 51.6704\n",
      "Epoch 99: val_loss improved from 16310.52930 to 16142.84766, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3771.6558 - mean_absolute_error: 38.8999 - val_loss: 16142.8477 - val_mean_absolute_error: 113.7916\n",
      "Epoch 100/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3894.3181 - mean_absolute_error: 33.3828\n",
      "Epoch 100: val_loss improved from 16142.84766 to 15975.20508, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4069.9663 - mean_absolute_error: 38.9591 - val_loss: 15975.2051 - val_mean_absolute_error: 113.0583\n",
      "Epoch 101/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6010.3394 - mean_absolute_error: 42.5415\n",
      "Epoch 101: val_loss improved from 15975.20508 to 15810.94434, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4311.2822 - mean_absolute_error: 40.9336 - val_loss: 15810.9443 - val_mean_absolute_error: 112.3285\n",
      "Epoch 102/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4492.8887 - mean_absolute_error: 44.8650\n",
      "Epoch 102: val_loss improved from 15810.94434 to 15656.08594, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3874.1692 - mean_absolute_error: 38.9868 - val_loss: 15656.0859 - val_mean_absolute_error: 111.6418\n",
      "Epoch 103/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2725.6831 - mean_absolute_error: 31.2338\n",
      "Epoch 103: val_loss improved from 15656.08594 to 15491.18066, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3980.4116 - mean_absolute_error: 38.5094 - val_loss: 15491.1807 - val_mean_absolute_error: 110.9020\n",
      "Epoch 104/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4573.7998 - mean_absolute_error: 42.2515\n",
      "Epoch 104: val_loss improved from 15491.18066 to 15335.19629, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3609.3230 - mean_absolute_error: 37.5146 - val_loss: 15335.1963 - val_mean_absolute_error: 110.1995\n",
      "Epoch 105/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1439.8036 - mean_absolute_error: 24.9671\n",
      "Epoch 105: val_loss improved from 15335.19629 to 15174.79395, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3630.4370 - mean_absolute_error: 37.8887 - val_loss: 15174.7939 - val_mean_absolute_error: 109.4761\n",
      "Epoch 106/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4544.0986 - mean_absolute_error: 47.6359\n",
      "Epoch 106: val_loss improved from 15174.79395 to 15015.39160, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3623.3391 - mean_absolute_error: 37.9047 - val_loss: 15015.3916 - val_mean_absolute_error: 108.7440\n",
      "Epoch 107/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2384.5923 - mean_absolute_error: 35.8383\n",
      "Epoch 107: val_loss improved from 15015.39160 to 14863.61328, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3531.7800 - mean_absolute_error: 37.5032 - val_loss: 14863.6133 - val_mean_absolute_error: 108.0533\n",
      "Epoch 108/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2222.2615 - mean_absolute_error: 30.4235\n",
      "Epoch 108: val_loss improved from 14863.61328 to 14704.12402, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3504.3479 - mean_absolute_error: 36.2749 - val_loss: 14704.1240 - val_mean_absolute_error: 107.3124\n",
      "Epoch 109/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 759.1098 - mean_absolute_error: 18.9148\n",
      "Epoch 109: val_loss improved from 14704.12402 to 14550.66992, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3204.6743 - mean_absolute_error: 34.3479 - val_loss: 14550.6699 - val_mean_absolute_error: 106.5968\n",
      "Epoch 110/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2131.2126 - mean_absolute_error: 28.5241\n",
      "Epoch 110: val_loss improved from 14550.66992 to 14395.58105, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3556.0339 - mean_absolute_error: 35.7477 - val_loss: 14395.5811 - val_mean_absolute_error: 105.8644\n",
      "Epoch 111/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3370.3018 - mean_absolute_error: 39.4679\n",
      "Epoch 111: val_loss improved from 14395.58105 to 14241.91504, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3426.7214 - mean_absolute_error: 37.0147 - val_loss: 14241.9150 - val_mean_absolute_error: 105.1444\n",
      "Epoch 112/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2004.0348 - mean_absolute_error: 32.3674\n",
      "Epoch 112: val_loss improved from 14241.91504 to 14093.84277, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3322.2917 - mean_absolute_error: 36.6513 - val_loss: 14093.8428 - val_mean_absolute_error: 104.4520\n",
      "Epoch 113/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2133.8945 - mean_absolute_error: 34.0488\n",
      "Epoch 113: val_loss improved from 14093.84277 to 13935.92090, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3489.4158 - mean_absolute_error: 36.5876 - val_loss: 13935.9209 - val_mean_absolute_error: 103.6934\n",
      "Epoch 114/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7417.4189 - mean_absolute_error: 43.5378\n",
      "Epoch 114: val_loss improved from 13935.92090 to 13785.02344, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3488.8435 - mean_absolute_error: 35.9116 - val_loss: 13785.0234 - val_mean_absolute_error: 102.9587\n",
      "Epoch 115/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2827.7786 - mean_absolute_error: 33.3946\n",
      "Epoch 115: val_loss improved from 13785.02344 to 13651.71191, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2939.2002 - mean_absolute_error: 33.8452 - val_loss: 13651.7119 - val_mean_absolute_error: 102.3314\n",
      "Epoch 116/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2154.5488 - mean_absolute_error: 33.3787\n",
      "Epoch 116: val_loss improved from 13651.71191 to 13501.42383, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3093.2124 - mean_absolute_error: 34.8771 - val_loss: 13501.4238 - val_mean_absolute_error: 101.5978\n",
      "Epoch 117/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2072.7986 - mean_absolute_error: 30.1643\n",
      "Epoch 117: val_loss improved from 13501.42383 to 13354.09473, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3360.4136 - mean_absolute_error: 35.6974 - val_loss: 13354.0947 - val_mean_absolute_error: 100.8791\n",
      "Epoch 118/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2454.0823 - mean_absolute_error: 34.0996\n",
      "Epoch 118: val_loss improved from 13354.09473 to 13204.77539, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3155.3311 - mean_absolute_error: 34.2975 - val_loss: 13204.7754 - val_mean_absolute_error: 100.1228\n",
      "Epoch 119/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4647.1079 - mean_absolute_error: 38.2505\n",
      "Epoch 119: val_loss improved from 13204.77539 to 13063.42383, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3353.8142 - mean_absolute_error: 34.6230 - val_loss: 13063.4238 - val_mean_absolute_error: 99.4208\n",
      "Epoch 120/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2692.2515 - mean_absolute_error: 37.7875\n",
      "Epoch 120: val_loss improved from 13063.42383 to 12925.81250, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3291.4241 - mean_absolute_error: 36.2431 - val_loss: 12925.8125 - val_mean_absolute_error: 98.7450\n",
      "Epoch 121/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2129.0754 - mean_absolute_error: 27.7780\n",
      "Epoch 121: val_loss improved from 12925.81250 to 12777.21387, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3043.4802 - mean_absolute_error: 34.2152 - val_loss: 12777.2139 - val_mean_absolute_error: 97.9675\n",
      "Epoch 122/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3640.8491 - mean_absolute_error: 36.3695\n",
      "Epoch 122: val_loss improved from 12777.21387 to 12644.93555, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3206.9995 - mean_absolute_error: 35.0728 - val_loss: 12644.9355 - val_mean_absolute_error: 97.3171\n",
      "Epoch 123/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3352.6938 - mean_absolute_error: 36.1442\n",
      "Epoch 123: val_loss improved from 12644.93555 to 12506.26855, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2995.0259 - mean_absolute_error: 33.3312 - val_loss: 12506.2686 - val_mean_absolute_error: 96.5914\n",
      "Epoch 124/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3780.1282 - mean_absolute_error: 35.0189\n",
      "Epoch 124: val_loss improved from 12506.26855 to 12373.73633, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2811.5459 - mean_absolute_error: 32.3293 - val_loss: 12373.7363 - val_mean_absolute_error: 95.9323\n",
      "Epoch 125/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1721.1143 - mean_absolute_error: 29.1021\n",
      "Epoch 125: val_loss improved from 12373.73633 to 12238.82617, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2907.4558 - mean_absolute_error: 33.9785 - val_loss: 12238.8262 - val_mean_absolute_error: 95.2412\n",
      "Epoch 126/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3080.8076 - mean_absolute_error: 38.3126\n",
      "Epoch 126: val_loss improved from 12238.82617 to 12098.83984, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2963.2715 - mean_absolute_error: 33.1126 - val_loss: 12098.8398 - val_mean_absolute_error: 94.4896\n",
      "Epoch 127/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2969.7734 - mean_absolute_error: 37.2343\n",
      "Epoch 127: val_loss improved from 12098.83984 to 11974.82031, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2784.5947 - mean_absolute_error: 33.4304 - val_loss: 11974.8203 - val_mean_absolute_error: 93.8577\n",
      "Epoch 128/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3062.6274 - mean_absolute_error: 34.4438 \n",
      "Epoch 128: val_loss improved from 11974.82031 to 11844.74219, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3053.9636 - mean_absolute_error: 34.3560 - val_loss: 11844.7422 - val_mean_absolute_error: 93.1884\n",
      "Epoch 129/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2118.4021 - mean_absolute_error: 28.1776\n",
      "Epoch 129: val_loss improved from 11844.74219 to 11700.93750, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3006.9326 - mean_absolute_error: 33.0862 - val_loss: 11700.9375 - val_mean_absolute_error: 92.4150\n",
      "Epoch 130/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 957.1620 - mean_absolute_error: 22.2430\n",
      "Epoch 130: val_loss improved from 11700.93750 to 11577.21289, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2692.9441 - mean_absolute_error: 31.6338 - val_loss: 11577.2129 - val_mean_absolute_error: 91.7939\n",
      "Epoch 131/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2815.5896 - mean_absolute_error: 32.4666\n",
      "Epoch 131: val_loss improved from 11577.21289 to 11447.22461, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2822.3169 - mean_absolute_error: 32.8051 - val_loss: 11447.2246 - val_mean_absolute_error: 91.1302\n",
      "Epoch 132/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1131.2810 - mean_absolute_error: 19.1780\n",
      "Epoch 132: val_loss improved from 11447.22461 to 11313.12109, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2439.5645 - mean_absolute_error: 30.3498 - val_loss: 11313.1211 - val_mean_absolute_error: 90.4290\n",
      "Epoch 133/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3858.5886 - mean_absolute_error: 34.7800\n",
      "Epoch 133: val_loss improved from 11313.12109 to 11193.01758, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3129.3965 - mean_absolute_error: 32.8843 - val_loss: 11193.0176 - val_mean_absolute_error: 89.8402\n",
      "Epoch 134/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 710.2313 - mean_absolute_error: 19.9553\n",
      "Epoch 134: val_loss improved from 11193.01758 to 11068.30371, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2673.0159 - mean_absolute_error: 31.4322 - val_loss: 11068.3037 - val_mean_absolute_error: 89.2020\n",
      "Epoch 135/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3002.6392 - mean_absolute_error: 32.5878 \n",
      "Epoch 135: val_loss improved from 11068.30371 to 10951.97461, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2977.1704 - mean_absolute_error: 32.5116 - val_loss: 10951.9746 - val_mean_absolute_error: 88.6244\n",
      "Epoch 136/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1050.8499 - mean_absolute_error: 22.1079\n",
      "Epoch 136: val_loss improved from 10951.97461 to 10813.87500, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2542.3887 - mean_absolute_error: 30.4556 - val_loss: 10813.8750 - val_mean_absolute_error: 87.8673\n",
      "Epoch 137/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3010.5378 - mean_absolute_error: 30.9407\n",
      "Epoch 137: val_loss improved from 10813.87500 to 10698.79883, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2620.8025 - mean_absolute_error: 31.0188 - val_loss: 10698.7988 - val_mean_absolute_error: 87.2817\n",
      "Epoch 138/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3546.2549 - mean_absolute_error: 33.7656\n",
      "Epoch 138: val_loss improved from 10698.79883 to 10581.24805, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2485.7000 - mean_absolute_error: 30.2568 - val_loss: 10581.2480 - val_mean_absolute_error: 86.6663\n",
      "Epoch 139/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3016.3606 - mean_absolute_error: 32.5037 \n",
      "Epoch 139: val_loss improved from 10581.24805 to 10451.78516, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2979.5203 - mean_absolute_error: 32.3611 - val_loss: 10451.7852 - val_mean_absolute_error: 85.9597\n",
      "Epoch 140/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2404.4529 - mean_absolute_error: 29.1374\n",
      "Epoch 140: val_loss improved from 10451.78516 to 10332.10156, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2420.1047 - mean_absolute_error: 29.2897 - val_loss: 10332.1016 - val_mean_absolute_error: 85.3045\n",
      "Epoch 141/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4817.5874 - mean_absolute_error: 36.6302\n",
      "Epoch 141: val_loss improved from 10332.10156 to 10221.01367, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2698.9390 - mean_absolute_error: 31.5696 - val_loss: 10221.0137 - val_mean_absolute_error: 84.7307\n",
      "Epoch 142/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5941.9639 - mean_absolute_error: 49.7430\n",
      "Epoch 142: val_loss improved from 10221.01367 to 10104.91211, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2759.8926 - mean_absolute_error: 31.2238 - val_loss: 10104.9121 - val_mean_absolute_error: 84.0992\n",
      "Epoch 143/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3388.8018 - mean_absolute_error: 29.7641\n",
      "Epoch 143: val_loss improved from 10104.91211 to 9987.71387, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2765.7053 - mean_absolute_error: 31.8103 - val_loss: 9987.7139 - val_mean_absolute_error: 83.4665\n",
      "Epoch 144/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 934.0795 - mean_absolute_error: 20.9309\n",
      "Epoch 144: val_loss improved from 9987.71387 to 9880.90234, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2231.5322 - mean_absolute_error: 29.4142 - val_loss: 9880.9023 - val_mean_absolute_error: 82.8876\n",
      "Epoch 145/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3463.2695 - mean_absolute_error: 36.8774\n",
      "Epoch 145: val_loss improved from 9880.90234 to 9757.90820, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2452.3860 - mean_absolute_error: 30.2592 - val_loss: 9757.9082 - val_mean_absolute_error: 82.1986\n",
      "Epoch 146/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2024.3959 - mean_absolute_error: 29.8180\n",
      "Epoch 146: val_loss improved from 9757.90820 to 9641.46973, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2341.6162 - mean_absolute_error: 30.0622 - val_loss: 9641.4697 - val_mean_absolute_error: 81.5890\n",
      "Epoch 147/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2907.5510 - mean_absolute_error: 38.0000\n",
      "Epoch 147: val_loss improved from 9641.46973 to 9529.35059, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2482.2568 - mean_absolute_error: 31.2972 - val_loss: 9529.3506 - val_mean_absolute_error: 81.0065\n",
      "Epoch 148/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 3409.1616 - mean_absolute_error: 34.2171\n",
      "Epoch 148: val_loss improved from 9529.35059 to 9424.94824, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2507.3325 - mean_absolute_error: 30.0474 - val_loss: 9424.9482 - val_mean_absolute_error: 80.4664\n",
      "Epoch 149/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5088.0361 - mean_absolute_error: 43.3271\n",
      "Epoch 149: val_loss improved from 9424.94824 to 9304.69141, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2445.7014 - mean_absolute_error: 29.6802 - val_loss: 9304.6914 - val_mean_absolute_error: 79.8224\n",
      "Epoch 150/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2383.8108 - mean_absolute_error: 29.1739 \n",
      "Epoch 150: val_loss improved from 9304.69141 to 9195.50781, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2378.1829 - mean_absolute_error: 29.1958 - val_loss: 9195.5078 - val_mean_absolute_error: 79.2856\n",
      "Epoch 151/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2160.9106 - mean_absolute_error: 28.1789 \n",
      "Epoch 151: val_loss improved from 9195.50781 to 9084.41699, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2173.9023 - mean_absolute_error: 28.2675 - val_loss: 9084.4170 - val_mean_absolute_error: 78.7285\n",
      "Epoch 152/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2238.2744 - mean_absolute_error: 28.4206 \n",
      "Epoch 152: val_loss improved from 9084.41699 to 8987.46777, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2251.0564 - mean_absolute_error: 28.5900 - val_loss: 8987.4678 - val_mean_absolute_error: 78.2540\n",
      "Epoch 153/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2053.8821 - mean_absolute_error: 27.1473 \n",
      "Epoch 153: val_loss improved from 8987.46777 to 8873.09961, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2083.2007 - mean_absolute_error: 27.3880 - val_loss: 8873.0996 - val_mean_absolute_error: 77.6660\n",
      "Epoch 154/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4037.8779 - mean_absolute_error: 36.9027\n",
      "Epoch 154: val_loss improved from 8873.09961 to 8777.95312, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2488.0266 - mean_absolute_error: 30.3983 - val_loss: 8777.9531 - val_mean_absolute_error: 77.1989\n",
      "Epoch 155/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 940.0481 - mean_absolute_error: 22.2105\n",
      "Epoch 155: val_loss improved from 8777.95312 to 8673.71973, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2137.4702 - mean_absolute_error: 28.2228 - val_loss: 8673.7197 - val_mean_absolute_error: 76.6565\n",
      "Epoch 156/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3097.1416 - mean_absolute_error: 30.6199\n",
      "Epoch 156: val_loss improved from 8673.71973 to 8560.27051, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2237.3713 - mean_absolute_error: 28.4091 - val_loss: 8560.2705 - val_mean_absolute_error: 76.0537\n",
      "Epoch 157/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2241.2422 - mean_absolute_error: 29.3631 \n",
      "Epoch 157: val_loss improved from 8560.27051 to 8458.53516, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2214.6033 - mean_absolute_error: 29.1133 - val_loss: 8458.5352 - val_mean_absolute_error: 75.5237\n",
      "Epoch 158/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1099.6895 - mean_absolute_error: 22.9213\n",
      "Epoch 158: val_loss improved from 8458.53516 to 8363.51465, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1892.1960 - mean_absolute_error: 26.7010 - val_loss: 8363.5146 - val_mean_absolute_error: 75.0263\n",
      "Epoch 159/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2079.7278 - mean_absolute_error: 26.3716\n",
      "Epoch 159: val_loss improved from 8363.51465 to 8258.41797, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2264.8909 - mean_absolute_error: 28.7709 - val_loss: 8258.4180 - val_mean_absolute_error: 74.4645\n",
      "Epoch 160/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1716.8435 - mean_absolute_error: 25.4765\n",
      "Epoch 160: val_loss improved from 8258.41797 to 8161.02100, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2030.5857 - mean_absolute_error: 27.6785 - val_loss: 8161.0210 - val_mean_absolute_error: 73.9477\n",
      "Epoch 161/1500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1756.7916 - mean_absolute_error: 25.9419 \n",
      "Epoch 161: val_loss improved from 8161.02100 to 8056.03076, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1865.1754 - mean_absolute_error: 26.4944 - val_loss: 8056.0308 - val_mean_absolute_error: 73.3602\n",
      "Epoch 162/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2100.4707 - mean_absolute_error: 28.3659 \n",
      "Epoch 162: val_loss improved from 8056.03076 to 7966.59033, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2098.6128 - mean_absolute_error: 28.3263 - val_loss: 7966.5903 - val_mean_absolute_error: 72.8895\n",
      "Epoch 163/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1429.7635 - mean_absolute_error: 26.2768\n",
      "Epoch 163: val_loss improved from 7966.59033 to 7862.47510, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2059.0034 - mean_absolute_error: 27.1010 - val_loss: 7862.4751 - val_mean_absolute_error: 72.2977\n",
      "Epoch 164/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2436.7646 - mean_absolute_error: 27.7597\n",
      "Epoch 164: val_loss improved from 7862.47510 to 7756.81641, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1920.7186 - mean_absolute_error: 26.7317 - val_loss: 7756.8164 - val_mean_absolute_error: 71.6954\n",
      "Epoch 165/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2451.7710 - mean_absolute_error: 30.0099 \n",
      "Epoch 165: val_loss improved from 7756.81641 to 7671.36182, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2399.5413 - mean_absolute_error: 29.6961 - val_loss: 7671.3618 - val_mean_absolute_error: 71.2376\n",
      "Epoch 166/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2206.5320 - mean_absolute_error: 28.2544 \n",
      "Epoch 166: val_loss improved from 7671.36182 to 7559.00830, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2200.1750 - mean_absolute_error: 28.2225 - val_loss: 7559.0083 - val_mean_absolute_error: 70.5668\n",
      "Epoch 167/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1764.6206 - mean_absolute_error: 28.2285\n",
      "Epoch 167: val_loss improved from 7559.00830 to 7350.67139, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1908.9689 - mean_absolute_error: 26.6206 - val_loss: 7350.6714 - val_mean_absolute_error: 69.3385\n",
      "Epoch 168/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1437.5859 - mean_absolute_error: 25.7057\n",
      "Epoch 168: val_loss improved from 7350.67139 to 7213.50586, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1743.5964 - mean_absolute_error: 26.7644 - val_loss: 7213.5059 - val_mean_absolute_error: 68.5891\n",
      "Epoch 169/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2050.9968 - mean_absolute_error: 28.7844\n",
      "Epoch 169: val_loss improved from 7213.50586 to 7116.90186, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2052.2566 - mean_absolute_error: 27.0710 - val_loss: 7116.9019 - val_mean_absolute_error: 68.0134\n",
      "Epoch 170/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2014.2125 - mean_absolute_error: 27.4560\n",
      "Epoch 170: val_loss improved from 7116.90186 to 7024.67383, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2000.6736 - mean_absolute_error: 27.3611 - val_loss: 7024.6738 - val_mean_absolute_error: 67.4503\n",
      "Epoch 171/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1475.3982 - mean_absolute_error: 22.8205\n",
      "Epoch 171: val_loss improved from 7024.67383 to 6933.86035, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1986.1267 - mean_absolute_error: 26.5520 - val_loss: 6933.8604 - val_mean_absolute_error: 66.8860\n",
      "Epoch 172/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1731.6299 - mean_absolute_error: 25.2215\n",
      "Epoch 172: val_loss improved from 6933.86035 to 6851.29883, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1568.3679 - mean_absolute_error: 24.9851 - val_loss: 6851.2988 - val_mean_absolute_error: 66.3780\n",
      "Epoch 173/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2773.7317 - mean_absolute_error: 25.4991\n",
      "Epoch 173: val_loss improved from 6851.29883 to 6760.96045, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1885.4409 - mean_absolute_error: 26.3345 - val_loss: 6760.9604 - val_mean_absolute_error: 65.8121\n",
      "Epoch 174/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1644.2267 - mean_absolute_error: 25.2578\n",
      "Epoch 174: val_loss improved from 6760.96045 to 6680.75439, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1686.9680 - mean_absolute_error: 25.4859 - val_loss: 6680.7544 - val_mean_absolute_error: 65.3214\n",
      "Epoch 175/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1673.5249 - mean_absolute_error: 24.6815\n",
      "Epoch 175: val_loss improved from 6680.75439 to 6598.07861, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1854.2825 - mean_absolute_error: 26.2825 - val_loss: 6598.0786 - val_mean_absolute_error: 64.8269\n",
      "Epoch 176/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1436.2142 - mean_absolute_error: 23.5374\n",
      "Epoch 176: val_loss improved from 6598.07861 to 6515.49414, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1560.8123 - mean_absolute_error: 24.6462 - val_loss: 6515.4941 - val_mean_absolute_error: 64.3094\n",
      "Epoch 177/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 444.5681 - mean_absolute_error: 17.0538\n",
      "Epoch 177: val_loss improved from 6515.49414 to 6447.62842, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1602.7699 - mean_absolute_error: 24.3061 - val_loss: 6447.6284 - val_mean_absolute_error: 63.9169\n",
      "Epoch 178/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1769.2671 - mean_absolute_error: 25.8112 \n",
      "Epoch 178: val_loss improved from 6447.62842 to 6360.01953, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1768.2469 - mean_absolute_error: 25.8077 - val_loss: 6360.0195 - val_mean_absolute_error: 63.3519\n",
      "Epoch 179/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2092.9395 - mean_absolute_error: 27.3186 \n",
      "Epoch 179: val_loss improved from 6360.01953 to 6290.70605, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2082.4614 - mean_absolute_error: 27.2708 - val_loss: 6290.7061 - val_mean_absolute_error: 62.9374\n",
      "Epoch 180/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1604.1418 - mean_absolute_error: 26.3557\n",
      "Epoch 180: val_loss improved from 6290.70605 to 6206.67383, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1588.1116 - mean_absolute_error: 24.8567 - val_loss: 6206.6738 - val_mean_absolute_error: 62.3746\n",
      "Epoch 181/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1232.5608 - mean_absolute_error: 22.4024\n",
      "Epoch 181: val_loss improved from 6206.67383 to 6129.36230, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1632.9114 - mean_absolute_error: 24.6988 - val_loss: 6129.3623 - val_mean_absolute_error: 61.8781\n",
      "Epoch 182/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1028.4052 - mean_absolute_error: 22.5950\n",
      "Epoch 182: val_loss improved from 6129.36230 to 6058.79395, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1532.4310 - mean_absolute_error: 24.8626 - val_loss: 6058.7939 - val_mean_absolute_error: 61.4293\n",
      "Epoch 183/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1334.4664 - mean_absolute_error: 22.7754\n",
      "Epoch 183: val_loss improved from 6058.79395 to 5999.34814, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1422.2227 - mean_absolute_error: 23.4315 - val_loss: 5999.3481 - val_mean_absolute_error: 61.0750\n",
      "Epoch 184/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2050.4670 - mean_absolute_error: 30.2764\n",
      "Epoch 184: val_loss improved from 5999.34814 to 5918.75098, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1629.2819 - mean_absolute_error: 24.9968 - val_loss: 5918.7510 - val_mean_absolute_error: 60.5219\n",
      "Epoch 185/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1222.3312 - mean_absolute_error: 21.1403\n",
      "Epoch 185: val_loss improved from 5918.75098 to 5844.52197, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1459.7175 - mean_absolute_error: 24.1051 - val_loss: 5844.5220 - val_mean_absolute_error: 60.0129\n",
      "Epoch 186/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 935.5306 - mean_absolute_error: 20.8738\n",
      "Epoch 186: val_loss improved from 5844.52197 to 5789.00098, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1822.9342 - mean_absolute_error: 25.3871 - val_loss: 5789.0010 - val_mean_absolute_error: 59.6748\n",
      "Epoch 187/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1678.1888 - mean_absolute_error: 25.0369 \n",
      "Epoch 187: val_loss improved from 5789.00098 to 5710.77197, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1673.7996 - mean_absolute_error: 25.0784 - val_loss: 5710.7720 - val_mean_absolute_error: 59.1257\n",
      "Epoch 188/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1728.3246 - mean_absolute_error: 25.3961 \n",
      "Epoch 188: val_loss improved from 5710.77197 to 5633.60107, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1721.5968 - mean_absolute_error: 25.3668 - val_loss: 5633.6011 - val_mean_absolute_error: 58.5737\n",
      "Epoch 189/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2161.4995 - mean_absolute_error: 23.7473\n",
      "Epoch 189: val_loss improved from 5633.60107 to 5563.64014, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1585.6379 - mean_absolute_error: 24.1168 - val_loss: 5563.6401 - val_mean_absolute_error: 58.0896\n",
      "Epoch 190/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1245.3452 - mean_absolute_error: 27.5605\n",
      "Epoch 190: val_loss improved from 5563.64014 to 5499.08057, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1431.3889 - mean_absolute_error: 24.6766 - val_loss: 5499.0806 - val_mean_absolute_error: 57.6629\n",
      "Epoch 191/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 300.9741 - mean_absolute_error: 13.6329\n",
      "Epoch 191: val_loss improved from 5499.08057 to 5436.75537, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1393.8411 - mean_absolute_error: 23.4999 - val_loss: 5436.7554 - val_mean_absolute_error: 57.2495\n",
      "Epoch 192/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 2047.8252 - mean_absolute_error: 30.9581\n",
      "Epoch 192: val_loss improved from 5436.75537 to 5357.70020, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1645.8760 - mean_absolute_error: 25.0786 - val_loss: 5357.7002 - val_mean_absolute_error: 56.6880\n",
      "Epoch 193/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 555.5270 - mean_absolute_error: 19.0294\n",
      "Epoch 193: val_loss improved from 5357.70020 to 5307.47559, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1419.4266 - mean_absolute_error: 24.2288 - val_loss: 5307.4756 - val_mean_absolute_error: 56.3597\n",
      "Epoch 194/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1588.0920 - mean_absolute_error: 25.9794\n",
      "Epoch 194: val_loss improved from 5307.47559 to 5243.30518, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1647.4473 - mean_absolute_error: 25.2862 - val_loss: 5243.3052 - val_mean_absolute_error: 55.9304\n",
      "Epoch 195/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 901.6617 - mean_absolute_error: 21.3355\n",
      "Epoch 195: val_loss improved from 5243.30518 to 5180.51514, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1346.2645 - mean_absolute_error: 23.2257 - val_loss: 5180.5151 - val_mean_absolute_error: 55.4922\n",
      "Epoch 196/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1522.1938 - mean_absolute_error: 24.1319 \n",
      "Epoch 196: val_loss improved from 5180.51514 to 5121.05664, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1514.8616 - mean_absolute_error: 24.0975 - val_loss: 5121.0566 - val_mean_absolute_error: 55.1218\n",
      "Epoch 197/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1385.0411 - mean_absolute_error: 23.7129\n",
      "Epoch 197: val_loss improved from 5121.05664 to 5065.93945, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1388.6113 - mean_absolute_error: 23.7273 - val_loss: 5065.9395 - val_mean_absolute_error: 54.7824\n",
      "Epoch 198/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1124.6064 - mean_absolute_error: 20.0878\n",
      "Epoch 198: val_loss improved from 5065.93945 to 4999.27686, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1416.6477 - mean_absolute_error: 23.1283 - val_loss: 4999.2769 - val_mean_absolute_error: 54.3489\n",
      "Epoch 199/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1070.3516 - mean_absolute_error: 19.0962\n",
      "Epoch 199: val_loss improved from 4999.27686 to 4950.52588, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1502.1294 - mean_absolute_error: 23.5563 - val_loss: 4950.5259 - val_mean_absolute_error: 54.0464\n",
      "Epoch 200/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1853.1541 - mean_absolute_error: 25.3323\n",
      "Epoch 200: val_loss improved from 4950.52588 to 4901.72998, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1439.0449 - mean_absolute_error: 23.7783 - val_loss: 4901.7300 - val_mean_absolute_error: 53.7433\n",
      "Epoch 201/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2479.9329 - mean_absolute_error: 29.0712\n",
      "Epoch 201: val_loss improved from 4901.72998 to 4846.71924, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1484.1249 - mean_absolute_error: 23.4863 - val_loss: 4846.7192 - val_mean_absolute_error: 53.3767\n",
      "Epoch 202/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2054.4521 - mean_absolute_error: 23.7742\n",
      "Epoch 202: val_loss improved from 4846.71924 to 4791.37207, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1408.0594 - mean_absolute_error: 22.8499 - val_loss: 4791.3721 - val_mean_absolute_error: 53.0282\n",
      "Epoch 203/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1064.0797 - mean_absolute_error: 20.3206\n",
      "Epoch 203: val_loss improved from 4791.37207 to 4741.44629, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1303.9821 - mean_absolute_error: 22.4499 - val_loss: 4741.4463 - val_mean_absolute_error: 52.6871\n",
      "Epoch 204/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3285.5857 - mean_absolute_error: 34.8794\n",
      "Epoch 204: val_loss improved from 4741.44629 to 4675.93066, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1521.4653 - mean_absolute_error: 24.6263 - val_loss: 4675.9307 - val_mean_absolute_error: 52.2164\n",
      "Epoch 205/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1599.4409 - mean_absolute_error: 23.9963 \n",
      "Epoch 205: val_loss improved from 4675.93066 to 4629.28369, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1578.7937 - mean_absolute_error: 23.9471 - val_loss: 4629.2837 - val_mean_absolute_error: 51.9245\n",
      "Epoch 206/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 982.5211 - mean_absolute_error: 20.5569\n",
      "Epoch 206: val_loss improved from 4629.28369 to 4587.53955, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1452.8904 - mean_absolute_error: 23.2985 - val_loss: 4587.5396 - val_mean_absolute_error: 51.6766\n",
      "Epoch 207/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 752.7120 - mean_absolute_error: 19.7873\n",
      "Epoch 207: val_loss improved from 4587.53955 to 4533.74316, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1671.5194 - mean_absolute_error: 24.9696 - val_loss: 4533.7432 - val_mean_absolute_error: 51.3089\n",
      "Epoch 208/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1327.1589 - mean_absolute_error: 25.7238\n",
      "Epoch 208: val_loss improved from 4533.74316 to 4482.58154, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1311.7853 - mean_absolute_error: 22.7484 - val_loss: 4482.5815 - val_mean_absolute_error: 50.9565\n",
      "Epoch 209/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1348.6704 - mean_absolute_error: 23.0363\n",
      "Epoch 209: val_loss improved from 4482.58154 to 4426.26367, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1357.3048 - mean_absolute_error: 23.1086 - val_loss: 4426.2637 - val_mean_absolute_error: 50.5582\n",
      "Epoch 210/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 836.8014 - mean_absolute_error: 20.0374\n",
      "Epoch 210: val_loss improved from 4426.26367 to 4380.20898, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1532.1022 - mean_absolute_error: 23.9491 - val_loss: 4380.2090 - val_mean_absolute_error: 50.2612\n",
      "Epoch 211/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 669.7616 - mean_absolute_error: 18.2050\n",
      "Epoch 211: val_loss improved from 4380.20898 to 4339.34717, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1245.3479 - mean_absolute_error: 22.5900 - val_loss: 4339.3472 - val_mean_absolute_error: 50.0075\n",
      "Epoch 212/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1462.6934 - mean_absolute_error: 25.7823\n",
      "Epoch 212: val_loss improved from 4339.34717 to 4291.93213, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1374.5524 - mean_absolute_error: 23.4322 - val_loss: 4291.9321 - val_mean_absolute_error: 49.6877\n",
      "Epoch 213/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 775.4188 - mean_absolute_error: 18.5917\n",
      "Epoch 213: val_loss improved from 4291.93213 to 4266.60059, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1255.3447 - mean_absolute_error: 22.7552 - val_loss: 4266.6006 - val_mean_absolute_error: 49.5871\n",
      "Epoch 214/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247.4451 - mean_absolute_error: 22.3008 \n",
      "Epoch 214: val_loss improved from 4266.60059 to 4223.19873, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1253.6501 - mean_absolute_error: 22.3510 - val_loss: 4223.1987 - val_mean_absolute_error: 49.3372\n",
      "Epoch 215/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2326.1216 - mean_absolute_error: 26.3710\n",
      "Epoch 215: val_loss improved from 4223.19873 to 4175.44189, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1369.4702 - mean_absolute_error: 22.5235 - val_loss: 4175.4419 - val_mean_absolute_error: 49.0736\n",
      "Epoch 216/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1824.4409 - mean_absolute_error: 28.7216\n",
      "Epoch 216: val_loss improved from 4175.44189 to 4140.19629, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1320.4590 - mean_absolute_error: 22.9504 - val_loss: 4140.1963 - val_mean_absolute_error: 48.9037\n",
      "Epoch 217/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1542.0123 - mean_absolute_error: 24.5787\n",
      "Epoch 217: val_loss improved from 4140.19629 to 4083.77002, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1389.4056 - mean_absolute_error: 23.3728 - val_loss: 4083.7700 - val_mean_absolute_error: 48.5471\n",
      "Epoch 218/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1264.3579 - mean_absolute_error: 22.2605 \n",
      "Epoch 218: val_loss improved from 4083.77002 to 4044.97241, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1270.8337 - mean_absolute_error: 22.3526 - val_loss: 4044.9724 - val_mean_absolute_error: 48.3457\n",
      "Epoch 219/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 625.5834 - mean_absolute_error: 19.3685\n",
      "Epoch 219: val_loss improved from 4044.97241 to 4003.74316, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1301.3358 - mean_absolute_error: 23.3799 - val_loss: 4003.7432 - val_mean_absolute_error: 48.1019\n",
      "Epoch 220/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1351.4517 - mean_absolute_error: 24.8267\n",
      "Epoch 220: val_loss improved from 4003.74316 to 3973.85010, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1299.1619 - mean_absolute_error: 22.1161 - val_loss: 3973.8501 - val_mean_absolute_error: 47.9647\n",
      "Epoch 221/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1362.7040 - mean_absolute_error: 23.8759\n",
      "Epoch 221: val_loss improved from 3973.85010 to 3925.16724, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1233.2023 - mean_absolute_error: 22.0419 - val_loss: 3925.1672 - val_mean_absolute_error: 47.6644\n",
      "Epoch 222/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.7318 - mean_absolute_error: 21.8377 \n",
      "Epoch 222: val_loss improved from 3925.16724 to 3897.98389, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1148.2919 - mean_absolute_error: 21.9370 - val_loss: 3897.9839 - val_mean_absolute_error: 47.5434\n",
      "Epoch 223/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.8472 - mean_absolute_error: 21.8058\n",
      "Epoch 223: val_loss improved from 3897.98389 to 3848.07202, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1167.1669 - mean_absolute_error: 21.8527 - val_loss: 3848.0720 - val_mean_absolute_error: 47.1848\n",
      "Epoch 224/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1632.3345 - mean_absolute_error: 25.8259\n",
      "Epoch 224: val_loss improved from 3848.07202 to 3832.43286, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1331.6967 - mean_absolute_error: 23.5075 - val_loss: 3832.4329 - val_mean_absolute_error: 47.1853\n",
      "Epoch 225/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2286.1392 - mean_absolute_error: 31.4216\n",
      "Epoch 225: val_loss improved from 3832.43286 to 3783.48340, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1583.3159 - mean_absolute_error: 24.6722 - val_loss: 3783.4834 - val_mean_absolute_error: 46.8643\n",
      "Epoch 226/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1214.8647 - mean_absolute_error: 22.2337 \n",
      "Epoch 226: val_loss improved from 3783.48340 to 3752.88721, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1219.4141 - mean_absolute_error: 22.2578 - val_loss: 3752.8872 - val_mean_absolute_error: 46.6961\n",
      "Epoch 227/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1350.2306 - mean_absolute_error: 27.7907\n",
      "Epoch 227: val_loss improved from 3752.88721 to 3717.06250, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1145.8975 - mean_absolute_error: 22.4953 - val_loss: 3717.0625 - val_mean_absolute_error: 46.4679\n",
      "Epoch 228/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1388.7540 - mean_absolute_error: 22.9041 \n",
      "Epoch 228: val_loss improved from 3717.06250 to 3682.91382, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1384.8765 - mean_absolute_error: 22.8902 - val_loss: 3682.9138 - val_mean_absolute_error: 46.2522\n",
      "Epoch 229/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2009.2798 - mean_absolute_error: 28.1482\n",
      "Epoch 229: val_loss improved from 3682.91382 to 3652.42773, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1233.7002 - mean_absolute_error: 22.8066 - val_loss: 3652.4277 - val_mean_absolute_error: 46.0750\n",
      "Epoch 230/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1237.9629 - mean_absolute_error: 25.2889\n",
      "Epoch 230: val_loss improved from 3652.42773 to 3618.44214, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1198.0865 - mean_absolute_error: 22.6866 - val_loss: 3618.4421 - val_mean_absolute_error: 45.8550\n",
      "Epoch 231/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1278.9856 - mean_absolute_error: 23.3346 \n",
      "Epoch 231: val_loss improved from 3618.44214 to 3586.46533, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1269.6770 - mean_absolute_error: 23.1442 - val_loss: 3586.4653 - val_mean_absolute_error: 45.6528\n",
      "Epoch 232/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1059.7413 - mean_absolute_error: 21.9544\n",
      "Epoch 232: val_loss improved from 3586.46533 to 3556.05566, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1228.8086 - mean_absolute_error: 22.7186 - val_loss: 3556.0557 - val_mean_absolute_error: 45.4834\n",
      "Epoch 233/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1362.8086 - mean_absolute_error: 27.0011\n",
      "Epoch 233: val_loss improved from 3556.05566 to 3529.44409, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1198.7792 - mean_absolute_error: 22.0504 - val_loss: 3529.4441 - val_mean_absolute_error: 45.3204\n",
      "Epoch 234/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1078.9213 - mean_absolute_error: 20.9195\n",
      "Epoch 234: val_loss improved from 3529.44409 to 3488.14941, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1313.0249 - mean_absolute_error: 23.1494 - val_loss: 3488.1494 - val_mean_absolute_error: 45.0269\n",
      "Epoch 235/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248.5336 - mean_absolute_error: 22.8985\n",
      "Epoch 235: val_loss improved from 3488.14941 to 3476.67310, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243.1886 - mean_absolute_error: 22.7864 - val_loss: 3476.6731 - val_mean_absolute_error: 45.0326\n",
      "Epoch 236/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1281.4479 - mean_absolute_error: 22.5118\n",
      "Epoch 236: val_loss improved from 3476.67310 to 3437.25586, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1283.8749 - mean_absolute_error: 22.5652 - val_loss: 3437.2559 - val_mean_absolute_error: 44.7444\n",
      "Epoch 237/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 522.5360 - mean_absolute_error: 15.9489\n",
      "Epoch 237: val_loss improved from 3437.25586 to 3416.87695, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1191.1835 - mean_absolute_error: 22.2910 - val_loss: 3416.8770 - val_mean_absolute_error: 44.7067\n",
      "Epoch 238/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2138.8267 - mean_absolute_error: 31.7603\n",
      "Epoch 238: val_loss improved from 3416.87695 to 3381.84546, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1242.7961 - mean_absolute_error: 22.4216 - val_loss: 3381.8455 - val_mean_absolute_error: 44.4982\n",
      "Epoch 239/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 3644.7383 - mean_absolute_error: 36.3381\n",
      "Epoch 239: val_loss improved from 3381.84546 to 3363.98560, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1445.7139 - mean_absolute_error: 23.6732 - val_loss: 3363.9856 - val_mean_absolute_error: 44.4705\n",
      "Epoch 240/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 407.8088 - mean_absolute_error: 13.6696\n",
      "Epoch 240: val_loss improved from 3363.98560 to 3340.48315, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1079.0912 - mean_absolute_error: 21.0722 - val_loss: 3340.4832 - val_mean_absolute_error: 44.3400\n",
      "Epoch 241/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 289.3956 - mean_absolute_error: 14.3246\n",
      "Epoch 241: val_loss improved from 3340.48315 to 3313.02490, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1229.0985 - mean_absolute_error: 21.8724 - val_loss: 3313.0249 - val_mean_absolute_error: 44.1814\n",
      "Epoch 242/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 597.0720 - mean_absolute_error: 15.9147\n",
      "Epoch 242: val_loss improved from 3313.02490 to 3294.61230, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1062.4785 - mean_absolute_error: 20.8876 - val_loss: 3294.6123 - val_mean_absolute_error: 44.0862\n",
      "Epoch 243/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2304.6255 - mean_absolute_error: 28.2750\n",
      "Epoch 243: val_loss improved from 3294.61230 to 3269.36548, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1308.4104 - mean_absolute_error: 22.8960 - val_loss: 3269.3655 - val_mean_absolute_error: 43.9714\n",
      "Epoch 244/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1262.0205 - mean_absolute_error: 22.4424 \n",
      "Epoch 244: val_loss improved from 3269.36548 to 3246.33105, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243.7115 - mean_absolute_error: 22.3000 - val_loss: 3246.3311 - val_mean_absolute_error: 43.8802\n",
      "Epoch 245/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1287.3071 - mean_absolute_error: 22.2442\n",
      "Epoch 245: val_loss improved from 3246.33105 to 3223.04346, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1270.0854 - mean_absolute_error: 22.1994 - val_loss: 3223.0435 - val_mean_absolute_error: 43.7658\n",
      "Epoch 246/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 842.8160 - mean_absolute_error: 19.5435\n",
      "Epoch 246: val_loss improved from 3223.04346 to 3198.58716, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1064.7159 - mean_absolute_error: 20.9871 - val_loss: 3198.5872 - val_mean_absolute_error: 43.6403\n",
      "Epoch 247/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2159.9551 - mean_absolute_error: 25.3957\n",
      "Epoch 247: val_loss improved from 3198.58716 to 3169.71460, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1243.4437 - mean_absolute_error: 22.0344 - val_loss: 3169.7146 - val_mean_absolute_error: 43.4709\n",
      "Epoch 248/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1243.5220 - mean_absolute_error: 22.7791\n",
      "Epoch 248: val_loss did not improve from 3169.71460\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1235.6649 - mean_absolute_error: 22.6899 - val_loss: 3169.8855 - val_mean_absolute_error: 43.5835\n",
      "Epoch 249/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 762.0685 - mean_absolute_error: 19.8414\n",
      "Epoch 249: val_loss improved from 3169.71460 to 3137.14282, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1145.8159 - mean_absolute_error: 22.0940 - val_loss: 3137.1428 - val_mean_absolute_error: 43.4122\n",
      "Epoch 250/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 951.3583 - mean_absolute_error: 18.2771\n",
      "Epoch 250: val_loss improved from 3137.14282 to 3115.61255, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1116.9855 - mean_absolute_error: 21.3188 - val_loss: 3115.6125 - val_mean_absolute_error: 43.3027\n",
      "Epoch 251/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2926.4939 - mean_absolute_error: 29.3887\n",
      "Epoch 251: val_loss improved from 3115.61255 to 3097.43018, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1252.5591 - mean_absolute_error: 21.6954 - val_loss: 3097.4302 - val_mean_absolute_error: 43.2620\n",
      "Epoch 252/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1202.4651 - mean_absolute_error: 21.5161 \n",
      "Epoch 252: val_loss improved from 3097.43018 to 3066.92236, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1194.9249 - mean_absolute_error: 21.5492 - val_loss: 3066.9224 - val_mean_absolute_error: 43.1636\n",
      "Epoch 253/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.8003 - mean_absolute_error: 21.7568\n",
      "Epoch 253: val_loss improved from 3066.92236 to 3046.90723, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1124.2947 - mean_absolute_error: 21.7551 - val_loss: 3046.9072 - val_mean_absolute_error: 43.0765\n",
      "Epoch 254/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1433.0812 - mean_absolute_error: 27.6428\n",
      "Epoch 254: val_loss improved from 3046.90723 to 3039.83594, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1218.5690 - mean_absolute_error: 22.9638 - val_loss: 3039.8359 - val_mean_absolute_error: 43.1044\n",
      "Epoch 255/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1040.1570 - mean_absolute_error: 21.5967\n",
      "Epoch 255: val_loss improved from 3039.83594 to 3014.46460, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1073.6382 - mean_absolute_error: 21.3348 - val_loss: 3014.4646 - val_mean_absolute_error: 42.9784\n",
      "Epoch 256/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.9557 - mean_absolute_error: 20.7382 \n",
      "Epoch 256: val_loss improved from 3014.46460 to 2997.22632, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1129.0394 - mean_absolute_error: 20.9170 - val_loss: 2997.2263 - val_mean_absolute_error: 42.9577\n",
      "Epoch 257/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1127.4636 - mean_absolute_error: 21.5650\n",
      "Epoch 257: val_loss improved from 2997.22632 to 2988.44214, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1127.4456 - mean_absolute_error: 21.5739 - val_loss: 2988.4421 - val_mean_absolute_error: 42.9596\n",
      "Epoch 258/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1165.8839 - mean_absolute_error: 21.8544\n",
      "Epoch 258: val_loss improved from 2988.44214 to 2967.52954, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1397.5543 - mean_absolute_error: 23.4557 - val_loss: 2967.5295 - val_mean_absolute_error: 42.8706\n",
      "Epoch 259/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 883.4198 - mean_absolute_error: 20.2233\n",
      "Epoch 259: val_loss improved from 2967.52954 to 2959.32837, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1070.3086 - mean_absolute_error: 20.9681 - val_loss: 2959.3284 - val_mean_absolute_error: 42.8781\n",
      "Epoch 260/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1174.0619 - mean_absolute_error: 22.4255 \n",
      "Epoch 260: val_loss improved from 2959.32837 to 2930.20264, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1171.0128 - mean_absolute_error: 22.3792 - val_loss: 2930.2026 - val_mean_absolute_error: 42.7299\n",
      "Epoch 261/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.6055 - mean_absolute_error: 21.9262\n",
      "Epoch 261: val_loss improved from 2930.20264 to 2908.25586, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1132.0596 - mean_absolute_error: 21.9120 - val_loss: 2908.2559 - val_mean_absolute_error: 42.6383\n",
      "Epoch 262/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1946.2369 - mean_absolute_error: 26.5837\n",
      "Epoch 262: val_loss improved from 2908.25586 to 2896.38232, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1020.5445 - mean_absolute_error: 20.6178 - val_loss: 2896.3823 - val_mean_absolute_error: 42.6219\n",
      "Epoch 263/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 364.9082 - mean_absolute_error: 14.7671\n",
      "Epoch 263: val_loss improved from 2896.38232 to 2890.02954, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 937.7653 - mean_absolute_error: 20.3547 - val_loss: 2890.0295 - val_mean_absolute_error: 42.5977\n",
      "Epoch 264/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 645.9855 - mean_absolute_error: 19.8767\n",
      "Epoch 264: val_loss improved from 2890.02954 to 2865.01440, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1202.8718 - mean_absolute_error: 22.5691 - val_loss: 2865.0144 - val_mean_absolute_error: 42.4862\n",
      "Epoch 265/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 717.9280 - mean_absolute_error: 19.5148\n",
      "Epoch 265: val_loss improved from 2865.01440 to 2851.70996, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1025.1266 - mean_absolute_error: 21.2093 - val_loss: 2851.7100 - val_mean_absolute_error: 42.4579\n",
      "Epoch 266/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 910.5992 - mean_absolute_error: 22.5091\n",
      "Epoch 266: val_loss improved from 2851.70996 to 2823.70093, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1039.9153 - mean_absolute_error: 21.3260 - val_loss: 2823.7009 - val_mean_absolute_error: 42.2816\n",
      "Epoch 267/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1208.9500 - mean_absolute_error: 23.8891\n",
      "Epoch 267: val_loss improved from 2823.70093 to 2812.72974, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1153.2302 - mean_absolute_error: 21.8562 - val_loss: 2812.7297 - val_mean_absolute_error: 42.2848\n",
      "Epoch 268/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 557.3640 - mean_absolute_error: 17.6035\n",
      "Epoch 268: val_loss did not improve from 2812.72974\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1238.8867 - mean_absolute_error: 23.0918 - val_loss: 2814.4939 - val_mean_absolute_error: 42.3391\n",
      "Epoch 269/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1075.1724 - mean_absolute_error: 21.1609\n",
      "Epoch 269: val_loss improved from 2812.72974 to 2802.21875, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1079.7687 - mean_absolute_error: 21.2334 - val_loss: 2802.2188 - val_mean_absolute_error: 42.3099\n",
      "Epoch 270/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 506.5232 - mean_absolute_error: 16.2876\n",
      "Epoch 270: val_loss improved from 2802.21875 to 2784.31592, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1043.0631 - mean_absolute_error: 21.2385 - val_loss: 2784.3159 - val_mean_absolute_error: 42.2261\n",
      "Epoch 271/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2868.7236 - mean_absolute_error: 35.8735\n",
      "Epoch 271: val_loss improved from 2784.31592 to 2764.09473, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1165.3035 - mean_absolute_error: 22.4938 - val_loss: 2764.0947 - val_mean_absolute_error: 42.1487\n",
      "Epoch 272/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 557.5436 - mean_absolute_error: 17.2287\n",
      "Epoch 272: val_loss improved from 2764.09473 to 2752.99243, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1023.7301 - mean_absolute_error: 20.9226 - val_loss: 2752.9924 - val_mean_absolute_error: 42.1343\n",
      "Epoch 273/1500\n",
      "\u001b[1m23/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.6577 - mean_absolute_error: 19.7804 \n",
      "Epoch 273: val_loss improved from 2752.99243 to 2739.68945, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 909.9064 - mean_absolute_error: 20.2973 - val_loss: 2739.6895 - val_mean_absolute_error: 42.0736\n",
      "Epoch 274/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 932.8571 - mean_absolute_error: 20.2619 \n",
      "Epoch 274: val_loss improved from 2739.68945 to 2739.09985, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 941.7521 - mean_absolute_error: 20.3330 - val_loss: 2739.0999 - val_mean_absolute_error: 42.1117\n",
      "Epoch 275/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 517.2519 - mean_absolute_error: 14.7799\n",
      "Epoch 275: val_loss improved from 2739.09985 to 2719.21265, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1053.5452 - mean_absolute_error: 20.9082 - val_loss: 2719.2126 - val_mean_absolute_error: 42.0124\n",
      "Epoch 276/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1979.8468 - mean_absolute_error: 26.1012\n",
      "Epoch 276: val_loss improved from 2719.21265 to 2706.87842, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1106.2299 - mean_absolute_error: 21.3605 - val_loss: 2706.8784 - val_mean_absolute_error: 41.9759\n",
      "Epoch 277/1500\n",
      "\u001b[1m21/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1044.5111 - mean_absolute_error: 20.2918\n",
      "Epoch 277: val_loss improved from 2706.87842 to 2675.32642, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1073.5592 - mean_absolute_error: 20.7797 - val_loss: 2675.3264 - val_mean_absolute_error: 41.7808\n",
      "Epoch 278/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 955.7747 - mean_absolute_error: 21.0435 \n",
      "Epoch 278: val_loss did not improve from 2675.32642\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 963.0992 - mean_absolute_error: 21.0663 - val_loss: 2677.9705 - val_mean_absolute_error: 41.8531\n",
      "Epoch 279/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 327.8210 - mean_absolute_error: 14.2795\n",
      "Epoch 279: val_loss improved from 2675.32642 to 2664.76562, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1124.1920 - mean_absolute_error: 21.2078 - val_loss: 2664.7656 - val_mean_absolute_error: 41.7959\n",
      "Epoch 280/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 564.3423 - mean_absolute_error: 17.8764\n",
      "Epoch 280: val_loss did not improve from 2664.76562\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 871.5773 - mean_absolute_error: 19.8930 - val_loss: 2667.6919 - val_mean_absolute_error: 41.8409\n",
      "Epoch 281/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 523.7655 - mean_absolute_error: 17.2494\n",
      "Epoch 281: val_loss improved from 2664.76562 to 2646.06445, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1009.7348 - mean_absolute_error: 20.7287 - val_loss: 2646.0645 - val_mean_absolute_error: 41.7596\n",
      "Epoch 282/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1105.0760 - mean_absolute_error: 22.1334 \n",
      "Epoch 282: val_loss improved from 2646.06445 to 2635.16846, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1102.3026 - mean_absolute_error: 22.0400 - val_loss: 2635.1685 - val_mean_absolute_error: 41.7088\n",
      "Epoch 283/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1061.8073 - mean_absolute_error: 21.9238\n",
      "Epoch 283: val_loss improved from 2635.16846 to 2620.76392, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1061.9551 - mean_absolute_error: 21.9052 - val_loss: 2620.7639 - val_mean_absolute_error: 41.6392\n",
      "Epoch 284/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1195.6736 - mean_absolute_error: 27.1525\n",
      "Epoch 284: val_loss improved from 2620.76392 to 2611.96069, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1150.0146 - mean_absolute_error: 22.3757 - val_loss: 2611.9607 - val_mean_absolute_error: 41.5959\n",
      "Epoch 285/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1670.0736 - mean_absolute_error: 29.3279\n",
      "Epoch 285: val_loss did not improve from 2611.96069\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.2220 - mean_absolute_error: 22.0103 - val_loss: 2612.2246 - val_mean_absolute_error: 41.6448\n",
      "Epoch 286/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 884.3470 - mean_absolute_error: 22.1611\n",
      "Epoch 286: val_loss improved from 2611.96069 to 2601.04199, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1107.2897 - mean_absolute_error: 21.8905 - val_loss: 2601.0420 - val_mean_absolute_error: 41.5909\n",
      "Epoch 287/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236.8451 - mean_absolute_error: 22.1107 \n",
      "Epoch 287: val_loss improved from 2601.04199 to 2582.84863, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1231.5725 - mean_absolute_error: 22.0844 - val_loss: 2582.8486 - val_mean_absolute_error: 41.5007\n",
      "Epoch 288/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 605.6889 - mean_absolute_error: 17.2425\n",
      "Epoch 288: val_loss did not improve from 2582.84863\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.5651 - mean_absolute_error: 20.1498 - val_loss: 2593.7051 - val_mean_absolute_error: 41.5941\n",
      "Epoch 289/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 491.7650 - mean_absolute_error: 15.3137\n",
      "Epoch 289: val_loss improved from 2582.84863 to 2571.79858, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1029.6290 - mean_absolute_error: 20.6520 - val_loss: 2571.7986 - val_mean_absolute_error: 41.4695\n",
      "Epoch 290/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 424.4325 - mean_absolute_error: 15.1732\n",
      "Epoch 290: val_loss improved from 2571.79858 to 2555.79688, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 930.6924 - mean_absolute_error: 19.7975 - val_loss: 2555.7969 - val_mean_absolute_error: 41.3939\n",
      "Epoch 291/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.8640 - mean_absolute_error: 20.8219 \n",
      "Epoch 291: val_loss improved from 2555.79688 to 2548.90161, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1007.2769 - mean_absolute_error: 20.8952 - val_loss: 2548.9016 - val_mean_absolute_error: 41.3853\n",
      "Epoch 292/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 865.8649 - mean_absolute_error: 18.4427\n",
      "Epoch 292: val_loss did not improve from 2548.90161\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1043.6978 - mean_absolute_error: 21.1739 - val_loss: 2585.0354 - val_mean_absolute_error: 41.5410\n",
      "Epoch 293/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 310.3784 - mean_absolute_error: 13.7991\n",
      "Epoch 293: val_loss improved from 2548.90161 to 2537.26660, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 919.8818 - mean_absolute_error: 19.7888 - val_loss: 2537.2666 - val_mean_absolute_error: 41.3285\n",
      "Epoch 294/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 949.6398 - mean_absolute_error: 20.8789\n",
      "Epoch 294: val_loss improved from 2537.26660 to 2532.92700, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1113.8098 - mean_absolute_error: 21.3033 - val_loss: 2532.9270 - val_mean_absolute_error: 41.3489\n",
      "Epoch 295/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 810.0406 - mean_absolute_error: 20.9106\n",
      "Epoch 295: val_loss improved from 2532.92700 to 2530.27832, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1042.4025 - mean_absolute_error: 21.5077 - val_loss: 2530.2783 - val_mean_absolute_error: 41.3333\n",
      "Epoch 296/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1210.1277 - mean_absolute_error: 22.0229 \n",
      "Epoch 296: val_loss improved from 2530.27832 to 2519.61255, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1187.0994 - mean_absolute_error: 21.9203 - val_loss: 2519.6125 - val_mean_absolute_error: 41.2780\n",
      "Epoch 297/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1765.4121 - mean_absolute_error: 27.0026\n",
      "Epoch 297: val_loss improved from 2519.61255 to 2518.98145, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1070.7568 - mean_absolute_error: 21.2965 - val_loss: 2518.9814 - val_mean_absolute_error: 41.2661\n",
      "Epoch 298/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 533.5008 - mean_absolute_error: 15.8696\n",
      "Epoch 298: val_loss improved from 2518.98145 to 2489.75806, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 995.6706 - mean_absolute_error: 20.6803 - val_loss: 2489.7581 - val_mean_absolute_error: 41.0717\n",
      "Epoch 299/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1274.5847 - mean_absolute_error: 24.2708\n",
      "Epoch 299: val_loss improved from 2489.75806 to 2475.44165, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1123.8707 - mean_absolute_error: 21.9017 - val_loss: 2475.4417 - val_mean_absolute_error: 41.0000\n",
      "Epoch 300/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 927.1316 - mean_absolute_error: 21.1884 \n",
      "Epoch 300: val_loss did not improve from 2475.44165\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 942.8140 - mean_absolute_error: 21.1238 - val_loss: 2483.2703 - val_mean_absolute_error: 41.0597\n",
      "Epoch 301/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 916.8420 - mean_absolute_error: 23.0794\n",
      "Epoch 301: val_loss improved from 2475.44165 to 2464.85132, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1037.6188 - mean_absolute_error: 21.3583 - val_loss: 2464.8513 - val_mean_absolute_error: 40.9530\n",
      "Epoch 302/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 456.6346 - mean_absolute_error: 14.3288\n",
      "Epoch 302: val_loss improved from 2464.85132 to 2458.63110, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 926.4259 - mean_absolute_error: 20.7005 - val_loss: 2458.6311 - val_mean_absolute_error: 40.9250\n",
      "Epoch 303/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1671.0710 - mean_absolute_error: 27.8177\n",
      "Epoch 303: val_loss improved from 2458.63110 to 2449.84644, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 981.8033 - mean_absolute_error: 21.1661 - val_loss: 2449.8464 - val_mean_absolute_error: 40.9287\n",
      "Epoch 304/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1323.2437 - mean_absolute_error: 26.4874\n",
      "Epoch 304: val_loss improved from 2449.84644 to 2444.94067, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1109.6370 - mean_absolute_error: 22.0555 - val_loss: 2444.9407 - val_mean_absolute_error: 40.8938\n",
      "Epoch 305/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 942.2004 - mean_absolute_error: 19.7211 \n",
      "Epoch 305: val_loss improved from 2444.94067 to 2438.63110, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 952.8226 - mean_absolute_error: 19.8707 - val_loss: 2438.6311 - val_mean_absolute_error: 40.8339\n",
      "Epoch 306/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 841.4197 - mean_absolute_error: 21.0221\n",
      "Epoch 306: val_loss did not improve from 2438.63110\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1067.1228 - mean_absolute_error: 21.6453 - val_loss: 2444.8967 - val_mean_absolute_error: 40.8959\n",
      "Epoch 307/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1465.2668 - mean_absolute_error: 22.6106\n",
      "Epoch 307: val_loss improved from 2438.63110 to 2416.80835, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1181.0334 - mean_absolute_error: 21.1401 - val_loss: 2416.8083 - val_mean_absolute_error: 40.7582\n",
      "Epoch 308/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 866.6548 - mean_absolute_error: 18.6916\n",
      "Epoch 308: val_loss did not improve from 2416.80835\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 909.7288 - mean_absolute_error: 20.0551 - val_loss: 2427.5896 - val_mean_absolute_error: 40.7871\n",
      "Epoch 309/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1240.9094 - mean_absolute_error: 23.0221\n",
      "Epoch 309: val_loss did not improve from 2416.80835\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.6343 - mean_absolute_error: 21.5474 - val_loss: 2427.1919 - val_mean_absolute_error: 40.8429\n",
      "Epoch 310/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 984.0022 - mean_absolute_error: 21.1261  \n",
      "Epoch 310: val_loss improved from 2416.80835 to 2406.36743, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 990.1773 - mean_absolute_error: 21.0614 - val_loss: 2406.3674 - val_mean_absolute_error: 40.6990\n",
      "Epoch 311/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2110.7292 - mean_absolute_error: 24.9490\n",
      "Epoch 311: val_loss did not improve from 2406.36743\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1152.7947 - mean_absolute_error: 22.0457 - val_loss: 2408.4417 - val_mean_absolute_error: 40.7789\n",
      "Epoch 312/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 407.2653 - mean_absolute_error: 15.8838\n",
      "Epoch 312: val_loss improved from 2406.36743 to 2391.87061, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 913.7103 - mean_absolute_error: 20.2108 - val_loss: 2391.8706 - val_mean_absolute_error: 40.6635\n",
      "Epoch 313/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 692.3856 - mean_absolute_error: 19.6066\n",
      "Epoch 313: val_loss improved from 2391.87061 to 2388.62720, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 978.7808 - mean_absolute_error: 20.6685 - val_loss: 2388.6272 - val_mean_absolute_error: 40.6499\n",
      "Epoch 314/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 641.3143 - mean_absolute_error: 17.3774\n",
      "Epoch 314: val_loss improved from 2388.62720 to 2384.97168, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 842.2830 - mean_absolute_error: 19.9445 - val_loss: 2384.9717 - val_mean_absolute_error: 40.6632\n",
      "Epoch 315/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1093.9889 - mean_absolute_error: 22.9427\n",
      "Epoch 315: val_loss did not improve from 2384.97168\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 933.8539 - mean_absolute_error: 20.5908 - val_loss: 2388.3525 - val_mean_absolute_error: 40.6858\n",
      "Epoch 316/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 803.3907 - mean_absolute_error: 21.4646\n",
      "Epoch 316: val_loss improved from 2384.97168 to 2363.28418, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1075.4858 - mean_absolute_error: 21.5089 - val_loss: 2363.2842 - val_mean_absolute_error: 40.5423\n",
      "Epoch 317/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1090.8612 - mean_absolute_error: 24.5666\n",
      "Epoch 317: val_loss improved from 2363.28418 to 2358.29614, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.8004 - mean_absolute_error: 20.5386 - val_loss: 2358.2961 - val_mean_absolute_error: 40.5421\n",
      "Epoch 318/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1920.0576 - mean_absolute_error: 28.2369\n",
      "Epoch 318: val_loss did not improve from 2358.29614\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1035.6678 - mean_absolute_error: 21.1948 - val_loss: 2367.0581 - val_mean_absolute_error: 40.5833\n",
      "Epoch 319/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 880.4766 - mean_absolute_error: 20.0588 \n",
      "Epoch 319: val_loss improved from 2358.29614 to 2355.95312, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 908.4214 - mean_absolute_error: 20.2653 - val_loss: 2355.9531 - val_mean_absolute_error: 40.5484\n",
      "Epoch 320/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 414.0442 - mean_absolute_error: 13.6909\n",
      "Epoch 320: val_loss did not improve from 2355.95312\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 999.9905 - mean_absolute_error: 20.5331 - val_loss: 2361.9475 - val_mean_absolute_error: 40.5762\n",
      "Epoch 321/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1188.7550 - mean_absolute_error: 24.7973\n",
      "Epoch 321: val_loss did not improve from 2355.95312\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.3468 - mean_absolute_error: 21.9618 - val_loss: 2356.1204 - val_mean_absolute_error: 40.5270\n",
      "Epoch 322/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1326.7773 - mean_absolute_error: 23.1869\n",
      "Epoch 322: val_loss improved from 2355.95312 to 2351.40063, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1048.0190 - mean_absolute_error: 21.2804 - val_loss: 2351.4006 - val_mean_absolute_error: 40.5105\n",
      "Epoch 323/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 676.0010 - mean_absolute_error: 19.0664\n",
      "Epoch 323: val_loss improved from 2351.40063 to 2337.00879, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 866.7571 - mean_absolute_error: 20.2777 - val_loss: 2337.0088 - val_mean_absolute_error: 40.4213\n",
      "Epoch 324/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1018.6774 - mean_absolute_error: 20.6263\n",
      "Epoch 324: val_loss did not improve from 2337.00879\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1015.7267 - mean_absolute_error: 20.6934 - val_loss: 2341.0918 - val_mean_absolute_error: 40.4576\n",
      "Epoch 325/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.8824 - mean_absolute_error: 22.1938 \n",
      "Epoch 325: val_loss did not improve from 2337.00879\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1068.9790 - mean_absolute_error: 22.0807 - val_loss: 2352.5098 - val_mean_absolute_error: 40.5310\n",
      "Epoch 326/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 858.6947 - mean_absolute_error: 20.6485\n",
      "Epoch 326: val_loss did not improve from 2337.00879\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 923.9683 - mean_absolute_error: 20.8841 - val_loss: 2342.5662 - val_mean_absolute_error: 40.4679\n",
      "Epoch 327/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 908.8264 - mean_absolute_error: 19.9566\n",
      "Epoch 327: val_loss improved from 2337.00879 to 2313.47925, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1000.1938 - mean_absolute_error: 20.8832 - val_loss: 2313.4792 - val_mean_absolute_error: 40.3432\n",
      "Epoch 328/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 486.6077 - mean_absolute_error: 15.2670\n",
      "Epoch 328: val_loss improved from 2313.47925 to 2311.50513, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 890.9425 - mean_absolute_error: 19.9690 - val_loss: 2311.5051 - val_mean_absolute_error: 40.3182\n",
      "Epoch 329/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 906.8719 - mean_absolute_error: 20.4005 \n",
      "Epoch 329: val_loss improved from 2311.50513 to 2302.22900, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 931.8872 - mean_absolute_error: 20.5301 - val_loss: 2302.2290 - val_mean_absolute_error: 40.2326\n",
      "Epoch 330/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 566.1191 - mean_absolute_error: 17.3446\n",
      "Epoch 330: val_loss did not improve from 2302.22900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1013.4672 - mean_absolute_error: 21.4584 - val_loss: 2323.0535 - val_mean_absolute_error: 40.3768\n",
      "Epoch 331/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1308.0659 - mean_absolute_error: 21.1222\n",
      "Epoch 331: val_loss did not improve from 2302.22900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.0187 - mean_absolute_error: 20.6408 - val_loss: 2304.4419 - val_mean_absolute_error: 40.3020\n",
      "Epoch 332/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 547.8653 - mean_absolute_error: 14.3228\n",
      "Epoch 332: val_loss did not improve from 2302.22900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1028.0784 - mean_absolute_error: 20.2340 - val_loss: 2317.2275 - val_mean_absolute_error: 40.3600\n",
      "Epoch 333/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 493.7498 - mean_absolute_error: 16.9365\n",
      "Epoch 333: val_loss did not improve from 2302.22900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 998.5011 - mean_absolute_error: 21.2020 - val_loss: 2330.1833 - val_mean_absolute_error: 40.3873\n",
      "Epoch 334/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1026.7759 - mean_absolute_error: 25.5136\n",
      "Epoch 334: val_loss improved from 2302.22900 to 2278.92334, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 992.5667 - mean_absolute_error: 20.5866 - val_loss: 2278.9233 - val_mean_absolute_error: 40.1002\n",
      "Epoch 335/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 539.4084 - mean_absolute_error: 18.7472\n",
      "Epoch 335: val_loss did not improve from 2278.92334\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1007.4509 - mean_absolute_error: 21.5321 - val_loss: 2287.5886 - val_mean_absolute_error: 40.2385\n",
      "Epoch 336/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 847.5452 - mean_absolute_error: 21.3814\n",
      "Epoch 336: val_loss did not improve from 2278.92334\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.6698 - mean_absolute_error: 21.0477 - val_loss: 2280.6841 - val_mean_absolute_error: 40.1877\n",
      "Epoch 337/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 774.8250 - mean_absolute_error: 21.1145\n",
      "Epoch 337: val_loss improved from 2278.92334 to 2267.53613, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 890.2548 - mean_absolute_error: 20.4447 - val_loss: 2267.5361 - val_mean_absolute_error: 40.0726\n",
      "Epoch 338/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 947.4893 - mean_absolute_error: 20.3797 \n",
      "Epoch 338: val_loss did not improve from 2267.53613\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 958.0872 - mean_absolute_error: 20.4565 - val_loss: 2270.0249 - val_mean_absolute_error: 40.1016\n",
      "Epoch 339/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 620.1706 - mean_absolute_error: 18.0759\n",
      "Epoch 339: val_loss did not improve from 2267.53613\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1063.6600 - mean_absolute_error: 21.6243 - val_loss: 2270.7854 - val_mean_absolute_error: 40.1207\n",
      "Epoch 340/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1188.0775 - mean_absolute_error: 25.2104\n",
      "Epoch 340: val_loss improved from 2267.53613 to 2267.09058, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1004.4438 - mean_absolute_error: 21.4809 - val_loss: 2267.0906 - val_mean_absolute_error: 40.0963\n",
      "Epoch 341/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1496.7874 - mean_absolute_error: 22.9900\n",
      "Epoch 341: val_loss did not improve from 2267.09058\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.6041 - mean_absolute_error: 21.4178 - val_loss: 2273.1277 - val_mean_absolute_error: 40.1223\n",
      "Epoch 342/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 610.8513 - mean_absolute_error: 18.7935\n",
      "Epoch 342: val_loss improved from 2267.09058 to 2257.13940, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 973.3070 - mean_absolute_error: 20.9534 - val_loss: 2257.1394 - val_mean_absolute_error: 40.0349\n",
      "Epoch 343/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1004.8360 - mean_absolute_error: 20.3017\n",
      "Epoch 343: val_loss did not improve from 2257.13940\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1004.3024 - mean_absolute_error: 20.4161 - val_loss: 2262.8376 - val_mean_absolute_error: 40.0602\n",
      "Epoch 344/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1346.3043 - mean_absolute_error: 21.6040\n",
      "Epoch 344: val_loss did not improve from 2257.13940\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1048.0226 - mean_absolute_error: 20.9719 - val_loss: 2267.0879 - val_mean_absolute_error: 40.0846\n",
      "Epoch 345/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 815.6927 - mean_absolute_error: 21.0868\n",
      "Epoch 345: val_loss did not improve from 2257.13940\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 982.8636 - mean_absolute_error: 20.7551 - val_loss: 2273.5664 - val_mean_absolute_error: 40.0764\n",
      "Epoch 346/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 879.7846 - mean_absolute_error: 23.1561\n",
      "Epoch 346: val_loss improved from 2257.13940 to 2233.74585, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 944.0920 - mean_absolute_error: 20.7130 - val_loss: 2233.7458 - val_mean_absolute_error: 39.8479\n",
      "Epoch 347/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1038.8188 - mean_absolute_error: 23.6661\n",
      "Epoch 347: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1044.8486 - mean_absolute_error: 21.7571 - val_loss: 2246.4736 - val_mean_absolute_error: 39.9560\n",
      "Epoch 348/1500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 968.5383 - mean_absolute_error: 21.1010 \n",
      "Epoch 348: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 986.7996 - mean_absolute_error: 21.0612 - val_loss: 2238.8098 - val_mean_absolute_error: 39.9151\n",
      "Epoch 349/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.7268 - mean_absolute_error: 22.1060 \n",
      "Epoch 349: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1118.9503 - mean_absolute_error: 22.0684 - val_loss: 2262.3474 - val_mean_absolute_error: 40.0067\n",
      "Epoch 350/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 908.2834 - mean_absolute_error: 20.3122\n",
      "Epoch 350: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 852.0324 - mean_absolute_error: 19.8029 - val_loss: 2252.2871 - val_mean_absolute_error: 39.9546\n",
      "Epoch 351/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 689.3680 - mean_absolute_error: 21.3076\n",
      "Epoch 351: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 945.9901 - mean_absolute_error: 20.5746 - val_loss: 2240.9209 - val_mean_absolute_error: 39.9111\n",
      "Epoch 352/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 474.4622 - mean_absolute_error: 16.6013\n",
      "Epoch 352: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.7680 - mean_absolute_error: 20.0089 - val_loss: 2237.7297 - val_mean_absolute_error: 39.9229\n",
      "Epoch 353/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 502.0696 - mean_absolute_error: 17.1200\n",
      "Epoch 353: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 880.8987 - mean_absolute_error: 19.8598 - val_loss: 2235.8044 - val_mean_absolute_error: 39.8811\n",
      "Epoch 354/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1944.8784 - mean_absolute_error: 20.7962\n",
      "Epoch 354: val_loss did not improve from 2233.74585\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1032.9330 - mean_absolute_error: 20.8554 - val_loss: 2237.5874 - val_mean_absolute_error: 39.8829\n",
      "Epoch 355/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1080.6396 - mean_absolute_error: 22.2252\n",
      "Epoch 355: val_loss improved from 2233.74585 to 2231.19995, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 954.0270 - mean_absolute_error: 20.8077 - val_loss: 2231.2000 - val_mean_absolute_error: 39.8747\n",
      "Epoch 356/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 640.0128 - mean_absolute_error: 18.1487\n",
      "Epoch 356: val_loss did not improve from 2231.19995\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1038.0966 - mean_absolute_error: 21.0460 - val_loss: 2238.4614 - val_mean_absolute_error: 39.8927\n",
      "Epoch 357/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.4484 - mean_absolute_error: 22.2433 \n",
      "Epoch 357: val_loss did not improve from 2231.19995\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1062.9225 - mean_absolute_error: 21.9481 - val_loss: 2236.4182 - val_mean_absolute_error: 39.8602\n",
      "Epoch 358/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 890.7896 - mean_absolute_error: 19.7010 \n",
      "Epoch 358: val_loss improved from 2231.19995 to 2222.98022, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 904.0071 - mean_absolute_error: 19.8510 - val_loss: 2222.9802 - val_mean_absolute_error: 39.7770\n",
      "Epoch 359/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 648.3101 - mean_absolute_error: 19.8701\n",
      "Epoch 359: val_loss improved from 2222.98022 to 2215.20972, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1085.1027 - mean_absolute_error: 21.5275 - val_loss: 2215.2097 - val_mean_absolute_error: 39.7508\n",
      "Epoch 360/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1191.1112 - mean_absolute_error: 21.5350\n",
      "Epoch 360: val_loss did not improve from 2215.20972\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1150.1237 - mean_absolute_error: 21.8694 - val_loss: 2224.2461 - val_mean_absolute_error: 39.7735\n",
      "Epoch 361/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 804.1146 - mean_absolute_error: 19.3737 \n",
      "Epoch 361: val_loss improved from 2215.20972 to 2210.67261, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 830.6876 - mean_absolute_error: 19.5748 - val_loss: 2210.6726 - val_mean_absolute_error: 39.7299\n",
      "Epoch 362/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2975.7061 - mean_absolute_error: 34.5996\n",
      "Epoch 362: val_loss did not improve from 2210.67261\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1210.7874 - mean_absolute_error: 22.8210 - val_loss: 2242.9817 - val_mean_absolute_error: 39.8135\n",
      "Epoch 363/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 502.7114 - mean_absolute_error: 17.0982\n",
      "Epoch 363: val_loss improved from 2210.67261 to 2198.17969, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 961.5441 - mean_absolute_error: 20.6949 - val_loss: 2198.1797 - val_mean_absolute_error: 39.6229\n",
      "Epoch 364/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1275.1946 - mean_absolute_error: 20.0573\n",
      "Epoch 364: val_loss did not improve from 2198.17969\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 912.9672 - mean_absolute_error: 19.5048 - val_loss: 2214.9570 - val_mean_absolute_error: 39.7331\n",
      "Epoch 365/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 964.9509 - mean_absolute_error: 22.0313\n",
      "Epoch 365: val_loss improved from 2198.17969 to 2198.12280, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 955.9506 - mean_absolute_error: 20.5471 - val_loss: 2198.1228 - val_mean_absolute_error: 39.6020\n",
      "Epoch 366/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1098.5392 - mean_absolute_error: 21.7368 \n",
      "Epoch 366: val_loss did not improve from 2198.12280\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1076.7056 - mean_absolute_error: 21.5273 - val_loss: 2225.4409 - val_mean_absolute_error: 39.7699\n",
      "Epoch 367/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2582.9080 - mean_absolute_error: 27.8962\n",
      "Epoch 367: val_loss did not improve from 2198.12280\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1072.2545 - mean_absolute_error: 20.8263 - val_loss: 2209.1067 - val_mean_absolute_error: 39.6343\n",
      "Epoch 368/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 369.3087 - mean_absolute_error: 14.2536\n",
      "Epoch 368: val_loss improved from 2198.12280 to 2191.70093, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 793.2935 - mean_absolute_error: 18.8343 - val_loss: 2191.7009 - val_mean_absolute_error: 39.5493\n",
      "Epoch 369/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 705.0919 - mean_absolute_error: 20.4383\n",
      "Epoch 369: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 786.9965 - mean_absolute_error: 19.8679 - val_loss: 2196.1680 - val_mean_absolute_error: 39.5855\n",
      "Epoch 370/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 938.7524 - mean_absolute_error: 20.2581 \n",
      "Epoch 370: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 943.8329 - mean_absolute_error: 20.3170 - val_loss: 2209.3208 - val_mean_absolute_error: 39.6674\n",
      "Epoch 371/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 920.6523 - mean_absolute_error: 20.2371  \n",
      "Epoch 371: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 923.5347 - mean_absolute_error: 20.2580 - val_loss: 2205.6538 - val_mean_absolute_error: 39.6391\n",
      "Epoch 372/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 976.4218 - mean_absolute_error: 20.2257\n",
      "Epoch 372: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 936.8622 - mean_absolute_error: 20.3350 - val_loss: 2192.4250 - val_mean_absolute_error: 39.5414\n",
      "Epoch 373/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 618.9263 - mean_absolute_error: 19.0086\n",
      "Epoch 373: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 799.8091 - mean_absolute_error: 19.2751 - val_loss: 2194.9685 - val_mean_absolute_error: 39.5580\n",
      "Epoch 374/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2525.5645 - mean_absolute_error: 32.7974\n",
      "Epoch 374: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1224.2853 - mean_absolute_error: 23.4954 - val_loss: 2211.2905 - val_mean_absolute_error: 39.6392\n",
      "Epoch 375/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 817.9571 - mean_absolute_error: 19.7044\n",
      "Epoch 375: val_loss did not improve from 2191.70093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 962.1795 - mean_absolute_error: 20.7906 - val_loss: 2193.4307 - val_mean_absolute_error: 39.5535\n",
      "Epoch 376/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 874.2095 - mean_absolute_error: 20.2094 \n",
      "Epoch 376: val_loss improved from 2191.70093 to 2189.29028, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 893.9038 - mean_absolute_error: 20.3149 - val_loss: 2189.2903 - val_mean_absolute_error: 39.5337\n",
      "Epoch 377/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 848.1874 - mean_absolute_error: 21.0093\n",
      "Epoch 377: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071.1322 - mean_absolute_error: 21.8515 - val_loss: 2205.1541 - val_mean_absolute_error: 39.5845\n",
      "Epoch 378/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1293.6648 - mean_absolute_error: 24.0936\n",
      "Epoch 378: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1007.5529 - mean_absolute_error: 20.8014 - val_loss: 2194.2842 - val_mean_absolute_error: 39.5103\n",
      "Epoch 379/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1302.8696 - mean_absolute_error: 24.3079\n",
      "Epoch 379: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1082.0153 - mean_absolute_error: 21.1145 - val_loss: 2204.6494 - val_mean_absolute_error: 39.5621\n",
      "Epoch 380/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 907.5114 - mean_absolute_error: 19.8320 \n",
      "Epoch 380: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 917.6931 - mean_absolute_error: 19.9536 - val_loss: 2189.9702 - val_mean_absolute_error: 39.4851\n",
      "Epoch 381/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1234.3226 - mean_absolute_error: 23.6071\n",
      "Epoch 381: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1055.1700 - mean_absolute_error: 21.4227 - val_loss: 2193.5273 - val_mean_absolute_error: 39.4958\n",
      "Epoch 382/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 571.2504 - mean_absolute_error: 18.4141\n",
      "Epoch 382: val_loss did not improve from 2189.29028\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 936.1572 - mean_absolute_error: 19.7932 - val_loss: 2216.8638 - val_mean_absolute_error: 39.5638\n",
      "Epoch 383/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 630.7058 - mean_absolute_error: 17.4164\n",
      "Epoch 383: val_loss improved from 2189.29028 to 2175.88428, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1052.4562 - mean_absolute_error: 21.1626 - val_loss: 2175.8843 - val_mean_absolute_error: 39.3976\n",
      "Epoch 384/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 439.5482 - mean_absolute_error: 15.5064\n",
      "Epoch 384: val_loss did not improve from 2175.88428\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 887.2087 - mean_absolute_error: 20.2634 - val_loss: 2179.8699 - val_mean_absolute_error: 39.4272\n",
      "Epoch 385/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 944.2407 - mean_absolute_error: 20.6307 \n",
      "Epoch 385: val_loss did not improve from 2175.88428\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 947.8812 - mean_absolute_error: 20.6139 - val_loss: 2195.5237 - val_mean_absolute_error: 39.5288\n",
      "Epoch 386/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 800.2166 - mean_absolute_error: 19.2772\n",
      "Epoch 386: val_loss did not improve from 2175.88428\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1040.3123 - mean_absolute_error: 21.4804 - val_loss: 2193.3538 - val_mean_absolute_error: 39.4826\n",
      "Epoch 387/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 435.3474 - mean_absolute_error: 15.3528\n",
      "Epoch 387: val_loss did not improve from 2175.88428\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 979.7375 - mean_absolute_error: 21.0607 - val_loss: 2198.0691 - val_mean_absolute_error: 39.5198\n",
      "Epoch 388/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1507.6833 - mean_absolute_error: 24.5657\n",
      "Epoch 388: val_loss did not improve from 2175.88428\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1004.3408 - mean_absolute_error: 21.1184 - val_loss: 2178.4092 - val_mean_absolute_error: 39.4035\n",
      "Epoch 389/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 621.1835 - mean_absolute_error: 16.7863\n",
      "Epoch 389: val_loss improved from 2175.88428 to 2164.33057, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 996.7335 - mean_absolute_error: 20.4817 - val_loss: 2164.3306 - val_mean_absolute_error: 39.3024\n",
      "Epoch 390/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 918.8552 - mean_absolute_error: 19.7861 \n",
      "Epoch 390: val_loss did not improve from 2164.33057\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 931.3425 - mean_absolute_error: 20.0303 - val_loss: 2184.2891 - val_mean_absolute_error: 39.4333\n",
      "Epoch 391/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1383.6021 - mean_absolute_error: 23.8226\n",
      "Epoch 391: val_loss improved from 2164.33057 to 2161.47705, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 928.2053 - mean_absolute_error: 20.1408 - val_loss: 2161.4771 - val_mean_absolute_error: 39.2713\n",
      "Epoch 392/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1758.7671 - mean_absolute_error: 25.3209\n",
      "Epoch 392: val_loss did not improve from 2161.47705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1000.2974 - mean_absolute_error: 20.5235 - val_loss: 2169.8472 - val_mean_absolute_error: 39.3312\n",
      "Epoch 393/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 850.8685 - mean_absolute_error: 23.1983\n",
      "Epoch 393: val_loss did not improve from 2161.47705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 972.5355 - mean_absolute_error: 21.1403 - val_loss: 2175.9390 - val_mean_absolute_error: 39.3550\n",
      "Epoch 394/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1145.9921 - mean_absolute_error: 24.0607\n",
      "Epoch 394: val_loss did not improve from 2161.47705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 946.1243 - mean_absolute_error: 19.9799 - val_loss: 2238.3726 - val_mean_absolute_error: 39.5898\n",
      "Epoch 395/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1080.4065 - mean_absolute_error: 21.1142\n",
      "Epoch 395: val_loss did not improve from 2161.47705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1061.7910 - mean_absolute_error: 21.0529 - val_loss: 2165.5176 - val_mean_absolute_error: 39.3019\n",
      "Epoch 396/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 866.4534 - mean_absolute_error: 19.3729\n",
      "Epoch 396: val_loss did not improve from 2161.47705\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 969.5168 - mean_absolute_error: 19.7815 - val_loss: 2163.5388 - val_mean_absolute_error: 39.2660\n",
      "Epoch 397/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1369.0052 - mean_absolute_error: 24.4781\n",
      "Epoch 397: val_loss improved from 2161.47705 to 2160.12305, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 973.2349 - mean_absolute_error: 21.2217 - val_loss: 2160.1230 - val_mean_absolute_error: 39.2366\n",
      "Epoch 398/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 910.1420 - mean_absolute_error: 20.4609 \n",
      "Epoch 398: val_loss improved from 2160.12305 to 2152.88306, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 923.8187 - mean_absolute_error: 20.5218 - val_loss: 2152.8831 - val_mean_absolute_error: 39.1857\n",
      "Epoch 399/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1132.1787 - mean_absolute_error: 25.3588\n",
      "Epoch 399: val_loss did not improve from 2152.88306\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1027.1339 - mean_absolute_error: 21.3966 - val_loss: 2155.5911 - val_mean_absolute_error: 39.2096\n",
      "Epoch 400/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 978.8692 - mean_absolute_error: 20.7373 \n",
      "Epoch 400: val_loss did not improve from 2152.88306\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 977.7480 - mean_absolute_error: 20.7218 - val_loss: 2168.0676 - val_mean_absolute_error: 39.2658\n",
      "Epoch 401/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1088.8701 - mean_absolute_error: 22.2174\n",
      "Epoch 401: val_loss did not improve from 2152.88306\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 905.0220 - mean_absolute_error: 20.3180 - val_loss: 2166.2219 - val_mean_absolute_error: 39.2612\n",
      "Epoch 402/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 752.1525 - mean_absolute_error: 17.8810\n",
      "Epoch 402: val_loss did not improve from 2152.88306\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1029.0229 - mean_absolute_error: 19.8822 - val_loss: 2188.6128 - val_mean_absolute_error: 39.3284\n",
      "Epoch 403/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1123.0652 - mean_absolute_error: 19.2310\n",
      "Epoch 403: val_loss did not improve from 2152.88306\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1028.2148 - mean_absolute_error: 20.9545 - val_loss: 2154.7175 - val_mean_absolute_error: 39.1677\n",
      "Epoch 404/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 771.3458 - mean_absolute_error: 19.7290\n",
      "Epoch 404: val_loss improved from 2152.88306 to 2140.76758, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 860.0479 - mean_absolute_error: 20.0561 - val_loss: 2140.7676 - val_mean_absolute_error: 39.0642\n",
      "Epoch 405/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1048.7452 - mean_absolute_error: 20.9460 \n",
      "Epoch 405: val_loss did not improve from 2140.76758\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1032.9902 - mean_absolute_error: 20.8550 - val_loss: 2195.4106 - val_mean_absolute_error: 39.3440\n",
      "Epoch 406/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 756.1959 - mean_absolute_error: 22.0795\n",
      "Epoch 406: val_loss did not improve from 2140.76758\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 926.3661 - mean_absolute_error: 20.7123 - val_loss: 2186.5139 - val_mean_absolute_error: 39.3198\n",
      "Epoch 407/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 560.0366 - mean_absolute_error: 15.4915\n",
      "Epoch 407: val_loss improved from 2140.76758 to 2137.32935, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1034.2081 - mean_absolute_error: 20.8765 - val_loss: 2137.3293 - val_mean_absolute_error: 39.0344\n",
      "Epoch 408/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1131.3358 - mean_absolute_error: 21.6152\n",
      "Epoch 408: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.9211 - mean_absolute_error: 21.0282 - val_loss: 2138.7607 - val_mean_absolute_error: 39.0258\n",
      "Epoch 409/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2035.9998 - mean_absolute_error: 27.9589\n",
      "Epoch 409: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.1653 - mean_absolute_error: 21.5276 - val_loss: 2145.3789 - val_mean_absolute_error: 39.0829\n",
      "Epoch 410/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 912.8063 - mean_absolute_error: 20.1597 \n",
      "Epoch 410: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 921.8413 - mean_absolute_error: 20.2562 - val_loss: 2208.7371 - val_mean_absolute_error: 39.3383\n",
      "Epoch 411/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 878.7264 - mean_absolute_error: 20.1494 \n",
      "Epoch 411: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 885.5393 - mean_absolute_error: 20.1877 - val_loss: 2175.4409 - val_mean_absolute_error: 39.2099\n",
      "Epoch 412/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1257.5568 - mean_absolute_error: 26.1580\n",
      "Epoch 412: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1030.6484 - mean_absolute_error: 21.5593 - val_loss: 2219.4546 - val_mean_absolute_error: 39.4241\n",
      "Epoch 413/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1883.2301 - mean_absolute_error: 29.3398\n",
      "Epoch 413: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.8945 - mean_absolute_error: 22.1333 - val_loss: 2167.7568 - val_mean_absolute_error: 39.2327\n",
      "Epoch 414/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1179.4924 - mean_absolute_error: 22.6143\n",
      "Epoch 414: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1017.3896 - mean_absolute_error: 21.1284 - val_loss: 2176.1169 - val_mean_absolute_error: 39.2490\n",
      "Epoch 415/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1045.9713 - mean_absolute_error: 21.0033 \n",
      "Epoch 415: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1030.7440 - mean_absolute_error: 20.9329 - val_loss: 2190.7766 - val_mean_absolute_error: 39.2953\n",
      "Epoch 416/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1172.0580 - mean_absolute_error: 22.0097\n",
      "Epoch 416: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1154.8867 - mean_absolute_error: 21.9266 - val_loss: 2217.3027 - val_mean_absolute_error: 39.3844\n",
      "Epoch 417/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 997.1407 - mean_absolute_error: 22.1885\n",
      "Epoch 417: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1021.9534 - mean_absolute_error: 20.9144 - val_loss: 2158.9802 - val_mean_absolute_error: 39.1203\n",
      "Epoch 418/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 664.0858 - mean_absolute_error: 19.7548\n",
      "Epoch 418: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 859.6625 - mean_absolute_error: 19.5034 - val_loss: 2142.4690 - val_mean_absolute_error: 39.0234\n",
      "Epoch 419/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 883.9077 - mean_absolute_error: 22.7592\n",
      "Epoch 419: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 887.9813 - mean_absolute_error: 20.5962 - val_loss: 2138.4407 - val_mean_absolute_error: 38.9954\n",
      "Epoch 420/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 847.2081 - mean_absolute_error: 19.5035 \n",
      "Epoch 420: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 855.6432 - mean_absolute_error: 19.5801 - val_loss: 2154.3027 - val_mean_absolute_error: 39.0735\n",
      "Epoch 421/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1478.9863 - mean_absolute_error: 24.1794\n",
      "Epoch 421: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.8066 - mean_absolute_error: 21.2642 - val_loss: 2166.5574 - val_mean_absolute_error: 39.1189\n",
      "Epoch 422/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 394.7463 - mean_absolute_error: 15.4887\n",
      "Epoch 422: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 825.8699 - mean_absolute_error: 19.1796 - val_loss: 2145.9241 - val_mean_absolute_error: 39.0315\n",
      "Epoch 423/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1269.1636 - mean_absolute_error: 23.3800\n",
      "Epoch 423: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 905.6223 - mean_absolute_error: 20.3476 - val_loss: 2170.9214 - val_mean_absolute_error: 39.1306\n",
      "Epoch 424/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 774.0724 - mean_absolute_error: 20.4660\n",
      "Epoch 424: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 942.5901 - mean_absolute_error: 20.8998 - val_loss: 2162.8669 - val_mean_absolute_error: 39.1148\n",
      "Epoch 425/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 503.2919 - mean_absolute_error: 16.3259\n",
      "Epoch 425: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 881.9384 - mean_absolute_error: 19.9881 - val_loss: 2164.5559 - val_mean_absolute_error: 39.0950\n",
      "Epoch 426/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 901.4245 - mean_absolute_error: 20.3953  \n",
      "Epoch 426: val_loss did not improve from 2137.32935\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 904.4610 - mean_absolute_error: 20.3984 - val_loss: 2186.9631 - val_mean_absolute_error: 39.1806\n",
      "Epoch 427/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 806.2202 - mean_absolute_error: 22.1869\n",
      "Epoch 427: val_loss improved from 2137.32935 to 2127.44800, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.9528 - mean_absolute_error: 19.9132 - val_loss: 2127.4480 - val_mean_absolute_error: 38.8581\n",
      "Epoch 428/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 493.5945 - mean_absolute_error: 16.0219\n",
      "Epoch 428: val_loss did not improve from 2127.44800\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 837.5164 - mean_absolute_error: 19.3628 - val_loss: 2129.1316 - val_mean_absolute_error: 38.8349\n",
      "Epoch 429/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1104.3984 - mean_absolute_error: 25.4207\n",
      "Epoch 429: val_loss did not improve from 2127.44800\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 970.0529 - mean_absolute_error: 21.2698 - val_loss: 2142.2058 - val_mean_absolute_error: 38.9614\n",
      "Epoch 430/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 733.8063 - mean_absolute_error: 22.7643\n",
      "Epoch 430: val_loss did not improve from 2127.44800\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 964.1289 - mean_absolute_error: 21.3553 - val_loss: 2140.6802 - val_mean_absolute_error: 38.9596\n",
      "Epoch 431/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 947.0062 - mean_absolute_error: 20.6296 \n",
      "Epoch 431: val_loss did not improve from 2127.44800\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 949.1697 - mean_absolute_error: 20.6100 - val_loss: 2128.6143 - val_mean_absolute_error: 38.8529\n",
      "Epoch 432/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1743.3060 - mean_absolute_error: 28.7119\n",
      "Epoch 432: val_loss did not improve from 2127.44800\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1064.2343 - mean_absolute_error: 21.1513 - val_loss: 2160.9368 - val_mean_absolute_error: 39.0259\n",
      "Epoch 433/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 756.4908 - mean_absolute_error: 17.5756\n",
      "Epoch 433: val_loss improved from 2127.44800 to 2123.57349, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 935.5353 - mean_absolute_error: 19.4547 - val_loss: 2123.5735 - val_mean_absolute_error: 38.7969\n",
      "Epoch 434/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2337.5215 - mean_absolute_error: 23.7558\n",
      "Epoch 434: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.8696 - mean_absolute_error: 20.8346 - val_loss: 2158.0874 - val_mean_absolute_error: 39.0042\n",
      "Epoch 435/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1026.9237 - mean_absolute_error: 21.4374\n",
      "Epoch 435: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1039.3619 - mean_absolute_error: 21.2501 - val_loss: 2161.4841 - val_mean_absolute_error: 39.0172\n",
      "Epoch 436/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1011.9008 - mean_absolute_error: 20.9210 \n",
      "Epoch 436: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1002.4637 - mean_absolute_error: 20.8589 - val_loss: 2156.7112 - val_mean_absolute_error: 38.9884\n",
      "Epoch 437/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 901.5955 - mean_absolute_error: 20.0476 \n",
      "Epoch 437: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 904.9207 - mean_absolute_error: 20.0825 - val_loss: 2129.0010 - val_mean_absolute_error: 38.8207\n",
      "Epoch 438/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1436.1917 - mean_absolute_error: 23.0832\n",
      "Epoch 438: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1053.4562 - mean_absolute_error: 20.7961 - val_loss: 2125.6846 - val_mean_absolute_error: 38.7693\n",
      "Epoch 439/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1133.7559 - mean_absolute_error: 21.5527\n",
      "Epoch 439: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 884.1334 - mean_absolute_error: 19.9997 - val_loss: 2130.5713 - val_mean_absolute_error: 38.8421\n",
      "Epoch 440/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 503.8673 - mean_absolute_error: 16.5067\n",
      "Epoch 440: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 937.0247 - mean_absolute_error: 20.7385 - val_loss: 2124.3340 - val_mean_absolute_error: 38.7798\n",
      "Epoch 441/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 931.0282 - mean_absolute_error: 20.1331 \n",
      "Epoch 441: val_loss did not improve from 2123.57349\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 935.1527 - mean_absolute_error: 20.1803 - val_loss: 2133.2363 - val_mean_absolute_error: 38.8569\n",
      "Epoch 442/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 598.9496 - mean_absolute_error: 17.2381\n",
      "Epoch 442: val_loss improved from 2123.57349 to 2118.13550, saving model to checkpoint.model4.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 907.0521 - mean_absolute_error: 19.9460 - val_loss: 2118.1355 - val_mean_absolute_error: 38.6736\n",
      "Epoch 443/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1354.1982 - mean_absolute_error: 21.6315\n",
      "Epoch 443: val_loss did not improve from 2118.13550\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 932.6898 - mean_absolute_error: 19.9764 - val_loss: 2120.2019 - val_mean_absolute_error: 38.7325\n",
      "Epoch 444/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1591.3341 - mean_absolute_error: 23.8871\n",
      "Epoch 444: val_loss did not improve from 2118.13550\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 986.3942 - mean_absolute_error: 20.8387 - val_loss: 2144.6433 - val_mean_absolute_error: 38.9064\n",
      "Epoch 445/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1758.6002 - mean_absolute_error: 22.2116\n",
      "Epoch 445: val_loss did not improve from 2118.13550\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1004.6140 - mean_absolute_error: 20.5698 - val_loss: 2123.4607 - val_mean_absolute_error: 38.7435\n",
      "Epoch 446/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1063.6611 - mean_absolute_error: 20.7359 \n",
      "Epoch 446: val_loss did not improve from 2118.13550\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1056.5615 - mean_absolute_error: 20.7117 - val_loss: 2141.5005 - val_mean_absolute_error: 38.8650\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 962.5504 - mean_absolute_error: 20.6203 \n",
      "Epoch 1035: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 955.7740 - mean_absolute_error: 20.5737 - val_loss: 2125.9092 - val_mean_absolute_error: 38.1045\n",
      "Epoch 1036/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 781.6201 - mean_absolute_error: 20.5116\n",
      "Epoch 1036: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 859.2037 - mean_absolute_error: 20.2430 - val_loss: 2196.4377 - val_mean_absolute_error: 38.6124\n",
      "Epoch 1037/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1158.4155 - mean_absolute_error: 24.4476\n",
      "Epoch 1037: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 966.3185 - mean_absolute_error: 20.9037 - val_loss: 2213.3760 - val_mean_absolute_error: 38.8219\n",
      "Epoch 1038/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 882.7100 - mean_absolute_error: 19.6898 \n",
      "Epoch 1038: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 879.8992 - mean_absolute_error: 19.7390 - val_loss: 2182.3970 - val_mean_absolute_error: 38.2942\n",
      "Epoch 1039/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 722.8909 - mean_absolute_error: 21.0412\n",
      "Epoch 1039: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 875.1757 - mean_absolute_error: 20.0232 - val_loss: 2161.8918 - val_mean_absolute_error: 38.3819\n",
      "Epoch 1040/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 502.2835 - mean_absolute_error: 16.8806\n",
      "Epoch 1040: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 796.3705 - mean_absolute_error: 19.2607 - val_loss: 2168.3193 - val_mean_absolute_error: 38.3736\n",
      "Epoch 1041/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 638.6652 - mean_absolute_error: 18.7425\n",
      "Epoch 1041: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 900.4530 - mean_absolute_error: 20.4425 - val_loss: 2170.3044 - val_mean_absolute_error: 38.3819\n",
      "Epoch 1042/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 693.1494 - mean_absolute_error: 21.3327\n",
      "Epoch 1042: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 817.9471 - mean_absolute_error: 19.8046 - val_loss: 2153.8450 - val_mean_absolute_error: 38.3228\n",
      "Epoch 1043/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 972.2538 - mean_absolute_error: 20.5374\n",
      "Epoch 1043: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 925.8678 - mean_absolute_error: 20.6160 - val_loss: 2186.6404 - val_mean_absolute_error: 38.3641\n",
      "Epoch 1044/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 985.3835 - mean_absolute_error: 19.9754  \n",
      "Epoch 1044: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 973.3794 - mean_absolute_error: 19.9831 - val_loss: 2194.4646 - val_mean_absolute_error: 38.5061\n",
      "Epoch 1045/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 946.8439 - mean_absolute_error: 19.5647\n",
      "Epoch 1045: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 940.4299 - mean_absolute_error: 19.9682 - val_loss: 2183.8855 - val_mean_absolute_error: 38.5398\n",
      "Epoch 1046/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 715.0021 - mean_absolute_error: 16.7542\n",
      "Epoch 1046: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 896.6520 - mean_absolute_error: 19.6064 - val_loss: 2169.9333 - val_mean_absolute_error: 38.3467\n",
      "Epoch 1047/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1846.3774 - mean_absolute_error: 29.1468\n",
      "Epoch 1047: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 938.8882 - mean_absolute_error: 20.5504 - val_loss: 2161.3032 - val_mean_absolute_error: 38.3500\n",
      "Epoch 1048/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 697.5420 - mean_absolute_error: 21.0061\n",
      "Epoch 1048: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 887.8456 - mean_absolute_error: 19.7500 - val_loss: 2210.5356 - val_mean_absolute_error: 38.8165\n",
      "Epoch 1049/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 802.7564 - mean_absolute_error: 18.8839  \n",
      "Epoch 1049: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 819.0544 - mean_absolute_error: 19.1453 - val_loss: 2175.6353 - val_mean_absolute_error: 38.4736\n",
      "Epoch 1050/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 872.2209 - mean_absolute_error: 18.2324\n",
      "Epoch 1050: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 878.3308 - mean_absolute_error: 19.5938 - val_loss: 2180.3550 - val_mean_absolute_error: 38.6594\n",
      "Epoch 1051/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 964.9598 - mean_absolute_error: 23.7482\n",
      "Epoch 1051: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 873.4087 - mean_absolute_error: 20.0334 - val_loss: 2152.3328 - val_mean_absolute_error: 38.3096\n",
      "Epoch 1052/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 286.6888 - mean_absolute_error: 13.5337\n",
      "Epoch 1052: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 954.0321 - mean_absolute_error: 20.0137 - val_loss: 2165.1316 - val_mean_absolute_error: 38.3825\n",
      "Epoch 1053/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 722.1129 - mean_absolute_error: 16.7000\n",
      "Epoch 1053: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 876.2937 - mean_absolute_error: 19.9531 - val_loss: 2171.4873 - val_mean_absolute_error: 38.3372\n",
      "Epoch 1054/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 463.8504 - mean_absolute_error: 14.7365\n",
      "Epoch 1054: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 805.4809 - mean_absolute_error: 19.4083 - val_loss: 2171.6924 - val_mean_absolute_error: 38.4454\n",
      "Epoch 1055/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 958.8434 - mean_absolute_error: 20.1815 \n",
      "Epoch 1055: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 949.1755 - mean_absolute_error: 20.1427 - val_loss: 2185.3645 - val_mean_absolute_error: 38.5191\n",
      "Epoch 1056/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 612.8906 - mean_absolute_error: 17.0867\n",
      "Epoch 1056: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 930.8448 - mean_absolute_error: 20.2292 - val_loss: 2165.6082 - val_mean_absolute_error: 38.3987\n",
      "Epoch 1057/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 987.9591 - mean_absolute_error: 22.9258\n",
      "Epoch 1057: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 837.0770 - mean_absolute_error: 19.9829 - val_loss: 2164.2708 - val_mean_absolute_error: 38.3867\n",
      "Epoch 1058/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 450.2736 - mean_absolute_error: 14.8654\n",
      "Epoch 1058: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 764.5932 - mean_absolute_error: 18.9911 - val_loss: 2173.0190 - val_mean_absolute_error: 38.4236\n",
      "Epoch 1059/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 932.2457 - mean_absolute_error: 21.8753\n",
      "Epoch 1059: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 847.7921 - mean_absolute_error: 20.1945 - val_loss: 2183.5154 - val_mean_absolute_error: 38.4951\n",
      "Epoch 1060/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 980.2261 - mean_absolute_error: 21.1447 \n",
      "Epoch 1060: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 965.5352 - mean_absolute_error: 21.0119 - val_loss: 2177.8616 - val_mean_absolute_error: 38.4688\n",
      "Epoch 1061/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 783.5005 - mean_absolute_error: 18.8012  \n",
      "Epoch 1061: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 786.5171 - mean_absolute_error: 18.8350 - val_loss: 2186.1582 - val_mean_absolute_error: 38.2970\n",
      "Epoch 1062/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 964.2759 - mean_absolute_error: 19.9575  \n",
      "Epoch 1062: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 959.3853 - mean_absolute_error: 19.9670 - val_loss: 2174.7927 - val_mean_absolute_error: 38.4674\n",
      "Epoch 1063/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1067.9150 - mean_absolute_error: 24.8420\n",
      "Epoch 1063: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 988.1274 - mean_absolute_error: 21.0468 - val_loss: 2174.4575 - val_mean_absolute_error: 38.5538\n",
      "Epoch 1064/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 926.0801 - mean_absolute_error: 22.8506\n",
      "Epoch 1064: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 910.8010 - mean_absolute_error: 20.7028 - val_loss: 2172.9331 - val_mean_absolute_error: 38.4564\n",
      "Epoch 1065/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1464.4434 - mean_absolute_error: 25.6654\n",
      "Epoch 1065: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 910.6129 - mean_absolute_error: 20.2844 - val_loss: 2176.1084 - val_mean_absolute_error: 38.3875\n",
      "Epoch 1066/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 899.7223 - mean_absolute_error: 20.3062 \n",
      "Epoch 1066: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 898.6230 - mean_absolute_error: 20.2823 - val_loss: 2169.9094 - val_mean_absolute_error: 38.3484\n",
      "Epoch 1067/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 636.8511 - mean_absolute_error: 17.2231\n",
      "Epoch 1067: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 773.0601 - mean_absolute_error: 19.1722 - val_loss: 2221.0815 - val_mean_absolute_error: 38.8787\n",
      "Epoch 1068/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 613.8185 - mean_absolute_error: 20.1450\n",
      "Epoch 1068: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 949.2637 - mean_absolute_error: 20.6801 - val_loss: 2178.8245 - val_mean_absolute_error: 38.4583\n",
      "Epoch 1069/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 282.1696 - mean_absolute_error: 13.1328\n",
      "Epoch 1069: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.6981 - mean_absolute_error: 19.5785 - val_loss: 2171.1062 - val_mean_absolute_error: 38.3999\n",
      "Epoch 1070/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1553.1934 - mean_absolute_error: 27.3917\n",
      "Epoch 1070: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 905.2873 - mean_absolute_error: 20.3756 - val_loss: 2193.6394 - val_mean_absolute_error: 38.5905\n",
      "Epoch 1071/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1082.5219 - mean_absolute_error: 20.7855\n",
      "Epoch 1071: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 894.6522 - mean_absolute_error: 19.9693 - val_loss: 2157.9966 - val_mean_absolute_error: 38.3510\n",
      "Epoch 1072/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 874.0544 - mean_absolute_error: 19.8744  \n",
      "Epoch 1072: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 871.0221 - mean_absolute_error: 19.8307 - val_loss: 2187.6870 - val_mean_absolute_error: 38.5213\n",
      "Epoch 1073/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.2924 - mean_absolute_error: 19.2169 \n",
      "Epoch 1073: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 829.4130 - mean_absolute_error: 19.2629 - val_loss: 2197.1038 - val_mean_absolute_error: 38.6847\n",
      "Epoch 1074/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1150.7292 - mean_absolute_error: 23.4835\n",
      "Epoch 1074: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 971.8915 - mean_absolute_error: 20.7382 - val_loss: 2173.8264 - val_mean_absolute_error: 38.4733\n",
      "Epoch 1075/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 299.5571 - mean_absolute_error: 13.0862\n",
      "Epoch 1075: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 808.8104 - mean_absolute_error: 19.2299 - val_loss: 2183.7874 - val_mean_absolute_error: 38.3427\n",
      "Epoch 1076/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 380.4727 - mean_absolute_error: 15.4613\n",
      "Epoch 1076: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 864.7966 - mean_absolute_error: 19.2740 - val_loss: 2162.1348 - val_mean_absolute_error: 38.3759\n",
      "Epoch 1077/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 893.4231 - mean_absolute_error: 19.7272  \n",
      "Epoch 1077: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 892.0698 - mean_absolute_error: 19.7422 - val_loss: 2200.4951 - val_mean_absolute_error: 38.5284\n",
      "Epoch 1078/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 699.5199 - mean_absolute_error: 21.1332\n",
      "Epoch 1078: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 821.9292 - mean_absolute_error: 19.0460 - val_loss: 2172.8662 - val_mean_absolute_error: 38.4839\n",
      "Epoch 1079/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 524.1657 - mean_absolute_error: 16.0381\n",
      "Epoch 1079: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 778.9645 - mean_absolute_error: 19.2566 - val_loss: 2182.0427 - val_mean_absolute_error: 38.4292\n",
      "Epoch 1080/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1023.6243 - mean_absolute_error: 22.2186\n",
      "Epoch 1080: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 873.9898 - mean_absolute_error: 19.3655 - val_loss: 2194.2620 - val_mean_absolute_error: 38.6356\n",
      "Epoch 1081/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1583.0082 - mean_absolute_error: 24.1523\n",
      "Epoch 1081: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 917.1205 - mean_absolute_error: 20.0189 - val_loss: 2197.9880 - val_mean_absolute_error: 38.5552\n",
      "Epoch 1082/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1148.6990 - mean_absolute_error: 24.3859\n",
      "Epoch 1082: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 899.0679 - mean_absolute_error: 20.4627 - val_loss: 2198.2922 - val_mean_absolute_error: 38.7081\n",
      "Epoch 1083/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 733.7629 - mean_absolute_error: 18.5206 \n",
      "Epoch 1083: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 755.3274 - mean_absolute_error: 18.7144 - val_loss: 2198.3401 - val_mean_absolute_error: 38.6402\n",
      "Epoch 1084/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1025.1426 - mean_absolute_error: 23.8863\n",
      "Epoch 1084: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 873.8612 - mean_absolute_error: 20.1561 - val_loss: 2169.6235 - val_mean_absolute_error: 38.4118\n",
      "Epoch 1085/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 543.8766 - mean_absolute_error: 16.3403\n",
      "Epoch 1085: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 882.1199 - mean_absolute_error: 20.1908 - val_loss: 2191.0061 - val_mean_absolute_error: 38.6306\n",
      "Epoch 1086/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 564.4465 - mean_absolute_error: 18.7780\n",
      "Epoch 1086: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 828.1893 - mean_absolute_error: 19.8162 - val_loss: 2204.2693 - val_mean_absolute_error: 38.4885\n",
      "Epoch 1087/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 612.1579 - mean_absolute_error: 16.7904\n",
      "Epoch 1087: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 733.0571 - mean_absolute_error: 18.6748 - val_loss: 2174.4263 - val_mean_absolute_error: 38.4925\n",
      "Epoch 1088/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 460.0104 - mean_absolute_error: 16.3629\n",
      "Epoch 1088: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 773.2719 - mean_absolute_error: 19.2671 - val_loss: 2179.2849 - val_mean_absolute_error: 38.4947\n",
      "Epoch 1089/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 823.1782 - mean_absolute_error: 19.8255 \n",
      "Epoch 1089: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 831.9036 - mean_absolute_error: 19.8469 - val_loss: 2181.0950 - val_mean_absolute_error: 38.5017\n",
      "Epoch 1090/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 512.8567 - mean_absolute_error: 18.4842\n",
      "Epoch 1090: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 887.4340 - mean_absolute_error: 20.5062 - val_loss: 2188.1809 - val_mean_absolute_error: 38.5851\n",
      "Epoch 1091/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 754.5944 - mean_absolute_error: 22.7819\n",
      "Epoch 1091: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 846.1665 - mean_absolute_error: 20.2506 - val_loss: 2169.3418 - val_mean_absolute_error: 38.3982\n",
      "Epoch 1092/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 569.4359 - mean_absolute_error: 16.8050\n",
      "Epoch 1092: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 924.2983 - mean_absolute_error: 20.4116 - val_loss: 2203.2800 - val_mean_absolute_error: 38.3848\n",
      "Epoch 1093/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 452.5049 - mean_absolute_error: 15.4769\n",
      "Epoch 1093: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 831.2061 - mean_absolute_error: 19.6846 - val_loss: 2175.6414 - val_mean_absolute_error: 38.4505\n",
      "Epoch 1094/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 413.5178 - mean_absolute_error: 14.6985\n",
      "Epoch 1094: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 771.1294 - mean_absolute_error: 18.8771 - val_loss: 2175.0935 - val_mean_absolute_error: 38.4468\n",
      "Epoch 1095/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 884.1957 - mean_absolute_error: 19.9815 \n",
      "Epoch 1095: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 882.8550 - mean_absolute_error: 19.9820 - val_loss: 2237.9302 - val_mean_absolute_error: 39.1366\n",
      "Epoch 1096/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 729.7076 - mean_absolute_error: 18.6293 \n",
      "Epoch 1096: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 738.3831 - mean_absolute_error: 18.7048 - val_loss: 2145.7415 - val_mean_absolute_error: 38.3112\n",
      "Epoch 1097/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 856.0316 - mean_absolute_error: 22.4875\n",
      "Epoch 1097: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 874.8788 - mean_absolute_error: 19.9854 - val_loss: 2223.1245 - val_mean_absolute_error: 38.9471\n",
      "Epoch 1098/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1282.2418 - mean_absolute_error: 23.7887\n",
      "Epoch 1098: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 902.6520 - mean_absolute_error: 20.3399 - val_loss: 2220.8806 - val_mean_absolute_error: 38.8758\n",
      "Epoch 1099/1500\n",
      "\u001b[1m17/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 848.0200 - mean_absolute_error: 20.2137 \n",
      "Epoch 1099: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 889.6439 - mean_absolute_error: 20.2790 - val_loss: 2190.2097 - val_mean_absolute_error: 38.6317\n",
      "Epoch 1100/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 778.3906 - mean_absolute_error: 19.1868 \n",
      "Epoch 1100: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 800.3950 - mean_absolute_error: 19.3820 - val_loss: 2177.7825 - val_mean_absolute_error: 38.4631\n",
      "Epoch 1101/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.2786 - mean_absolute_error: 19.4009 \n",
      "Epoch 1101: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 822.0230 - mean_absolute_error: 19.4978 - val_loss: 2167.6077 - val_mean_absolute_error: 38.4525\n",
      "Epoch 1102/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 838.2841 - mean_absolute_error: 22.8701\n",
      "Epoch 1102: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 846.3065 - mean_absolute_error: 20.1004 - val_loss: 2200.9014 - val_mean_absolute_error: 38.5249\n",
      "Epoch 1103/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1812.9823 - mean_absolute_error: 28.9436\n",
      "Epoch 1103: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 985.1840 - mean_absolute_error: 20.8010 - val_loss: 2177.4353 - val_mean_absolute_error: 38.5239\n",
      "Epoch 1104/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 519.7949 - mean_absolute_error: 15.2217\n",
      "Epoch 1104: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 773.4105 - mean_absolute_error: 19.0487 - val_loss: 2161.6213 - val_mean_absolute_error: 38.3567\n",
      "Epoch 1105/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 879.6354 - mean_absolute_error: 20.1171  \n",
      "Epoch 1105: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 879.5320 - mean_absolute_error: 20.0997 - val_loss: 2184.3694 - val_mean_absolute_error: 38.5982\n",
      "Epoch 1106/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1316.6310 - mean_absolute_error: 25.5604\n",
      "Epoch 1106: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 961.0533 - mean_absolute_error: 21.0568 - val_loss: 2161.2666 - val_mean_absolute_error: 38.4103\n",
      "Epoch 1107/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 910.2685 - mean_absolute_error: 21.7089\n",
      "Epoch 1107: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 898.1984 - mean_absolute_error: 20.5034 - val_loss: 2165.2759 - val_mean_absolute_error: 38.4364\n",
      "Epoch 1108/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1166.1401 - mean_absolute_error: 20.0957\n",
      "Epoch 1108: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 898.4244 - mean_absolute_error: 19.4709 - val_loss: 2200.7256 - val_mean_absolute_error: 38.6329\n",
      "Epoch 1109/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 718.6157 - mean_absolute_error: 16.6460\n",
      "Epoch 1109: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 804.9888 - mean_absolute_error: 19.0812 - val_loss: 2234.5757 - val_mean_absolute_error: 38.9681\n",
      "Epoch 1110/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 755.9856 - mean_absolute_error: 18.5805 \n",
      "Epoch 1110: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 776.5859 - mean_absolute_error: 18.8731 - val_loss: 2198.2500 - val_mean_absolute_error: 38.5028\n",
      "Epoch 1111/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 843.0605 - mean_absolute_error: 19.9343 \n",
      "Epoch 1111: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 845.6848 - mean_absolute_error: 19.9491 - val_loss: 2157.1775 - val_mean_absolute_error: 38.2769\n",
      "Epoch 1112/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1289.8840 - mean_absolute_error: 24.9464\n",
      "Epoch 1112: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 830.7942 - mean_absolute_error: 19.2490 - val_loss: 2136.8162 - val_mean_absolute_error: 38.1791\n",
      "Epoch 1113/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 652.7377 - mean_absolute_error: 18.6434\n",
      "Epoch 1113: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 905.9143 - mean_absolute_error: 19.7000 - val_loss: 2186.1064 - val_mean_absolute_error: 38.5828\n",
      "Epoch 1114/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 762.1978 - mean_absolute_error: 20.1125\n",
      "Epoch 1114: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 891.2532 - mean_absolute_error: 19.9871 - val_loss: 2192.2585 - val_mean_absolute_error: 38.5591\n",
      "Epoch 1115/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 917.3844 - mean_absolute_error: 19.6080  \n",
      "Epoch 1115: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 913.0391 - mean_absolute_error: 19.6488 - val_loss: 2193.2971 - val_mean_absolute_error: 38.6885\n",
      "Epoch 1116/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 994.7700 - mean_absolute_error: 21.7681\n",
      "Epoch 1116: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 767.6545 - mean_absolute_error: 18.8817 - val_loss: 2166.4495 - val_mean_absolute_error: 38.4558\n",
      "Epoch 1117/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 720.5882 - mean_absolute_error: 18.0806\n",
      "Epoch 1117: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 885.2577 - mean_absolute_error: 20.3271 - val_loss: 2190.5393 - val_mean_absolute_error: 38.4230\n",
      "Epoch 1118/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1463.6606 - mean_absolute_error: 26.6311\n",
      "Epoch 1118: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.8187 - mean_absolute_error: 21.3263 - val_loss: 2165.2273 - val_mean_absolute_error: 38.4386\n",
      "Epoch 1119/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 625.7865 - mean_absolute_error: 17.9692\n",
      "Epoch 1119: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 808.2901 - mean_absolute_error: 20.0688 - val_loss: 2212.6145 - val_mean_absolute_error: 38.8603\n",
      "Epoch 1120/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1031.1910 - mean_absolute_error: 21.9154\n",
      "Epoch 1120: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 996.9788 - mean_absolute_error: 21.4508 - val_loss: 2202.0833 - val_mean_absolute_error: 38.4785\n",
      "Epoch 1121/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 917.1422 - mean_absolute_error: 20.2242 \n",
      "Epoch 1121: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 915.3720 - mean_absolute_error: 20.2164 - val_loss: 2194.0393 - val_mean_absolute_error: 38.6686\n",
      "Epoch 1122/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1027.9697 - mean_absolute_error: 25.3356\n",
      "Epoch 1122: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.6071 - mean_absolute_error: 20.0969 - val_loss: 2164.1882 - val_mean_absolute_error: 38.4325\n",
      "Epoch 1123/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 516.5214 - mean_absolute_error: 15.6002\n",
      "Epoch 1123: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 763.0749 - mean_absolute_error: 19.0620 - val_loss: 2171.4568 - val_mean_absolute_error: 38.4102\n",
      "Epoch 1124/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1264.7869 - mean_absolute_error: 24.1050\n",
      "Epoch 1124: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 916.5135 - mean_absolute_error: 20.5481 - val_loss: 2187.6658 - val_mean_absolute_error: 38.5993\n",
      "Epoch 1125/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 811.7313 - mean_absolute_error: 19.7169  \n",
      "Epoch 1125: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 816.8136 - mean_absolute_error: 19.7200 - val_loss: 2187.3005 - val_mean_absolute_error: 38.5947\n",
      "Epoch 1126/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 645.5955 - mean_absolute_error: 17.9204\n",
      "Epoch 1126: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 917.2648 - mean_absolute_error: 20.2110 - val_loss: 2173.5388 - val_mean_absolute_error: 38.5439\n",
      "Epoch 1127/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 569.2530 - mean_absolute_error: 18.9925\n",
      "Epoch 1127: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 920.5807 - mean_absolute_error: 20.6826 - val_loss: 2170.8135 - val_mean_absolute_error: 38.4746\n",
      "Epoch 1128/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 753.5645 - mean_absolute_error: 20.5115\n",
      "Epoch 1128: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 785.3420 - mean_absolute_error: 18.8854 - val_loss: 2189.3044 - val_mean_absolute_error: 38.5995\n",
      "Epoch 1129/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 793.6165 - mean_absolute_error: 20.5877\n",
      "Epoch 1129: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 819.9305 - mean_absolute_error: 19.6903 - val_loss: 2180.7104 - val_mean_absolute_error: 38.5403\n",
      "Epoch 1130/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.6354 - mean_absolute_error: 21.2006\n",
      "Epoch 1130: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1079.9041 - mean_absolute_error: 21.0106 - val_loss: 2171.7466 - val_mean_absolute_error: 38.4993\n",
      "Epoch 1131/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1258.5101 - mean_absolute_error: 22.2397\n",
      "Epoch 1131: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.5239 - mean_absolute_error: 19.5643 - val_loss: 2216.8655 - val_mean_absolute_error: 38.8485\n",
      "Epoch 1132/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 899.1938 - mean_absolute_error: 19.6759 \n",
      "Epoch 1132: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 898.6315 - mean_absolute_error: 19.6865 - val_loss: 2151.0217 - val_mean_absolute_error: 38.3447\n",
      "Epoch 1133/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1765.3640 - mean_absolute_error: 25.2547\n",
      "Epoch 1133: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 963.5458 - mean_absolute_error: 20.3944 - val_loss: 2218.0793 - val_mean_absolute_error: 38.6270\n",
      "Epoch 1134/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1495.7057 - mean_absolute_error: 23.9094\n",
      "Epoch 1134: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.9673 - mean_absolute_error: 21.4398 - val_loss: 2205.5740 - val_mean_absolute_error: 38.6753\n",
      "Epoch 1135/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 663.7943 - mean_absolute_error: 19.9123\n",
      "Epoch 1135: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 850.4532 - mean_absolute_error: 20.3603 - val_loss: 2188.4036 - val_mean_absolute_error: 38.5465\n",
      "Epoch 1136/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1004.7109 - mean_absolute_error: 21.3446 \n",
      "Epoch 1136: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 986.5054 - mean_absolute_error: 21.1674 - val_loss: 2180.7263 - val_mean_absolute_error: 38.5608\n",
      "Epoch 1137/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1148.1802 - mean_absolute_error: 21.9505\n",
      "Epoch 1137: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 825.0469 - mean_absolute_error: 19.3227 - val_loss: 2227.1917 - val_mean_absolute_error: 38.8551\n",
      "Epoch 1138/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1169.3241 - mean_absolute_error: 23.7624\n",
      "Epoch 1138: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 916.0502 - mean_absolute_error: 20.2362 - val_loss: 2226.1453 - val_mean_absolute_error: 39.0489\n",
      "Epoch 1139/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 716.0063 - mean_absolute_error: 19.4868\n",
      "Epoch 1139: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 796.1922 - mean_absolute_error: 19.4469 - val_loss: 2177.4331 - val_mean_absolute_error: 38.5412\n",
      "Epoch 1140/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 697.0161 - mean_absolute_error: 18.4776\n",
      "Epoch 1140: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 864.9573 - mean_absolute_error: 20.0010 - val_loss: 2171.4333 - val_mean_absolute_error: 38.4935\n",
      "Epoch 1141/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 959.8912 - mean_absolute_error: 20.8325  \n",
      "Epoch 1141: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 957.3467 - mean_absolute_error: 20.8043 - val_loss: 2193.5652 - val_mean_absolute_error: 38.6199\n",
      "Epoch 1142/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 927.6576 - mean_absolute_error: 20.3503  \n",
      "Epoch 1142: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 924.7574 - mean_absolute_error: 20.3284 - val_loss: 2188.5815 - val_mean_absolute_error: 38.4408\n",
      "Epoch 1143/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1201.8309 - mean_absolute_error: 26.7110\n",
      "Epoch 1143: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 866.4663 - mean_absolute_error: 20.2820 - val_loss: 2177.2456 - val_mean_absolute_error: 38.5518\n",
      "Epoch 1144/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 957.5438 - mean_absolute_error: 22.1760\n",
      "Epoch 1144: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.6976 - mean_absolute_error: 19.6425 - val_loss: 2220.9863 - val_mean_absolute_error: 38.9692\n",
      "Epoch 1145/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 837.7413 - mean_absolute_error: 20.2747\n",
      "Epoch 1145: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 831.8373 - mean_absolute_error: 19.8856 - val_loss: 2187.3860 - val_mean_absolute_error: 38.5938\n",
      "Epoch 1146/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 786.4115 - mean_absolute_error: 18.8776 \n",
      "Epoch 1146: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 794.4166 - mean_absolute_error: 18.9787 - val_loss: 2183.2041 - val_mean_absolute_error: 38.4327\n",
      "Epoch 1147/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 735.1309 - mean_absolute_error: 21.1439\n",
      "Epoch 1147: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 862.7013 - mean_absolute_error: 19.8139 - val_loss: 2185.3713 - val_mean_absolute_error: 38.6121\n",
      "Epoch 1148/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 769.0223 - mean_absolute_error: 19.3865 \n",
      "Epoch 1148: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 775.6736 - mean_absolute_error: 19.4290 - val_loss: 2189.5806 - val_mean_absolute_error: 38.6242\n",
      "Epoch 1149/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 679.1743 - mean_absolute_error: 20.0139\n",
      "Epoch 1149: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 791.9946 - mean_absolute_error: 19.3657 - val_loss: 2176.5750 - val_mean_absolute_error: 38.5005\n",
      "Epoch 1150/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1462.4607 - mean_absolute_error: 23.5257\n",
      "Epoch 1150: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 957.0671 - mean_absolute_error: 19.9901 - val_loss: 2186.1907 - val_mean_absolute_error: 38.6207\n",
      "Epoch 1151/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 865.2289 - mean_absolute_error: 18.7572\n",
      "Epoch 1151: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 845.5672 - mean_absolute_error: 19.6741 - val_loss: 2176.8533 - val_mean_absolute_error: 38.4347\n",
      "Epoch 1152/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 933.9154 - mean_absolute_error: 21.0162 \n",
      "Epoch 1152: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 923.9559 - mean_absolute_error: 20.8490 - val_loss: 2204.5857 - val_mean_absolute_error: 38.7226\n",
      "Epoch 1153/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 825.7086 - mean_absolute_error: 19.5296 \n",
      "Epoch 1153: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 834.1423 - mean_absolute_error: 19.6042 - val_loss: 2183.2852 - val_mean_absolute_error: 38.5413\n",
      "Epoch 1154/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 807.4819 - mean_absolute_error: 21.9135\n",
      "Epoch 1154: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 857.0640 - mean_absolute_error: 19.7822 - val_loss: 2172.1619 - val_mean_absolute_error: 38.5422\n",
      "Epoch 1155/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1932.2560 - mean_absolute_error: 29.7402\n",
      "Epoch 1155: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 871.1025 - mean_absolute_error: 20.2209 - val_loss: 2167.3184 - val_mean_absolute_error: 38.4305\n",
      "Epoch 1156/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 810.3245 - mean_absolute_error: 19.4525\n",
      "Epoch 1156: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 793.3925 - mean_absolute_error: 19.4069 - val_loss: 2180.4861 - val_mean_absolute_error: 38.5731\n",
      "Epoch 1157/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 922.9766 - mean_absolute_error: 20.4426 \n",
      "Epoch 1157: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 915.3859 - mean_absolute_error: 20.3568 - val_loss: 2191.7043 - val_mean_absolute_error: 38.4884\n",
      "Epoch 1158/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 233.3775 - mean_absolute_error: 12.0847\n",
      "Epoch 1158: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 709.6077 - mean_absolute_error: 18.0352 - val_loss: 2181.4717 - val_mean_absolute_error: 38.5968\n",
      "Epoch 1159/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 948.3596 - mean_absolute_error: 21.5478\n",
      "Epoch 1159: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 828.8427 - mean_absolute_error: 20.0973 - val_loss: 2182.8022 - val_mean_absolute_error: 38.5966\n",
      "Epoch 1160/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 389.9539 - mean_absolute_error: 14.4370\n",
      "Epoch 1160: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 928.5054 - mean_absolute_error: 19.8220 - val_loss: 2189.5935 - val_mean_absolute_error: 38.6394\n",
      "Epoch 1161/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 528.8630 - mean_absolute_error: 14.8712\n",
      "Epoch 1161: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 846.4079 - mean_absolute_error: 19.0265 - val_loss: 2209.8440 - val_mean_absolute_error: 38.8123\n",
      "Epoch 1162/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 695.6475 - mean_absolute_error: 21.1642\n",
      "Epoch 1162: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 867.2361 - mean_absolute_error: 20.2505 - val_loss: 2177.8298 - val_mean_absolute_error: 38.6105\n",
      "Epoch 1163/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 850.8869 - mean_absolute_error: 20.0235  \n",
      "Epoch 1163: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 852.4275 - mean_absolute_error: 19.9747 - val_loss: 2170.2800 - val_mean_absolute_error: 38.5266\n",
      "Epoch 1164/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 885.4601 - mean_absolute_error: 21.3642\n",
      "Epoch 1164: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 882.7832 - mean_absolute_error: 20.3278 - val_loss: 2166.9307 - val_mean_absolute_error: 38.5138\n",
      "Epoch 1165/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 433.4664 - mean_absolute_error: 15.7594\n",
      "Epoch 1165: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 810.1469 - mean_absolute_error: 19.2048 - val_loss: 2184.7878 - val_mean_absolute_error: 38.6392\n",
      "Epoch 1166/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 641.6268 - mean_absolute_error: 19.0057\n",
      "Epoch 1166: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 864.3279 - mean_absolute_error: 19.9339 - val_loss: 2151.9033 - val_mean_absolute_error: 38.4760\n",
      "Epoch 1167/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 858.4999 - mean_absolute_error: 20.3154 \n",
      "Epoch 1167: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.3990 - mean_absolute_error: 20.2738 - val_loss: 2168.5176 - val_mean_absolute_error: 38.5187\n",
      "Epoch 1168/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 957.4985 - mean_absolute_error: 20.8708  \n",
      "Epoch 1168: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 955.2068 - mean_absolute_error: 20.8444 - val_loss: 2183.2507 - val_mean_absolute_error: 38.5125\n",
      "Epoch 1169/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 881.5079 - mean_absolute_error: 19.7406  \n",
      "Epoch 1169: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 881.5154 - mean_absolute_error: 19.7496 - val_loss: 2178.2771 - val_mean_absolute_error: 38.6052\n",
      "Epoch 1170/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 411.2004 - mean_absolute_error: 15.2120\n",
      "Epoch 1170: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 777.3928 - mean_absolute_error: 19.1675 - val_loss: 2214.8296 - val_mean_absolute_error: 38.8722\n",
      "Epoch 1171/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 524.3242 - mean_absolute_error: 16.2462\n",
      "Epoch 1171: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 777.2063 - mean_absolute_error: 19.0982 - val_loss: 2178.2725 - val_mean_absolute_error: 38.5666\n",
      "Epoch 1172/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 659.5270 - mean_absolute_error: 18.3402\n",
      "Epoch 1172: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 938.3987 - mean_absolute_error: 20.2561 - val_loss: 2199.5083 - val_mean_absolute_error: 38.7024\n",
      "Epoch 1173/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 876.1775 - mean_absolute_error: 19.8132  \n",
      "Epoch 1173: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 877.5638 - mean_absolute_error: 19.8276 - val_loss: 2212.6006 - val_mean_absolute_error: 38.9167\n",
      "Epoch 1174/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 664.1041 - mean_absolute_error: 20.8673\n",
      "Epoch 1174: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 920.2706 - mean_absolute_error: 20.8741 - val_loss: 2165.0623 - val_mean_absolute_error: 38.4574\n",
      "Epoch 1175/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 749.4791 - mean_absolute_error: 18.8108\n",
      "Epoch 1175: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 886.5352 - mean_absolute_error: 20.2174 - val_loss: 2189.1658 - val_mean_absolute_error: 38.6567\n",
      "Epoch 1176/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 866.2875 - mean_absolute_error: 21.1462\n",
      "Epoch 1176: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 969.2639 - mean_absolute_error: 20.7646 - val_loss: 2185.5625 - val_mean_absolute_error: 38.6425\n",
      "Epoch 1177/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1061.8185 - mean_absolute_error: 22.9788\n",
      "Epoch 1177: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 867.9478 - mean_absolute_error: 19.9671 - val_loss: 2196.8022 - val_mean_absolute_error: 38.7214\n",
      "Epoch 1178/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 813.8783 - mean_absolute_error: 19.8228 \n",
      "Epoch 1178: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 832.1696 - mean_absolute_error: 19.8567 - val_loss: 2174.6018 - val_mean_absolute_error: 38.5882\n",
      "Epoch 1179/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 761.7938 - mean_absolute_error: 20.5551\n",
      "Epoch 1179: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 903.3290 - mean_absolute_error: 19.9387 - val_loss: 2186.4224 - val_mean_absolute_error: 38.5233\n",
      "Epoch 1180/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 905.6733 - mean_absolute_error: 23.1782\n",
      "Epoch 1180: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915.8190 - mean_absolute_error: 20.6868 - val_loss: 2210.8784 - val_mean_absolute_error: 38.8060\n",
      "Epoch 1181/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 628.1377 - mean_absolute_error: 18.1843\n",
      "Epoch 1181: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 795.6495 - mean_absolute_error: 19.1242 - val_loss: 2196.2725 - val_mean_absolute_error: 38.6032\n",
      "Epoch 1182/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 643.6986 - mean_absolute_error: 18.6899\n",
      "Epoch 1182: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839.7095 - mean_absolute_error: 20.1051 - val_loss: 2212.3721 - val_mean_absolute_error: 38.8533\n",
      "Epoch 1183/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1016.4249 - mean_absolute_error: 21.1356 \n",
      "Epoch 1183: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1003.8274 - mean_absolute_error: 21.0354 - val_loss: 2190.8521 - val_mean_absolute_error: 38.6561\n",
      "Epoch 1184/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 969.8047 - mean_absolute_error: 20.9335 \n",
      "Epoch 1184: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 956.4183 - mean_absolute_error: 20.8054 - val_loss: 2171.6685 - val_mean_absolute_error: 38.4855\n",
      "Epoch 1185/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 948.4149 - mean_absolute_error: 23.3045\n",
      "Epoch 1185: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 941.7960 - mean_absolute_error: 20.6496 - val_loss: 2200.8584 - val_mean_absolute_error: 38.7938\n",
      "Epoch 1186/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 551.8489 - mean_absolute_error: 17.0413\n",
      "Epoch 1186: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 866.0088 - mean_absolute_error: 20.0098 - val_loss: 2157.9707 - val_mean_absolute_error: 38.4881\n",
      "Epoch 1187/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 607.2657 - mean_absolute_error: 16.6918\n",
      "Epoch 1187: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 924.2122 - mean_absolute_error: 20.5047 - val_loss: 2189.6826 - val_mean_absolute_error: 38.5272\n",
      "Epoch 1188/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 944.7229 - mean_absolute_error: 20.9473  \n",
      "Epoch 1188: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 937.9872 - mean_absolute_error: 20.8430 - val_loss: 2176.0994 - val_mean_absolute_error: 38.5901\n",
      "Epoch 1189/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 805.7300 - mean_absolute_error: 19.1533 \n",
      "Epoch 1189: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 809.6296 - mean_absolute_error: 19.2008 - val_loss: 2197.9250 - val_mean_absolute_error: 38.7181\n",
      "Epoch 1190/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 699.1284 - mean_absolute_error: 18.1904\n",
      "Epoch 1190: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 744.7766 - mean_absolute_error: 18.5838 - val_loss: 2196.7605 - val_mean_absolute_error: 38.7224\n",
      "Epoch 1191/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 817.4636 - mean_absolute_error: 19.5548\n",
      "Epoch 1191: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 926.4170 - mean_absolute_error: 20.4756 - val_loss: 2173.1482 - val_mean_absolute_error: 38.5562\n",
      "Epoch 1192/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2630.2017 - mean_absolute_error: 26.8755\n",
      "Epoch 1192: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1078.5305 - mean_absolute_error: 20.7718 - val_loss: 2192.8220 - val_mean_absolute_error: 38.7024\n",
      "Epoch 1193/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.9296 - mean_absolute_error: 21.2566 \n",
      "Epoch 1193: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1000.6224 - mean_absolute_error: 21.0301 - val_loss: 2186.6721 - val_mean_absolute_error: 38.7120\n",
      "Epoch 1194/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 609.8193 - mean_absolute_error: 18.1945\n",
      "Epoch 1194: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 893.6410 - mean_absolute_error: 20.1223 - val_loss: 2212.2310 - val_mean_absolute_error: 38.7501\n",
      "Epoch 1195/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 859.9824 - mean_absolute_error: 19.9733 \n",
      "Epoch 1195: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 860.3813 - mean_absolute_error: 19.9721 - val_loss: 2239.8918 - val_mean_absolute_error: 39.0936\n",
      "Epoch 1196/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 642.7741 - mean_absolute_error: 17.9715\n",
      "Epoch 1196: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 829.2521 - mean_absolute_error: 19.3373 - val_loss: 2244.5183 - val_mean_absolute_error: 39.0039\n",
      "Epoch 1197/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 584.2991 - mean_absolute_error: 17.2874\n",
      "Epoch 1197: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.1787 - mean_absolute_error: 19.2883 - val_loss: 2229.0220 - val_mean_absolute_error: 38.9241\n",
      "Epoch 1198/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 678.5964 - mean_absolute_error: 18.3182\n",
      "Epoch 1198: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 955.3897 - mean_absolute_error: 20.8486 - val_loss: 2186.3193 - val_mean_absolute_error: 38.6674\n",
      "Epoch 1199/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 857.6722 - mean_absolute_error: 19.9506 \n",
      "Epoch 1199: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 860.0149 - mean_absolute_error: 19.9269 - val_loss: 2179.1780 - val_mean_absolute_error: 38.5950\n",
      "Epoch 1200/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2308.8833 - mean_absolute_error: 26.3579\n",
      "Epoch 1200: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 947.6775 - mean_absolute_error: 20.2446 - val_loss: 2174.1274 - val_mean_absolute_error: 38.6122\n",
      "Epoch 1201/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 448.4826 - mean_absolute_error: 15.6279\n",
      "Epoch 1201: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1001.8594 - mean_absolute_error: 20.7199 - val_loss: 2161.5886 - val_mean_absolute_error: 38.4684\n",
      "Epoch 1202/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 539.1437 - mean_absolute_error: 15.4839\n",
      "Epoch 1202: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 795.6840 - mean_absolute_error: 19.1912 - val_loss: 2227.2109 - val_mean_absolute_error: 38.9385\n",
      "Epoch 1203/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 765.7651 - mean_absolute_error: 19.5072 \n",
      "Epoch 1203: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 772.7951 - mean_absolute_error: 19.5547 - val_loss: 2215.6604 - val_mean_absolute_error: 38.8119\n",
      "Epoch 1204/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 261.4602 - mean_absolute_error: 13.1195\n",
      "Epoch 1204: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 919.7844 - mean_absolute_error: 20.3481 - val_loss: 2227.7151 - val_mean_absolute_error: 39.0546\n",
      "Epoch 1205/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 883.6272 - mean_absolute_error: 21.8283\n",
      "Epoch 1205: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 853.7968 - mean_absolute_error: 19.6497 - val_loss: 2199.4651 - val_mean_absolute_error: 38.7184\n",
      "Epoch 1206/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1564.4524 - mean_absolute_error: 25.3491\n",
      "Epoch 1206: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 991.9376 - mean_absolute_error: 20.5352 - val_loss: 2183.4458 - val_mean_absolute_error: 38.6453\n",
      "Epoch 1207/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 966.5156 - mean_absolute_error: 19.9140\n",
      "Epoch 1207: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 868.1321 - mean_absolute_error: 19.8838 - val_loss: 2210.8862 - val_mean_absolute_error: 38.9058\n",
      "Epoch 1208/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 729.3692 - mean_absolute_error: 18.5144 \n",
      "Epoch 1208: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 754.3330 - mean_absolute_error: 18.7562 - val_loss: 2189.3792 - val_mean_absolute_error: 38.7031\n",
      "Epoch 1209/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 3259.0439 - mean_absolute_error: 36.6039\n",
      "Epoch 1209: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.2805 - mean_absolute_error: 21.6421 - val_loss: 2177.8259 - val_mean_absolute_error: 38.6372\n",
      "Epoch 1210/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 832.0523 - mean_absolute_error: 19.5103 \n",
      "Epoch 1210: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 835.7622 - mean_absolute_error: 19.5554 - val_loss: 2194.3804 - val_mean_absolute_error: 38.7209\n",
      "Epoch 1211/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 772.8996 - mean_absolute_error: 21.1499\n",
      "Epoch 1211: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 775.4470 - mean_absolute_error: 19.2088 - val_loss: 2217.4780 - val_mean_absolute_error: 38.6590\n",
      "Epoch 1212/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 543.5195 - mean_absolute_error: 16.5312\n",
      "Epoch 1212: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 948.4514 - mean_absolute_error: 20.4896 - val_loss: 2246.5710 - val_mean_absolute_error: 39.2255\n",
      "Epoch 1213/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1464.4438 - mean_absolute_error: 22.6690\n",
      "Epoch 1213: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 935.5716 - mean_absolute_error: 20.1492 - val_loss: 2160.0813 - val_mean_absolute_error: 38.5284\n",
      "Epoch 1214/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 771.4365 - mean_absolute_error: 19.2672 \n",
      "Epoch 1214: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 780.2767 - mean_absolute_error: 19.3231 - val_loss: 2204.3374 - val_mean_absolute_error: 38.7196\n",
      "Epoch 1215/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1087.1879 - mean_absolute_error: 19.7556\n",
      "Epoch 1215: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1007.3521 - mean_absolute_error: 21.1773 - val_loss: 2199.0996 - val_mean_absolute_error: 38.7406\n",
      "Epoch 1216/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 519.2107 - mean_absolute_error: 18.1936\n",
      "Epoch 1216: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 731.4145 - mean_absolute_error: 18.6559 - val_loss: 2197.7839 - val_mean_absolute_error: 38.7400\n",
      "Epoch 1217/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 569.6249 - mean_absolute_error: 17.0934\n",
      "Epoch 1217: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 815.9224 - mean_absolute_error: 19.6145 - val_loss: 2203.0579 - val_mean_absolute_error: 38.8840\n",
      "Epoch 1218/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 873.0039 - mean_absolute_error: 21.5817\n",
      "Epoch 1218: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.8049 - mean_absolute_error: 20.7150 - val_loss: 2235.9360 - val_mean_absolute_error: 39.0421\n",
      "Epoch 1219/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 863.3073 - mean_absolute_error: 20.0599  \n",
      "Epoch 1219: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 863.1611 - mean_absolute_error: 20.0414 - val_loss: 2185.8042 - val_mean_absolute_error: 38.6741\n",
      "Epoch 1220/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 502.8521 - mean_absolute_error: 15.8516\n",
      "Epoch 1220: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 846.4838 - mean_absolute_error: 19.2843 - val_loss: 2236.5786 - val_mean_absolute_error: 39.1276\n",
      "Epoch 1221/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.4662 - mean_absolute_error: 19.4236 \n",
      "Epoch 1221: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 814.3279 - mean_absolute_error: 19.4406 - val_loss: 2185.7668 - val_mean_absolute_error: 38.6704\n",
      "Epoch 1222/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 370.6398 - mean_absolute_error: 15.9511\n",
      "Epoch 1222: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 779.2953 - mean_absolute_error: 18.9376 - val_loss: 2192.3838 - val_mean_absolute_error: 38.7968\n",
      "Epoch 1223/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1241.2280 - mean_absolute_error: 25.8900\n",
      "Epoch 1223: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 893.6564 - mean_absolute_error: 20.4061 - val_loss: 2177.9409 - val_mean_absolute_error: 38.6167\n",
      "Epoch 1224/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1225.6479 - mean_absolute_error: 22.7941\n",
      "Epoch 1224: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 932.8490 - mean_absolute_error: 20.3288 - val_loss: 2196.6692 - val_mean_absolute_error: 38.7167\n",
      "Epoch 1225/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.8295 - mean_absolute_error: 20.0702 \n",
      "Epoch 1225: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 862.2543 - mean_absolute_error: 20.0800 - val_loss: 2209.6250 - val_mean_absolute_error: 38.8474\n",
      "Epoch 1226/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 679.1316 - mean_absolute_error: 18.3753 \n",
      "Epoch 1226: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 701.4939 - mean_absolute_error: 18.5490 - val_loss: 2187.7251 - val_mean_absolute_error: 38.6939\n",
      "Epoch 1227/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 991.0480 - mean_absolute_error: 20.8134\n",
      "Epoch 1227: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 868.4397 - mean_absolute_error: 19.8799 - val_loss: 2205.1755 - val_mean_absolute_error: 38.7802\n",
      "Epoch 1228/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 897.4105 - mean_absolute_error: 19.8865 \n",
      "Epoch 1228: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 896.3165 - mean_absolute_error: 19.8953 - val_loss: 2235.6768 - val_mean_absolute_error: 39.1296\n",
      "Epoch 1229/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 819.2946 - mean_absolute_error: 19.5942 \n",
      "Epoch 1229: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 823.7015 - mean_absolute_error: 19.6216 - val_loss: 2196.2244 - val_mean_absolute_error: 38.6728\n",
      "Epoch 1230/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 872.0182 - mean_absolute_error: 19.5591 \n",
      "Epoch 1230: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 875.6737 - mean_absolute_error: 19.6450 - val_loss: 2205.2566 - val_mean_absolute_error: 38.7045\n",
      "Epoch 1231/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 853.5493 - mean_absolute_error: 19.4239 \n",
      "Epoch 1231: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.7590 - mean_absolute_error: 19.5211 - val_loss: 2202.7307 - val_mean_absolute_error: 38.8528\n",
      "Epoch 1232/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 772.8163 - mean_absolute_error: 20.7452\n",
      "Epoch 1232: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 896.9847 - mean_absolute_error: 20.1528 - val_loss: 2228.7520 - val_mean_absolute_error: 38.8850\n",
      "Epoch 1233/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 894.2683 - mean_absolute_error: 23.0199\n",
      "Epoch 1233: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 850.8232 - mean_absolute_error: 19.9118 - val_loss: 2201.6487 - val_mean_absolute_error: 38.7878\n",
      "Epoch 1234/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 852.0582 - mean_absolute_error: 21.6224\n",
      "Epoch 1234: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 840.7718 - mean_absolute_error: 19.4763 - val_loss: 2239.5066 - val_mean_absolute_error: 39.0739\n",
      "Epoch 1235/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 806.8740 - mean_absolute_error: 19.7919 \n",
      "Epoch 1235: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 819.4979 - mean_absolute_error: 19.7919 - val_loss: 2189.3135 - val_mean_absolute_error: 38.6733\n",
      "Epoch 1236/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 888.8911 - mean_absolute_error: 20.2159 \n",
      "Epoch 1236: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 887.5298 - mean_absolute_error: 20.1916 - val_loss: 2193.1697 - val_mean_absolute_error: 38.7159\n",
      "Epoch 1237/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 994.6829 - mean_absolute_error: 22.3706\n",
      "Epoch 1237: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 775.5428 - mean_absolute_error: 19.3643 - val_loss: 2197.8279 - val_mean_absolute_error: 38.7737\n",
      "Epoch 1238/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 812.5082 - mean_absolute_error: 21.7173\n",
      "Epoch 1238: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 881.9688 - mean_absolute_error: 19.9266 - val_loss: 2218.3652 - val_mean_absolute_error: 38.8474\n",
      "Epoch 1239/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1238.1733 - mean_absolute_error: 21.8906\n",
      "Epoch 1239: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 922.3226 - mean_absolute_error: 20.7182 - val_loss: 2215.4177 - val_mean_absolute_error: 38.8638\n",
      "Epoch 1240/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 953.3062 - mean_absolute_error: 21.2103 \n",
      "Epoch 1240: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 948.6180 - mean_absolute_error: 21.1405 - val_loss: 2182.0427 - val_mean_absolute_error: 38.6235\n",
      "Epoch 1241/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 869.3720 - mean_absolute_error: 19.6952 \n",
      "Epoch 1241: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 869.5519 - mean_absolute_error: 19.7090 - val_loss: 2168.9448 - val_mean_absolute_error: 38.5649\n",
      "Epoch 1242/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1114.8131 - mean_absolute_error: 23.7530\n",
      "Epoch 1242: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 964.9247 - mean_absolute_error: 21.2277 - val_loss: 2220.0864 - val_mean_absolute_error: 38.9982\n",
      "Epoch 1243/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1615.8032 - mean_absolute_error: 28.0372\n",
      "Epoch 1243: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.2502 - mean_absolute_error: 21.0758 - val_loss: 2176.7339 - val_mean_absolute_error: 38.6069\n",
      "Epoch 1244/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1006.3669 - mean_absolute_error: 20.4218 \n",
      "Epoch 1244: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 991.2253 - mean_absolute_error: 20.3787 - val_loss: 2219.7859 - val_mean_absolute_error: 38.9096\n",
      "Epoch 1245/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 927.5234 - mean_absolute_error: 20.9019  \n",
      "Epoch 1245: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 922.0601 - mean_absolute_error: 20.7907 - val_loss: 2205.2192 - val_mean_absolute_error: 38.8019\n",
      "Epoch 1246/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 571.4293 - mean_absolute_error: 15.1968\n",
      "Epoch 1246: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 735.7661 - mean_absolute_error: 18.6886 - val_loss: 2212.0198 - val_mean_absolute_error: 38.8304\n",
      "Epoch 1247/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 880.5326 - mean_absolute_error: 22.6980\n",
      "Epoch 1247: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 948.3411 - mean_absolute_error: 20.6465 - val_loss: 2202.2256 - val_mean_absolute_error: 38.8285\n",
      "Epoch 1248/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 874.8473 - mean_absolute_error: 19.4798\n",
      "Epoch 1248: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 879.8730 - mean_absolute_error: 19.7814 - val_loss: 2203.5691 - val_mean_absolute_error: 38.7775\n",
      "Epoch 1249/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 949.9982 - mean_absolute_error: 20.4845  \n",
      "Epoch 1249: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 939.1256 - mean_absolute_error: 20.4126 - val_loss: 2206.6951 - val_mean_absolute_error: 38.7155\n",
      "Epoch 1250/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 977.7301 - mean_absolute_error: 23.3538\n",
      "Epoch 1250: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 886.8616 - mean_absolute_error: 20.2233 - val_loss: 2169.2957 - val_mean_absolute_error: 38.6350\n",
      "Epoch 1251/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 787.6235 - mean_absolute_error: 19.3060 \n",
      "Epoch 1251: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 790.0295 - mean_absolute_error: 19.3204 - val_loss: 2197.5278 - val_mean_absolute_error: 38.7352\n",
      "Epoch 1252/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 476.3647 - mean_absolute_error: 17.0923\n",
      "Epoch 1252: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 817.7280 - mean_absolute_error: 19.8774 - val_loss: 2249.6887 - val_mean_absolute_error: 39.2322\n",
      "Epoch 1253/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 495.3690 - mean_absolute_error: 15.4170\n",
      "Epoch 1253: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 822.0331 - mean_absolute_error: 19.6775 - val_loss: 2206.7712 - val_mean_absolute_error: 38.7007\n",
      "Epoch 1254/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2318.1428 - mean_absolute_error: 23.4938\n",
      "Epoch 1254: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 923.0989 - mean_absolute_error: 19.7927 - val_loss: 2236.8840 - val_mean_absolute_error: 39.0912\n",
      "Epoch 1255/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 920.9507 - mean_absolute_error: 18.2462\n",
      "Epoch 1255: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 873.8328 - mean_absolute_error: 19.7310 - val_loss: 2184.5657 - val_mean_absolute_error: 38.7292\n",
      "Epoch 1256/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 595.1406 - mean_absolute_error: 17.3367\n",
      "Epoch 1256: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 823.9069 - mean_absolute_error: 19.9615 - val_loss: 2189.1980 - val_mean_absolute_error: 38.7513\n",
      "Epoch 1257/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1740.5474 - mean_absolute_error: 27.3594\n",
      "Epoch 1257: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 919.8494 - mean_absolute_error: 20.1729 - val_loss: 2247.9719 - val_mean_absolute_error: 39.1962\n",
      "Epoch 1258/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 880.1495 - mean_absolute_error: 20.1994\n",
      "Epoch 1258: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 770.1749 - mean_absolute_error: 19.0289 - val_loss: 2176.9683 - val_mean_absolute_error: 38.6332\n",
      "Epoch 1259/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 766.5800 - mean_absolute_error: 19.9151\n",
      "Epoch 1259: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 933.1636 - mean_absolute_error: 20.6749 - val_loss: 2184.1104 - val_mean_absolute_error: 38.7177\n",
      "Epoch 1260/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 929.6279 - mean_absolute_error: 20.7535 \n",
      "Epoch 1260: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 920.8284 - mean_absolute_error: 20.6182 - val_loss: 2230.8386 - val_mean_absolute_error: 39.0466\n",
      "Epoch 1261/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 966.0609 - mean_absolute_error: 20.5019  \n",
      "Epoch 1261: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 960.8728 - mean_absolute_error: 20.4777 - val_loss: 2192.4121 - val_mean_absolute_error: 38.7464\n",
      "Epoch 1262/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 922.8331 - mean_absolute_error: 19.8249\n",
      "Epoch 1262: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 875.9123 - mean_absolute_error: 19.9706 - val_loss: 2216.8662 - val_mean_absolute_error: 38.8248\n",
      "Epoch 1263/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1196.6665 - mean_absolute_error: 23.0773\n",
      "Epoch 1263: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 935.3553 - mean_absolute_error: 20.7853 - val_loss: 2180.4597 - val_mean_absolute_error: 38.6687\n",
      "Epoch 1264/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 559.9291 - mean_absolute_error: 18.9489\n",
      "Epoch 1264: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 798.6632 - mean_absolute_error: 19.6287 - val_loss: 2269.5933 - val_mean_absolute_error: 39.2380\n",
      "Epoch 1265/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 908.0654 - mean_absolute_error: 19.7451 \n",
      "Epoch 1265: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 901.8087 - mean_absolute_error: 19.7668 - val_loss: 2226.5654 - val_mean_absolute_error: 38.9570\n",
      "Epoch 1266/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 780.0375 - mean_absolute_error: 21.1002\n",
      "Epoch 1266: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 888.2454 - mean_absolute_error: 20.7450 - val_loss: 2211.4944 - val_mean_absolute_error: 38.8381\n",
      "Epoch 1267/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 682.5385 - mean_absolute_error: 20.9196\n",
      "Epoch 1267: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 862.9140 - mean_absolute_error: 20.1661 - val_loss: 2202.9319 - val_mean_absolute_error: 38.8184\n",
      "Epoch 1268/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 447.7031 - mean_absolute_error: 15.5426\n",
      "Epoch 1268: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 862.0869 - mean_absolute_error: 19.9994 - val_loss: 2223.9958 - val_mean_absolute_error: 39.1302\n",
      "Epoch 1269/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 609.0341 - mean_absolute_error: 16.6860\n",
      "Epoch 1269: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 817.8198 - mean_absolute_error: 19.5206 - val_loss: 2222.4966 - val_mean_absolute_error: 39.0137\n",
      "Epoch 1270/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 810.2463 - mean_absolute_error: 19.4336 \n",
      "Epoch 1270: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 812.1160 - mean_absolute_error: 19.4454 - val_loss: 2197.4905 - val_mean_absolute_error: 38.7867\n",
      "Epoch 1271/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1072.7593 - mean_absolute_error: 22.1987\n",
      "Epoch 1271: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 968.7570 - mean_absolute_error: 20.5895 - val_loss: 2180.9309 - val_mean_absolute_error: 38.7101\n",
      "Epoch 1272/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1066.0421 - mean_absolute_error: 23.7116\n",
      "Epoch 1272: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 875.8055 - mean_absolute_error: 20.3853 - val_loss: 2182.3450 - val_mean_absolute_error: 38.6686\n",
      "Epoch 1273/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1045.5610 - mean_absolute_error: 25.1679\n",
      "Epoch 1273: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 859.3580 - mean_absolute_error: 20.2264 - val_loss: 2200.7356 - val_mean_absolute_error: 38.8210\n",
      "Epoch 1274/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 307.4789 - mean_absolute_error: 13.7116\n",
      "Epoch 1274: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.3237 - mean_absolute_error: 19.4743 - val_loss: 2191.2434 - val_mean_absolute_error: 38.7398\n",
      "Epoch 1275/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 966.8995 - mean_absolute_error: 20.4064 \n",
      "Epoch 1275: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 947.8057 - mean_absolute_error: 20.2941 - val_loss: 2233.5264 - val_mean_absolute_error: 38.9733\n",
      "Epoch 1276/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 414.5180 - mean_absolute_error: 16.6458\n",
      "Epoch 1276: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 866.4387 - mean_absolute_error: 20.5740 - val_loss: 2194.7637 - val_mean_absolute_error: 38.7051\n",
      "Epoch 1277/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1283.5200 - mean_absolute_error: 25.1720\n",
      "Epoch 1277: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 945.5756 - mean_absolute_error: 20.8254 - val_loss: 2193.5083 - val_mean_absolute_error: 38.7840\n",
      "Epoch 1278/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 507.0621 - mean_absolute_error: 16.8436\n",
      "Epoch 1278: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839.5427 - mean_absolute_error: 19.6625 - val_loss: 2197.0881 - val_mean_absolute_error: 38.7766\n",
      "Epoch 1279/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1688.3091 - mean_absolute_error: 26.3244\n",
      "Epoch 1279: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.7119 - mean_absolute_error: 21.8360 - val_loss: 2224.5891 - val_mean_absolute_error: 39.0772\n",
      "Epoch 1280/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 951.4026 - mean_absolute_error: 20.5600  \n",
      "Epoch 1280: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 942.1912 - mean_absolute_error: 20.4785 - val_loss: 2182.9922 - val_mean_absolute_error: 38.7215\n",
      "Epoch 1281/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 570.0173 - mean_absolute_error: 19.7182\n",
      "Epoch 1281: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 951.3475 - mean_absolute_error: 20.8241 - val_loss: 2246.5964 - val_mean_absolute_error: 39.1383\n",
      "Epoch 1282/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 432.4559 - mean_absolute_error: 16.7251\n",
      "Epoch 1282: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 858.4008 - mean_absolute_error: 19.8826 - val_loss: 2202.3518 - val_mean_absolute_error: 38.8231\n",
      "Epoch 1283/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 917.7161 - mean_absolute_error: 20.2834\n",
      "Epoch 1283: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 841.4765 - mean_absolute_error: 19.4494 - val_loss: 2217.2253 - val_mean_absolute_error: 38.8505\n",
      "Epoch 1284/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 826.7081 - mean_absolute_error: 21.6599\n",
      "Epoch 1284: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.1599 - mean_absolute_error: 20.6721 - val_loss: 2200.7996 - val_mean_absolute_error: 38.8260\n",
      "Epoch 1285/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 813.4000 - mean_absolute_error: 19.4222 \n",
      "Epoch 1285: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 817.4474 - mean_absolute_error: 19.4635 - val_loss: 2201.9724 - val_mean_absolute_error: 38.7166\n",
      "Epoch 1286/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 421.9180 - mean_absolute_error: 14.8732\n",
      "Epoch 1286: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 783.4957 - mean_absolute_error: 18.8256 - val_loss: 2204.0652 - val_mean_absolute_error: 38.8069\n",
      "Epoch 1287/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 977.6973 - mean_absolute_error: 22.3289\n",
      "Epoch 1287: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 912.4136 - mean_absolute_error: 20.1147 - val_loss: 2189.3987 - val_mean_absolute_error: 38.7806\n",
      "Epoch 1288/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 599.6587 - mean_absolute_error: 18.3491\n",
      "Epoch 1288: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 800.3662 - mean_absolute_error: 19.5821 - val_loss: 2198.1858 - val_mean_absolute_error: 38.7347\n",
      "Epoch 1289/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1283.2974 - mean_absolute_error: 21.9081\n",
      "Epoch 1289: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 991.8353 - mean_absolute_error: 20.3648 - val_loss: 2190.0081 - val_mean_absolute_error: 38.7776\n",
      "Epoch 1290/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1551.2520 - mean_absolute_error: 27.0850\n",
      "Epoch 1290: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 933.9539 - mean_absolute_error: 20.5159 - val_loss: 2217.5312 - val_mean_absolute_error: 38.7137\n",
      "Epoch 1291/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 849.7509 - mean_absolute_error: 19.9304  \n",
      "Epoch 1291: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 850.3417 - mean_absolute_error: 19.9319 - val_loss: 2197.9026 - val_mean_absolute_error: 38.8138\n",
      "Epoch 1292/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 762.2703 - mean_absolute_error: 18.7694 \n",
      "Epoch 1292: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 772.0512 - mean_absolute_error: 18.8678 - val_loss: 2228.9126 - val_mean_absolute_error: 39.2610\n",
      "Epoch 1293/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 837.4545 - mean_absolute_error: 19.4500\n",
      "Epoch 1293: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.1760 - mean_absolute_error: 20.6530 - val_loss: 2206.2090 - val_mean_absolute_error: 38.8554\n",
      "Epoch 1294/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1459.5260 - mean_absolute_error: 24.0757\n",
      "Epoch 1294: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1014.1055 - mean_absolute_error: 21.1315 - val_loss: 2185.5754 - val_mean_absolute_error: 38.7523\n",
      "Epoch 1295/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 889.0615 - mean_absolute_error: 20.4490\n",
      "Epoch 1295: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 818.4054 - mean_absolute_error: 19.4364 - val_loss: 2207.9729 - val_mean_absolute_error: 38.7175\n",
      "Epoch 1296/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 852.4655 - mean_absolute_error: 19.8400 \n",
      "Epoch 1296: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 858.5121 - mean_absolute_error: 19.8654 - val_loss: 2212.4219 - val_mean_absolute_error: 38.8613\n",
      "Epoch 1297/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 284.9121 - mean_absolute_error: 13.9345\n",
      "Epoch 1297: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 798.8071 - mean_absolute_error: 19.4875 - val_loss: 2202.1128 - val_mean_absolute_error: 38.8486\n",
      "Epoch 1298/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 541.7568 - mean_absolute_error: 14.7375\n",
      "Epoch 1298: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 798.9211 - mean_absolute_error: 18.9456 - val_loss: 2184.9873 - val_mean_absolute_error: 38.7704\n",
      "Epoch 1299/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2073.7139 - mean_absolute_error: 26.1484\n",
      "Epoch 1299: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062.1073 - mean_absolute_error: 21.3118 - val_loss: 2211.9958 - val_mean_absolute_error: 38.8927\n",
      "Epoch 1300/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1255.9473 - mean_absolute_error: 25.3506\n",
      "Epoch 1300: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.2896 - mean_absolute_error: 20.0578 - val_loss: 2213.5232 - val_mean_absolute_error: 38.8949\n",
      "Epoch 1301/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 891.0389 - mean_absolute_error: 19.7840 \n",
      "Epoch 1301: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 890.3226 - mean_absolute_error: 19.7863 - val_loss: 2201.9536 - val_mean_absolute_error: 38.8342\n",
      "Epoch 1302/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1283.9390 - mean_absolute_error: 24.9267\n",
      "Epoch 1302: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 854.7618 - mean_absolute_error: 19.8114 - val_loss: 2204.4084 - val_mean_absolute_error: 38.8546\n",
      "Epoch 1303/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 567.2009 - mean_absolute_error: 18.0747\n",
      "Epoch 1303: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 879.8906 - mean_absolute_error: 19.7660 - val_loss: 2235.5667 - val_mean_absolute_error: 39.0898\n",
      "Epoch 1304/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1736.9384 - mean_absolute_error: 25.0011\n",
      "Epoch 1304: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 909.6719 - mean_absolute_error: 20.0814 - val_loss: 2203.5249 - val_mean_absolute_error: 38.8051\n",
      "Epoch 1305/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 799.8188 - mean_absolute_error: 21.1914\n",
      "Epoch 1305: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 812.7370 - mean_absolute_error: 19.9786 - val_loss: 2211.0918 - val_mean_absolute_error: 38.8383\n",
      "Epoch 1306/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 827.7081 - mean_absolute_error: 19.9060 \n",
      "Epoch 1306: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 833.8724 - mean_absolute_error: 19.9283 - val_loss: 2253.5876 - val_mean_absolute_error: 39.3138\n",
      "Epoch 1307/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1391.8823 - mean_absolute_error: 25.3334\n",
      "Epoch 1307: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 908.5128 - mean_absolute_error: 20.3681 - val_loss: 2213.8159 - val_mean_absolute_error: 38.9084\n",
      "Epoch 1308/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 311.2574 - mean_absolute_error: 14.1443\n",
      "Epoch 1308: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 730.8123 - mean_absolute_error: 18.9308 - val_loss: 2236.2236 - val_mean_absolute_error: 39.1591\n",
      "Epoch 1309/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1266.6615 - mean_absolute_error: 23.7049\n",
      "Epoch 1309: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 941.1091 - mean_absolute_error: 20.6092 - val_loss: 2225.4417 - val_mean_absolute_error: 38.9681\n",
      "Epoch 1310/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 553.9701 - mean_absolute_error: 18.1050\n",
      "Epoch 1310: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 902.8585 - mean_absolute_error: 20.3466 - val_loss: 2237.7659 - val_mean_absolute_error: 39.1285\n",
      "Epoch 1311/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.3752 - mean_absolute_error: 20.7278  \n",
      "Epoch 1311: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 977.9470 - mean_absolute_error: 20.5984 - val_loss: 2191.0107 - val_mean_absolute_error: 38.7962\n",
      "Epoch 1312/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 779.7635 - mean_absolute_error: 21.4597\n",
      "Epoch 1312: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 850.8749 - mean_absolute_error: 20.2272 - val_loss: 2204.4097 - val_mean_absolute_error: 38.9044\n",
      "Epoch 1313/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1689.6011 - mean_absolute_error: 28.1227\n",
      "Epoch 1313: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 974.0865 - mean_absolute_error: 21.3629 - val_loss: 2197.9661 - val_mean_absolute_error: 38.7523\n",
      "Epoch 1314/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1056.7610 - mean_absolute_error: 20.4076\n",
      "Epoch 1314: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 882.8474 - mean_absolute_error: 20.0187 - val_loss: 2182.1702 - val_mean_absolute_error: 38.7149\n",
      "Epoch 1315/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1448.3789 - mean_absolute_error: 27.1159\n",
      "Epoch 1315: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 867.9026 - mean_absolute_error: 19.9119 - val_loss: 2241.4797 - val_mean_absolute_error: 39.1185\n",
      "Epoch 1316/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 924.2335 - mean_absolute_error: 19.9620 \n",
      "Epoch 1316: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 911.8203 - mean_absolute_error: 19.9161 - val_loss: 2185.2490 - val_mean_absolute_error: 38.7570\n",
      "Epoch 1317/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 628.0310 - mean_absolute_error: 18.2918\n",
      "Epoch 1317: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816.7980 - mean_absolute_error: 19.4039 - val_loss: 2315.1909 - val_mean_absolute_error: 39.8368\n",
      "Epoch 1318/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 722.6108 - mean_absolute_error: 18.5660 \n",
      "Epoch 1318: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 731.4890 - mean_absolute_error: 18.6434 - val_loss: 2184.2139 - val_mean_absolute_error: 38.7496\n",
      "Epoch 1319/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 911.1506 - mean_absolute_error: 22.4285\n",
      "Epoch 1319: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 812.9683 - mean_absolute_error: 19.7361 - val_loss: 2254.3730 - val_mean_absolute_error: 39.3471\n",
      "Epoch 1320/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 837.0719 - mean_absolute_error: 21.0157\n",
      "Epoch 1320: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 845.3898 - mean_absolute_error: 19.9142 - val_loss: 2195.9919 - val_mean_absolute_error: 38.8095\n",
      "Epoch 1321/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 690.4618 - mean_absolute_error: 19.4271\n",
      "Epoch 1321: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 834.9686 - mean_absolute_error: 20.1312 - val_loss: 2200.1697 - val_mean_absolute_error: 38.8770\n",
      "Epoch 1322/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 861.8661 - mean_absolute_error: 20.7631 \n",
      "Epoch 1322: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 867.0870 - mean_absolute_error: 20.6940 - val_loss: 2181.6089 - val_mean_absolute_error: 38.7057\n",
      "Epoch 1323/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 900.7514 - mean_absolute_error: 20.4967 \n",
      "Epoch 1323: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.2780 - mean_absolute_error: 20.4457 - val_loss: 2205.8794 - val_mean_absolute_error: 38.8694\n",
      "Epoch 1324/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 795.5946 - mean_absolute_error: 21.4385\n",
      "Epoch 1324: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 877.7732 - mean_absolute_error: 19.9319 - val_loss: 2202.7322 - val_mean_absolute_error: 38.8863\n",
      "Epoch 1325/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 528.0953 - mean_absolute_error: 17.6326\n",
      "Epoch 1325: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 913.8322 - mean_absolute_error: 20.6093 - val_loss: 2222.3354 - val_mean_absolute_error: 38.9754\n",
      "Epoch 1326/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1184.6019 - mean_absolute_error: 25.4664\n",
      "Epoch 1326: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 819.6439 - mean_absolute_error: 19.6941 - val_loss: 2208.2314 - val_mean_absolute_error: 38.8849\n",
      "Epoch 1327/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 892.4675 - mean_absolute_error: 20.0680  \n",
      "Epoch 1327: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 890.5909 - mean_absolute_error: 20.0476 - val_loss: 2186.2578 - val_mean_absolute_error: 38.7841\n",
      "Epoch 1328/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 547.2447 - mean_absolute_error: 17.8866\n",
      "Epoch 1328: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 836.2863 - mean_absolute_error: 19.8473 - val_loss: 2220.4292 - val_mean_absolute_error: 38.9543\n",
      "Epoch 1329/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 624.3816 - mean_absolute_error: 18.6360\n",
      "Epoch 1329: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 902.4026 - mean_absolute_error: 20.5166 - val_loss: 2204.8079 - val_mean_absolute_error: 38.8622\n",
      "Epoch 1330/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 849.0782 - mean_absolute_error: 21.9854\n",
      "Epoch 1330: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 867.8261 - mean_absolute_error: 19.7830 - val_loss: 2204.5156 - val_mean_absolute_error: 38.8835\n",
      "Epoch 1331/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 643.1584 - mean_absolute_error: 17.3036\n",
      "Epoch 1331: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 945.8729 - mean_absolute_error: 20.4595 - val_loss: 2216.9480 - val_mean_absolute_error: 38.9317\n",
      "Epoch 1332/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 825.7606 - mean_absolute_error: 21.9143\n",
      "Epoch 1332: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 842.5303 - mean_absolute_error: 20.3650 - val_loss: 2211.2183 - val_mean_absolute_error: 38.8414\n",
      "Epoch 1333/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 910.1661 - mean_absolute_error: 20.5166 \n",
      "Epoch 1333: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 907.2040 - mean_absolute_error: 20.4892 - val_loss: 2225.3184 - val_mean_absolute_error: 39.0395\n",
      "Epoch 1334/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1061.3480 - mean_absolute_error: 24.3030\n",
      "Epoch 1334: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 912.6865 - mean_absolute_error: 20.5063 - val_loss: 2189.7664 - val_mean_absolute_error: 38.8125\n",
      "Epoch 1335/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 732.0237 - mean_absolute_error: 17.5558\n",
      "Epoch 1335: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 750.0255 - mean_absolute_error: 18.9683 - val_loss: 2294.6934 - val_mean_absolute_error: 39.6564\n",
      "Epoch 1336/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 558.4294 - mean_absolute_error: 17.7857\n",
      "Epoch 1336: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 969.1390 - mean_absolute_error: 21.0418 - val_loss: 2286.3748 - val_mean_absolute_error: 39.5265\n",
      "Epoch 1337/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1039.8296 - mean_absolute_error: 21.7611\n",
      "Epoch 1337: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 931.4984 - mean_absolute_error: 20.6941 - val_loss: 2188.5293 - val_mean_absolute_error: 38.7885\n",
      "Epoch 1338/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 492.9613 - mean_absolute_error: 16.7125\n",
      "Epoch 1338: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 934.7968 - mean_absolute_error: 20.6075 - val_loss: 2205.2219 - val_mean_absolute_error: 38.9173\n",
      "Epoch 1339/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 805.7706 - mean_absolute_error: 18.9731 \n",
      "Epoch 1339: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 809.5351 - mean_absolute_error: 19.0211 - val_loss: 2203.2007 - val_mean_absolute_error: 38.8558\n",
      "Epoch 1340/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 489.9456 - mean_absolute_error: 14.9622\n",
      "Epoch 1340: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.5059 - mean_absolute_error: 19.5051 - val_loss: 2226.7515 - val_mean_absolute_error: 39.0416\n",
      "Epoch 1341/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 614.8140 - mean_absolute_error: 17.6485\n",
      "Epoch 1341: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 790.0145 - mean_absolute_error: 19.6037 - val_loss: 2208.1975 - val_mean_absolute_error: 38.8905\n",
      "Epoch 1342/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 529.2460 - mean_absolute_error: 17.3695\n",
      "Epoch 1342: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 807.1448 - mean_absolute_error: 19.8355 - val_loss: 2215.5654 - val_mean_absolute_error: 38.9669\n",
      "Epoch 1343/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 925.7046 - mean_absolute_error: 20.4411 \n",
      "Epoch 1343: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 913.4267 - mean_absolute_error: 20.3139 - val_loss: 2198.2178 - val_mean_absolute_error: 38.8664\n",
      "Epoch 1344/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 828.5644 - mean_absolute_error: 20.8174\n",
      "Epoch 1344: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 885.1133 - mean_absolute_error: 20.2461 - val_loss: 2184.3872 - val_mean_absolute_error: 38.7721\n",
      "Epoch 1345/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 733.8586 - mean_absolute_error: 15.7239\n",
      "Epoch 1345: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 885.8652 - mean_absolute_error: 20.2182 - val_loss: 2198.2539 - val_mean_absolute_error: 38.7952\n",
      "Epoch 1346/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1008.9095 - mean_absolute_error: 24.7278\n",
      "Epoch 1346: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 923.2234 - mean_absolute_error: 20.6198 - val_loss: 2200.8369 - val_mean_absolute_error: 38.8599\n",
      "Epoch 1347/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2900.7109 - mean_absolute_error: 27.7204\n",
      "Epoch 1347: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.3687 - mean_absolute_error: 20.8199 - val_loss: 2191.2468 - val_mean_absolute_error: 38.7914\n",
      "Epoch 1348/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.0220 - mean_absolute_error: 19.3385 \n",
      "Epoch 1348: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 829.9402 - mean_absolute_error: 19.3943 - val_loss: 2205.8289 - val_mean_absolute_error: 38.9169\n",
      "Epoch 1349/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 983.6663 - mean_absolute_error: 19.6268\n",
      "Epoch 1349: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 875.9970 - mean_absolute_error: 20.3120 - val_loss: 2195.2407 - val_mean_absolute_error: 38.8472\n",
      "Epoch 1350/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 506.5410 - mean_absolute_error: 17.2276\n",
      "Epoch 1350: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 950.2564 - mean_absolute_error: 20.3806 - val_loss: 2253.7639 - val_mean_absolute_error: 39.3749\n",
      "Epoch 1351/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1316.3319 - mean_absolute_error: 26.7551\n",
      "Epoch 1351: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 873.5392 - mean_absolute_error: 20.1754 - val_loss: 2213.5857 - val_mean_absolute_error: 38.9345\n",
      "Epoch 1352/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 574.7380 - mean_absolute_error: 17.0717\n",
      "Epoch 1352: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 851.9811 - mean_absolute_error: 19.3626 - val_loss: 2199.0862 - val_mean_absolute_error: 38.8800\n",
      "Epoch 1353/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 858.4751 - mean_absolute_error: 20.6466  \n",
      "Epoch 1353: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 866.5737 - mean_absolute_error: 20.5186 - val_loss: 2201.5369 - val_mean_absolute_error: 38.8688\n",
      "Epoch 1354/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1006.1099 - mean_absolute_error: 20.8851\n",
      "Epoch 1354: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 993.5947 - mean_absolute_error: 20.7936 - val_loss: 2216.0662 - val_mean_absolute_error: 38.9410\n",
      "Epoch 1355/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1176.5653 - mean_absolute_error: 21.0129\n",
      "Epoch 1355: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 821.3054 - mean_absolute_error: 19.3379 - val_loss: 2186.5964 - val_mean_absolute_error: 38.8107\n",
      "Epoch 1356/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1190.1478 - mean_absolute_error: 22.2811\n",
      "Epoch 1356: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 766.5529 - mean_absolute_error: 18.9929 - val_loss: 2220.2607 - val_mean_absolute_error: 38.9419\n",
      "Epoch 1357/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 554.5577 - mean_absolute_error: 18.8120\n",
      "Epoch 1357: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 843.2463 - mean_absolute_error: 19.8644 - val_loss: 2274.4346 - val_mean_absolute_error: 39.4633\n",
      "Epoch 1358/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 865.0829 - mean_absolute_error: 19.7955 \n",
      "Epoch 1358: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 865.8566 - mean_absolute_error: 19.8217 - val_loss: 2211.1362 - val_mean_absolute_error: 38.9377\n",
      "Epoch 1359/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 767.5672 - mean_absolute_error: 18.5944 \n",
      "Epoch 1359: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 770.6745 - mean_absolute_error: 18.6319 - val_loss: 2210.4885 - val_mean_absolute_error: 38.9452\n",
      "Epoch 1360/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1135.4458 - mean_absolute_error: 24.9821\n",
      "Epoch 1360: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 827.8004 - mean_absolute_error: 20.0158 - val_loss: 2202.8992 - val_mean_absolute_error: 38.8803\n",
      "Epoch 1361/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 786.0045 - mean_absolute_error: 21.2943\n",
      "Epoch 1361: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 930.4130 - mean_absolute_error: 20.4475 - val_loss: 2201.8020 - val_mean_absolute_error: 38.9121\n",
      "Epoch 1362/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 533.5367 - mean_absolute_error: 17.6077\n",
      "Epoch 1362: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 954.8160 - mean_absolute_error: 19.8823 - val_loss: 2210.9263 - val_mean_absolute_error: 39.1659\n",
      "Epoch 1363/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.5616 - mean_absolute_error: 20.6196  \n",
      "Epoch 1363: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 856.3896 - mean_absolute_error: 20.4600 - val_loss: 2178.6582 - val_mean_absolute_error: 38.7401\n",
      "Epoch 1364/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 722.2017 - mean_absolute_error: 21.0780\n",
      "Epoch 1364: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 898.6274 - mean_absolute_error: 20.6754 - val_loss: 2210.9954 - val_mean_absolute_error: 38.9392\n",
      "Epoch 1365/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 683.7073 - mean_absolute_error: 20.5028\n",
      "Epoch 1365: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.0076 - mean_absolute_error: 19.6247 - val_loss: 2212.8459 - val_mean_absolute_error: 38.9594\n",
      "Epoch 1366/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1034.9233 - mean_absolute_error: 21.4900\n",
      "Epoch 1366: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.7460 - mean_absolute_error: 19.7554 - val_loss: 2195.5464 - val_mean_absolute_error: 38.8348\n",
      "Epoch 1367/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 894.2747 - mean_absolute_error: 20.2260  \n",
      "Epoch 1367: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 892.1440 - mean_absolute_error: 20.1984 - val_loss: 2211.1221 - val_mean_absolute_error: 38.9182\n",
      "Epoch 1368/1500\n",
      "\u001b[1m17/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 758.2614 - mean_absolute_error: 18.5439 \n",
      "Epoch 1368: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 833.8763 - mean_absolute_error: 19.3203 - val_loss: 2227.2322 - val_mean_absolute_error: 39.0477\n",
      "Epoch 1369/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1228.9321 - mean_absolute_error: 22.0010\n",
      "Epoch 1369: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 775.3346 - mean_absolute_error: 18.6929 - val_loss: 2194.0964 - val_mean_absolute_error: 38.8685\n",
      "Epoch 1370/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 969.1357 - mean_absolute_error: 21.3416\n",
      "Epoch 1370: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 863.0421 - mean_absolute_error: 19.5915 - val_loss: 2192.3789 - val_mean_absolute_error: 38.8734\n",
      "Epoch 1371/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 615.6144 - mean_absolute_error: 18.7879\n",
      "Epoch 1371: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 946.3882 - mean_absolute_error: 20.7841 - val_loss: 2250.1926 - val_mean_absolute_error: 39.0509\n",
      "Epoch 1372/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 283.8568 - mean_absolute_error: 13.9208\n",
      "Epoch 1372: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 738.7880 - mean_absolute_error: 18.3797 - val_loss: 2251.2742 - val_mean_absolute_error: 39.1777\n",
      "Epoch 1373/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 837.0551 - mean_absolute_error: 19.6613 \n",
      "Epoch 1373: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 838.7933 - mean_absolute_error: 19.6736 - val_loss: 2202.4573 - val_mean_absolute_error: 38.8730\n",
      "Epoch 1374/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 829.0281 - mean_absolute_error: 21.4761\n",
      "Epoch 1374: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 805.7255 - mean_absolute_error: 19.4394 - val_loss: 2204.4065 - val_mean_absolute_error: 38.8978\n",
      "Epoch 1375/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1161.1877 - mean_absolute_error: 25.1575\n",
      "Epoch 1375: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1014.0934 - mean_absolute_error: 21.1123 - val_loss: 2214.7952 - val_mean_absolute_error: 39.0485\n",
      "Epoch 1376/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 751.7984 - mean_absolute_error: 19.6402\n",
      "Epoch 1376: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 805.1149 - mean_absolute_error: 19.5246 - val_loss: 2232.4924 - val_mean_absolute_error: 39.0300\n",
      "Epoch 1377/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 866.8370 - mean_absolute_error: 23.2284\n",
      "Epoch 1377: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 894.8365 - mean_absolute_error: 20.5708 - val_loss: 2235.2690 - val_mean_absolute_error: 38.9523\n",
      "Epoch 1378/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 878.6985 - mean_absolute_error: 19.7527  \n",
      "Epoch 1378: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 877.5242 - mean_absolute_error: 19.7852 - val_loss: 2178.1589 - val_mean_absolute_error: 38.7986\n",
      "Epoch 1379/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 448.4283 - mean_absolute_error: 17.2225\n",
      "Epoch 1379: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 821.1508 - mean_absolute_error: 19.7427 - val_loss: 2233.4197 - val_mean_absolute_error: 39.0623\n",
      "Epoch 1380/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 736.9171 - mean_absolute_error: 20.2009\n",
      "Epoch 1380: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 762.6818 - mean_absolute_error: 19.1341 - val_loss: 2230.6265 - val_mean_absolute_error: 39.0757\n",
      "Epoch 1381/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 669.0537 - mean_absolute_error: 18.3829\n",
      "Epoch 1381: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 805.2443 - mean_absolute_error: 19.7340 - val_loss: 2220.2366 - val_mean_absolute_error: 38.9855\n",
      "Epoch 1382/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2461.7390 - mean_absolute_error: 28.8813\n",
      "Epoch 1382: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 991.7632 - mean_absolute_error: 20.7042 - val_loss: 2192.0715 - val_mean_absolute_error: 38.8788\n",
      "Epoch 1383/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 931.5645 - mean_absolute_error: 20.6225 \n",
      "Epoch 1383: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 927.7049 - mean_absolute_error: 20.5747 - val_loss: 2190.2661 - val_mean_absolute_error: 38.8501\n",
      "Epoch 1384/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 764.4941 - mean_absolute_error: 22.5730\n",
      "Epoch 1384: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 819.9134 - mean_absolute_error: 19.9037 - val_loss: 2259.0698 - val_mean_absolute_error: 39.3662\n",
      "Epoch 1385/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 547.8914 - mean_absolute_error: 16.1922\n",
      "Epoch 1385: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 770.9570 - mean_absolute_error: 19.1846 - val_loss: 2190.7200 - val_mean_absolute_error: 38.8060\n",
      "Epoch 1386/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 776.8828 - mean_absolute_error: 21.0434\n",
      "Epoch 1386: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 839.1279 - mean_absolute_error: 19.9896 - val_loss: 2169.9700 - val_mean_absolute_error: 38.7037\n",
      "Epoch 1387/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 662.9879 - mean_absolute_error: 18.5924\n",
      "Epoch 1387: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 785.7889 - mean_absolute_error: 19.2666 - val_loss: 2237.1365 - val_mean_absolute_error: 39.0429\n",
      "Epoch 1388/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 860.3552 - mean_absolute_error: 19.7661 \n",
      "Epoch 1388: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 861.6396 - mean_absolute_error: 19.7722 - val_loss: 2238.0815 - val_mean_absolute_error: 39.0884\n",
      "Epoch 1389/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1089.1627 - mean_absolute_error: 23.1266\n",
      "Epoch 1389: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.5861 - mean_absolute_error: 19.3340 - val_loss: 2256.6101 - val_mean_absolute_error: 39.3899\n",
      "Epoch 1390/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 707.0964 - mean_absolute_error: 19.9032\n",
      "Epoch 1390: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 885.4652 - mean_absolute_error: 19.9186 - val_loss: 2230.9189 - val_mean_absolute_error: 39.0454\n",
      "Epoch 1391/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 766.9232 - mean_absolute_error: 18.5804\n",
      "Epoch 1391: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 779.9575 - mean_absolute_error: 18.7498 - val_loss: 2213.2229 - val_mean_absolute_error: 38.9704\n",
      "Epoch 1392/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 937.1971 - mean_absolute_error: 20.3185 \n",
      "Epoch 1392: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 923.7098 - mean_absolute_error: 20.2342 - val_loss: 2245.8369 - val_mean_absolute_error: 39.1387\n",
      "Epoch 1393/1500\n",
      "\u001b[1m21/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 737.1315 - mean_absolute_error: 18.8232 \n",
      "Epoch 1393: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 782.3320 - mean_absolute_error: 19.2046 - val_loss: 2194.9927 - val_mean_absolute_error: 38.9077\n",
      "Epoch 1394/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 841.9573 - mean_absolute_error: 16.6653\n",
      "Epoch 1394: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 833.5495 - mean_absolute_error: 19.0772 - val_loss: 2212.6221 - val_mean_absolute_error: 38.9934\n",
      "Epoch 1395/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1414.3750 - mean_absolute_error: 26.0678\n",
      "Epoch 1395: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.0444 - mean_absolute_error: 20.3357 - val_loss: 2212.0974 - val_mean_absolute_error: 39.0201\n",
      "Epoch 1396/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 570.4172 - mean_absolute_error: 18.3645\n",
      "Epoch 1396: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 819.2556 - mean_absolute_error: 19.7336 - val_loss: 2179.5271 - val_mean_absolute_error: 38.8176\n",
      "Epoch 1397/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 878.8981 - mean_absolute_error: 20.2330  \n",
      "Epoch 1397: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 877.4336 - mean_absolute_error: 20.1781 - val_loss: 2213.7366 - val_mean_absolute_error: 38.9510\n",
      "Epoch 1398/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 727.3942 - mean_absolute_error: 18.2495 \n",
      "Epoch 1398: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 751.7161 - mean_absolute_error: 18.5300 - val_loss: 2220.8718 - val_mean_absolute_error: 39.0017\n",
      "Epoch 1399/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 820.9469 - mean_absolute_error: 19.6105 \n",
      "Epoch 1399: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 823.6190 - mean_absolute_error: 19.6257 - val_loss: 2196.4114 - val_mean_absolute_error: 38.9501\n",
      "Epoch 1400/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 656.3265 - mean_absolute_error: 16.5196\n",
      "Epoch 1400: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 808.9033 - mean_absolute_error: 19.1879 - val_loss: 2224.3403 - val_mean_absolute_error: 39.0338\n",
      "Epoch 1401/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1322.8684 - mean_absolute_error: 27.7295\n",
      "Epoch 1401: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 789.7919 - mean_absolute_error: 19.2474 - val_loss: 2254.1294 - val_mean_absolute_error: 39.3698\n",
      "Epoch 1402/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 780.6689 - mean_absolute_error: 19.4541 \n",
      "Epoch 1402: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 804.0502 - mean_absolute_error: 19.5825 - val_loss: 2205.2583 - val_mean_absolute_error: 38.9994\n",
      "Epoch 1403/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 803.9471 - mean_absolute_error: 19.3656 \n",
      "Epoch 1403: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 814.9487 - mean_absolute_error: 19.4401 - val_loss: 2194.3472 - val_mean_absolute_error: 38.9031\n",
      "Epoch 1404/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 872.2051 - mean_absolute_error: 19.9418 \n",
      "Epoch 1404: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 872.0141 - mean_absolute_error: 19.9396 - val_loss: 2252.1399 - val_mean_absolute_error: 39.3983\n",
      "Epoch 1405/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1622.6497 - mean_absolute_error: 23.0296\n",
      "Epoch 1405: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 941.5264 - mean_absolute_error: 20.2461 - val_loss: 2206.6299 - val_mean_absolute_error: 38.9371\n",
      "Epoch 1406/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 902.9936 - mean_absolute_error: 20.8434\n",
      "Epoch 1406: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 711.3929 - mean_absolute_error: 18.7224 - val_loss: 2228.9187 - val_mean_absolute_error: 39.0392\n",
      "Epoch 1407/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 855.8149 - mean_absolute_error: 20.0395  \n",
      "Epoch 1407: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 863.3164 - mean_absolute_error: 20.0427 - val_loss: 2232.8047 - val_mean_absolute_error: 39.0521\n",
      "Epoch 1408/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 892.1331 - mean_absolute_error: 19.8638 \n",
      "Epoch 1408: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 891.4111 - mean_absolute_error: 19.8667 - val_loss: 2220.2249 - val_mean_absolute_error: 38.9810\n",
      "Epoch 1409/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 887.4589 - mean_absolute_error: 22.0948\n",
      "Epoch 1409: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 843.4377 - mean_absolute_error: 20.0451 - val_loss: 2190.2036 - val_mean_absolute_error: 38.8909\n",
      "Epoch 1410/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1027.9340 - mean_absolute_error: 21.8523\n",
      "Epoch 1410: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 905.4683 - mean_absolute_error: 20.0604 - val_loss: 2237.3149 - val_mean_absolute_error: 39.1037\n",
      "Epoch 1411/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 576.2996 - mean_absolute_error: 17.2075\n",
      "Epoch 1411: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 796.1570 - mean_absolute_error: 19.3232 - val_loss: 2246.6096 - val_mean_absolute_error: 39.2069\n",
      "Epoch 1412/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 886.7844 - mean_absolute_error: 20.1194 \n",
      "Epoch 1412: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 885.7405 - mean_absolute_error: 20.0924 - val_loss: 2253.4089 - val_mean_absolute_error: 39.3358\n",
      "Epoch 1413/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 892.8020 - mean_absolute_error: 19.7691 \n",
      "Epoch 1413: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 888.7307 - mean_absolute_error: 19.7824 - val_loss: 2214.8638 - val_mean_absolute_error: 39.0527\n",
      "Epoch 1414/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 714.1558 - mean_absolute_error: 18.6899 \n",
      "Epoch 1414: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 718.7535 - mean_absolute_error: 18.7284 - val_loss: 2207.8213 - val_mean_absolute_error: 38.9940\n",
      "Epoch 1415/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 945.5435 - mean_absolute_error: 22.9871\n",
      "Epoch 1415: val_loss did not improve from 2092.47754\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 945.3451 - mean_absolute_error: 20.2228 - val_loss: 2246.3262 - val_mean_absolute_error: 39.1482\n",
      "Epoch 1416/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 593.9225 - mean_absolute_error: 15.1032\n",
      "Epoch 1416: val_loss did not improve from 2092.47754\n"
     ]
    }
   ],
   "source": [
    "model4.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=1500, callbacks=[cp4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.51</td>\n",
       "      <td>74.96</td>\n",
       "      <td>159.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.50</td>\n",
       "      <td>81.38</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.45</td>\n",
       "      <td>64.66</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>0.48</td>\n",
       "      <td>56.41</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>0.38</td>\n",
       "      <td>48.90</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>0.51</td>\n",
       "      <td>67.82</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.40</td>\n",
       "      <td>102.06</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.29</td>\n",
       "      <td>86.84</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.53</td>\n",
       "      <td>65.92</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>0.75</td>\n",
       "      <td>79.49</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>103.14</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>109.45</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.36</td>\n",
       "      <td>102.28</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.40</td>\n",
       "      <td>106.05</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.43</td>\n",
       "      <td>113.21</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.71</td>\n",
       "      <td>99.30</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.63</td>\n",
       "      <td>101.43</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.42</td>\n",
       "      <td>91.86</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.66</td>\n",
       "      <td>79.06</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>0.31</td>\n",
       "      <td>76.87</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>0.56</td>\n",
       "      <td>81.75</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.52</td>\n",
       "      <td>95.49</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>0.59</td>\n",
       "      <td>90.75</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.49</td>\n",
       "      <td>98.08</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>0.34</td>\n",
       "      <td>115.67</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>0.19</td>\n",
       "      <td>119.65</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>0.51</td>\n",
       "      <td>124.78</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>0.65</td>\n",
       "      <td>88.99</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.44</td>\n",
       "      <td>111.66</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.33</td>\n",
       "      <td>93.28</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.52</td>\n",
       "      <td>78.51</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                      \n",
       "2024-01-01      0.51       74.96         159.49\n",
       "2024-01-02      0.50       81.38         201.22\n",
       "2024-01-03      0.45       64.66         235.04\n",
       "2024-01-04      0.48       56.41         223.36\n",
       "2024-01-05      0.38       48.90         153.35\n",
       "2024-01-06      0.51       67.82         176.58\n",
       "2024-01-07      0.40      102.06         179.29\n",
       "2024-01-08      0.29       86.84         260.26\n",
       "2024-01-09      0.53       65.92         144.39\n",
       "2024-01-10      0.75       79.49         176.85\n",
       "2024-01-11      0.50      103.14         200.03\n",
       "2024-01-12      0.50      109.45         161.85\n",
       "2024-01-13      0.36      102.28         324.88\n",
       "2024-01-14      0.40      106.05         285.11\n",
       "2024-01-15      0.43      113.21         191.13\n",
       "2024-01-16      0.71       99.30         194.15\n",
       "2024-01-17      0.63      101.43         188.70\n",
       "2024-01-18      0.42       91.86         201.74\n",
       "2024-01-19      0.66       79.06         174.39\n",
       "2024-01-20      0.31       76.87         206.83\n",
       "2024-01-21      0.56       81.75         181.35\n",
       "2024-01-22      0.52       95.49         234.13\n",
       "2024-01-23      0.59       90.75         244.36\n",
       "2024-01-24      0.49       98.08         252.99\n",
       "2024-01-25      0.34      115.67         212.36\n",
       "2024-01-26      0.19      119.65         401.43\n",
       "2024-01-27      0.51      124.78         220.10\n",
       "2024-01-28      0.65       88.99         284.35\n",
       "2024-01-29      0.44      111.66         216.37\n",
       "2024-01-30      0.33       93.28         219.25\n",
       "2024-01-31      0.52       78.51         204.15"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.363021</td>\n",
       "      <td>106.197917</td>\n",
       "      <td>228.512153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.514931</td>\n",
       "      <td>99.705556</td>\n",
       "      <td>180.473188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.438437</td>\n",
       "      <td>95.739931</td>\n",
       "      <td>281.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.463750</td>\n",
       "      <td>83.224653</td>\n",
       "      <td>235.994318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0.509792</td>\n",
       "      <td>58.152431</td>\n",
       "      <td>226.246875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                      \n",
       "2023-12-27  0.363021  106.197917     228.512153\n",
       "2023-12-28  0.514931   99.705556     180.473188\n",
       "2023-12-29  0.438437   95.739931     281.644444\n",
       "2023-12-30  0.463750   83.224653     235.994318\n",
       "2023-12-31  0.509792   58.152431     226.246875"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.50979167,  58.15243056, 226.246875  ]]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_start = df_corr.values[-1]\n",
    "x_test_start = np.reshape(x_test_start,(1,1,3))\n",
    "x_test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([159.49, 201.22, 235.04, 223.36, 153.35, 176.58, 179.29, 260.26,\n",
       "       144.39, 176.85, 200.03, 161.85, 324.88, 285.11, 191.13, 194.15,\n",
       "       188.7 , 201.74, 174.39, 206.83, 181.35, 234.13, 244.36, 252.99,\n",
       "       212.36, 401.43, 220.1 , 284.35, 216.37, 219.25, 204.15])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_start = val.values[0,-1]\n",
    "y_test = []\n",
    "y_test.append(y_test_start)\n",
    "for i in list(y2_test):\n",
    "    y_test.append(i)\n",
    "y_test = np.array(y_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(InputLayer((1, 3)))\n",
    "model4.add(LSTM(64))\n",
    "model4.add(Dense(8, 'relu'))\n",
    "model4.add(Dense(1, 'linear'))\n",
    "model4.load_weights('checkpoint.model4.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "FmwshpETs-jE",
    "outputId": "f9ea03ff-6d06-4ed5-cd59-5199bfdecc15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.09791667e-01 5.81524306e+01 2.26246875e+02]]\n",
      "\n",
      " [[5.10000000e-01 7.49600000e+01 1.59490000e+02]]\n",
      "\n",
      " [[5.00000000e-01 8.13800000e+01 2.01220000e+02]]\n",
      "\n",
      " [[4.50000000e-01 6.46600000e+01 2.35040000e+02]]\n",
      "\n",
      " [[4.80000000e-01 5.64100000e+01 2.23360000e+02]]\n",
      "\n",
      " [[3.80000000e-01 4.89000000e+01 1.53350000e+02]]\n",
      "\n",
      " [[5.10000000e-01 6.78200000e+01 1.76580000e+02]]\n",
      "\n",
      " [[4.00000000e-01 1.02060000e+02 1.79290000e+02]]\n",
      "\n",
      " [[2.90000000e-01 8.68400000e+01 2.60260000e+02]]\n",
      "\n",
      " [[5.30000000e-01 6.59200000e+01 1.44390000e+02]]\n",
      "\n",
      " [[7.50000000e-01 7.94900000e+01 1.76850000e+02]]\n",
      "\n",
      " [[5.00000000e-01 1.03140000e+02 2.00030000e+02]]\n",
      "\n",
      " [[5.00000000e-01 1.09450000e+02 1.61850000e+02]]\n",
      "\n",
      " [[3.60000000e-01 1.02280000e+02 3.24880000e+02]]\n",
      "\n",
      " [[4.00000000e-01 1.06050000e+02 2.85110000e+02]]\n",
      "\n",
      " [[4.30000000e-01 1.13210000e+02 1.91130000e+02]]\n",
      "\n",
      " [[7.10000000e-01 9.93000000e+01 1.94150000e+02]]\n",
      "\n",
      " [[6.30000000e-01 1.01430000e+02 1.88700000e+02]]\n",
      "\n",
      " [[4.20000000e-01 9.18600000e+01 2.01740000e+02]]\n",
      "\n",
      " [[6.60000000e-01 7.90600000e+01 1.74390000e+02]]\n",
      "\n",
      " [[3.10000000e-01 7.68700000e+01 2.06830000e+02]]\n",
      "\n",
      " [[5.60000000e-01 8.17500000e+01 1.81350000e+02]]\n",
      "\n",
      " [[5.20000000e-01 9.54900000e+01 2.34130000e+02]]\n",
      "\n",
      " [[5.90000000e-01 9.07500000e+01 2.44360000e+02]]\n",
      "\n",
      " [[4.90000000e-01 9.80800000e+01 2.52990000e+02]]\n",
      "\n",
      " [[3.40000000e-01 1.15670000e+02 2.12360000e+02]]\n",
      "\n",
      " [[1.90000000e-01 1.19650000e+02 4.01430000e+02]]\n",
      "\n",
      " [[5.10000000e-01 1.24780000e+02 2.20100000e+02]]\n",
      "\n",
      " [[6.50000000e-01 8.89900000e+01 2.84350000e+02]]\n",
      "\n",
      " [[4.40000000e-01 1.11660000e+02 2.16370000e+02]]\n",
      "\n",
      " [[3.30000000e-01 9.32800000e+01 2.19250000e+02]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_predictions1(model, X, y, start=0, end=100):\n",
    "  predictions = model.predict(X).flatten()+18\n",
    "  df = pd.DataFrame(data={'Predictions':predictions, 'Actuals':y})\n",
    "  plt.plot(df['Predictions'][start:end])\n",
    "  plt.plot(df['Actuals'][start:end])\n",
    "  return df, mae(y, predictions)\n",
    "X_test = np.vstack((x_test_start, X2_test))\n",
    "print(X_test)\n",
    "df_4, mae_4 = plot_predictions1(model4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212.909912</td>\n",
       "      <td>159.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.562714</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210.922256</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>223.621368</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210.722794</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.654175</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>195.274246</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202.553665</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>239.975006</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>171.657959</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184.620911</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>210.499390</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>182.209122</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>251.415771</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>244.009445</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>207.478882</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>197.970764</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>198.256805</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>214.677414</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>187.484497</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>220.636765</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>196.955780</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>225.558319</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>227.119400</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>233.272430</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>222.144943</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>259.510071</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>219.164581</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>237.942719</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>220.667480</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>225.795547</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions  Actuals\n",
       "0    212.909912   159.49\n",
       "1    184.562714   201.22\n",
       "2    210.922256   235.04\n",
       "3    223.621368   223.36\n",
       "4    210.722794   153.35\n",
       "5    180.654175   176.58\n",
       "6    195.274246   179.29\n",
       "7    202.553665   260.26\n",
       "8    239.975006   144.39\n",
       "9    171.657959   176.85\n",
       "10   184.620911   200.03\n",
       "11   210.499390   161.85\n",
       "12   182.209122   324.88\n",
       "13   251.415771   285.11\n",
       "14   244.009445   191.13\n",
       "15   207.478882   194.15\n",
       "16   197.970764   188.70\n",
       "17   198.256805   201.74\n",
       "18   214.677414   174.39\n",
       "19   187.484497   206.83\n",
       "20   220.636765   181.35\n",
       "21   196.955780   234.13\n",
       "22   225.558319   244.36\n",
       "23   227.119400   252.99\n",
       "24   233.272430   212.36\n",
       "25   222.144943   401.43\n",
       "26   259.510071   220.10\n",
       "27   219.164581   284.35\n",
       "28   237.942719   216.37\n",
       "29   220.667480   219.25\n",
       "30   225.795547   204.15"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.062957547095515"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df_4.index = val.index\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_4['Predictions']])\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], val['PM2.5 (µg/m³)']])\n",
    "\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train_last_few')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction_test')\n",
    "plt.plot(df_org.index[len(df_corr['PM2.5 (µg/m³)']):],df_org[len(df_corr['PM2.5 (µg/m³)']):],color='green',label='actual_test')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "7EViSFyntz9j"
   },
   "outputs": [],
   "source": [
    "def df_to_X_y3(df, window_size=1):\n",
    "  df_as_np = df.to_numpy()\n",
    "  X = []\n",
    "  y = []\n",
    "  for i in range(len(df_as_np)-window_size):\n",
    "    row = [r for r in df_as_np[i:i+window_size]]\n",
    "    X.append(row)\n",
    "    label = df_as_np[i+window_size]\n",
    "    y.append(label)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6iv-AUQuJdX",
    "outputId": "c5d6aafb-a91e-4d2e-fd07-90734fcad509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1094, 1, 3), (1094, 3))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3, y3 = df_to_X_y3(df_corr)\n",
    "X3.shape, y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAaiWt0buKa4",
    "outputId": "9e431fbf-f8b8-4dc4-932b-d3242d2ab266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1040, 1, 3), (1040, 3), (54, 1, 3), (54, 3), (30, 1, 3), (30, 3))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3_train, y3_train = X3[:1040], y3[:1040]\n",
    "X3_val, y3_val = X3[1040:], y3[1040:]\n",
    "X3_test, y3_test = df_to_X_y3(val)\n",
    "X3_train.shape, y3_train.shape, X3_val.shape, y3_val.shape, X3_test.shape, y3_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czHWSE2Uv4Br",
    "outputId": "7b192759-b752-4f24-9f24-cf3a089ce7df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m17,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,955</span> (70.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,955\u001b[0m (70.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,955</span> (70.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,955\u001b[0m (70.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((1, 3)))\n",
    "model5.add(LSTM(64))\n",
    "model5.add(Dense(8, 'relu'))\n",
    "model5.add(Dense(3, 'linear'))\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "HY4LnQYxwDI2"
   },
   "outputs": [],
   "source": [
    "cp5 = ModelCheckpoint('checkpoint.model5.keras', monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model5.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR6NEXeSwF6J",
    "outputId": "63d8ef64-7125-40e9-d3ba-6e0895617e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 1s/step - loss: 17650.8594 - mean_absolute_error: 92.6394\n",
      "Epoch 1: val_loss improved from inf to 16156.08691, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 16280.2959 - mean_absolute_error: 89.7283 - val_loss: 16156.0869 - val_mean_absolute_error: 96.0287\n",
      "Epoch 2/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13791.0059 - mean_absolute_error: 80.7919\n",
      "Epoch 2: val_loss improved from 16156.08691 to 16134.31250, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16026.4707 - mean_absolute_error: 89.1088 - val_loss: 16134.3125 - val_mean_absolute_error: 95.9460\n",
      "Epoch 3/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 18871.8340 - mean_absolute_error: 96.6559\n",
      "Epoch 3: val_loss improved from 16134.31250 to 16111.58008, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16605.9297 - mean_absolute_error: 90.3716 - val_loss: 16111.5801 - val_mean_absolute_error: 95.8619\n",
      "Epoch 4/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17051.1211 - mean_absolute_error: 90.4368\n",
      "Epoch 4: val_loss improved from 16111.58008 to 16086.54395, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16005.6436 - mean_absolute_error: 89.2101 - val_loss: 16086.5439 - val_mean_absolute_error: 95.7743\n",
      "Epoch 5/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 16321.4805 - mean_absolute_error: 91.0483\n",
      "Epoch 5: val_loss improved from 16086.54395 to 16057.00488, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16565.4434 - mean_absolute_error: 89.9309 - val_loss: 16057.0049 - val_mean_absolute_error: 95.6808\n",
      "Epoch 6/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16051.8193 - mean_absolute_error: 89.2189 \n",
      "Epoch 6: val_loss improved from 16057.00488 to 16015.17285, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16053.7520 - mean_absolute_error: 89.2269 - val_loss: 16015.1729 - val_mean_absolute_error: 95.5605\n",
      "Epoch 7/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 17707.9453 - mean_absolute_error: 93.4158\n",
      "Epoch 7: val_loss improved from 16015.17285 to 15971.19434, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16196.0850 - mean_absolute_error: 89.4731 - val_loss: 15971.1943 - val_mean_absolute_error: 95.4397\n",
      "Epoch 8/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14867.1123 - mean_absolute_error: 83.9367\n",
      "Epoch 8: val_loss improved from 15971.19434 to 15922.27441, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15458.7803 - mean_absolute_error: 87.3935 - val_loss: 15922.2744 - val_mean_absolute_error: 95.3139\n",
      "Epoch 9/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17963.2070 - mean_absolute_error: 91.4625\n",
      "Epoch 9: val_loss improved from 15922.27441 to 15860.16406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15760.3936 - mean_absolute_error: 88.5484 - val_loss: 15860.1641 - val_mean_absolute_error: 95.1518\n",
      "Epoch 10/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14593.5020 - mean_absolute_error: 88.3323\n",
      "Epoch 10: val_loss improved from 15860.16406 to 15787.27441, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15691.3125 - mean_absolute_error: 88.8406 - val_loss: 15787.2744 - val_mean_absolute_error: 94.9737\n",
      "Epoch 11/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15968.2773 - mean_absolute_error: 88.8257\n",
      "Epoch 11: val_loss improved from 15787.27441 to 15712.35449, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15781.9756 - mean_absolute_error: 88.8232 - val_loss: 15712.3545 - val_mean_absolute_error: 94.7819\n",
      "Epoch 12/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14632.4844 - mean_absolute_error: 88.6053\n",
      "Epoch 12: val_loss improved from 15712.35449 to 15636.77539, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15441.8906 - mean_absolute_error: 87.7790 - val_loss: 15636.7754 - val_mean_absolute_error: 94.5576\n",
      "Epoch 13/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 15618.1973 - mean_absolute_error: 89.9470\n",
      "Epoch 13: val_loss improved from 15636.77539 to 15563.04199, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15838.2490 - mean_absolute_error: 88.8253 - val_loss: 15563.0420 - val_mean_absolute_error: 94.3092\n",
      "Epoch 14/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13500.6016 - mean_absolute_error: 82.8661\n",
      "Epoch 14: val_loss improved from 15563.04199 to 15472.93066, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15463.2969 - mean_absolute_error: 88.0053 - val_loss: 15472.9307 - val_mean_absolute_error: 94.0156\n",
      "Epoch 15/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15016.5410 - mean_absolute_error: 85.5933\n",
      "Epoch 15: val_loss improved from 15472.93066 to 15387.79590, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15365.0410 - mean_absolute_error: 87.3766 - val_loss: 15387.7959 - val_mean_absolute_error: 93.7127\n",
      "Epoch 16/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 18605.6797 - mean_absolute_error: 95.1402\n",
      "Epoch 16: val_loss improved from 15387.79590 to 15296.65527, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15758.7793 - mean_absolute_error: 88.6279 - val_loss: 15296.6553 - val_mean_absolute_error: 93.3813\n",
      "Epoch 17/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12994.6309 - mean_absolute_error: 83.9925\n",
      "Epoch 17: val_loss improved from 15296.65527 to 15204.17871, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15091.9053 - mean_absolute_error: 86.8039 - val_loss: 15204.1787 - val_mean_absolute_error: 93.0366\n",
      "Epoch 18/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 15778.2861 - mean_absolute_error: 84.4143\n",
      "Epoch 18: val_loss improved from 15204.17871 to 15098.15527, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15438.8975 - mean_absolute_error: 87.1964 - val_loss: 15098.1553 - val_mean_absolute_error: 92.6419\n",
      "Epoch 19/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12374.8965 - mean_absolute_error: 77.9003\n",
      "Epoch 19: val_loss improved from 15098.15527 to 14987.70020, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14820.8838 - mean_absolute_error: 85.5666 - val_loss: 14987.7002 - val_mean_absolute_error: 92.2191\n",
      "Epoch 20/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13309.7578 - mean_absolute_error: 82.2051\n",
      "Epoch 20: val_loss improved from 14987.70020 to 14874.53906, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14985.0811 - mean_absolute_error: 86.5358 - val_loss: 14874.5391 - val_mean_absolute_error: 91.7802\n",
      "Epoch 21/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 17301.1172 - mean_absolute_error: 92.6615\n",
      "Epoch 21: val_loss improved from 14874.53906 to 14761.09961, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14568.6250 - mean_absolute_error: 85.0301 - val_loss: 14761.0996 - val_mean_absolute_error: 91.3379\n",
      "Epoch 22/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 16915.4668 - mean_absolute_error: 88.8546\n",
      "Epoch 22: val_loss improved from 14761.09961 to 14644.80371, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14792.8135 - mean_absolute_error: 85.2412 - val_loss: 14644.8037 - val_mean_absolute_error: 90.8842\n",
      "Epoch 23/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12981.5723 - mean_absolute_error: 78.2687\n",
      "Epoch 23: val_loss improved from 14644.80371 to 14536.87305, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14311.4629 - mean_absolute_error: 84.0878 - val_loss: 14536.8730 - val_mean_absolute_error: 90.4486\n",
      "Epoch 24/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13080.4043 - mean_absolute_error: 77.4220\n",
      "Epoch 24: val_loss improved from 14536.87305 to 14426.56934, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14066.7861 - mean_absolute_error: 82.9248 - val_loss: 14426.5693 - val_mean_absolute_error: 89.9964\n",
      "Epoch 25/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15511.0977 - mean_absolute_error: 83.2676\n",
      "Epoch 25: val_loss improved from 14426.56934 to 14317.71777, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14449.5879 - mean_absolute_error: 83.3781 - val_loss: 14317.7178 - val_mean_absolute_error: 89.5446\n",
      "Epoch 26/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13255.3770 - mean_absolute_error: 81.8960\n",
      "Epoch 26: val_loss improved from 14317.71777 to 14209.51855, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14138.3457 - mean_absolute_error: 83.0999 - val_loss: 14209.5186 - val_mean_absolute_error: 89.0937\n",
      "Epoch 27/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14732.1992 - mean_absolute_error: 83.8768\n",
      "Epoch 27: val_loss improved from 14209.51855 to 14104.91406, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14076.0244 - mean_absolute_error: 82.9319 - val_loss: 14104.9141 - val_mean_absolute_error: 88.6526\n",
      "Epoch 28/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 14162.6660 - mean_absolute_error: 83.3529\n",
      "Epoch 28: val_loss improved from 14104.91406 to 14002.29883, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14015.3486 - mean_absolute_error: 82.7800 - val_loss: 14002.2988 - val_mean_absolute_error: 88.2135\n",
      "Epoch 29/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15324.5811 - mean_absolute_error: 84.4178\n",
      "Epoch 29: val_loss improved from 14002.29883 to 13882.56738, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14358.8682 - mean_absolute_error: 83.2112 - val_loss: 13882.5674 - val_mean_absolute_error: 87.6954\n",
      "Epoch 30/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14964.4180 - mean_absolute_error: 83.2935\n",
      "Epoch 30: val_loss improved from 13882.56738 to 13744.49414, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13677.1387 - mean_absolute_error: 80.9771 - val_loss: 13744.4941 - val_mean_absolute_error: 87.0961\n",
      "Epoch 31/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10915.5381 - mean_absolute_error: 74.5963\n",
      "Epoch 31: val_loss improved from 13744.49414 to 13551.65039, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13372.4688 - mean_absolute_error: 80.4374 - val_loss: 13551.6504 - val_mean_absolute_error: 86.2733\n",
      "Epoch 32/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12804.1387 - mean_absolute_error: 78.5469\n",
      "Epoch 32: val_loss improved from 13551.65039 to 13420.84766, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13071.0439 - mean_absolute_error: 79.1830 - val_loss: 13420.8477 - val_mean_absolute_error: 85.6940\n",
      "Epoch 33/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 13543.1699 - mean_absolute_error: 80.8503\n",
      "Epoch 33: val_loss improved from 13420.84766 to 13295.89746, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13308.4521 - mean_absolute_error: 79.3191 - val_loss: 13295.8975 - val_mean_absolute_error: 85.1361\n",
      "Epoch 34/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 11979.9531 - mean_absolute_error: 75.1880\n",
      "Epoch 34: val_loss improved from 13295.89746 to 13182.36621, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12957.6836 - mean_absolute_error: 78.4709 - val_loss: 13182.3662 - val_mean_absolute_error: 84.6216\n",
      "Epoch 35/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13716.8193 - mean_absolute_error: 80.3187\n",
      "Epoch 35: val_loss improved from 13182.36621 to 13073.65039, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13181.2969 - mean_absolute_error: 78.5206 - val_loss: 13073.6504 - val_mean_absolute_error: 84.1246\n",
      "Epoch 36/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 17418.2422 - mean_absolute_error: 88.1853\n",
      "Epoch 36: val_loss improved from 13073.65039 to 12967.00586, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13394.2129 - mean_absolute_error: 78.9488 - val_loss: 12967.0059 - val_mean_absolute_error: 83.6341\n",
      "Epoch 37/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12595.2920 - mean_absolute_error: 75.9134\n",
      "Epoch 37: val_loss improved from 12967.00586 to 12846.04883, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12813.4531 - mean_absolute_error: 77.3234 - val_loss: 12846.0488 - val_mean_absolute_error: 83.0611\n",
      "Epoch 38/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11868.7285 - mean_absolute_error: 74.8799\n",
      "Epoch 38: val_loss improved from 12846.04883 to 12727.35547, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12311.5508 - mean_absolute_error: 75.9070 - val_loss: 12727.3555 - val_mean_absolute_error: 82.5036\n",
      "Epoch 39/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13352.0840 - mean_absolute_error: 79.7649\n",
      "Epoch 39: val_loss improved from 12727.35547 to 12616.58203, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12727.0186 - mean_absolute_error: 77.1250 - val_loss: 12616.5820 - val_mean_absolute_error: 81.9883\n",
      "Epoch 40/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 12002.1543 - mean_absolute_error: 74.5336\n",
      "Epoch 40: val_loss improved from 12616.58203 to 12500.85059, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12549.5684 - mean_absolute_error: 76.1394 - val_loss: 12500.8506 - val_mean_absolute_error: 81.4342\n",
      "Epoch 41/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13771.3086 - mean_absolute_error: 74.2778\n",
      "Epoch 41: val_loss improved from 12500.85059 to 12380.01074, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12488.8633 - mean_absolute_error: 75.2232 - val_loss: 12380.0107 - val_mean_absolute_error: 80.8536\n",
      "Epoch 42/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10311.1084 - mean_absolute_error: 65.9242\n",
      "Epoch 42: val_loss improved from 12380.01074 to 12263.07031, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12101.4854 - mean_absolute_error: 73.9167 - val_loss: 12263.0703 - val_mean_absolute_error: 80.3063\n",
      "Epoch 43/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14317.1328 - mean_absolute_error: 81.5963\n",
      "Epoch 43: val_loss improved from 12263.07031 to 12150.23340, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12280.3633 - mean_absolute_error: 75.0156 - val_loss: 12150.2334 - val_mean_absolute_error: 79.7844\n",
      "Epoch 44/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12139.3330 - mean_absolute_error: 74.6596 \n",
      "Epoch 44: val_loss improved from 12150.23340 to 12038.06348, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12128.2148 - mean_absolute_error: 74.5985 - val_loss: 12038.0635 - val_mean_absolute_error: 79.2707\n",
      "Epoch 45/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 12243.6816 - mean_absolute_error: 71.6878\n",
      "Epoch 45: val_loss improved from 12038.06348 to 11929.11230, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11936.3740 - mean_absolute_error: 73.1922 - val_loss: 11929.1123 - val_mean_absolute_error: 78.7583\n",
      "Epoch 46/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12171.4512 - mean_absolute_error: 77.6923\n",
      "Epoch 46: val_loss improved from 11929.11230 to 11820.43066, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11677.7881 - mean_absolute_error: 72.6854 - val_loss: 11820.4307 - val_mean_absolute_error: 78.2393\n",
      "Epoch 47/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 11006.5244 - mean_absolute_error: 72.8338\n",
      "Epoch 47: val_loss improved from 11820.43066 to 11711.99805, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11843.5391 - mean_absolute_error: 72.7983 - val_loss: 11711.9980 - val_mean_absolute_error: 77.7264\n",
      "Epoch 48/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11693.0566 - mean_absolute_error: 72.2783\n",
      "Epoch 48: val_loss improved from 11711.99805 to 11602.98926, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11615.9082 - mean_absolute_error: 72.4387 - val_loss: 11602.9893 - val_mean_absolute_error: 77.2057\n",
      "Epoch 49/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7615.6558 - mean_absolute_error: 58.0339\n",
      "Epoch 49: val_loss improved from 11602.98926 to 11470.59961, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11053.5166 - mean_absolute_error: 70.5392 - val_loss: 11470.5996 - val_mean_absolute_error: 76.5118\n",
      "Epoch 50/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11166.4893 - mean_absolute_error: 67.8256\n",
      "Epoch 50: val_loss improved from 11470.59961 to 11346.64160, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11425.5166 - mean_absolute_error: 71.1643 - val_loss: 11346.6416 - val_mean_absolute_error: 75.8927\n",
      "Epoch 51/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11005.4531 - mean_absolute_error: 72.5766\n",
      "Epoch 51: val_loss improved from 11346.64160 to 11233.15430, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10757.7412 - mean_absolute_error: 69.4449 - val_loss: 11233.1543 - val_mean_absolute_error: 75.3638\n",
      "Epoch 52/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 12434.1230 - mean_absolute_error: 76.5648\n",
      "Epoch 52: val_loss improved from 11233.15430 to 11122.19434, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10907.0908 - mean_absolute_error: 69.7435 - val_loss: 11122.1943 - val_mean_absolute_error: 74.8490\n",
      "Epoch 53/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9396.2607 - mean_absolute_error: 63.7735\n",
      "Epoch 53: val_loss improved from 11122.19434 to 11011.14551, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10890.6660 - mean_absolute_error: 68.8732 - val_loss: 11011.1455 - val_mean_absolute_error: 74.3301\n",
      "Epoch 54/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9471.4971 - mean_absolute_error: 65.0224\n",
      "Epoch 54: val_loss improved from 11011.14551 to 10901.17578, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10894.4941 - mean_absolute_error: 69.2039 - val_loss: 10901.1758 - val_mean_absolute_error: 73.8096\n",
      "Epoch 55/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 10035.6367 - mean_absolute_error: 64.6449\n",
      "Epoch 55: val_loss improved from 10901.17578 to 10793.04199, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10631.4980 - mean_absolute_error: 67.8264 - val_loss: 10793.0420 - val_mean_absolute_error: 73.2931\n",
      "Epoch 56/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10325.4629 - mean_absolute_error: 64.1490\n",
      "Epoch 56: val_loss improved from 10793.04199 to 10685.26172, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10478.5879 - mean_absolute_error: 67.1779 - val_loss: 10685.2617 - val_mean_absolute_error: 72.7722\n",
      "Epoch 57/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9322.5762 - mean_absolute_error: 65.2144\n",
      "Epoch 57: val_loss improved from 10685.26172 to 10577.38086, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10434.2520 - mean_absolute_error: 67.4661 - val_loss: 10577.3809 - val_mean_absolute_error: 72.2468\n",
      "Epoch 58/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8412.0215 - mean_absolute_error: 60.1756\n",
      "Epoch 58: val_loss improved from 10577.38086 to 10471.04199, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10156.0781 - mean_absolute_error: 66.1260 - val_loss: 10471.0420 - val_mean_absolute_error: 71.7224\n",
      "Epoch 59/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13329.1475 - mean_absolute_error: 75.8395\n",
      "Epoch 59: val_loss improved from 10471.04199 to 10365.20508, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10285.4248 - mean_absolute_error: 66.4324 - val_loss: 10365.2051 - val_mean_absolute_error: 71.1959\n",
      "Epoch 60/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9801.8623 - mean_absolute_error: 66.9624\n",
      "Epoch 60: val_loss improved from 10365.20508 to 10259.43848, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9780.2959 - mean_absolute_error: 65.1147 - val_loss: 10259.4385 - val_mean_absolute_error: 70.6671\n",
      "Epoch 61/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9854.1738 - mean_absolute_error: 65.8043\n",
      "Epoch 61: val_loss improved from 10259.43848 to 10154.18359, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9964.4668 - mean_absolute_error: 65.1649 - val_loss: 10154.1836 - val_mean_absolute_error: 70.1341\n",
      "Epoch 62/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 11634.8311 - mean_absolute_error: 68.5839\n",
      "Epoch 62: val_loss improved from 10154.18359 to 10049.04297, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9841.5439 - mean_absolute_error: 64.5179 - val_loss: 10049.0430 - val_mean_absolute_error: 69.5991\n",
      "Epoch 63/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 14338.6719 - mean_absolute_error: 73.8946\n",
      "Epoch 63: val_loss improved from 10049.04297 to 9944.98535, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9995.8193 - mean_absolute_error: 65.0552 - val_loss: 9944.9854 - val_mean_absolute_error: 69.0636\n",
      "Epoch 64/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9482.9395 - mean_absolute_error: 63.7064\n",
      "Epoch 64: val_loss improved from 9944.98535 to 9840.95215, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9491.7168 - mean_absolute_error: 63.4800 - val_loss: 9840.9521 - val_mean_absolute_error: 68.5233\n",
      "Epoch 65/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 10276.1143 - mean_absolute_error: 64.7675\n",
      "Epoch 65: val_loss improved from 9840.95215 to 9731.44434, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9430.6270 - mean_absolute_error: 63.3916 - val_loss: 9731.4443 - val_mean_absolute_error: 67.9448\n",
      "Epoch 66/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 10458.9561 - mean_absolute_error: 67.5081\n",
      "Epoch 66: val_loss improved from 9731.44434 to 9617.77344, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9706.2236 - mean_absolute_error: 63.8446 - val_loss: 9617.7734 - val_mean_absolute_error: 67.3391\n",
      "Epoch 67/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9761.4307 - mean_absolute_error: 66.4464\n",
      "Epoch 67: val_loss improved from 9617.77344 to 9489.58594, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9461.1514 - mean_absolute_error: 63.0414 - val_loss: 9489.5859 - val_mean_absolute_error: 66.6423\n",
      "Epoch 68/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10564.1182 - mean_absolute_error: 64.4450\n",
      "Epoch 68: val_loss improved from 9489.58594 to 9372.04297, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9542.2773 - mean_absolute_error: 62.6704 - val_loss: 9372.0430 - val_mean_absolute_error: 65.9887\n",
      "Epoch 69/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9087.6729 - mean_absolute_error: 63.7549\n",
      "Epoch 69: val_loss improved from 9372.04297 to 9263.23047, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9095.8252 - mean_absolute_error: 61.2719 - val_loss: 9263.2305 - val_mean_absolute_error: 65.3778\n",
      "Epoch 70/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11593.7832 - mean_absolute_error: 68.2698\n",
      "Epoch 70: val_loss improved from 9263.23047 to 9150.51660, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9125.1680 - mean_absolute_error: 61.1089 - val_loss: 9150.5166 - val_mean_absolute_error: 64.7409\n",
      "Epoch 71/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8551.4326 - mean_absolute_error: 59.7677\n",
      "Epoch 71: val_loss improved from 9150.51660 to 9015.66016, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8921.5293 - mean_absolute_error: 60.4657 - val_loss: 9015.6602 - val_mean_absolute_error: 63.9951\n",
      "Epoch 72/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9246.2695 - mean_absolute_error: 62.1294\n",
      "Epoch 72: val_loss improved from 9015.66016 to 8889.86816, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9172.9424 - mean_absolute_error: 61.0449 - val_loss: 8889.8682 - val_mean_absolute_error: 63.3122\n",
      "Epoch 73/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7885.3203 - mean_absolute_error: 57.2160\n",
      "Epoch 73: val_loss improved from 8889.86816 to 8774.91895, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8799.3818 - mean_absolute_error: 60.2447 - val_loss: 8774.9189 - val_mean_absolute_error: 62.6825\n",
      "Epoch 74/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6453.3574 - mean_absolute_error: 51.1850\n",
      "Epoch 74: val_loss improved from 8774.91895 to 8667.44238, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8027.0151 - mean_absolute_error: 57.1196 - val_loss: 8667.4424 - val_mean_absolute_error: 62.0859\n",
      "Epoch 75/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6156.0576 - mean_absolute_error: 51.4952\n",
      "Epoch 75: val_loss improved from 8667.44238 to 8555.46582, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8085.6030 - mean_absolute_error: 57.9023 - val_loss: 8555.4658 - val_mean_absolute_error: 61.4467\n",
      "Epoch 76/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7699.7510 - mean_absolute_error: 58.9225\n",
      "Epoch 76: val_loss improved from 8555.46582 to 8438.12109, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8081.8901 - mean_absolute_error: 57.4895 - val_loss: 8438.1211 - val_mean_absolute_error: 60.7486\n",
      "Epoch 77/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7335.0166 - mean_absolute_error: 52.7318\n",
      "Epoch 77: val_loss improved from 8438.12109 to 8324.98828, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8244.6191 - mean_absolute_error: 57.6763 - val_loss: 8324.9883 - val_mean_absolute_error: 60.0799\n",
      "Epoch 78/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9594.5801 - mean_absolute_error: 61.3176\n",
      "Epoch 78: val_loss improved from 8324.98828 to 8219.67383, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7868.3198 - mean_absolute_error: 56.2116 - val_loss: 8219.6738 - val_mean_absolute_error: 59.4542\n",
      "Epoch 79/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7763.7231 - mean_absolute_error: 55.7904\n",
      "Epoch 79: val_loss improved from 8219.67383 to 8116.43066, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7818.2700 - mean_absolute_error: 56.4195 - val_loss: 8116.4307 - val_mean_absolute_error: 58.8298\n",
      "Epoch 80/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8422.9609 - mean_absolute_error: 56.4256\n",
      "Epoch 80: val_loss improved from 8116.43066 to 8018.02295, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7620.3247 - mean_absolute_error: 55.2519 - val_loss: 8018.0229 - val_mean_absolute_error: 58.2295\n",
      "Epoch 81/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7227.8472 - mean_absolute_error: 53.8992\n",
      "Epoch 81: val_loss improved from 8018.02295 to 7905.59131, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7469.7061 - mean_absolute_error: 54.8036 - val_loss: 7905.5913 - val_mean_absolute_error: 57.5287\n",
      "Epoch 82/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7226.5542 - mean_absolute_error: 53.4554 \n",
      "Epoch 82: val_loss improved from 7905.59131 to 7790.39795, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7304.5254 - mean_absolute_error: 53.7763 - val_loss: 7790.3979 - val_mean_absolute_error: 56.8120\n",
      "Epoch 83/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7072.9600 - mean_absolute_error: 54.0991\n",
      "Epoch 83: val_loss improved from 7790.39795 to 7688.74707, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7545.5093 - mean_absolute_error: 54.2641 - val_loss: 7688.7471 - val_mean_absolute_error: 56.1745\n",
      "Epoch 84/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6855.4131 - mean_absolute_error: 53.8468\n",
      "Epoch 84: val_loss improved from 7688.74707 to 7582.09717, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6872.7100 - mean_absolute_error: 52.2757 - val_loss: 7582.0972 - val_mean_absolute_error: 55.4680\n",
      "Epoch 85/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6456.7603 - mean_absolute_error: 52.0736\n",
      "Epoch 85: val_loss improved from 7582.09717 to 7477.13477, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6940.4683 - mean_absolute_error: 53.0909 - val_loss: 7477.1348 - val_mean_absolute_error: 54.7886\n",
      "Epoch 86/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6026.6201 - mean_absolute_error: 50.1317\n",
      "Epoch 86: val_loss improved from 7477.13477 to 7379.74023, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6874.9463 - mean_absolute_error: 52.5618 - val_loss: 7379.7402 - val_mean_absolute_error: 54.1506\n",
      "Epoch 87/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8761.1445 - mean_absolute_error: 57.8655\n",
      "Epoch 87: val_loss improved from 7379.74023 to 7284.98340, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7138.0918 - mean_absolute_error: 52.5134 - val_loss: 7284.9834 - val_mean_absolute_error: 53.5221\n",
      "Epoch 88/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7311.3730 - mean_absolute_error: 55.4649\n",
      "Epoch 88: val_loss improved from 7284.98340 to 7191.63232, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7035.2217 - mean_absolute_error: 52.6895 - val_loss: 7191.6323 - val_mean_absolute_error: 52.8955\n",
      "Epoch 89/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7518.9458 - mean_absolute_error: 52.5269\n",
      "Epoch 89: val_loss improved from 7191.63232 to 7100.27881, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6942.5850 - mean_absolute_error: 51.9499 - val_loss: 7100.2788 - val_mean_absolute_error: 52.2764\n",
      "Epoch 90/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6116.9023 - mean_absolute_error: 50.2755\n",
      "Epoch 90: val_loss improved from 7100.27881 to 7011.03027, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6661.6724 - mean_absolute_error: 50.8499 - val_loss: 7011.0303 - val_mean_absolute_error: 51.6622\n",
      "Epoch 91/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7303.1289 - mean_absolute_error: 51.9733\n",
      "Epoch 91: val_loss improved from 7011.03027 to 6921.59424, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6600.3403 - mean_absolute_error: 50.6046 - val_loss: 6921.5942 - val_mean_absolute_error: 51.0367\n",
      "Epoch 92/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5924.7266 - mean_absolute_error: 52.2114\n",
      "Epoch 92: val_loss improved from 6921.59424 to 6834.08691, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6387.8994 - mean_absolute_error: 49.7929 - val_loss: 6834.0869 - val_mean_absolute_error: 50.4356\n",
      "Epoch 93/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9315.2773 - mean_absolute_error: 58.2171\n",
      "Epoch 93: val_loss improved from 6834.08691 to 6748.05566, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6802.3882 - mean_absolute_error: 50.8947 - val_loss: 6748.0557 - val_mean_absolute_error: 49.8356\n",
      "Epoch 94/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8034.6963 - mean_absolute_error: 54.6701\n",
      "Epoch 94: val_loss improved from 6748.05566 to 6663.90039, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6523.3164 - mean_absolute_error: 50.1695 - val_loss: 6663.9004 - val_mean_absolute_error: 49.2695\n",
      "Epoch 95/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5399.5469 - mean_absolute_error: 45.6954\n",
      "Epoch 95: val_loss improved from 6663.90039 to 6582.82861, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6094.6128 - mean_absolute_error: 48.3881 - val_loss: 6582.8286 - val_mean_absolute_error: 48.7282\n",
      "Epoch 96/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6269.7148 - mean_absolute_error: 49.1932 \n",
      "Epoch 96: val_loss improved from 6582.82861 to 6497.20557, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6232.1489 - mean_absolute_error: 48.9922 - val_loss: 6497.2056 - val_mean_absolute_error: 48.1147\n",
      "Epoch 97/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7967.6157 - mean_absolute_error: 56.7128\n",
      "Epoch 97: val_loss improved from 6497.20557 to 6409.67432, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6139.9590 - mean_absolute_error: 48.7116 - val_loss: 6409.6743 - val_mean_absolute_error: 47.4610\n",
      "Epoch 98/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6224.4072 - mean_absolute_error: 49.1964\n",
      "Epoch 98: val_loss improved from 6409.67432 to 6326.25879, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5725.8247 - mean_absolute_error: 46.8071 - val_loss: 6326.2588 - val_mean_absolute_error: 46.8424\n",
      "Epoch 99/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4039.8318 - mean_absolute_error: 38.8434\n",
      "Epoch 99: val_loss improved from 6326.25879 to 6246.87402, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5541.6094 - mean_absolute_error: 46.0685 - val_loss: 6246.8740 - val_mean_absolute_error: 46.2577\n",
      "Epoch 100/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4834.1372 - mean_absolute_error: 41.9186\n",
      "Epoch 100: val_loss improved from 6246.87402 to 6172.44775, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5660.1406 - mean_absolute_error: 46.1548 - val_loss: 6172.4478 - val_mean_absolute_error: 45.7233\n",
      "Epoch 101/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4678.6006 - mean_absolute_error: 42.0563\n",
      "Epoch 101: val_loss improved from 6172.44775 to 6098.87744, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5594.8862 - mean_absolute_error: 46.5296 - val_loss: 6098.8774 - val_mean_absolute_error: 45.2202\n",
      "Epoch 102/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5901.1631 - mean_absolute_error: 50.9316\n",
      "Epoch 102: val_loss improved from 6098.87744 to 6028.54248, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5595.1729 - mean_absolute_error: 46.4472 - val_loss: 6028.5425 - val_mean_absolute_error: 44.7444\n",
      "Epoch 103/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5887.3584 - mean_absolute_error: 47.7141\n",
      "Epoch 103: val_loss improved from 6028.54248 to 5959.55908, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5665.0762 - mean_absolute_error: 46.4490 - val_loss: 5959.5591 - val_mean_absolute_error: 44.3081\n",
      "Epoch 104/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5727.1328 - mean_absolute_error: 46.5560\n",
      "Epoch 104: val_loss improved from 5959.55908 to 5892.75439, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5390.9263 - mean_absolute_error: 45.3272 - val_loss: 5892.7544 - val_mean_absolute_error: 43.9053\n",
      "Epoch 105/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7418.9780 - mean_absolute_error: 51.2961\n",
      "Epoch 105: val_loss improved from 5892.75439 to 5827.96826, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5775.0474 - mean_absolute_error: 46.2859 - val_loss: 5827.9683 - val_mean_absolute_error: 43.5394\n",
      "Epoch 106/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6040.3740 - mean_absolute_error: 51.1666\n",
      "Epoch 106: val_loss improved from 5827.96826 to 5765.63135, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5439.5835 - mean_absolute_error: 45.1976 - val_loss: 5765.6313 - val_mean_absolute_error: 43.1979\n",
      "Epoch 107/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4788.5508 - mean_absolute_error: 44.0177\n",
      "Epoch 107: val_loss improved from 5765.63135 to 5703.12500, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5097.6177 - mean_absolute_error: 43.9539 - val_loss: 5703.1250 - val_mean_absolute_error: 42.8828\n",
      "Epoch 108/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5133.3477 - mean_absolute_error: 44.2057\n",
      "Epoch 108: val_loss improved from 5703.12500 to 5644.37061, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5517.7251 - mean_absolute_error: 45.2994 - val_loss: 5644.3706 - val_mean_absolute_error: 42.6428\n",
      "Epoch 109/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5505.0947 - mean_absolute_error: 46.1649\n",
      "Epoch 109: val_loss improved from 5644.37061 to 5586.04639, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5488.1973 - mean_absolute_error: 45.3180 - val_loss: 5586.0464 - val_mean_absolute_error: 42.4501\n",
      "Epoch 110/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6917.1523 - mean_absolute_error: 51.1908\n",
      "Epoch 110: val_loss improved from 5586.04639 to 5530.03467, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5097.4961 - mean_absolute_error: 43.9912 - val_loss: 5530.0347 - val_mean_absolute_error: 42.2886\n",
      "Epoch 111/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7036.6860 - mean_absolute_error: 47.5401\n",
      "Epoch 111: val_loss improved from 5530.03467 to 5475.00586, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5130.2559 - mean_absolute_error: 43.5865 - val_loss: 5475.0059 - val_mean_absolute_error: 42.1415\n",
      "Epoch 112/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6402.2334 - mean_absolute_error: 47.0646\n",
      "Epoch 112: val_loss improved from 5475.00586 to 5424.03174, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4962.7183 - mean_absolute_error: 43.1636 - val_loss: 5424.0317 - val_mean_absolute_error: 42.0343\n",
      "Epoch 113/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5162.4131 - mean_absolute_error: 47.0460\n",
      "Epoch 113: val_loss improved from 5424.03174 to 5373.00830, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4662.5439 - mean_absolute_error: 42.5826 - val_loss: 5373.0083 - val_mean_absolute_error: 41.9383\n",
      "Epoch 114/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4845.0767 - mean_absolute_error: 42.7122\n",
      "Epoch 114: val_loss improved from 5373.00830 to 5323.90967, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4796.1079 - mean_absolute_error: 42.6512 - val_loss: 5323.9097 - val_mean_absolute_error: 41.8649\n",
      "Epoch 115/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6448.4375 - mean_absolute_error: 48.3973\n",
      "Epoch 115: val_loss improved from 5323.90967 to 5275.23828, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5001.9790 - mean_absolute_error: 43.1726 - val_loss: 5275.2383 - val_mean_absolute_error: 41.8066\n",
      "Epoch 116/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4385.4897 - mean_absolute_error: 39.3394\n",
      "Epoch 116: val_loss improved from 5275.23828 to 5231.32422, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4502.0854 - mean_absolute_error: 41.0879 - val_loss: 5231.3242 - val_mean_absolute_error: 41.7603\n",
      "Epoch 117/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3526.2056 - mean_absolute_error: 38.1474\n",
      "Epoch 117: val_loss improved from 5231.32422 to 5183.84375, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4679.1890 - mean_absolute_error: 41.7901 - val_loss: 5183.8438 - val_mean_absolute_error: 41.7087\n",
      "Epoch 118/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3923.1807 - mean_absolute_error: 38.7020\n",
      "Epoch 118: val_loss improved from 5183.84375 to 5143.08252, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4373.4526 - mean_absolute_error: 40.7032 - val_loss: 5143.0825 - val_mean_absolute_error: 41.6738\n",
      "Epoch 119/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3081.9338 - mean_absolute_error: 36.4297\n",
      "Epoch 119: val_loss improved from 5143.08252 to 5102.22607, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4506.0562 - mean_absolute_error: 41.2304 - val_loss: 5102.2261 - val_mean_absolute_error: 41.6398\n",
      "Epoch 120/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3760.8213 - mean_absolute_error: 40.4124\n",
      "Epoch 120: val_loss improved from 5102.22607 to 5062.95312, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4467.4023 - mean_absolute_error: 41.3284 - val_loss: 5062.9531 - val_mean_absolute_error: 41.6038\n",
      "Epoch 121/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4135.8955 - mean_absolute_error: 40.0956\n",
      "Epoch 121: val_loss improved from 5062.95312 to 5025.06494, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4203.0825 - mean_absolute_error: 39.9117 - val_loss: 5025.0649 - val_mean_absolute_error: 41.5637\n",
      "Epoch 122/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5001.5908 - mean_absolute_error: 44.2436\n",
      "Epoch 122: val_loss improved from 5025.06494 to 4987.10547, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4160.7305 - mean_absolute_error: 39.6372 - val_loss: 4987.1055 - val_mean_absolute_error: 41.5379\n",
      "Epoch 123/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2966.8535 - mean_absolute_error: 33.4224\n",
      "Epoch 123: val_loss improved from 4987.10547 to 4953.03125, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4078.5889 - mean_absolute_error: 39.1233 - val_loss: 4953.0312 - val_mean_absolute_error: 41.5391\n",
      "Epoch 124/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2879.0234 - mean_absolute_error: 35.3043\n",
      "Epoch 124: val_loss improved from 4953.03125 to 4921.17578, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4074.7476 - mean_absolute_error: 39.3791 - val_loss: 4921.1758 - val_mean_absolute_error: 41.5505\n",
      "Epoch 125/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3904.7891 - mean_absolute_error: 40.4849\n",
      "Epoch 125: val_loss improved from 4921.17578 to 4889.70850, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4107.4531 - mean_absolute_error: 39.6108 - val_loss: 4889.7085 - val_mean_absolute_error: 41.5965\n",
      "Epoch 126/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4519.9126 - mean_absolute_error: 39.9276\n",
      "Epoch 126: val_loss improved from 4889.70850 to 4860.04932, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4194.5215 - mean_absolute_error: 39.8813 - val_loss: 4860.0493 - val_mean_absolute_error: 41.6661\n",
      "Epoch 127/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3453.1760 - mean_absolute_error: 36.6047\n",
      "Epoch 127: val_loss improved from 4860.04932 to 4832.56006, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4128.3735 - mean_absolute_error: 39.1483 - val_loss: 4832.5601 - val_mean_absolute_error: 41.7532\n",
      "Epoch 128/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4669.2051 - mean_absolute_error: 41.0578\n",
      "Epoch 128: val_loss improved from 4832.56006 to 4804.64453, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4185.1929 - mean_absolute_error: 39.3283 - val_loss: 4804.6445 - val_mean_absolute_error: 41.8277\n",
      "Epoch 129/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 3167.3125 - mean_absolute_error: 35.1883\n",
      "Epoch 129: val_loss improved from 4804.64453 to 4782.32275, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3969.8523 - mean_absolute_error: 38.6910 - val_loss: 4782.3228 - val_mean_absolute_error: 41.9275\n",
      "Epoch 130/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3227.8701 - mean_absolute_error: 34.8946\n",
      "Epoch 130: val_loss improved from 4782.32275 to 4758.57422, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3868.3123 - mean_absolute_error: 37.9263 - val_loss: 4758.5742 - val_mean_absolute_error: 42.0143\n",
      "Epoch 131/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4727.0986 - mean_absolute_error: 40.2557\n",
      "Epoch 131: val_loss improved from 4758.57422 to 4737.87744, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3894.6064 - mean_absolute_error: 38.0040 - val_loss: 4737.8774 - val_mean_absolute_error: 42.1033\n",
      "Epoch 132/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4136.6636 - mean_absolute_error: 38.1394\n",
      "Epoch 132: val_loss improved from 4737.87744 to 4715.72217, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3999.0874 - mean_absolute_error: 38.6186 - val_loss: 4715.7222 - val_mean_absolute_error: 42.2019\n",
      "Epoch 133/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5087.8018 - mean_absolute_error: 41.9464\n",
      "Epoch 133: val_loss improved from 4715.72217 to 4700.45654, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3911.6716 - mean_absolute_error: 38.2417 - val_loss: 4700.4565 - val_mean_absolute_error: 42.3056\n",
      "Epoch 134/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4061.5881 - mean_absolute_error: 37.7047\n",
      "Epoch 134: val_loss improved from 4700.45654 to 4684.39795, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3864.3396 - mean_absolute_error: 38.0105 - val_loss: 4684.3979 - val_mean_absolute_error: 42.4157\n",
      "Epoch 135/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4544.0508 - mean_absolute_error: 40.3145\n",
      "Epoch 135: val_loss improved from 4684.39795 to 4666.88965, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3819.8123 - mean_absolute_error: 37.9928 - val_loss: 4666.8896 - val_mean_absolute_error: 42.5096\n",
      "Epoch 136/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4107.4995 - mean_absolute_error: 37.6491\n",
      "Epoch 136: val_loss improved from 4666.88965 to 4653.01904, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3840.1487 - mean_absolute_error: 37.6418 - val_loss: 4653.0190 - val_mean_absolute_error: 42.6137\n",
      "Epoch 137/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3150.1550 - mean_absolute_error: 35.7706\n",
      "Epoch 137: val_loss improved from 4653.01904 to 4641.33545, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3431.2625 - mean_absolute_error: 36.7068 - val_loss: 4641.3354 - val_mean_absolute_error: 42.7223\n",
      "Epoch 138/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3328.2329 - mean_absolute_error: 37.5667\n",
      "Epoch 138: val_loss improved from 4641.33545 to 4632.27100, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3706.2400 - mean_absolute_error: 37.6843 - val_loss: 4632.2710 - val_mean_absolute_error: 42.8429\n",
      "Epoch 139/1500\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3618.6377 - mean_absolute_error: 37.3551 \n",
      "Epoch 139: val_loss improved from 4632.27100 to 4622.15820, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3623.5664 - mean_absolute_error: 37.2909 - val_loss: 4622.1582 - val_mean_absolute_error: 42.9768\n",
      "Epoch 140/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2640.2812 - mean_absolute_error: 31.9363\n",
      "Epoch 140: val_loss improved from 4622.15820 to 4614.10352, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3592.4600 - mean_absolute_error: 37.2042 - val_loss: 4614.1035 - val_mean_absolute_error: 43.1032\n",
      "Epoch 141/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3210.9751 - mean_absolute_error: 36.0767\n",
      "Epoch 141: val_loss improved from 4614.10352 to 4607.14648, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3691.6814 - mean_absolute_error: 37.4439 - val_loss: 4607.1465 - val_mean_absolute_error: 43.2152\n",
      "Epoch 142/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4532.4253 - mean_absolute_error: 42.2515\n",
      "Epoch 142: val_loss improved from 4607.14648 to 4601.97852, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3697.1667 - mean_absolute_error: 37.7120 - val_loss: 4601.9785 - val_mean_absolute_error: 43.3427\n",
      "Epoch 143/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2360.6851 - mean_absolute_error: 31.0499\n",
      "Epoch 143: val_loss improved from 4601.97852 to 4598.70215, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3473.3491 - mean_absolute_error: 36.5487 - val_loss: 4598.7021 - val_mean_absolute_error: 43.4838\n",
      "Epoch 144/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3927.9226 - mean_absolute_error: 39.6009\n",
      "Epoch 144: val_loss improved from 4598.70215 to 4596.63672, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3462.4475 - mean_absolute_error: 36.4818 - val_loss: 4596.6367 - val_mean_absolute_error: 43.6426\n",
      "Epoch 145/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3425.8003 - mean_absolute_error: 36.1440 \n",
      "Epoch 145: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3429.9053 - mean_absolute_error: 36.1695 - val_loss: 4597.3101 - val_mean_absolute_error: 43.8018\n",
      "Epoch 146/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3203.2173 - mean_absolute_error: 34.7152 \n",
      "Epoch 146: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3217.4365 - mean_absolute_error: 34.8097 - val_loss: 4598.1929 - val_mean_absolute_error: 43.9539\n",
      "Epoch 147/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4483.5835 - mean_absolute_error: 38.0106\n",
      "Epoch 147: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3487.2825 - mean_absolute_error: 36.3530 - val_loss: 4600.0791 - val_mean_absolute_error: 44.1388\n",
      "Epoch 148/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3554.1655 - mean_absolute_error: 36.9020\n",
      "Epoch 148: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3436.1125 - mean_absolute_error: 36.2574 - val_loss: 4602.1284 - val_mean_absolute_error: 44.3053\n",
      "Epoch 149/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3443.7512 - mean_absolute_error: 36.3919 \n",
      "Epoch 149: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3439.2559 - mean_absolute_error: 36.3686 - val_loss: 4605.8828 - val_mean_absolute_error: 44.4744\n",
      "Epoch 150/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3327.6899 - mean_absolute_error: 38.2693\n",
      "Epoch 150: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3415.4402 - mean_absolute_error: 36.3961 - val_loss: 4609.3325 - val_mean_absolute_error: 44.6614\n",
      "Epoch 151/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4128.8398 - mean_absolute_error: 40.1482\n",
      "Epoch 151: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3340.5393 - mean_absolute_error: 36.3194 - val_loss: 4618.6602 - val_mean_absolute_error: 44.8491\n",
      "Epoch 152/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4348.7979 - mean_absolute_error: 39.7158\n",
      "Epoch 152: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3404.9668 - mean_absolute_error: 36.0732 - val_loss: 4626.0947 - val_mean_absolute_error: 45.0383\n",
      "Epoch 153/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3382.9673 - mean_absolute_error: 36.4802\n",
      "Epoch 153: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3346.7209 - mean_absolute_error: 35.5465 - val_loss: 4632.6841 - val_mean_absolute_error: 45.2062\n",
      "Epoch 154/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3746.8093 - mean_absolute_error: 39.7704\n",
      "Epoch 154: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3205.2966 - mean_absolute_error: 35.4443 - val_loss: 4644.8701 - val_mean_absolute_error: 45.4007\n",
      "Epoch 155/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4449.1787 - mean_absolute_error: 39.3861\n",
      "Epoch 155: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3410.9275 - mean_absolute_error: 35.9750 - val_loss: 4653.3877 - val_mean_absolute_error: 45.5749\n",
      "Epoch 156/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3973.2854 - mean_absolute_error: 37.8363\n",
      "Epoch 156: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3313.5029 - mean_absolute_error: 36.0984 - val_loss: 4667.0342 - val_mean_absolute_error: 45.7686\n",
      "Epoch 157/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3433.2148 - mean_absolute_error: 36.8515\n",
      "Epoch 157: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3271.1418 - mean_absolute_error: 35.6518 - val_loss: 4675.0796 - val_mean_absolute_error: 45.9374\n",
      "Epoch 158/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2395.5464 - mean_absolute_error: 33.7256\n",
      "Epoch 158: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3155.0613 - mean_absolute_error: 35.3140 - val_loss: 4687.3853 - val_mean_absolute_error: 46.1217\n",
      "Epoch 159/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3240.8987 - mean_absolute_error: 34.9209 \n",
      "Epoch 159: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3215.8235 - mean_absolute_error: 34.9288 - val_loss: 4700.4751 - val_mean_absolute_error: 46.3061\n",
      "Epoch 160/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3218.3792 - mean_absolute_error: 35.3845 \n",
      "Epoch 160: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3213.3923 - mean_absolute_error: 35.3597 - val_loss: 4712.0889 - val_mean_absolute_error: 46.4947\n",
      "Epoch 161/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 3132.1931 - mean_absolute_error: 33.7996\n",
      "Epoch 161: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3122.6643 - mean_absolute_error: 34.7426 - val_loss: 4727.2217 - val_mean_absolute_error: 46.7044\n",
      "Epoch 162/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3929.5486 - mean_absolute_error: 40.3015\n",
      "Epoch 162: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3256.9746 - mean_absolute_error: 35.4142 - val_loss: 4743.2114 - val_mean_absolute_error: 46.8972\n",
      "Epoch 163/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2697.3132 - mean_absolute_error: 33.2458\n",
      "Epoch 163: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3001.9956 - mean_absolute_error: 34.1711 - val_loss: 4755.9419 - val_mean_absolute_error: 47.0833\n",
      "Epoch 164/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2165.8892 - mean_absolute_error: 31.6836\n",
      "Epoch 164: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2987.9438 - mean_absolute_error: 34.2621 - val_loss: 4772.7720 - val_mean_absolute_error: 47.2683\n",
      "Epoch 165/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4273.3262 - mean_absolute_error: 38.0739\n",
      "Epoch 165: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3157.5596 - mean_absolute_error: 34.5523 - val_loss: 4788.6333 - val_mean_absolute_error: 47.4566\n",
      "Epoch 166/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2223.7678 - mean_absolute_error: 31.3456\n",
      "Epoch 166: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2955.1948 - mean_absolute_error: 34.1765 - val_loss: 4805.9800 - val_mean_absolute_error: 47.6400\n",
      "Epoch 167/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3194.1782 - mean_absolute_error: 37.0869\n",
      "Epoch 167: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3040.8540 - mean_absolute_error: 34.6337 - val_loss: 4823.1782 - val_mean_absolute_error: 47.7987\n",
      "Epoch 168/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2281.1597 - mean_absolute_error: 31.1435\n",
      "Epoch 168: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2885.1316 - mean_absolute_error: 33.8561 - val_loss: 4839.2026 - val_mean_absolute_error: 48.0038\n",
      "Epoch 169/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3943.8567 - mean_absolute_error: 38.6624\n",
      "Epoch 169: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3021.0029 - mean_absolute_error: 34.5164 - val_loss: 4856.2378 - val_mean_absolute_error: 48.2035\n",
      "Epoch 170/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3425.1807 - mean_absolute_error: 36.5351\n",
      "Epoch 170: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3127.9229 - mean_absolute_error: 34.9473 - val_loss: 4870.1138 - val_mean_absolute_error: 48.3565\n",
      "Epoch 171/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2306.7566 - mean_absolute_error: 32.5746\n",
      "Epoch 171: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2994.6750 - mean_absolute_error: 34.2058 - val_loss: 4885.1851 - val_mean_absolute_error: 48.5109\n",
      "Epoch 172/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2329.8213 - mean_absolute_error: 28.0738\n",
      "Epoch 172: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2788.7407 - mean_absolute_error: 32.5935 - val_loss: 4903.5337 - val_mean_absolute_error: 48.7407\n",
      "Epoch 173/1500\n",
      "\u001b[1m14/33\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2503.1040 - mean_absolute_error: 31.3402 \n",
      "Epoch 173: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2722.6660 - mean_absolute_error: 32.6414 - val_loss: 4918.8315 - val_mean_absolute_error: 48.8753\n",
      "Epoch 174/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4142.7852 - mean_absolute_error: 36.5000\n",
      "Epoch 174: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2996.5581 - mean_absolute_error: 34.0882 - val_loss: 4935.5557 - val_mean_absolute_error: 49.0666\n",
      "Epoch 175/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2491.4590 - mean_absolute_error: 31.1312\n",
      "Epoch 175: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2950.4121 - mean_absolute_error: 33.8066 - val_loss: 4952.5527 - val_mean_absolute_error: 49.2123\n",
      "Epoch 176/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3431.9800 - mean_absolute_error: 35.2988\n",
      "Epoch 176: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2982.2576 - mean_absolute_error: 34.5227 - val_loss: 4966.9287 - val_mean_absolute_error: 49.3605\n",
      "Epoch 177/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2424.4385 - mean_absolute_error: 29.1402\n",
      "Epoch 177: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2924.7139 - mean_absolute_error: 33.2619 - val_loss: 4980.9976 - val_mean_absolute_error: 49.4971\n",
      "Epoch 178/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3771.2358 - mean_absolute_error: 38.8587\n",
      "Epoch 178: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2964.7539 - mean_absolute_error: 33.9734 - val_loss: 4998.7148 - val_mean_absolute_error: 49.6508\n",
      "Epoch 179/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2565.5051 - mean_absolute_error: 31.5177\n",
      "Epoch 179: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2862.6367 - mean_absolute_error: 33.9018 - val_loss: 5010.4917 - val_mean_absolute_error: 49.7122\n",
      "Epoch 180/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2688.7310 - mean_absolute_error: 32.6619\n",
      "Epoch 180: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2746.3801 - mean_absolute_error: 33.3883 - val_loss: 5021.1504 - val_mean_absolute_error: 49.8502\n",
      "Epoch 181/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2590.9871 - mean_absolute_error: 32.6550\n",
      "Epoch 181: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2768.5718 - mean_absolute_error: 33.1868 - val_loss: 5032.2144 - val_mean_absolute_error: 49.9431\n",
      "Epoch 182/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3095.5200 - mean_absolute_error: 32.8537\n",
      "Epoch 182: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2904.1506 - mean_absolute_error: 33.6836 - val_loss: 5044.4980 - val_mean_absolute_error: 50.0753\n",
      "Epoch 183/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3174.7576 - mean_absolute_error: 34.1020\n",
      "Epoch 183: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2961.1626 - mean_absolute_error: 33.7815 - val_loss: 5053.3970 - val_mean_absolute_error: 50.1330\n",
      "Epoch 184/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2261.9897 - mean_absolute_error: 31.8473\n",
      "Epoch 184: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2589.1973 - mean_absolute_error: 32.1325 - val_loss: 5073.8521 - val_mean_absolute_error: 50.3571\n",
      "Epoch 185/1500\n",
      "\u001b[1m18/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3001.7292 - mean_absolute_error: 33.8476 \n",
      "Epoch 185: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2940.5291 - mean_absolute_error: 33.7057 - val_loss: 5085.6499 - val_mean_absolute_error: 50.4453\n",
      "Epoch 186/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3293.6455 - mean_absolute_error: 35.6039\n",
      "Epoch 186: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2803.0903 - mean_absolute_error: 33.2496 - val_loss: 5108.6802 - val_mean_absolute_error: 50.6621\n",
      "Epoch 187/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2647.2578 - mean_absolute_error: 34.8732\n",
      "Epoch 187: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2635.7754 - mean_absolute_error: 32.5252 - val_loss: 5117.3633 - val_mean_absolute_error: 50.6915\n",
      "Epoch 188/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2177.2368 - mean_absolute_error: 28.8914\n",
      "Epoch 188: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2660.1577 - mean_absolute_error: 32.2550 - val_loss: 5130.5464 - val_mean_absolute_error: 50.7934\n",
      "Epoch 189/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2281.0630 - mean_absolute_error: 30.4133\n",
      "Epoch 189: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2732.3125 - mean_absolute_error: 33.0691 - val_loss: 5143.7686 - val_mean_absolute_error: 50.8764\n",
      "Epoch 190/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2326.7354 - mean_absolute_error: 30.5841\n",
      "Epoch 190: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2811.3281 - mean_absolute_error: 33.1952 - val_loss: 5156.6436 - val_mean_absolute_error: 50.9353\n",
      "Epoch 191/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1679.0114 - mean_absolute_error: 27.5101\n",
      "Epoch 191: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2840.8184 - mean_absolute_error: 33.4496 - val_loss: 5166.0752 - val_mean_absolute_error: 50.9856\n",
      "Epoch 192/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2833.3726 - mean_absolute_error: 33.2676\n",
      "Epoch 192: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2848.9900 - mean_absolute_error: 33.5811 - val_loss: 5186.1206 - val_mean_absolute_error: 51.1231\n",
      "Epoch 193/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1611.3662 - mean_absolute_error: 25.4605\n",
      "Epoch 193: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2628.8577 - mean_absolute_error: 32.1346 - val_loss: 5204.2681 - val_mean_absolute_error: 51.3070\n",
      "Epoch 194/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2505.8198 - mean_absolute_error: 31.6637\n",
      "Epoch 194: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2754.2356 - mean_absolute_error: 32.6674 - val_loss: 5217.1250 - val_mean_absolute_error: 51.4063\n",
      "Epoch 195/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3824.3303 - mean_absolute_error: 37.6053\n",
      "Epoch 195: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2729.5520 - mean_absolute_error: 32.9588 - val_loss: 5228.2153 - val_mean_absolute_error: 51.4489\n",
      "Epoch 196/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3123.9976 - mean_absolute_error: 34.4958\n",
      "Epoch 196: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2666.4343 - mean_absolute_error: 32.2153 - val_loss: 5244.5933 - val_mean_absolute_error: 51.6010\n",
      "Epoch 197/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1830.6331 - mean_absolute_error: 30.0010\n",
      "Epoch 197: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2607.2666 - mean_absolute_error: 32.4912 - val_loss: 5252.0625 - val_mean_absolute_error: 51.6351\n",
      "Epoch 198/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2093.5706 - mean_absolute_error: 30.1891\n",
      "Epoch 198: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2643.2988 - mean_absolute_error: 32.5819 - val_loss: 5266.3105 - val_mean_absolute_error: 51.7340\n",
      "Epoch 199/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3021.4780 - mean_absolute_error: 35.0970\n",
      "Epoch 199: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2737.4932 - mean_absolute_error: 32.8588 - val_loss: 5281.0879 - val_mean_absolute_error: 51.8772\n",
      "Epoch 200/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2267.5469 - mean_absolute_error: 30.3930\n",
      "Epoch 200: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2490.5496 - mean_absolute_error: 31.3538 - val_loss: 5299.1865 - val_mean_absolute_error: 52.0453\n",
      "Epoch 201/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4059.5327 - mean_absolute_error: 37.7245\n",
      "Epoch 201: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2856.1125 - mean_absolute_error: 33.2872 - val_loss: 5297.6714 - val_mean_absolute_error: 51.9406\n",
      "Epoch 202/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1891.1952 - mean_absolute_error: 27.8801\n",
      "Epoch 202: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2727.9329 - mean_absolute_error: 32.9152 - val_loss: 5305.2178 - val_mean_absolute_error: 51.9406\n",
      "Epoch 203/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2588.7832 - mean_absolute_error: 32.5824\n",
      "Epoch 203: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2645.7515 - mean_absolute_error: 32.3522 - val_loss: 5350.3652 - val_mean_absolute_error: 52.4994\n",
      "Epoch 204/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1803.0240 - mean_absolute_error: 28.2775\n",
      "Epoch 204: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2602.5400 - mean_absolute_error: 32.1817 - val_loss: 5324.2378 - val_mean_absolute_error: 52.0416\n",
      "Epoch 205/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4080.4077 - mean_absolute_error: 40.5027\n",
      "Epoch 205: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2582.9758 - mean_absolute_error: 31.7570 - val_loss: 5372.4414 - val_mean_absolute_error: 52.6543\n",
      "Epoch 206/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2631.7778 - mean_absolute_error: 34.9857\n",
      "Epoch 206: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2740.3125 - mean_absolute_error: 33.0391 - val_loss: 5347.7905 - val_mean_absolute_error: 52.2014\n",
      "Epoch 207/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3664.1550 - mean_absolute_error: 35.1484\n",
      "Epoch 207: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2884.3635 - mean_absolute_error: 33.2535 - val_loss: 5368.5879 - val_mean_absolute_error: 52.4562\n",
      "Epoch 208/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2534.7302 - mean_absolute_error: 31.8068\n",
      "Epoch 208: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2530.0977 - mean_absolute_error: 31.5081 - val_loss: 5395.1001 - val_mean_absolute_error: 52.7399\n",
      "Epoch 209/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3101.4966 - mean_absolute_error: 34.4071\n",
      "Epoch 209: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2644.9902 - mean_absolute_error: 32.6874 - val_loss: 5378.0835 - val_mean_absolute_error: 52.4145\n",
      "Epoch 210/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 4116.1953 - mean_absolute_error: 38.2875\n",
      "Epoch 210: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2774.3992 - mean_absolute_error: 32.9005 - val_loss: 5388.7817 - val_mean_absolute_error: 52.5297\n",
      "Epoch 211/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1415.8132 - mean_absolute_error: 26.3413\n",
      "Epoch 211: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2318.7524 - mean_absolute_error: 30.5351 - val_loss: 5390.3208 - val_mean_absolute_error: 52.4685\n",
      "Epoch 212/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2357.0769 - mean_absolute_error: 28.5953\n",
      "Epoch 212: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2495.9651 - mean_absolute_error: 31.2511 - val_loss: 5399.7598 - val_mean_absolute_error: 52.5319\n",
      "Epoch 213/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2377.0586 - mean_absolute_error: 33.1040\n",
      "Epoch 213: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2619.4478 - mean_absolute_error: 32.4389 - val_loss: 5408.0381 - val_mean_absolute_error: 52.5811\n",
      "Epoch 214/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2032.0049 - mean_absolute_error: 30.0312\n",
      "Epoch 214: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2389.3760 - mean_absolute_error: 30.7867 - val_loss: 5434.8149 - val_mean_absolute_error: 52.8921\n",
      "Epoch 215/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2185.5337 - mean_absolute_error: 31.9645\n",
      "Epoch 215: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2408.3816 - mean_absolute_error: 31.2273 - val_loss: 5438.0215 - val_mean_absolute_error: 52.9188\n",
      "Epoch 216/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2312.9314 - mean_absolute_error: 31.7298\n",
      "Epoch 216: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2613.9292 - mean_absolute_error: 31.9072 - val_loss: 5408.9507 - val_mean_absolute_error: 52.3720\n",
      "Epoch 217/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1522.8428 - mean_absolute_error: 26.4594\n",
      "Epoch 217: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2372.5425 - mean_absolute_error: 30.8177 - val_loss: 5466.9565 - val_mean_absolute_error: 53.2159\n",
      "Epoch 218/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2600.3955 - mean_absolute_error: 31.4733\n",
      "Epoch 218: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2563.3528 - mean_absolute_error: 31.5689 - val_loss: 5452.1206 - val_mean_absolute_error: 52.9628\n",
      "Epoch 219/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3593.3667 - mean_absolute_error: 35.9181\n",
      "Epoch 219: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2649.8164 - mean_absolute_error: 32.2839 - val_loss: 5456.6899 - val_mean_absolute_error: 52.9664\n",
      "Epoch 220/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3577.2007 - mean_absolute_error: 36.7004\n",
      "Epoch 220: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2536.1150 - mean_absolute_error: 31.5326 - val_loss: 5460.6621 - val_mean_absolute_error: 52.9879\n",
      "Epoch 221/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3248.4268 - mean_absolute_error: 33.1038\n",
      "Epoch 221: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2636.5593 - mean_absolute_error: 31.9763 - val_loss: 5464.7739 - val_mean_absolute_error: 52.9687\n",
      "Epoch 222/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3132.7197 - mean_absolute_error: 34.3144\n",
      "Epoch 222: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2470.9680 - mean_absolute_error: 31.1452 - val_loss: 5475.0684 - val_mean_absolute_error: 53.0907\n",
      "Epoch 223/1500\n",
      "\u001b[1m13/33\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2534.6750 - mean_absolute_error: 32.1215 \n",
      "Epoch 223: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2533.8369 - mean_absolute_error: 31.8390 - val_loss: 5476.2100 - val_mean_absolute_error: 53.0130\n",
      "Epoch 224/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3501.9172 - mean_absolute_error: 33.9747\n",
      "Epoch 224: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2875.0271 - mean_absolute_error: 32.8613 - val_loss: 5486.3472 - val_mean_absolute_error: 53.1072\n",
      "Epoch 225/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1697.3717 - mean_absolute_error: 26.9920\n",
      "Epoch 225: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2500.3594 - mean_absolute_error: 31.3452 - val_loss: 5510.7539 - val_mean_absolute_error: 53.3935\n",
      "Epoch 226/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2002.7961 - mean_absolute_error: 29.3446\n",
      "Epoch 226: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2452.4360 - mean_absolute_error: 31.0877 - val_loss: 5505.7456 - val_mean_absolute_error: 53.2680\n",
      "Epoch 227/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2408.3320 - mean_absolute_error: 31.6461\n",
      "Epoch 227: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2455.0447 - mean_absolute_error: 31.1152 - val_loss: 5528.6919 - val_mean_absolute_error: 53.5358\n",
      "Epoch 228/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2547.5112 - mean_absolute_error: 30.4466\n",
      "Epoch 228: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2668.0754 - mean_absolute_error: 32.1591 - val_loss: 5506.1387 - val_mean_absolute_error: 53.1161\n",
      "Epoch 229/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2225.5830 - mean_absolute_error: 29.6455\n",
      "Epoch 229: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2356.4221 - mean_absolute_error: 30.1164 - val_loss: 5504.7129 - val_mean_absolute_error: 53.0071\n",
      "Epoch 230/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2066.3770 - mean_absolute_error: 30.8101\n",
      "Epoch 230: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2497.1396 - mean_absolute_error: 31.5024 - val_loss: 5539.0659 - val_mean_absolute_error: 53.5307\n",
      "Epoch 231/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2499.1204 - mean_absolute_error: 30.1143\n",
      "Epoch 231: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2493.0071 - mean_absolute_error: 31.2112 - val_loss: 5542.9814 - val_mean_absolute_error: 53.5473\n",
      "Epoch 232/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2926.0903 - mean_absolute_error: 33.8854\n",
      "Epoch 232: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2394.4082 - mean_absolute_error: 30.8621 - val_loss: 5548.6997 - val_mean_absolute_error: 53.5824\n",
      "Epoch 233/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2678.8608 - mean_absolute_error: 31.3147\n",
      "Epoch 233: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2409.7407 - mean_absolute_error: 30.7066 - val_loss: 5520.5698 - val_mean_absolute_error: 52.9833\n",
      "Epoch 234/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2062.6018 - mean_absolute_error: 27.8442\n",
      "Epoch 234: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2417.3174 - mean_absolute_error: 30.5296 - val_loss: 5547.4121 - val_mean_absolute_error: 53.5098\n",
      "Epoch 235/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2174.5205 - mean_absolute_error: 29.4683\n",
      "Epoch 235: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2287.3176 - mean_absolute_error: 29.9352 - val_loss: 5553.0708 - val_mean_absolute_error: 53.4959\n",
      "Epoch 236/1500\n",
      "\u001b[1m24/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2408.8647 - mean_absolute_error: 30.7136 \n",
      "Epoch 236: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2416.7632 - mean_absolute_error: 30.7714 - val_loss: 5542.9771 - val_mean_absolute_error: 53.3079\n",
      "Epoch 237/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2141.5522 - mean_absolute_error: 30.7734\n",
      "Epoch 237: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2348.1135 - mean_absolute_error: 30.5055 - val_loss: 5565.3428 - val_mean_absolute_error: 53.5751\n",
      "Epoch 238/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1909.8934 - mean_absolute_error: 27.7599\n",
      "Epoch 238: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2275.8845 - mean_absolute_error: 30.2605 - val_loss: 5604.4419 - val_mean_absolute_error: 54.1032\n",
      "Epoch 239/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2299.3308 - mean_absolute_error: 29.8553\n",
      "Epoch 239: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2522.3247 - mean_absolute_error: 31.4847 - val_loss: 5578.7456 - val_mean_absolute_error: 53.7551\n",
      "Epoch 240/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2972.2749 - mean_absolute_error: 35.9078\n",
      "Epoch 240: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2470.9133 - mean_absolute_error: 31.1157 - val_loss: 5589.8477 - val_mean_absolute_error: 53.8426\n",
      "Epoch 241/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2421.1084 - mean_absolute_error: 28.0703\n",
      "Epoch 241: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2379.0049 - mean_absolute_error: 30.4503 - val_loss: 5569.9072 - val_mean_absolute_error: 53.4442\n",
      "Epoch 242/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1643.3158 - mean_absolute_error: 27.0074\n",
      "Epoch 242: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2334.4285 - mean_absolute_error: 30.3368 - val_loss: 5580.3066 - val_mean_absolute_error: 53.5936\n",
      "Epoch 243/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2321.3860 - mean_absolute_error: 29.0562\n",
      "Epoch 243: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2302.7712 - mean_absolute_error: 30.2338 - val_loss: 5611.2373 - val_mean_absolute_error: 54.0256\n",
      "Epoch 244/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2015.5732 - mean_absolute_error: 29.6259\n",
      "Epoch 244: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2368.1702 - mean_absolute_error: 31.0886 - val_loss: 5610.2695 - val_mean_absolute_error: 53.9635\n",
      "Epoch 245/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1973.4917 - mean_absolute_error: 29.6868\n",
      "Epoch 245: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2301.4592 - mean_absolute_error: 30.1837 - val_loss: 5592.0269 - val_mean_absolute_error: 53.7041\n",
      "Epoch 246/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2210.6458 - mean_absolute_error: 30.2673\n",
      "Epoch 246: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2342.0015 - mean_absolute_error: 30.3535 - val_loss: 5590.0972 - val_mean_absolute_error: 53.5565\n",
      "Epoch 247/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2379.0566 - mean_absolute_error: 31.0659\n",
      "Epoch 247: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2314.1436 - mean_absolute_error: 30.4257 - val_loss: 5587.7583 - val_mean_absolute_error: 53.5026\n",
      "Epoch 248/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2161.6433 - mean_absolute_error: 29.1892\n",
      "Epoch 248: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2346.3635 - mean_absolute_error: 30.0466 - val_loss: 5619.5161 - val_mean_absolute_error: 53.9774\n",
      "Epoch 249/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2360.2180 - mean_absolute_error: 30.8888 \n",
      "Epoch 249: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2364.6748 - mean_absolute_error: 30.8656 - val_loss: 5593.4443 - val_mean_absolute_error: 53.4515\n",
      "Epoch 250/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1536.5820 - mean_absolute_error: 25.5911\n",
      "Epoch 250: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2349.4333 - mean_absolute_error: 30.0748 - val_loss: 5631.9824 - val_mean_absolute_error: 54.1087\n",
      "Epoch 251/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3017.6597 - mean_absolute_error: 35.6574\n",
      "Epoch 251: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2456.0176 - mean_absolute_error: 31.1842 - val_loss: 5616.7158 - val_mean_absolute_error: 53.8496\n",
      "Epoch 252/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2300.7329 - mean_absolute_error: 31.9366\n",
      "Epoch 252: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2393.1184 - mean_absolute_error: 31.1308 - val_loss: 5619.6587 - val_mean_absolute_error: 53.8782\n",
      "Epoch 253/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2392.6260 - mean_absolute_error: 30.0056\n",
      "Epoch 253: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2398.6995 - mean_absolute_error: 30.3261 - val_loss: 5665.7754 - val_mean_absolute_error: 54.5303\n",
      "Epoch 254/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1497.5378 - mean_absolute_error: 26.1001\n",
      "Epoch 254: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2233.1389 - mean_absolute_error: 29.9191 - val_loss: 5627.8145 - val_mean_absolute_error: 53.9204\n",
      "Epoch 255/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1987.7039 - mean_absolute_error: 30.7028\n",
      "Epoch 255: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2268.3938 - mean_absolute_error: 29.8698 - val_loss: 5611.2871 - val_mean_absolute_error: 53.5793\n",
      "Epoch 256/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4109.4414 - mean_absolute_error: 38.3696\n",
      "Epoch 256: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2506.0178 - mean_absolute_error: 31.1481 - val_loss: 5633.7178 - val_mean_absolute_error: 53.9667\n",
      "Epoch 257/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2486.9285 - mean_absolute_error: 32.8562\n",
      "Epoch 257: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2413.9182 - mean_absolute_error: 30.7660 - val_loss: 5652.1792 - val_mean_absolute_error: 54.2316\n",
      "Epoch 258/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2012.9412 - mean_absolute_error: 30.6328\n",
      "Epoch 258: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2241.5540 - mean_absolute_error: 29.7659 - val_loss: 5634.1528 - val_mean_absolute_error: 53.8649\n",
      "Epoch 259/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2570.2751 - mean_absolute_error: 33.0741\n",
      "Epoch 259: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2367.3098 - mean_absolute_error: 30.5355 - val_loss: 5638.3535 - val_mean_absolute_error: 53.9394\n",
      "Epoch 260/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1883.7518 - mean_absolute_error: 29.0389\n",
      "Epoch 260: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2252.2776 - mean_absolute_error: 29.9996 - val_loss: 5617.8335 - val_mean_absolute_error: 53.5552\n",
      "Epoch 261/1500\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2568.6396 - mean_absolute_error: 31.7940 \n",
      "Epoch 261: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2495.0933 - mean_absolute_error: 31.3424 - val_loss: 5634.2388 - val_mean_absolute_error: 53.8477\n",
      "Epoch 262/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2149.2830 - mean_absolute_error: 30.4006\n",
      "Epoch 262: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2173.9265 - mean_absolute_error: 29.4054 - val_loss: 5657.2754 - val_mean_absolute_error: 54.1758\n",
      "Epoch 263/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2650.6113 - mean_absolute_error: 32.9724\n",
      "Epoch 263: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2488.3601 - mean_absolute_error: 31.0377 - val_loss: 5639.0068 - val_mean_absolute_error: 53.8447\n",
      "Epoch 264/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2549.9346 - mean_absolute_error: 31.4521\n",
      "Epoch 264: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2373.0544 - mean_absolute_error: 30.2065 - val_loss: 5633.8950 - val_mean_absolute_error: 53.7565\n",
      "Epoch 265/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1956.4507 - mean_absolute_error: 28.6293\n",
      "Epoch 265: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2317.7163 - mean_absolute_error: 30.3386 - val_loss: 5641.7974 - val_mean_absolute_error: 53.9375\n",
      "Epoch 266/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2048.0747 - mean_absolute_error: 27.8730\n",
      "Epoch 266: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2367.4172 - mean_absolute_error: 30.7527 - val_loss: 5629.3271 - val_mean_absolute_error: 53.5897\n",
      "Epoch 267/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1957.5929 - mean_absolute_error: 30.1093\n",
      "Epoch 267: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2390.7905 - mean_absolute_error: 30.4983 - val_loss: 5686.6245 - val_mean_absolute_error: 54.5856\n",
      "Epoch 268/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2021.6302 - mean_absolute_error: 29.9157\n",
      "Epoch 268: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2087.4817 - mean_absolute_error: 28.9761 - val_loss: 5675.1133 - val_mean_absolute_error: 54.4212\n",
      "Epoch 269/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1751.3677 - mean_absolute_error: 28.3360\n",
      "Epoch 269: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2419.5627 - mean_absolute_error: 30.9791 - val_loss: 5658.5635 - val_mean_absolute_error: 54.1705\n",
      "Epoch 270/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2504.0173 - mean_absolute_error: 34.9065\n",
      "Epoch 270: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2320.5017 - mean_absolute_error: 30.4048 - val_loss: 5679.8335 - val_mean_absolute_error: 54.5009\n",
      "Epoch 271/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3317.1528 - mean_absolute_error: 33.8916\n",
      "Epoch 271: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2329.6028 - mean_absolute_error: 30.0342 - val_loss: 5676.4619 - val_mean_absolute_error: 54.4223\n",
      "Epoch 272/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3044.8911 - mean_absolute_error: 35.8662\n",
      "Epoch 272: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2560.1987 - mean_absolute_error: 31.5214 - val_loss: 5660.1685 - val_mean_absolute_error: 54.1412\n",
      "Epoch 273/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3311.6250 - mean_absolute_error: 32.5704\n",
      "Epoch 273: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2369.9470 - mean_absolute_error: 29.9913 - val_loss: 5660.9272 - val_mean_absolute_error: 54.1748\n",
      "Epoch 274/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 1396.1362 - mean_absolute_error: 25.3598\n",
      "Epoch 274: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2199.8931 - mean_absolute_error: 29.6454 - val_loss: 5678.8252 - val_mean_absolute_error: 54.4341\n",
      "Epoch 275/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1692.7501 - mean_absolute_error: 28.0367\n",
      "Epoch 275: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2308.3391 - mean_absolute_error: 30.5738 - val_loss: 5670.8589 - val_mean_absolute_error: 54.2868\n",
      "Epoch 276/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1948.2393 - mean_absolute_error: 28.5722\n",
      "Epoch 276: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2307.6797 - mean_absolute_error: 30.0613 - val_loss: 5649.1030 - val_mean_absolute_error: 53.8880\n",
      "Epoch 277/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1701.3528 - mean_absolute_error: 26.6873\n",
      "Epoch 277: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2331.8120 - mean_absolute_error: 29.8988 - val_loss: 5640.4131 - val_mean_absolute_error: 53.6686\n",
      "Epoch 278/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2683.0825 - mean_absolute_error: 34.0061\n",
      "Epoch 278: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2387.6284 - mean_absolute_error: 30.3813 - val_loss: 5647.9019 - val_mean_absolute_error: 53.8082\n",
      "Epoch 279/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1895.1116 - mean_absolute_error: 28.8510\n",
      "Epoch 279: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2194.3982 - mean_absolute_error: 29.4265 - val_loss: 5685.4126 - val_mean_absolute_error: 54.4949\n",
      "Epoch 280/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2994.9114 - mean_absolute_error: 34.1263\n",
      "Epoch 280: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2300.6121 - mean_absolute_error: 29.8481 - val_loss: 5699.6304 - val_mean_absolute_error: 54.7104\n",
      "Epoch 281/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3164.2524 - mean_absolute_error: 36.6869\n",
      "Epoch 281: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2343.7812 - mean_absolute_error: 30.3711 - val_loss: 5656.2593 - val_mean_absolute_error: 54.0148\n",
      "Epoch 282/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2127.5364 - mean_absolute_error: 30.1919\n",
      "Epoch 282: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2260.4407 - mean_absolute_error: 29.6287 - val_loss: 5661.1050 - val_mean_absolute_error: 54.1183\n",
      "Epoch 283/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1747.8699 - mean_absolute_error: 26.4371\n",
      "Epoch 283: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2277.8804 - mean_absolute_error: 30.0916 - val_loss: 5679.4932 - val_mean_absolute_error: 54.4273\n",
      "Epoch 284/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2172.7517 - mean_absolute_error: 28.9782\n",
      "Epoch 284: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2286.5742 - mean_absolute_error: 29.7332 - val_loss: 5691.3911 - val_mean_absolute_error: 54.6498\n",
      "Epoch 285/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2316.3384 - mean_absolute_error: 29.1057\n",
      "Epoch 285: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2369.5598 - mean_absolute_error: 30.3732 - val_loss: 5668.9849 - val_mean_absolute_error: 54.3097\n",
      "Epoch 286/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2461.3289 - mean_absolute_error: 30.5002 \n",
      "Epoch 286: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2411.6060 - mean_absolute_error: 30.3064 - val_loss: 5648.7490 - val_mean_absolute_error: 53.9601\n",
      "Epoch 287/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1704.4819 - mean_absolute_error: 27.3818\n",
      "Epoch 287: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2198.1240 - mean_absolute_error: 29.2923 - val_loss: 5673.6831 - val_mean_absolute_error: 54.4480\n",
      "Epoch 288/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1716.1149 - mean_absolute_error: 26.0679\n",
      "Epoch 288: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2221.3811 - mean_absolute_error: 29.5305 - val_loss: 5661.8428 - val_mean_absolute_error: 54.2424\n",
      "Epoch 289/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1610.0026 - mean_absolute_error: 26.9117\n",
      "Epoch 289: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2386.1389 - mean_absolute_error: 30.3690 - val_loss: 5657.6240 - val_mean_absolute_error: 54.1431\n",
      "Epoch 290/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2046.6669 - mean_absolute_error: 26.5283\n",
      "Epoch 290: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2230.6716 - mean_absolute_error: 28.9642 - val_loss: 5661.9336 - val_mean_absolute_error: 54.2556\n",
      "Epoch 291/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1780.9958 - mean_absolute_error: 26.3487\n",
      "Epoch 291: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2191.6365 - mean_absolute_error: 29.3035 - val_loss: 5679.9595 - val_mean_absolute_error: 54.5341\n",
      "Epoch 292/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2525.1938 - mean_absolute_error: 31.2059\n",
      "Epoch 292: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2273.2603 - mean_absolute_error: 30.0243 - val_loss: 5671.5708 - val_mean_absolute_error: 54.4528\n",
      "Epoch 293/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3141.8254 - mean_absolute_error: 31.5375\n",
      "Epoch 293: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2365.4124 - mean_absolute_error: 29.9996 - val_loss: 5654.8774 - val_mean_absolute_error: 54.2273\n",
      "Epoch 294/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2076.3328 - mean_absolute_error: 29.0090\n",
      "Epoch 294: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2249.3372 - mean_absolute_error: 29.3974 - val_loss: 5658.9106 - val_mean_absolute_error: 54.2866\n",
      "Epoch 295/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1397.7316 - mean_absolute_error: 25.6808\n",
      "Epoch 295: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2052.0410 - mean_absolute_error: 28.2984 - val_loss: 5665.3086 - val_mean_absolute_error: 54.3630\n",
      "Epoch 296/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2734.9409 - mean_absolute_error: 33.9927\n",
      "Epoch 296: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2299.1809 - mean_absolute_error: 30.0107 - val_loss: 5627.8740 - val_mean_absolute_error: 53.7683\n",
      "Epoch 297/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2001.4583 - mean_absolute_error: 27.6416\n",
      "Epoch 297: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2277.4585 - mean_absolute_error: 29.6746 - val_loss: 5663.1006 - val_mean_absolute_error: 54.3596\n",
      "Epoch 298/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1624.3081 - mean_absolute_error: 26.4042\n",
      "Epoch 298: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2244.5208 - mean_absolute_error: 29.2874 - val_loss: 5628.7383 - val_mean_absolute_error: 53.7110\n",
      "Epoch 299/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1777.2159 - mean_absolute_error: 26.8954\n",
      "Epoch 299: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2307.8745 - mean_absolute_error: 29.5633 - val_loss: 5696.2710 - val_mean_absolute_error: 54.8430\n",
      "Epoch 300/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2062.5225 - mean_absolute_error: 28.7921\n",
      "Epoch 300: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2237.3689 - mean_absolute_error: 29.4834 - val_loss: 5701.4419 - val_mean_absolute_error: 54.9372\n",
      "Epoch 301/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2423.5940 - mean_absolute_error: 32.6085\n",
      "Epoch 301: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2384.7466 - mean_absolute_error: 30.8716 - val_loss: 5639.0552 - val_mean_absolute_error: 54.1005\n",
      "Epoch 302/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2222.2793 - mean_absolute_error: 27.8217\n",
      "Epoch 302: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2175.6084 - mean_absolute_error: 29.2031 - val_loss: 5704.0239 - val_mean_absolute_error: 55.0105\n",
      "Epoch 303/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1618.5784 - mean_absolute_error: 26.4702\n",
      "Epoch 303: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2222.2888 - mean_absolute_error: 29.5109 - val_loss: 5602.3740 - val_mean_absolute_error: 53.2483\n",
      "Epoch 304/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2077.7197 - mean_absolute_error: 29.7948\n",
      "Epoch 304: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2155.5330 - mean_absolute_error: 29.1266 - val_loss: 5645.4971 - val_mean_absolute_error: 54.2790\n",
      "Epoch 305/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 2855.5537 - mean_absolute_error: 32.2565\n",
      "Epoch 305: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2374.4812 - mean_absolute_error: 30.1466 - val_loss: 5648.6348 - val_mean_absolute_error: 54.3121\n",
      "Epoch 306/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2105.0732 - mean_absolute_error: 29.8763\n",
      "Epoch 306: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2128.3406 - mean_absolute_error: 28.9775 - val_loss: 5636.8208 - val_mean_absolute_error: 54.1964\n",
      "Epoch 307/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2128.2466 - mean_absolute_error: 29.6390\n",
      "Epoch 307: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2274.0093 - mean_absolute_error: 29.7876 - val_loss: 5628.5498 - val_mean_absolute_error: 54.0983\n",
      "Epoch 308/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1685.0073 - mean_absolute_error: 29.4036\n",
      "Epoch 308: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2175.8984 - mean_absolute_error: 29.4471 - val_loss: 5624.4131 - val_mean_absolute_error: 54.1520\n",
      "Epoch 309/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1873.5898 - mean_absolute_error: 27.5201\n",
      "Epoch 309: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2079.3689 - mean_absolute_error: 28.3564 - val_loss: 5616.1323 - val_mean_absolute_error: 54.0793\n",
      "Epoch 310/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1067.3245 - mean_absolute_error: 21.9791\n",
      "Epoch 310: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2283.8062 - mean_absolute_error: 29.6636 - val_loss: 5604.8760 - val_mean_absolute_error: 53.9417\n",
      "Epoch 311/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2288.6357 - mean_absolute_error: 29.6869 \n",
      "Epoch 311: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2280.9150 - mean_absolute_error: 29.6360 - val_loss: 5605.0186 - val_mean_absolute_error: 54.0489\n",
      "Epoch 312/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1771.3525 - mean_absolute_error: 27.1681\n",
      "Epoch 312: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2112.4229 - mean_absolute_error: 28.8051 - val_loss: 5586.1782 - val_mean_absolute_error: 53.7539\n",
      "Epoch 313/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1199.3967 - mean_absolute_error: 22.8652\n",
      "Epoch 313: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2227.6296 - mean_absolute_error: 29.4494 - val_loss: 5601.0273 - val_mean_absolute_error: 54.0962\n",
      "Epoch 314/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1649.4438 - mean_absolute_error: 23.9952\n",
      "Epoch 314: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2276.3174 - mean_absolute_error: 29.2166 - val_loss: 5574.1309 - val_mean_absolute_error: 53.7167\n",
      "Epoch 315/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2460.6045 - mean_absolute_error: 29.7996\n",
      "Epoch 315: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2186.0854 - mean_absolute_error: 29.2032 - val_loss: 5575.7534 - val_mean_absolute_error: 53.8131\n",
      "Epoch 316/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1700.5967 - mean_absolute_error: 25.2755\n",
      "Epoch 316: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2187.9790 - mean_absolute_error: 28.9050 - val_loss: 5560.6997 - val_mean_absolute_error: 53.6643\n",
      "Epoch 317/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3421.9272 - mean_absolute_error: 35.0276\n",
      "Epoch 317: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2349.6382 - mean_absolute_error: 29.7549 - val_loss: 5563.9966 - val_mean_absolute_error: 53.8123\n",
      "Epoch 318/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1837.0027 - mean_absolute_error: 28.4891\n",
      "Epoch 318: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2262.2266 - mean_absolute_error: 29.4503 - val_loss: 5618.6748 - val_mean_absolute_error: 54.5244\n",
      "Epoch 319/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1911.7332 - mean_absolute_error: 26.4207\n",
      "Epoch 319: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2193.9944 - mean_absolute_error: 29.3420 - val_loss: 5558.0474 - val_mean_absolute_error: 53.8405\n",
      "Epoch 320/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1785.0084 - mean_absolute_error: 27.4518\n",
      "Epoch 320: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2081.2637 - mean_absolute_error: 28.8749 - val_loss: 5545.8306 - val_mean_absolute_error: 53.6629\n",
      "Epoch 321/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 992.7770 - mean_absolute_error: 21.0987\n",
      "Epoch 321: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2047.0240 - mean_absolute_error: 27.5531 - val_loss: 5563.2910 - val_mean_absolute_error: 53.9927\n",
      "Epoch 322/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2711.2556 - mean_absolute_error: 32.6267\n",
      "Epoch 322: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2176.5886 - mean_absolute_error: 29.2622 - val_loss: 5559.2651 - val_mean_absolute_error: 53.9766\n",
      "Epoch 323/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2208.4187 - mean_absolute_error: 29.8919 \n",
      "Epoch 323: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2203.9705 - mean_absolute_error: 29.6987 - val_loss: 5525.2305 - val_mean_absolute_error: 53.6025\n",
      "Epoch 324/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2218.5205 - mean_absolute_error: 27.3672\n",
      "Epoch 324: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2204.7095 - mean_absolute_error: 29.0365 - val_loss: 5483.6055 - val_mean_absolute_error: 52.9732\n",
      "Epoch 325/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2751.9021 - mean_absolute_error: 32.1742\n",
      "Epoch 325: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2166.3674 - mean_absolute_error: 28.8336 - val_loss: 5475.3315 - val_mean_absolute_error: 52.9326\n",
      "Epoch 326/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1574.7502 - mean_absolute_error: 26.7458\n",
      "Epoch 326: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2126.2017 - mean_absolute_error: 28.4857 - val_loss: 5507.3188 - val_mean_absolute_error: 53.5510\n",
      "Epoch 327/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1954.9999 - mean_absolute_error: 28.2597\n",
      "Epoch 327: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2222.8030 - mean_absolute_error: 29.0544 - val_loss: 5459.5981 - val_mean_absolute_error: 52.8232\n",
      "Epoch 328/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1216.5425 - mean_absolute_error: 22.4559\n",
      "Epoch 328: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2183.6409 - mean_absolute_error: 28.3992 - val_loss: 5461.4443 - val_mean_absolute_error: 52.9909\n",
      "Epoch 329/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1472.5516 - mean_absolute_error: 23.1098\n",
      "Epoch 329: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2167.8550 - mean_absolute_error: 28.8837 - val_loss: 5422.6074 - val_mean_absolute_error: 52.2932\n",
      "Epoch 330/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1119.7178 - mean_absolute_error: 22.9406\n",
      "Epoch 330: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2172.1536 - mean_absolute_error: 28.5129 - val_loss: 5468.4585 - val_mean_absolute_error: 53.3079\n",
      "Epoch 331/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3281.2129 - mean_absolute_error: 33.4644\n",
      "Epoch 331: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2298.4392 - mean_absolute_error: 29.2867 - val_loss: 5455.4780 - val_mean_absolute_error: 53.2037\n",
      "Epoch 332/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3062.8347 - mean_absolute_error: 32.3704\n",
      "Epoch 332: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2414.5955 - mean_absolute_error: 30.2061 - val_loss: 5416.3062 - val_mean_absolute_error: 52.5817\n",
      "Epoch 333/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2517.0254 - mean_absolute_error: 31.2595\n",
      "Epoch 333: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2152.2549 - mean_absolute_error: 28.4261 - val_loss: 5445.7417 - val_mean_absolute_error: 53.1532\n",
      "Epoch 334/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2252.6807 - mean_absolute_error: 29.2577\n",
      "Epoch 334: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2164.1621 - mean_absolute_error: 29.1227 - val_loss: 5431.2183 - val_mean_absolute_error: 53.0248\n",
      "Epoch 335/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2058.7708 - mean_absolute_error: 28.3792 \n",
      "Epoch 335: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2069.6719 - mean_absolute_error: 28.4136 - val_loss: 5413.1724 - val_mean_absolute_error: 52.8306\n",
      "Epoch 336/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2694.1064 - mean_absolute_error: 32.0850\n",
      "Epoch 336: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2126.4978 - mean_absolute_error: 28.7439 - val_loss: 5386.1221 - val_mean_absolute_error: 52.5363\n",
      "Epoch 337/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2032.4131 - mean_absolute_error: 27.2751\n",
      "Epoch 337: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2086.8916 - mean_absolute_error: 28.2504 - val_loss: 5406.6377 - val_mean_absolute_error: 52.9620\n",
      "Epoch 338/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1509.8457 - mean_absolute_error: 23.3089\n",
      "Epoch 338: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2134.6038 - mean_absolute_error: 28.5529 - val_loss: 5384.7271 - val_mean_absolute_error: 52.7036\n",
      "Epoch 339/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1736.0330 - mean_absolute_error: 24.0572\n",
      "Epoch 339: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2210.5842 - mean_absolute_error: 28.6923 - val_loss: 5361.4785 - val_mean_absolute_error: 52.4376\n",
      "Epoch 340/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1700.7416 - mean_absolute_error: 26.5878\n",
      "Epoch 340: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2010.7019 - mean_absolute_error: 27.8808 - val_loss: 5376.2710 - val_mean_absolute_error: 52.7516\n",
      "Epoch 341/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2243.2065 - mean_absolute_error: 29.2095\n",
      "Epoch 341: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2085.0059 - mean_absolute_error: 28.3632 - val_loss: 5349.0630 - val_mean_absolute_error: 52.4818\n",
      "Epoch 342/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1502.3367 - mean_absolute_error: 25.3574\n",
      "Epoch 342: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2073.8306 - mean_absolute_error: 27.9408 - val_loss: 5327.0244 - val_mean_absolute_error: 52.2253\n",
      "Epoch 343/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2612.2695 - mean_absolute_error: 29.6160\n",
      "Epoch 343: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2260.9517 - mean_absolute_error: 28.9280 - val_loss: 5340.7285 - val_mean_absolute_error: 52.5176\n",
      "Epoch 344/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1637.1445 - mean_absolute_error: 25.6128\n",
      "Epoch 344: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1950.2606 - mean_absolute_error: 27.5710 - val_loss: 5314.1489 - val_mean_absolute_error: 52.1889\n",
      "Epoch 345/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2719.8457 - mean_absolute_error: 32.4739\n",
      "Epoch 345: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2139.9829 - mean_absolute_error: 28.5698 - val_loss: 5309.0254 - val_mean_absolute_error: 52.1921\n",
      "Epoch 346/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2580.7947 - mean_absolute_error: 29.2368\n",
      "Epoch 346: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2123.3818 - mean_absolute_error: 27.8517 - val_loss: 5274.7363 - val_mean_absolute_error: 51.8062\n",
      "Epoch 347/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1891.8459 - mean_absolute_error: 28.3124\n",
      "Epoch 347: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2054.8447 - mean_absolute_error: 28.2987 - val_loss: 5279.7876 - val_mean_absolute_error: 51.9967\n",
      "Epoch 348/1500\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2010.5669 - mean_absolute_error: 28.3114 \n",
      "Epoch 348: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2030.7526 - mean_absolute_error: 28.2215 - val_loss: 5298.2651 - val_mean_absolute_error: 52.3842\n",
      "Epoch 349/1500\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2204.2671 - mean_absolute_error: 29.2123 \n",
      "Epoch 349: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2173.5647 - mean_absolute_error: 28.9596 - val_loss: 5252.6528 - val_mean_absolute_error: 51.7635\n",
      "Epoch 350/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3327.0459 - mean_absolute_error: 35.4751\n",
      "Epoch 350: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2265.2288 - mean_absolute_error: 29.2924 - val_loss: 5243.2280 - val_mean_absolute_error: 51.7338\n",
      "Epoch 351/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3471.9302 - mean_absolute_error: 33.2336\n",
      "Epoch 351: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2235.0481 - mean_absolute_error: 28.6930 - val_loss: 5251.0801 - val_mean_absolute_error: 51.9927\n",
      "Epoch 352/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1936.1045 - mean_absolute_error: 26.4664\n",
      "Epoch 352: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2071.1570 - mean_absolute_error: 27.9637 - val_loss: 5214.9917 - val_mean_absolute_error: 51.4327\n",
      "Epoch 353/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2719.3872 - mean_absolute_error: 30.1815\n",
      "Epoch 353: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2225.1921 - mean_absolute_error: 28.8013 - val_loss: 5216.2090 - val_mean_absolute_error: 51.7002\n",
      "Epoch 354/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1750.1243 - mean_absolute_error: 26.9440\n",
      "Epoch 354: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1975.7198 - mean_absolute_error: 27.8071 - val_loss: 5172.4312 - val_mean_absolute_error: 51.0330\n",
      "Epoch 355/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1907.7297 - mean_absolute_error: 27.0662\n",
      "Epoch 355: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1978.5493 - mean_absolute_error: 27.5698 - val_loss: 5198.4272 - val_mean_absolute_error: 51.6006\n",
      "Epoch 356/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2869.3291 - mean_absolute_error: 31.4465\n",
      "Epoch 356: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2186.4082 - mean_absolute_error: 28.7147 - val_loss: 5214.2495 - val_mean_absolute_error: 51.9792\n",
      "Epoch 357/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1775.5647 - mean_absolute_error: 27.5634\n",
      "Epoch 357: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1958.1488 - mean_absolute_error: 27.6177 - val_loss: 5171.1782 - val_mean_absolute_error: 51.4143\n",
      "Epoch 358/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2845.0854 - mean_absolute_error: 31.2621\n",
      "Epoch 358: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2181.5430 - mean_absolute_error: 29.0388 - val_loss: 5128.0269 - val_mean_absolute_error: 50.6832\n",
      "Epoch 359/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2828.9043 - mean_absolute_error: 32.7665\n",
      "Epoch 359: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2189.4814 - mean_absolute_error: 28.7169 - val_loss: 5147.9678 - val_mean_absolute_error: 51.3568\n",
      "Epoch 360/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1959.7148 - mean_absolute_error: 27.1218 \n",
      "Epoch 360: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1984.3521 - mean_absolute_error: 27.3098 - val_loss: 5134.0903 - val_mean_absolute_error: 51.2240\n",
      "Epoch 361/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1955.9302 - mean_absolute_error: 27.4060 \n",
      "Epoch 361: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1967.0934 - mean_absolute_error: 27.4518 - val_loss: 5143.5229 - val_mean_absolute_error: 51.4855\n",
      "Epoch 362/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2551.4814 - mean_absolute_error: 31.6469\n",
      "Epoch 362: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2076.9434 - mean_absolute_error: 28.2205 - val_loss: 5125.0044 - val_mean_absolute_error: 51.3638\n",
      "Epoch 363/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1785.0115 - mean_absolute_error: 26.7836\n",
      "Epoch 363: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1893.9993 - mean_absolute_error: 27.1380 - val_loss: 5120.6665 - val_mean_absolute_error: 51.3847\n",
      "Epoch 364/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1759.6902 - mean_absolute_error: 26.9828\n",
      "Epoch 364: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2031.9226 - mean_absolute_error: 27.5908 - val_loss: 5079.6133 - val_mean_absolute_error: 50.8266\n",
      "Epoch 365/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1379.0491 - mean_absolute_error: 24.6013\n",
      "Epoch 365: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2036.2495 - mean_absolute_error: 27.9877 - val_loss: 5043.0684 - val_mean_absolute_error: 50.3525\n",
      "Epoch 366/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3104.5176 - mean_absolute_error: 37.1462\n",
      "Epoch 366: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2145.8884 - mean_absolute_error: 28.6610 - val_loss: 5047.3413 - val_mean_absolute_error: 50.5618\n",
      "Epoch 367/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1593.5626 - mean_absolute_error: 23.4700\n",
      "Epoch 367: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2012.1820 - mean_absolute_error: 27.2317 - val_loss: 5028.4365 - val_mean_absolute_error: 50.4127\n",
      "Epoch 368/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1428.3271 - mean_absolute_error: 23.5880\n",
      "Epoch 368: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2033.5312 - mean_absolute_error: 27.2793 - val_loss: 5009.8462 - val_mean_absolute_error: 50.2891\n",
      "Epoch 369/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1789.5232 - mean_absolute_error: 26.9969\n",
      "Epoch 369: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2007.5186 - mean_absolute_error: 27.3887 - val_loss: 5051.1128 - val_mean_absolute_error: 51.0283\n",
      "Epoch 370/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1942.2531 - mean_absolute_error: 28.1077\n",
      "Epoch 370: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2056.8027 - mean_absolute_error: 28.1602 - val_loss: 5010.6216 - val_mean_absolute_error: 50.6073\n",
      "Epoch 371/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1075.6919 - mean_absolute_error: 22.3784\n",
      "Epoch 371: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1862.1718 - mean_absolute_error: 26.8253 - val_loss: 4994.0166 - val_mean_absolute_error: 50.4981\n",
      "Epoch 372/1500\n",
      "\u001b[1m21/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2110.4578 - mean_absolute_error: 28.1272 \n",
      "Epoch 372: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2097.2632 - mean_absolute_error: 28.0761 - val_loss: 4967.8345 - val_mean_absolute_error: 50.1861\n",
      "Epoch 373/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2224.1521 - mean_absolute_error: 30.1876\n",
      "Epoch 373: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1917.4440 - mean_absolute_error: 27.0684 - val_loss: 4962.0381 - val_mean_absolute_error: 50.1878\n",
      "Epoch 374/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1950.4276 - mean_absolute_error: 26.3144\n",
      "Epoch 374: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2043.8196 - mean_absolute_error: 27.9272 - val_loss: 4934.8130 - val_mean_absolute_error: 49.9429\n",
      "Epoch 375/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1440.1865 - mean_absolute_error: 24.0476\n",
      "Epoch 375: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1949.5126 - mean_absolute_error: 27.1115 - val_loss: 4933.4932 - val_mean_absolute_error: 50.1227\n",
      "Epoch 376/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1425.2559 - mean_absolute_error: 25.9731\n",
      "Epoch 376: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1982.1703 - mean_absolute_error: 27.6744 - val_loss: 4905.4155 - val_mean_absolute_error: 49.7904\n",
      "Epoch 377/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1950.9895 - mean_absolute_error: 27.5626\n",
      "Epoch 377: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1993.3596 - mean_absolute_error: 27.5496 - val_loss: 4880.8862 - val_mean_absolute_error: 49.5096\n",
      "Epoch 378/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1597.0303 - mean_absolute_error: 24.8310\n",
      "Epoch 378: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1913.1028 - mean_absolute_error: 27.0592 - val_loss: 4874.2300 - val_mean_absolute_error: 49.5692\n",
      "Epoch 379/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2088.9739 - mean_absolute_error: 29.1335\n",
      "Epoch 379: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2010.3236 - mean_absolute_error: 27.6901 - val_loss: 4848.7324 - val_mean_absolute_error: 49.2175\n",
      "Epoch 380/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2102.4026 - mean_absolute_error: 28.5446\n",
      "Epoch 380: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2089.8489 - mean_absolute_error: 27.6430 - val_loss: 4853.5205 - val_mean_absolute_error: 49.5376\n",
      "Epoch 381/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1198.1140 - mean_absolute_error: 23.2543\n",
      "Epoch 381: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1956.5441 - mean_absolute_error: 26.8520 - val_loss: 4837.1240 - val_mean_absolute_error: 49.3686\n",
      "Epoch 382/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1642.3568 - mean_absolute_error: 25.4466\n",
      "Epoch 382: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1766.9084 - mean_absolute_error: 26.0691 - val_loss: 4815.0898 - val_mean_absolute_error: 49.1377\n",
      "Epoch 383/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1759.8802 - mean_absolute_error: 26.5732\n",
      "Epoch 383: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1932.3876 - mean_absolute_error: 26.9197 - val_loss: 4801.1519 - val_mean_absolute_error: 49.1550\n",
      "Epoch 384/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1957.6041 - mean_absolute_error: 26.7237 \n",
      "Epoch 384: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1967.0468 - mean_absolute_error: 26.8271 - val_loss: 4798.1587 - val_mean_absolute_error: 49.2387\n",
      "Epoch 385/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1539.2915 - mean_absolute_error: 22.2965\n",
      "Epoch 385: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1956.6621 - mean_absolute_error: 26.8154 - val_loss: 4799.0854 - val_mean_absolute_error: 49.3885\n",
      "Epoch 386/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1591.5344 - mean_absolute_error: 25.5217\n",
      "Epoch 386: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1950.7869 - mean_absolute_error: 27.1674 - val_loss: 4766.0771 - val_mean_absolute_error: 49.0548\n",
      "Epoch 387/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2602.8091 - mean_absolute_error: 28.9680\n",
      "Epoch 387: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1974.2632 - mean_absolute_error: 26.9657 - val_loss: 4756.2954 - val_mean_absolute_error: 49.0824\n",
      "Epoch 388/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2333.4941 - mean_absolute_error: 29.6782\n",
      "Epoch 388: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1979.4152 - mean_absolute_error: 27.1823 - val_loss: 4720.8354 - val_mean_absolute_error: 48.6207\n",
      "Epoch 389/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2194.2278 - mean_absolute_error: 28.3456\n",
      "Epoch 389: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2019.9016 - mean_absolute_error: 27.3434 - val_loss: 4735.9824 - val_mean_absolute_error: 48.9865\n",
      "Epoch 390/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1760.8767 - mean_absolute_error: 22.0565\n",
      "Epoch 390: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1863.8787 - mean_absolute_error: 25.9711 - val_loss: 4675.1699 - val_mean_absolute_error: 48.1461\n",
      "Epoch 391/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1506.0990 - mean_absolute_error: 22.4350\n",
      "Epoch 391: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1849.5625 - mean_absolute_error: 26.2867 - val_loss: 4693.8428 - val_mean_absolute_error: 48.7256\n",
      "Epoch 392/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1729.6353 - mean_absolute_error: 25.5247\n",
      "Epoch 392: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1896.2190 - mean_absolute_error: 26.7842 - val_loss: 4652.2065 - val_mean_absolute_error: 48.2159\n",
      "Epoch 393/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3085.8342 - mean_absolute_error: 33.3839\n",
      "Epoch 393: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1965.7023 - mean_absolute_error: 27.2727 - val_loss: 4652.3115 - val_mean_absolute_error: 48.3453\n",
      "Epoch 394/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1163.7140 - mean_absolute_error: 22.4784\n",
      "Epoch 394: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1926.7261 - mean_absolute_error: 27.1132 - val_loss: 4626.6533 - val_mean_absolute_error: 48.1058\n",
      "Epoch 395/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2243.2095 - mean_absolute_error: 28.8806\n",
      "Epoch 395: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2026.7428 - mean_absolute_error: 27.1313 - val_loss: 4614.0859 - val_mean_absolute_error: 48.1177\n",
      "Epoch 396/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 2503.4819 - mean_absolute_error: 31.6025\n",
      "Epoch 396: val_loss did not improve from 4596.63672\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2057.1511 - mean_absolute_error: 27.5450 - val_loss: 4606.1807 - val_mean_absolute_error: 48.1310\n",
      "Epoch 397/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1552.4243 - mean_absolute_error: 24.1696\n",
      "Epoch 397: val_loss improved from 4596.63672 to 4580.39209, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1907.3157 - mean_absolute_error: 26.7665 - val_loss: 4580.3921 - val_mean_absolute_error: 47.9188\n",
      "Epoch 398/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1594.5684 - mean_absolute_error: 23.9891\n",
      "Epoch 398: val_loss improved from 4580.39209 to 4534.72754, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2149.1790 - mean_absolute_error: 27.6816 - val_loss: 4534.7275 - val_mean_absolute_error: 47.2708\n",
      "Epoch 399/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1336.3079 - mean_absolute_error: 23.3218\n",
      "Epoch 399: val_loss improved from 4534.72754 to 4531.20947, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1793.9293 - mean_absolute_error: 25.9603 - val_loss: 4531.2095 - val_mean_absolute_error: 47.4975\n",
      "Epoch 400/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1931.5819 - mean_absolute_error: 23.4698\n",
      "Epoch 400: val_loss improved from 4531.20947 to 4519.79346, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2037.2710 - mean_absolute_error: 27.0610 - val_loss: 4519.7935 - val_mean_absolute_error: 47.5348\n",
      "Epoch 401/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1691.1655 - mean_absolute_error: 27.3306\n",
      "Epoch 401: val_loss improved from 4519.79346 to 4505.61670, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1763.5519 - mean_absolute_error: 25.6805 - val_loss: 4505.6167 - val_mean_absolute_error: 47.4421\n",
      "Epoch 402/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2265.1343 - mean_absolute_error: 25.2795\n",
      "Epoch 402: val_loss improved from 4505.61670 to 4463.10303, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1933.9489 - mean_absolute_error: 26.2773 - val_loss: 4463.1030 - val_mean_absolute_error: 46.9334\n",
      "Epoch 403/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1632.9082 - mean_absolute_error: 23.5990\n",
      "Epoch 403: val_loss improved from 4463.10303 to 4448.86279, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1798.2858 - mean_absolute_error: 25.4591 - val_loss: 4448.8628 - val_mean_absolute_error: 46.8986\n",
      "Epoch 404/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1911.3535 - mean_absolute_error: 26.4680\n",
      "Epoch 404: val_loss improved from 4448.86279 to 4440.12598, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1895.4497 - mean_absolute_error: 26.4944 - val_loss: 4440.1260 - val_mean_absolute_error: 47.0113\n",
      "Epoch 405/1500\n",
      "\u001b[1m17/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1909.9811 - mean_absolute_error: 26.2947\n",
      "Epoch 405: val_loss improved from 4440.12598 to 4437.94629, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1913.6613 - mean_absolute_error: 26.3362 - val_loss: 4437.9463 - val_mean_absolute_error: 47.1653\n",
      "Epoch 406/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2195.9851 - mean_absolute_error: 28.6369\n",
      "Epoch 406: val_loss improved from 4437.94629 to 4397.06396, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1991.3496 - mean_absolute_error: 27.0435 - val_loss: 4397.0640 - val_mean_absolute_error: 46.7351\n",
      "Epoch 407/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1676.7106 - mean_absolute_error: 26.1585\n",
      "Epoch 407: val_loss improved from 4397.06396 to 4375.77246, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1886.4103 - mean_absolute_error: 26.3578 - val_loss: 4375.7725 - val_mean_absolute_error: 46.5235\n",
      "Epoch 408/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1751.1532 - mean_absolute_error: 26.3851\n",
      "Epoch 408: val_loss improved from 4375.77246 to 4352.05615, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1885.9783 - mean_absolute_error: 26.3068 - val_loss: 4352.0562 - val_mean_absolute_error: 46.3272\n",
      "Epoch 409/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1245.6272 - mean_absolute_error: 22.3247\n",
      "Epoch 409: val_loss improved from 4352.05615 to 4328.61865, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1915.1676 - mean_absolute_error: 26.0700 - val_loss: 4328.6187 - val_mean_absolute_error: 46.2486\n",
      "Epoch 410/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2496.0737 - mean_absolute_error: 25.9881\n",
      "Epoch 410: val_loss did not improve from 4328.61865\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1877.9098 - mean_absolute_error: 25.8986 - val_loss: 4346.3364 - val_mean_absolute_error: 46.7121\n",
      "Epoch 411/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1542.1406 - mean_absolute_error: 25.4135\n",
      "Epoch 411: val_loss improved from 4328.61865 to 4291.89307, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1752.5731 - mean_absolute_error: 25.5578 - val_loss: 4291.8931 - val_mean_absolute_error: 45.9438\n",
      "Epoch 412/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1226.7695 - mean_absolute_error: 20.8871\n",
      "Epoch 412: val_loss improved from 4291.89307 to 4273.87354, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1821.1016 - mean_absolute_error: 25.7118 - val_loss: 4273.8735 - val_mean_absolute_error: 45.8280\n",
      "Epoch 413/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1934.3413 - mean_absolute_error: 24.4630\n",
      "Epoch 413: val_loss improved from 4273.87354 to 4254.92773, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1783.7598 - mean_absolute_error: 25.2947 - val_loss: 4254.9277 - val_mean_absolute_error: 45.8109\n",
      "Epoch 414/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1915.5392 - mean_absolute_error: 27.3646\n",
      "Epoch 414: val_loss improved from 4254.92773 to 4251.78174, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1888.8802 - mean_absolute_error: 25.9859 - val_loss: 4251.7817 - val_mean_absolute_error: 45.9552\n",
      "Epoch 415/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1938.6595 - mean_absolute_error: 26.7556 \n",
      "Epoch 415: val_loss improved from 4251.78174 to 4212.64258, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1904.1390 - mean_absolute_error: 26.5186 - val_loss: 4212.6426 - val_mean_absolute_error: 45.4481\n",
      "Epoch 416/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1228.3826 - mean_absolute_error: 22.2206\n",
      "Epoch 416: val_loss improved from 4212.64258 to 4206.10938, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1631.6555 - mean_absolute_error: 24.8390 - val_loss: 4206.1094 - val_mean_absolute_error: 45.6289\n",
      "Epoch 417/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1647.1799 - mean_absolute_error: 25.7226\n",
      "Epoch 417: val_loss improved from 4206.10938 to 4190.13135, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1628.4113 - mean_absolute_error: 24.6599 - val_loss: 4190.1313 - val_mean_absolute_error: 45.5945\n",
      "Epoch 418/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3077.7861 - mean_absolute_error: 35.6724\n",
      "Epoch 418: val_loss improved from 4190.13135 to 4156.84131, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2030.0342 - mean_absolute_error: 27.3417 - val_loss: 4156.8413 - val_mean_absolute_error: 45.2124\n",
      "Epoch 419/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1950.4187 - mean_absolute_error: 25.5518\n",
      "Epoch 419: val_loss improved from 4156.84131 to 4135.62939, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1814.6461 - mean_absolute_error: 25.5107 - val_loss: 4135.6294 - val_mean_absolute_error: 45.0504\n",
      "Epoch 420/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2192.6562 - mean_absolute_error: 28.4021\n",
      "Epoch 420: val_loss improved from 4135.62939 to 4121.93115, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1763.0187 - mean_absolute_error: 25.6400 - val_loss: 4121.9312 - val_mean_absolute_error: 45.1029\n",
      "Epoch 421/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1882.5581 - mean_absolute_error: 25.8194\n",
      "Epoch 421: val_loss improved from 4121.93115 to 4093.99561, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1736.7919 - mean_absolute_error: 25.0049 - val_loss: 4093.9956 - val_mean_absolute_error: 44.8863\n",
      "Epoch 422/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1778.5518 - mean_absolute_error: 25.2783\n",
      "Epoch 422: val_loss improved from 4093.99561 to 4078.33716, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1641.8214 - mean_absolute_error: 24.4873 - val_loss: 4078.3372 - val_mean_absolute_error: 44.8645\n",
      "Epoch 423/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1455.3591 - mean_absolute_error: 24.3588\n",
      "Epoch 423: val_loss improved from 4078.33716 to 4075.95361, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1726.1667 - mean_absolute_error: 25.2879 - val_loss: 4075.9536 - val_mean_absolute_error: 44.9790\n",
      "Epoch 424/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2517.6138 - mean_absolute_error: 25.9672\n",
      "Epoch 424: val_loss improved from 4075.95361 to 4038.18286, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1778.7061 - mean_absolute_error: 25.1444 - val_loss: 4038.1829 - val_mean_absolute_error: 44.5549\n",
      "Epoch 425/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1772.5751 - mean_absolute_error: 25.3004 \n",
      "Epoch 425: val_loss did not improve from 4038.18286\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1770.8213 - mean_absolute_error: 25.2871 - val_loss: 4042.0325 - val_mean_absolute_error: 44.8955\n",
      "Epoch 426/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1276.1531 - mean_absolute_error: 22.5408\n",
      "Epoch 426: val_loss improved from 4038.18286 to 4011.16211, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1821.9410 - mean_absolute_error: 25.5203 - val_loss: 4011.1621 - val_mean_absolute_error: 44.5623\n",
      "Epoch 427/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1473.3047 - mean_absolute_error: 22.5967\n",
      "Epoch 427: val_loss improved from 4011.16211 to 3993.60596, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1660.4698 - mean_absolute_error: 24.8249 - val_loss: 3993.6060 - val_mean_absolute_error: 44.4962\n",
      "Epoch 428/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1213.8987 - mean_absolute_error: 21.5496\n",
      "Epoch 428: val_loss improved from 3993.60596 to 3947.87842, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1705.1870 - mean_absolute_error: 25.0564 - val_loss: 3947.8784 - val_mean_absolute_error: 43.9031\n",
      "Epoch 429/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1460.9766 - mean_absolute_error: 23.0253\n",
      "Epoch 429: val_loss improved from 3947.87842 to 3937.43311, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1790.0177 - mean_absolute_error: 24.9518 - val_loss: 3937.4331 - val_mean_absolute_error: 43.8986\n",
      "Epoch 430/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2126.4600 - mean_absolute_error: 26.9658\n",
      "Epoch 430: val_loss improved from 3937.43311 to 3915.05103, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1701.7076 - mean_absolute_error: 24.8896 - val_loss: 3915.0510 - val_mean_absolute_error: 43.7808\n",
      "Epoch 431/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1997.7327 - mean_absolute_error: 26.8137\n",
      "Epoch 431: val_loss improved from 3915.05103 to 3888.68286, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1717.5188 - mean_absolute_error: 24.8262 - val_loss: 3888.6829 - val_mean_absolute_error: 43.6137\n",
      "Epoch 432/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1169.6758 - mean_absolute_error: 20.8804\n",
      "Epoch 432: val_loss improved from 3888.68286 to 3875.06714, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1613.2740 - mean_absolute_error: 24.3502 - val_loss: 3875.0671 - val_mean_absolute_error: 43.5359\n",
      "Epoch 433/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1644.0530 - mean_absolute_error: 22.5615\n",
      "Epoch 433: val_loss improved from 3875.06714 to 3853.88550, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1658.3557 - mean_absolute_error: 24.3658 - val_loss: 3853.8855 - val_mean_absolute_error: 43.4285\n",
      "Epoch 434/1500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1904.6444 - mean_absolute_error: 25.7548 \n",
      "Epoch 434: val_loss improved from 3853.88550 to 3834.55176, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1829.5930 - mean_absolute_error: 25.3576 - val_loss: 3834.5518 - val_mean_absolute_error: 43.2574\n",
      "Epoch 435/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1981.1842 - mean_absolute_error: 27.0128\n",
      "Epoch 435: val_loss improved from 3834.55176 to 3822.41089, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1755.5641 - mean_absolute_error: 24.7702 - val_loss: 3822.4109 - val_mean_absolute_error: 43.3334\n",
      "Epoch 436/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1214.7982 - mean_absolute_error: 20.4155\n",
      "Epoch 436: val_loss improved from 3822.41089 to 3803.90308, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1611.6299 - mean_absolute_error: 24.0670 - val_loss: 3803.9031 - val_mean_absolute_error: 43.2533\n",
      "Epoch 437/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1789.1697 - mean_absolute_error: 26.0602\n",
      "Epoch 437: val_loss improved from 3803.90308 to 3795.73901, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1735.8572 - mean_absolute_error: 24.9531 - val_loss: 3795.7390 - val_mean_absolute_error: 43.3269\n",
      "Epoch 438/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1361.8687 - mean_absolute_error: 23.5150\n",
      "Epoch 438: val_loss improved from 3795.73901 to 3770.87939, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1653.9431 - mean_absolute_error: 24.4618 - val_loss: 3770.8794 - val_mean_absolute_error: 43.1016\n",
      "Epoch 439/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1849.1096 - mean_absolute_error: 26.5115\n",
      "Epoch 439: val_loss improved from 3770.87939 to 3735.54565, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1686.3391 - mean_absolute_error: 24.7256 - val_loss: 3735.5457 - val_mean_absolute_error: 42.7208\n",
      "Epoch 440/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2042.2856 - mean_absolute_error: 26.5205\n",
      "Epoch 440: val_loss improved from 3735.54565 to 3716.57202, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1700.0560 - mean_absolute_error: 24.5461 - val_loss: 3716.5720 - val_mean_absolute_error: 42.6227\n",
      "Epoch 441/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1109.6342 - mean_absolute_error: 22.6759\n",
      "Epoch 441: val_loss improved from 3716.57202 to 3696.48120, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1585.7450 - mean_absolute_error: 24.0842 - val_loss: 3696.4812 - val_mean_absolute_error: 42.4899\n",
      "Epoch 442/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1360.0740 - mean_absolute_error: 24.4923\n",
      "Epoch 442: val_loss improved from 3696.48120 to 3685.00928, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1629.2589 - mean_absolute_error: 24.5354 - val_loss: 3685.0093 - val_mean_absolute_error: 42.5128\n",
      "Epoch 443/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1248.0520 - mean_absolute_error: 22.3671\n",
      "Epoch 443: val_loss did not improve from 3685.00928\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1550.2499 - mean_absolute_error: 23.5092 - val_loss: 3687.6448 - val_mean_absolute_error: 42.7447\n",
      "Epoch 444/1500\n",
      "\u001b[1m17/33\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1569.4652 - mean_absolute_error: 24.3670 \n",
      "Epoch 444: val_loss improved from 3685.00928 to 3665.85254, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1589.0975 - mean_absolute_error: 24.2134 - val_loss: 3665.8525 - val_mean_absolute_error: 42.5754\n",
      "Epoch 445/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1253.9358 - mean_absolute_error: 21.5780\n",
      "Epoch 445: val_loss improved from 3665.85254 to 3620.51367, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1582.0674 - mean_absolute_error: 24.3394 - val_loss: 3620.5137 - val_mean_absolute_error: 42.0675\n",
      "Epoch 446/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2419.2812 - mean_absolute_error: 27.0356\n",
      "Epoch 446: val_loss improved from 3620.51367 to 3597.02637, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1687.0403 - mean_absolute_error: 24.0248 - val_loss: 3597.0264 - val_mean_absolute_error: 41.8638\n",
      "Epoch 447/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1542.6560 - mean_absolute_error: 24.1612\n",
      "Epoch 447: val_loss improved from 3597.02637 to 3570.83618, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1635.4106 - mean_absolute_error: 24.0979 - val_loss: 3570.8362 - val_mean_absolute_error: 41.5626\n",
      "Epoch 448/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1925.1755 - mean_absolute_error: 26.9261\n",
      "Epoch 448: val_loss improved from 3570.83618 to 3556.77124, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1702.7056 - mean_absolute_error: 24.5472 - val_loss: 3556.7712 - val_mean_absolute_error: 41.5884\n",
      "Epoch 449/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 977.8376 - mean_absolute_error: 19.9321\n",
      "Epoch 449: val_loss improved from 3556.77124 to 3551.18262, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1603.4205 - mean_absolute_error: 23.9253 - val_loss: 3551.1826 - val_mean_absolute_error: 41.7465\n",
      "Epoch 450/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1419.6273 - mean_absolute_error: 24.6366\n",
      "Epoch 450: val_loss improved from 3551.18262 to 3518.02148, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1591.0251 - mean_absolute_error: 24.0038 - val_loss: 3518.0215 - val_mean_absolute_error: 41.3461\n",
      "Epoch 451/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 784.6795 - mean_absolute_error: 18.3950\n",
      "Epoch 451: val_loss improved from 3518.02148 to 3493.68579, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1555.9496 - mean_absolute_error: 23.5388 - val_loss: 3493.6858 - val_mean_absolute_error: 41.1069\n",
      "Epoch 452/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 980.0613 - mean_absolute_error: 20.5947\n",
      "Epoch 452: val_loss improved from 3493.68579 to 3474.72021, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1521.1453 - mean_absolute_error: 23.1336 - val_loss: 3474.7202 - val_mean_absolute_error: 41.0255\n",
      "Epoch 453/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1742.2860 - mean_absolute_error: 24.4507\n",
      "Epoch 453: val_loss improved from 3474.72021 to 3457.54590, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1642.0233 - mean_absolute_error: 24.0734 - val_loss: 3457.5459 - val_mean_absolute_error: 40.9713\n",
      "Epoch 454/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1531.1224 - mean_absolute_error: 23.1744\n",
      "Epoch 454: val_loss improved from 3457.54590 to 3448.34717, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1549.3690 - mean_absolute_error: 23.2952 - val_loss: 3448.3472 - val_mean_absolute_error: 41.0261\n",
      "Epoch 455/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1510.9817 - mean_absolute_error: 23.0634\n",
      "Epoch 455: val_loss improved from 3448.34717 to 3408.42822, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1625.0862 - mean_absolute_error: 24.0114 - val_loss: 3408.4282 - val_mean_absolute_error: 40.4325\n",
      "Epoch 456/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1086.4960 - mean_absolute_error: 18.4467\n",
      "Epoch 456: val_loss improved from 3408.42822 to 3399.60815, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1552.8866 - mean_absolute_error: 22.9332 - val_loss: 3399.6082 - val_mean_absolute_error: 40.7085\n",
      "Epoch 457/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1581.8888 - mean_absolute_error: 25.5150\n",
      "Epoch 457: val_loss improved from 3399.60815 to 3374.67188, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1619.3633 - mean_absolute_error: 24.0581 - val_loss: 3374.6719 - val_mean_absolute_error: 40.3412\n",
      "Epoch 458/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1108.5872 - mean_absolute_error: 20.1528\n",
      "Epoch 458: val_loss improved from 3374.67188 to 3354.01929, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1438.5393 - mean_absolute_error: 22.5655 - val_loss: 3354.0193 - val_mean_absolute_error: 40.2715\n",
      "Epoch 459/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1589.1736 - mean_absolute_error: 22.6730\n",
      "Epoch 459: val_loss improved from 3354.01929 to 3328.13916, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1682.6619 - mean_absolute_error: 23.9541 - val_loss: 3328.1392 - val_mean_absolute_error: 40.0001\n",
      "Epoch 460/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2195.8818 - mean_absolute_error: 27.5134\n",
      "Epoch 460: val_loss improved from 3328.13916 to 3324.83398, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1542.8237 - mean_absolute_error: 23.2938 - val_loss: 3324.8340 - val_mean_absolute_error: 40.1143\n",
      "Epoch 461/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1972.5172 - mean_absolute_error: 24.5644\n",
      "Epoch 461: val_loss improved from 3324.83398 to 3287.58105, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1688.1035 - mean_absolute_error: 24.0076 - val_loss: 3287.5811 - val_mean_absolute_error: 39.7200\n",
      "Epoch 462/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 961.7753 - mean_absolute_error: 19.9993\n",
      "Epoch 462: val_loss improved from 3287.58105 to 3277.96753, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1524.9758 - mean_absolute_error: 23.1391 - val_loss: 3277.9675 - val_mean_absolute_error: 39.8069\n",
      "Epoch 463/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1281.1086 - mean_absolute_error: 21.4849\n",
      "Epoch 463: val_loss improved from 3277.96753 to 3266.15283, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1531.4463 - mean_absolute_error: 23.2426 - val_loss: 3266.1528 - val_mean_absolute_error: 39.7417\n",
      "Epoch 464/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1531.6689 - mean_absolute_error: 23.9951\n",
      "Epoch 464: val_loss improved from 3266.15283 to 3235.07007, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1605.8180 - mean_absolute_error: 23.6649 - val_loss: 3235.0701 - val_mean_absolute_error: 39.4493\n",
      "Epoch 465/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1081.4806 - mean_absolute_error: 19.9403\n",
      "Epoch 465: val_loss improved from 3235.07007 to 3228.58008, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1453.7806 - mean_absolute_error: 22.4785 - val_loss: 3228.5801 - val_mean_absolute_error: 39.5204\n",
      "Epoch 466/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1236.4738 - mean_absolute_error: 23.7179\n",
      "Epoch 466: val_loss improved from 3228.58008 to 3199.32251, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1511.7882 - mean_absolute_error: 23.3054 - val_loss: 3199.3225 - val_mean_absolute_error: 39.2602\n",
      "Epoch 467/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 943.8684 - mean_absolute_error: 20.4116\n",
      "Epoch 467: val_loss improved from 3199.32251 to 3192.96191, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1449.0951 - mean_absolute_error: 22.9657 - val_loss: 3192.9619 - val_mean_absolute_error: 39.3318\n",
      "Epoch 468/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 847.5801 - mean_absolute_error: 17.0772\n",
      "Epoch 468: val_loss improved from 3192.96191 to 3179.81470, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1511.5026 - mean_absolute_error: 22.9597 - val_loss: 3179.8147 - val_mean_absolute_error: 39.2631\n",
      "Epoch 469/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1967.3933 - mean_absolute_error: 27.1455\n",
      "Epoch 469: val_loss improved from 3179.81470 to 3131.49121, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1719.5931 - mean_absolute_error: 24.3568 - val_loss: 3131.4912 - val_mean_absolute_error: 38.6423\n",
      "Epoch 470/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1866.7012 - mean_absolute_error: 27.3263\n",
      "Epoch 470: val_loss improved from 3131.49121 to 3115.32471, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1552.9319 - mean_absolute_error: 23.2872 - val_loss: 3115.3247 - val_mean_absolute_error: 38.5923\n",
      "Epoch 471/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1484.6503 - mean_absolute_error: 22.7339 \n",
      "Epoch 471: val_loss improved from 3115.32471 to 3105.59033, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1492.7933 - mean_absolute_error: 22.7894 - val_loss: 3105.5903 - val_mean_absolute_error: 38.6391\n",
      "Epoch 472/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1290.4374 - mean_absolute_error: 21.0532\n",
      "Epoch 472: val_loss improved from 3105.59033 to 3056.78247, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1434.8816 - mean_absolute_error: 22.4684 - val_loss: 3056.7825 - val_mean_absolute_error: 38.0662\n",
      "Epoch 473/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1416.1539 - mean_absolute_error: 21.5795\n",
      "Epoch 473: val_loss improved from 3056.78247 to 3045.15796, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1455.6938 - mean_absolute_error: 22.6237 - val_loss: 3045.1580 - val_mean_absolute_error: 38.1204\n",
      "Epoch 474/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1435.1436 - mean_absolute_error: 25.2511\n",
      "Epoch 474: val_loss improved from 3045.15796 to 3003.08179, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1541.6100 - mean_absolute_error: 23.4071 - val_loss: 3003.0818 - val_mean_absolute_error: 37.6776\n",
      "Epoch 475/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 1311.5469 - mean_absolute_error: 22.4351\n",
      "Epoch 475: val_loss improved from 3003.08179 to 2977.52319, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1523.6737 - mean_absolute_error: 23.0320 - val_loss: 2977.5232 - val_mean_absolute_error: 37.5129\n",
      "Epoch 476/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1140.0232 - mean_absolute_error: 21.2922\n",
      "Epoch 476: val_loss improved from 2977.52319 to 2953.54639, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1442.1045 - mean_absolute_error: 22.3490 - val_loss: 2953.5464 - val_mean_absolute_error: 37.3727\n",
      "Epoch 477/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1385.8073 - mean_absolute_error: 23.5854\n",
      "Epoch 477: val_loss improved from 2953.54639 to 2917.04858, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1432.6543 - mean_absolute_error: 22.6296 - val_loss: 2917.0486 - val_mean_absolute_error: 37.0308\n",
      "Epoch 478/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1391.4985 - mean_absolute_error: 22.2688\n",
      "Epoch 478: val_loss improved from 2917.04858 to 2894.64893, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1405.8047 - mean_absolute_error: 22.3294 - val_loss: 2894.6489 - val_mean_absolute_error: 36.8832\n",
      "Epoch 479/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 1563.0769 - mean_absolute_error: 24.4987\n",
      "Epoch 479: val_loss did not improve from 2894.64893\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1467.2642 - mean_absolute_error: 22.8252 - val_loss: 2895.7292 - val_mean_absolute_error: 37.0834\n",
      "Epoch 480/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1275.3264 - mean_absolute_error: 23.6865\n",
      "Epoch 480: val_loss improved from 2894.64893 to 2864.23413, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1568.5928 - mean_absolute_error: 23.3930 - val_loss: 2864.2341 - val_mean_absolute_error: 36.6909\n",
      "Epoch 481/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1798.4250 - mean_absolute_error: 26.5352\n",
      "Epoch 481: val_loss improved from 2864.23413 to 2836.68921, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1548.4152 - mean_absolute_error: 23.1373 - val_loss: 2836.6892 - val_mean_absolute_error: 36.3888\n",
      "Epoch 482/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1460.1512 - mean_absolute_error: 22.5457 \n",
      "Epoch 482: val_loss improved from 2836.68921 to 2821.12915, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1461.1278 - mean_absolute_error: 22.5249 - val_loss: 2821.1292 - val_mean_absolute_error: 36.2887\n",
      "Epoch 483/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1290.1084 - mean_absolute_error: 22.3242\n",
      "Epoch 483: val_loss improved from 2821.12915 to 2820.19092, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1368.8253 - mean_absolute_error: 21.8857 - val_loss: 2820.1909 - val_mean_absolute_error: 36.4809\n",
      "Epoch 484/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1440.9192 - mean_absolute_error: 25.4982\n",
      "Epoch 484: val_loss improved from 2820.19092 to 2797.09668, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1460.6992 - mean_absolute_error: 22.5452 - val_loss: 2797.0967 - val_mean_absolute_error: 36.2743\n",
      "Epoch 485/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1683.7007 - mean_absolute_error: 21.2692\n",
      "Epoch 485: val_loss improved from 2797.09668 to 2775.56934, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1420.6982 - mean_absolute_error: 21.8938 - val_loss: 2775.5693 - val_mean_absolute_error: 36.0537\n",
      "Epoch 486/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1459.3497 - mean_absolute_error: 22.3433 \n",
      "Epoch 486: val_loss improved from 2775.56934 to 2762.66211, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1460.2468 - mean_absolute_error: 22.3517 - val_loss: 2762.6621 - val_mean_absolute_error: 35.9874\n",
      "Epoch 487/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1496.7208 - mean_absolute_error: 22.7449\n",
      "Epoch 487: val_loss improved from 2762.66211 to 2740.01733, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1427.2451 - mean_absolute_error: 22.0413 - val_loss: 2740.0173 - val_mean_absolute_error: 35.7723\n",
      "Epoch 488/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 829.9148 - mean_absolute_error: 18.7481\n",
      "Epoch 488: val_loss improved from 2740.01733 to 2728.57129, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1358.3147 - mean_absolute_error: 21.3958 - val_loss: 2728.5713 - val_mean_absolute_error: 35.7091\n",
      "Epoch 489/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1103.9624 - mean_absolute_error: 18.7239\n",
      "Epoch 489: val_loss improved from 2728.57129 to 2704.70996, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1440.4998 - mean_absolute_error: 22.1970 - val_loss: 2704.7100 - val_mean_absolute_error: 35.4669\n",
      "Epoch 490/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1209.0924 - mean_absolute_error: 20.4000\n",
      "Epoch 490: val_loss improved from 2704.70996 to 2692.77905, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1453.9880 - mean_absolute_error: 22.1057 - val_loss: 2692.7791 - val_mean_absolute_error: 35.4327\n",
      "Epoch 491/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1753.9114 - mean_absolute_error: 26.3502\n",
      "Epoch 491: val_loss improved from 2692.77905 to 2674.13013, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1322.8077 - mean_absolute_error: 21.5426 - val_loss: 2674.1301 - val_mean_absolute_error: 35.2749\n",
      "Epoch 492/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1300.2190 - mean_absolute_error: 23.8456\n",
      "Epoch 492: val_loss improved from 2674.13013 to 2671.55005, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1334.6764 - mean_absolute_error: 21.8457 - val_loss: 2671.5500 - val_mean_absolute_error: 35.3859\n",
      "Epoch 493/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1699.5168 - mean_absolute_error: 21.7992\n",
      "Epoch 493: val_loss improved from 2671.55005 to 2642.30444, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1461.8519 - mean_absolute_error: 22.1773 - val_loss: 2642.3044 - val_mean_absolute_error: 35.0249\n",
      "Epoch 494/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 979.0087 - mean_absolute_error: 20.0928\n",
      "Epoch 494: val_loss improved from 2642.30444 to 2605.03149, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1521.9637 - mean_absolute_error: 22.8585 - val_loss: 2605.0315 - val_mean_absolute_error: 34.5670\n",
      "Epoch 495/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231.4562 - mean_absolute_error: 20.7810\n",
      "Epoch 495: val_loss improved from 2605.03149 to 2604.42139, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1236.6083 - mean_absolute_error: 20.8120 - val_loss: 2604.4214 - val_mean_absolute_error: 34.7626\n",
      "Epoch 496/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1497.3838 - mean_absolute_error: 22.9575\n",
      "Epoch 496: val_loss improved from 2604.42139 to 2586.40967, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1419.1185 - mean_absolute_error: 22.2682 - val_loss: 2586.4097 - val_mean_absolute_error: 34.5668\n",
      "Epoch 497/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1540.5676 - mean_absolute_error: 22.4469\n",
      "Epoch 497: val_loss improved from 2586.40967 to 2572.65405, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1420.3629 - mean_absolute_error: 22.1770 - val_loss: 2572.6541 - val_mean_absolute_error: 34.4632\n",
      "Epoch 498/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 654.3807 - mean_absolute_error: 14.6286\n",
      "Epoch 498: val_loss improved from 2572.65405 to 2550.52661, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1324.1027 - mean_absolute_error: 21.1966 - val_loss: 2550.5266 - val_mean_absolute_error: 34.2693\n",
      "Epoch 499/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1832.1624 - mean_absolute_error: 24.7409\n",
      "Epoch 499: val_loss improved from 2550.52661 to 2539.13257, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1390.4553 - mean_absolute_error: 21.8392 - val_loss: 2539.1326 - val_mean_absolute_error: 34.2292\n",
      "Epoch 500/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1815.4741 - mean_absolute_error: 24.3545\n",
      "Epoch 500: val_loss improved from 2539.13257 to 2526.77319, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1357.4816 - mean_absolute_error: 21.6072 - val_loss: 2526.7732 - val_mean_absolute_error: 34.1469\n",
      "Epoch 501/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1156.5459 - mean_absolute_error: 22.3619\n",
      "Epoch 501: val_loss improved from 2526.77319 to 2507.42334, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1397.3767 - mean_absolute_error: 21.9338 - val_loss: 2507.4233 - val_mean_absolute_error: 33.9802\n",
      "Epoch 502/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1443.1068 - mean_absolute_error: 21.8780\n",
      "Epoch 502: val_loss improved from 2507.42334 to 2488.92285, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1386.5356 - mean_absolute_error: 21.7475 - val_loss: 2488.9229 - val_mean_absolute_error: 33.7782\n",
      "Epoch 503/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1056.8101 - mean_absolute_error: 21.3173\n",
      "Epoch 503: val_loss improved from 2488.92285 to 2478.12598, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1358.9426 - mean_absolute_error: 21.8230 - val_loss: 2478.1260 - val_mean_absolute_error: 33.7705\n",
      "Epoch 504/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 765.5112 - mean_absolute_error: 16.9528\n",
      "Epoch 504: val_loss improved from 2478.12598 to 2470.29785, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232.4967 - mean_absolute_error: 20.4764 - val_loss: 2470.2979 - val_mean_absolute_error: 33.7599\n",
      "Epoch 505/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 626.5933 - mean_absolute_error: 16.5773\n",
      "Epoch 505: val_loss improved from 2470.29785 to 2457.94556, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242.9570 - mean_absolute_error: 20.8061 - val_loss: 2457.9456 - val_mean_absolute_error: 33.7181\n",
      "Epoch 506/1500\n",
      "\u001b[1m21/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1302.2437 - mean_absolute_error: 21.4245 \n",
      "Epoch 506: val_loss improved from 2457.94556 to 2420.66040, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1315.6676 - mean_absolute_error: 21.4147 - val_loss: 2420.6604 - val_mean_absolute_error: 33.2015\n",
      "Epoch 507/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1661.7462 - mean_absolute_error: 21.7118\n",
      "Epoch 507: val_loss improved from 2420.66040 to 2404.64185, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1409.9274 - mean_absolute_error: 21.5297 - val_loss: 2404.6418 - val_mean_absolute_error: 33.1106\n",
      "Epoch 508/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1055.6375 - mean_absolute_error: 19.5997\n",
      "Epoch 508: val_loss improved from 2404.64185 to 2386.55811, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1282.7648 - mean_absolute_error: 21.0577 - val_loss: 2386.5581 - val_mean_absolute_error: 32.9127\n",
      "Epoch 509/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1283.8781 - mean_absolute_error: 19.8204\n",
      "Epoch 509: val_loss improved from 2386.55811 to 2372.10864, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1424.9744 - mean_absolute_error: 21.9823 - val_loss: 2372.1086 - val_mean_absolute_error: 32.7841\n",
      "Epoch 510/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2255.0259 - mean_absolute_error: 27.2198\n",
      "Epoch 510: val_loss improved from 2372.10864 to 2359.15137, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1478.2908 - mean_absolute_error: 21.9589 - val_loss: 2359.1514 - val_mean_absolute_error: 32.7267\n",
      "Epoch 511/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2142.0254 - mean_absolute_error: 22.9409\n",
      "Epoch 511: val_loss improved from 2359.15137 to 2342.00073, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1516.6156 - mean_absolute_error: 21.9627 - val_loss: 2342.0007 - val_mean_absolute_error: 32.5201\n",
      "Epoch 512/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1218.5129 - mean_absolute_error: 20.5437\n",
      "Epoch 512: val_loss improved from 2342.00073 to 2318.76196, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1336.5710 - mean_absolute_error: 21.1378 - val_loss: 2318.7620 - val_mean_absolute_error: 32.2693\n",
      "Epoch 513/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1007.2449 - mean_absolute_error: 19.7632\n",
      "Epoch 513: val_loss did not improve from 2318.76196\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257.8660 - mean_absolute_error: 20.3202 - val_loss: 2334.5574 - val_mean_absolute_error: 32.7788\n",
      "Epoch 514/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1046.8372 - mean_absolute_error: 20.0486\n",
      "Epoch 514: val_loss improved from 2318.76196 to 2317.21582, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1367.0669 - mean_absolute_error: 21.4817 - val_loss: 2317.2158 - val_mean_absolute_error: 32.5996\n",
      "Epoch 515/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 652.7414 - mean_absolute_error: 15.6886\n",
      "Epoch 515: val_loss improved from 2317.21582 to 2292.60278, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1309.9711 - mean_absolute_error: 21.2022 - val_loss: 2292.6028 - val_mean_absolute_error: 32.3108\n",
      "Epoch 516/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1288.2406 - mean_absolute_error: 21.0272\n",
      "Epoch 516: val_loss improved from 2292.60278 to 2269.54102, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1289.1752 - mean_absolute_error: 21.2479 - val_loss: 2269.5410 - val_mean_absolute_error: 31.9351\n",
      "Epoch 517/1500\n",
      "\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1214.4984 - mean_absolute_error: 19.9935\n",
      "Epoch 517: val_loss improved from 2269.54102 to 2258.24707, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1231.6224 - mean_absolute_error: 20.1627 - val_loss: 2258.2471 - val_mean_absolute_error: 31.9810\n",
      "Epoch 518/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1528.2207 - mean_absolute_error: 23.2699\n",
      "Epoch 518: val_loss improved from 2258.24707 to 2246.09790, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1314.3777 - mean_absolute_error: 20.9131 - val_loss: 2246.0979 - val_mean_absolute_error: 31.9172\n",
      "Epoch 519/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2157.3696 - mean_absolute_error: 24.7183\n",
      "Epoch 519: val_loss improved from 2246.09790 to 2238.98022, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1353.4584 - mean_absolute_error: 20.8914 - val_loss: 2238.9802 - val_mean_absolute_error: 31.9475\n",
      "Epoch 520/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1342.1903 - mean_absolute_error: 19.0525\n",
      "Epoch 520: val_loss improved from 2238.98022 to 2215.15527, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1329.5975 - mean_absolute_error: 20.8030 - val_loss: 2215.1553 - val_mean_absolute_error: 31.6314\n",
      "Epoch 521/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1504.6060 - mean_absolute_error: 22.5478\n",
      "Epoch 521: val_loss improved from 2215.15527 to 2202.34497, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1392.6101 - mean_absolute_error: 21.3322 - val_loss: 2202.3450 - val_mean_absolute_error: 31.5840\n",
      "Epoch 522/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 718.3373 - mean_absolute_error: 17.1085\n",
      "Epoch 522: val_loss improved from 2202.34497 to 2181.54395, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1292.8464 - mean_absolute_error: 20.6627 - val_loss: 2181.5439 - val_mean_absolute_error: 31.3657\n",
      "Epoch 523/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1566.4531 - mean_absolute_error: 22.4713\n",
      "Epoch 523: val_loss improved from 2181.54395 to 2159.85059, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1282.1754 - mean_absolute_error: 20.8134 - val_loss: 2159.8506 - val_mean_absolute_error: 31.0751\n",
      "Epoch 524/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 689.1652 - mean_absolute_error: 14.1847\n",
      "Epoch 524: val_loss improved from 2159.85059 to 2151.16602, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1195.1333 - mean_absolute_error: 19.9050 - val_loss: 2151.1660 - val_mean_absolute_error: 31.0962\n",
      "Epoch 525/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 633.5473 - mean_absolute_error: 16.1278\n",
      "Epoch 525: val_loss improved from 2151.16602 to 2138.34204, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1333.3329 - mean_absolute_error: 20.8586 - val_loss: 2138.3420 - val_mean_absolute_error: 30.9900\n",
      "Epoch 526/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 925.2892 - mean_absolute_error: 16.8941\n",
      "Epoch 526: val_loss improved from 2138.34204 to 2120.19214, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1331.6218 - mean_absolute_error: 20.6770 - val_loss: 2120.1921 - val_mean_absolute_error: 30.7721\n",
      "Epoch 527/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 997.8203 - mean_absolute_error: 18.3834\n",
      "Epoch 527: val_loss improved from 2120.19214 to 2114.41211, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1195.1455 - mean_absolute_error: 20.1530 - val_loss: 2114.4121 - val_mean_absolute_error: 30.8878\n",
      "Epoch 528/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1200.6497 - mean_absolute_error: 21.1011\n",
      "Epoch 528: val_loss improved from 2114.41211 to 2102.32397, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1305.5242 - mean_absolute_error: 20.9862 - val_loss: 2102.3240 - val_mean_absolute_error: 30.8075\n",
      "Epoch 529/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 764.0482 - mean_absolute_error: 16.9607\n",
      "Epoch 529: val_loss improved from 2102.32397 to 2097.15649, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1192.3862 - mean_absolute_error: 19.9167 - val_loss: 2097.1565 - val_mean_absolute_error: 30.8176\n",
      "Epoch 530/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1229.9926 - mean_absolute_error: 20.6161\n",
      "Epoch 530: val_loss improved from 2097.15649 to 2075.05591, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1239.0621 - mean_absolute_error: 19.9023 - val_loss: 2075.0559 - val_mean_absolute_error: 30.6098\n",
      "Epoch 531/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1113.7523 - mean_absolute_error: 18.8489\n",
      "Epoch 531: val_loss improved from 2075.05591 to 2049.82812, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237.0050 - mean_absolute_error: 20.1705 - val_loss: 2049.8281 - val_mean_absolute_error: 30.2221\n",
      "Epoch 532/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1241.7550 - mean_absolute_error: 19.4974\n",
      "Epoch 532: val_loss improved from 2049.82812 to 2040.86218, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1333.2817 - mean_absolute_error: 20.8930 - val_loss: 2040.8622 - val_mean_absolute_error: 30.1196\n",
      "Epoch 533/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1234.8488 - mean_absolute_error: 20.5197\n",
      "Epoch 533: val_loss did not improve from 2040.86218\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1305.7550 - mean_absolute_error: 20.8730 - val_loss: 2054.7878 - val_mean_absolute_error: 30.6543\n",
      "Epoch 534/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 730.8041 - mean_absolute_error: 15.5234\n",
      "Epoch 534: val_loss improved from 2040.86218 to 2031.51184, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1317.4159 - mean_absolute_error: 20.9185 - val_loss: 2031.5118 - val_mean_absolute_error: 30.3908\n",
      "Epoch 535/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1021.4606 - mean_absolute_error: 19.1121\n",
      "Epoch 535: val_loss improved from 2031.51184 to 2020.24841, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1210.8203 - mean_absolute_error: 20.2147 - val_loss: 2020.2484 - val_mean_absolute_error: 30.2890\n",
      "Epoch 536/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1292.3848 - mean_absolute_error: 20.7059\n",
      "Epoch 536: val_loss improved from 2020.24841 to 2005.38623, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1231.2450 - mean_absolute_error: 20.0944 - val_loss: 2005.3862 - val_mean_absolute_error: 30.1662\n",
      "Epoch 537/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1464.1501 - mean_absolute_error: 23.3797\n",
      "Epoch 537: val_loss improved from 2005.38623 to 1988.33777, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1319.2769 - mean_absolute_error: 20.9855 - val_loss: 1988.3378 - val_mean_absolute_error: 29.9941\n",
      "Epoch 538/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1087.0814 - mean_absolute_error: 20.3776\n",
      "Epoch 538: val_loss improved from 1988.33777 to 1982.25793, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1354.1228 - mean_absolute_error: 21.0966 - val_loss: 1982.2579 - val_mean_absolute_error: 30.0339\n",
      "Epoch 539/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 835.9781 - mean_absolute_error: 17.5193\n",
      "Epoch 539: val_loss improved from 1982.25793 to 1955.06458, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1220.1960 - mean_absolute_error: 20.2459 - val_loss: 1955.0646 - val_mean_absolute_error: 29.6675\n",
      "Epoch 540/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1054.7849 - mean_absolute_error: 18.8554\n",
      "Epoch 540: val_loss improved from 1955.06458 to 1940.23303, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1265.9954 - mean_absolute_error: 20.7686 - val_loss: 1940.2330 - val_mean_absolute_error: 29.4333\n",
      "Epoch 541/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1332.5229 - mean_absolute_error: 19.6852\n",
      "Epoch 541: val_loss improved from 1940.23303 to 1927.53601, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249.6884 - mean_absolute_error: 19.7550 - val_loss: 1927.5360 - val_mean_absolute_error: 29.3402\n",
      "Epoch 542/1500\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1292.1440 - mean_absolute_error: 20.7984 \n",
      "Epoch 542: val_loss improved from 1927.53601 to 1915.98779, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1291.3101 - mean_absolute_error: 20.7867 - val_loss: 1915.9878 - val_mean_absolute_error: 29.3260\n",
      "Epoch 543/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1503.2701 - mean_absolute_error: 23.3976\n",
      "Epoch 543: val_loss improved from 1915.98779 to 1903.00378, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1357.7703 - mean_absolute_error: 21.2618 - val_loss: 1903.0038 - val_mean_absolute_error: 29.1149\n",
      "Epoch 544/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2786.3845 - mean_absolute_error: 29.2022\n",
      "Epoch 544: val_loss improved from 1903.00378 to 1902.12219, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1432.0114 - mean_absolute_error: 21.1156 - val_loss: 1902.1222 - val_mean_absolute_error: 29.3425\n",
      "Epoch 545/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1656.5348 - mean_absolute_error: 23.0126\n",
      "Epoch 545: val_loss improved from 1902.12219 to 1878.12671, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1294.1187 - mean_absolute_error: 20.7536 - val_loss: 1878.1267 - val_mean_absolute_error: 28.9312\n",
      "Epoch 546/1500\n",
      "\u001b[1m31/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1235.8657 - mean_absolute_error: 19.6835 \n",
      "Epoch 546: val_loss improved from 1878.12671 to 1876.14600, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237.3840 - mean_absolute_error: 19.7303 - val_loss: 1876.1460 - val_mean_absolute_error: 29.0248\n",
      "Epoch 547/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2256.0903 - mean_absolute_error: 26.4626\n",
      "Epoch 547: val_loss improved from 1876.14600 to 1863.24280, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1365.8324 - mean_absolute_error: 20.9811 - val_loss: 1863.2428 - val_mean_absolute_error: 28.8873\n",
      "Epoch 548/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 902.1671 - mean_absolute_error: 17.1952\n",
      "Epoch 548: val_loss did not improve from 1863.24280\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.7555 - mean_absolute_error: 19.7043 - val_loss: 1864.2755 - val_mean_absolute_error: 29.1004\n",
      "Epoch 549/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 960.9528 - mean_absolute_error: 19.2129\n",
      "Epoch 549: val_loss improved from 1863.24280 to 1832.75989, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.9730 - mean_absolute_error: 20.1589 - val_loss: 1832.7599 - val_mean_absolute_error: 28.5781\n",
      "Epoch 550/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 897.5172 - mean_absolute_error: 17.7462\n",
      "Epoch 550: val_loss improved from 1832.75989 to 1832.09900, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253.6476 - mean_absolute_error: 20.0250 - val_loss: 1832.0990 - val_mean_absolute_error: 28.7098\n",
      "Epoch 551/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1343.2042 - mean_absolute_error: 20.0952\n",
      "Epoch 551: val_loss improved from 1832.09900 to 1815.73230, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1246.6204 - mean_absolute_error: 20.0282 - val_loss: 1815.7323 - val_mean_absolute_error: 28.5045\n",
      "Epoch 552/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 775.6651 - mean_absolute_error: 16.6639\n",
      "Epoch 552: val_loss improved from 1815.73230 to 1812.04248, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257.5654 - mean_absolute_error: 20.3949 - val_loss: 1812.0425 - val_mean_absolute_error: 28.6010\n",
      "Epoch 553/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 575.2594 - mean_absolute_error: 14.2634\n",
      "Epoch 553: val_loss improved from 1812.04248 to 1799.50024, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1146.7837 - mean_absolute_error: 19.6634 - val_loss: 1799.5002 - val_mean_absolute_error: 28.4883\n",
      "Epoch 554/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1157.3210 - mean_absolute_error: 19.2157\n",
      "Epoch 554: val_loss improved from 1799.50024 to 1777.86462, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1230.4531 - mean_absolute_error: 19.9690 - val_loss: 1777.8646 - val_mean_absolute_error: 28.0512\n",
      "Epoch 555/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 752.9705 - mean_absolute_error: 16.5954\n",
      "Epoch 555: val_loss did not improve from 1777.86462\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1340.2355 - mean_absolute_error: 20.5949 - val_loss: 1792.6854 - val_mean_absolute_error: 28.5536\n",
      "Epoch 556/1500\n",
      "\u001b[1m30/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1181.8821 - mean_absolute_error: 19.5941 \n",
      "Epoch 556: val_loss improved from 1777.86462 to 1772.89404, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1187.8994 - mean_absolute_error: 19.6433 - val_loss: 1772.8940 - val_mean_absolute_error: 28.3210\n",
      "Epoch 557/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 771.0301 - mean_absolute_error: 18.1710\n",
      "Epoch 557: val_loss improved from 1772.89404 to 1771.13599, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1148.0049 - mean_absolute_error: 19.8375 - val_loss: 1771.1360 - val_mean_absolute_error: 28.3984\n",
      "Epoch 558/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1131.2329 - mean_absolute_error: 21.3142\n",
      "Epoch 558: val_loss improved from 1771.13599 to 1742.43604, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231.1399 - mean_absolute_error: 20.2366 - val_loss: 1742.4360 - val_mean_absolute_error: 27.7704\n",
      "Epoch 559/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1254.8889 - mean_absolute_error: 20.3240\n",
      "Epoch 559: val_loss improved from 1742.43604 to 1723.43933, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1288.0785 - mean_absolute_error: 20.1681 - val_loss: 1723.4393 - val_mean_absolute_error: 27.5583\n",
      "Epoch 560/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 910.6173 - mean_absolute_error: 17.9647\n",
      "Epoch 560: val_loss improved from 1723.43933 to 1715.82275, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1201.8585 - mean_absolute_error: 19.7279 - val_loss: 1715.8228 - val_mean_absolute_error: 27.5057\n",
      "Epoch 561/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1095.6008 - mean_absolute_error: 20.0014\n",
      "Epoch 561: val_loss improved from 1715.82275 to 1714.48816, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.5044 - mean_absolute_error: 19.4274 - val_loss: 1714.4882 - val_mean_absolute_error: 27.6692\n",
      "Epoch 562/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1501.0264 - mean_absolute_error: 21.8199\n",
      "Epoch 562: val_loss improved from 1714.48816 to 1694.04712, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1229.2621 - mean_absolute_error: 20.0208 - val_loss: 1694.0471 - val_mean_absolute_error: 27.3380\n",
      "Epoch 563/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1841.7174 - mean_absolute_error: 22.1959\n",
      "Epoch 563: val_loss improved from 1694.04712 to 1682.49329, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1324.5233 - mean_absolute_error: 20.3985 - val_loss: 1682.4933 - val_mean_absolute_error: 27.2818\n",
      "Epoch 564/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1160.6553 - mean_absolute_error: 18.9628\n",
      "Epoch 564: val_loss did not improve from 1682.49329\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1213.5637 - mean_absolute_error: 19.7822 - val_loss: 1683.5117 - val_mean_absolute_error: 27.3783\n",
      "Epoch 565/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1411.9227 - mean_absolute_error: 21.4329\n",
      "Epoch 565: val_loss improved from 1682.49329 to 1654.51904, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1204.0236 - mean_absolute_error: 19.8499 - val_loss: 1654.5190 - val_mean_absolute_error: 26.9897\n",
      "Epoch 566/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 841.6394 - mean_absolute_error: 18.2983\n",
      "Epoch 566: val_loss improved from 1654.51904 to 1633.60889, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1120.9244 - mean_absolute_error: 19.3300 - val_loss: 1633.6089 - val_mean_absolute_error: 26.4249\n",
      "Epoch 567/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 1047.0312 - mean_absolute_error: 18.2619\n",
      "Epoch 567: val_loss did not improve from 1633.60889\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240.3644 - mean_absolute_error: 20.0462 - val_loss: 1636.0521 - val_mean_absolute_error: 26.9795\n",
      "Epoch 568/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1071.0371 - mean_absolute_error: 19.6133\n",
      "Epoch 568: val_loss improved from 1633.60889 to 1615.36035, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1127.0277 - mean_absolute_error: 19.4274 - val_loss: 1615.3604 - val_mean_absolute_error: 26.4263\n",
      "Epoch 569/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1274.1583 - mean_absolute_error: 19.9031\n",
      "Epoch 569: val_loss improved from 1615.36035 to 1608.04358, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1130.3318 - mean_absolute_error: 19.3849 - val_loss: 1608.0436 - val_mean_absolute_error: 26.6355\n",
      "Epoch 570/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 593.1868 - mean_absolute_error: 14.5430\n",
      "Epoch 570: val_loss improved from 1608.04358 to 1598.58154, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.8075 - mean_absolute_error: 19.3558 - val_loss: 1598.5815 - val_mean_absolute_error: 26.4222\n",
      "Epoch 571/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1427.7004 - mean_absolute_error: 19.8331\n",
      "Epoch 571: val_loss improved from 1598.58154 to 1588.61145, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.1246 - mean_absolute_error: 19.3660 - val_loss: 1588.6115 - val_mean_absolute_error: 26.3894\n",
      "Epoch 572/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1700.6263 - mean_absolute_error: 22.7143\n",
      "Epoch 572: val_loss improved from 1588.61145 to 1585.05994, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257.7904 - mean_absolute_error: 20.0369 - val_loss: 1585.0599 - val_mean_absolute_error: 26.4836\n",
      "Epoch 573/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1039.0543 - mean_absolute_error: 18.5847\n",
      "Epoch 573: val_loss improved from 1585.05994 to 1574.35315, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1176.2518 - mean_absolute_error: 19.5682 - val_loss: 1574.3531 - val_mean_absolute_error: 26.2990\n",
      "Epoch 574/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1059.5359 - mean_absolute_error: 17.6213\n",
      "Epoch 574: val_loss improved from 1574.35315 to 1553.09900, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1236.4827 - mean_absolute_error: 19.9709 - val_loss: 1553.0990 - val_mean_absolute_error: 25.9738\n",
      "Epoch 575/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1234.5652 - mean_absolute_error: 21.1887\n",
      "Epoch 575: val_loss did not improve from 1553.09900\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.8297 - mean_absolute_error: 19.5024 - val_loss: 1556.0272 - val_mean_absolute_error: 26.2213\n",
      "Epoch 576/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 936.6865 - mean_absolute_error: 16.5268\n",
      "Epoch 576: val_loss improved from 1553.09900 to 1541.68665, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1155.7827 - mean_absolute_error: 19.2416 - val_loss: 1541.6866 - val_mean_absolute_error: 25.9425\n",
      "Epoch 577/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 914.3038 - mean_absolute_error: 19.2042\n",
      "Epoch 577: val_loss did not improve from 1541.68665\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248.4442 - mean_absolute_error: 19.9913 - val_loss: 1548.0830 - val_mean_absolute_error: 26.2657\n",
      "Epoch 578/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 911.9151 - mean_absolute_error: 16.5102\n",
      "Epoch 578: val_loss improved from 1541.68665 to 1538.58447, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1058.7913 - mean_absolute_error: 18.5972 - val_loss: 1538.5845 - val_mean_absolute_error: 26.1593\n",
      "Epoch 579/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1136.8197 - mean_absolute_error: 21.3127\n",
      "Epoch 579: val_loss improved from 1538.58447 to 1517.46643, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1232.6216 - mean_absolute_error: 20.1633 - val_loss: 1517.4664 - val_mean_absolute_error: 25.5235\n",
      "Epoch 580/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1212.7141 - mean_absolute_error: 19.9294\n",
      "Epoch 580: val_loss improved from 1517.46643 to 1514.23584, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1181.2794 - mean_absolute_error: 19.4760 - val_loss: 1514.2358 - val_mean_absolute_error: 25.6392\n",
      "Epoch 581/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 722.0265 - mean_absolute_error: 17.2142\n",
      "Epoch 581: val_loss improved from 1514.23584 to 1508.61414, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.3828 - mean_absolute_error: 19.6536 - val_loss: 1508.6141 - val_mean_absolute_error: 25.6930\n",
      "Epoch 582/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1455.6746 - mean_absolute_error: 22.7190\n",
      "Epoch 582: val_loss improved from 1508.61414 to 1505.72644, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.4072 - mean_absolute_error: 19.4917 - val_loss: 1505.7264 - val_mean_absolute_error: 25.8080\n",
      "Epoch 583/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1490.5444 - mean_absolute_error: 21.9198\n",
      "Epoch 583: val_loss did not improve from 1505.72644\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1191.0504 - mean_absolute_error: 19.8421 - val_loss: 1507.3917 - val_mean_absolute_error: 25.9932\n",
      "Epoch 584/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 787.7372 - mean_absolute_error: 17.3423\n",
      "Epoch 584: val_loss improved from 1505.72644 to 1491.33313, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1165.7679 - mean_absolute_error: 19.4953 - val_loss: 1491.3331 - val_mean_absolute_error: 25.7347\n",
      "Epoch 585/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1107.7173 - mean_absolute_error: 19.0428\n",
      "Epoch 585: val_loss improved from 1491.33313 to 1480.45996, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1162.3145 - mean_absolute_error: 19.4357 - val_loss: 1480.4600 - val_mean_absolute_error: 25.5012\n",
      "Epoch 586/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1274.3096 - mean_absolute_error: 20.7733\n",
      "Epoch 586: val_loss improved from 1480.45996 to 1467.14929, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1189.9446 - mean_absolute_error: 19.7735 - val_loss: 1467.1493 - val_mean_absolute_error: 25.2892\n",
      "Epoch 587/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1226.3558 - mean_absolute_error: 19.5581 \n",
      "Epoch 587: val_loss improved from 1467.14929 to 1464.89917, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1216.3929 - mean_absolute_error: 19.5267 - val_loss: 1464.8992 - val_mean_absolute_error: 25.3632\n",
      "Epoch 588/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1537.2480 - mean_absolute_error: 23.6050\n",
      "Epoch 588: val_loss did not improve from 1464.89917\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1163.4620 - mean_absolute_error: 19.5669 - val_loss: 1476.1376 - val_mean_absolute_error: 25.7829\n",
      "Epoch 589/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 740.2991 - mean_absolute_error: 16.1661\n",
      "Epoch 589: val_loss improved from 1464.89917 to 1442.94934, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1193.6459 - mean_absolute_error: 19.6253 - val_loss: 1442.9493 - val_mean_absolute_error: 24.8412\n",
      "Epoch 590/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1242.0756 - mean_absolute_error: 19.0646\n",
      "Epoch 590: val_loss improved from 1442.94934 to 1442.58997, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.0045 - mean_absolute_error: 18.9534 - val_loss: 1442.5900 - val_mean_absolute_error: 25.0715\n",
      "Epoch 591/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1280.6304 - mean_absolute_error: 20.2023\n",
      "Epoch 591: val_loss improved from 1442.58997 to 1431.79456, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1238.5972 - mean_absolute_error: 20.0135 - val_loss: 1431.7946 - val_mean_absolute_error: 24.8619\n",
      "Epoch 592/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1204.3690 - mean_absolute_error: 19.1756\n",
      "Epoch 592: val_loss did not improve from 1431.79456\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.9539 - mean_absolute_error: 19.0726 - val_loss: 1432.6765 - val_mean_absolute_error: 25.0114\n",
      "Epoch 593/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 780.9773 - mean_absolute_error: 15.4305\n",
      "Epoch 593: val_loss improved from 1431.79456 to 1427.83606, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1123.7449 - mean_absolute_error: 19.1104 - val_loss: 1427.8361 - val_mean_absolute_error: 25.0232\n",
      "Epoch 594/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 885.6754 - mean_absolute_error: 15.1135\n",
      "Epoch 594: val_loss improved from 1427.83606 to 1417.89746, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.0649 - mean_absolute_error: 18.9134 - val_loss: 1417.8975 - val_mean_absolute_error: 24.8618\n",
      "Epoch 595/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 977.4136 - mean_absolute_error: 18.0632\n",
      "Epoch 595: val_loss improved from 1417.89746 to 1404.55127, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1187.1254 - mean_absolute_error: 19.1926 - val_loss: 1404.5513 - val_mean_absolute_error: 24.4802\n",
      "Epoch 596/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 880.7727 - mean_absolute_error: 16.2547\n",
      "Epoch 596: val_loss improved from 1404.55127 to 1401.78845, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1216.1146 - mean_absolute_error: 19.3378 - val_loss: 1401.7885 - val_mean_absolute_error: 24.5782\n",
      "Epoch 597/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 879.3246 - mean_absolute_error: 16.0672\n",
      "Epoch 597: val_loss did not improve from 1401.78845\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.8306 - mean_absolute_error: 19.4662 - val_loss: 1403.6187 - val_mean_absolute_error: 24.8336\n",
      "Epoch 598/1500\n",
      "\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.5858 - mean_absolute_error: 18.9900 \n",
      "Epoch 598: val_loss improved from 1401.78845 to 1401.49951, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1176.0975 - mean_absolute_error: 19.0477 - val_loss: 1401.4995 - val_mean_absolute_error: 24.9517\n",
      "Epoch 599/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 896.1826 - mean_absolute_error: 17.8456\n",
      "Epoch 599: val_loss did not improve from 1401.49951\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1025.2324 - mean_absolute_error: 18.6507 - val_loss: 1402.3114 - val_mean_absolute_error: 24.9946\n",
      "Epoch 600/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1683.8447 - mean_absolute_error: 21.6663\n",
      "Epoch 600: val_loss improved from 1401.49951 to 1382.80957, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.0343 - mean_absolute_error: 18.9088 - val_loss: 1382.8096 - val_mean_absolute_error: 24.5362\n",
      "Epoch 601/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 925.8652 - mean_absolute_error: 18.5105\n",
      "Epoch 601: val_loss improved from 1382.80957 to 1370.78015, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.2930 - mean_absolute_error: 19.6044 - val_loss: 1370.7802 - val_mean_absolute_error: 24.2745\n",
      "Epoch 602/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1088.3682 - mean_absolute_error: 18.1331\n",
      "Epoch 602: val_loss improved from 1370.78015 to 1366.06360, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.2625 - mean_absolute_error: 19.4594 - val_loss: 1366.0636 - val_mean_absolute_error: 24.3546\n",
      "Epoch 603/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 736.9128 - mean_absolute_error: 16.5316\n",
      "Epoch 603: val_loss improved from 1366.06360 to 1356.64453, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.0643 - mean_absolute_error: 19.0462 - val_loss: 1356.6445 - val_mean_absolute_error: 24.0848\n",
      "Epoch 604/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1544.8064 - mean_absolute_error: 21.2592\n",
      "Epoch 604: val_loss did not improve from 1356.64453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1143.5835 - mean_absolute_error: 19.0648 - val_loss: 1392.0431 - val_mean_absolute_error: 25.1369\n",
      "Epoch 605/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1560.9735 - mean_absolute_error: 23.9941\n",
      "Epoch 605: val_loss did not improve from 1356.64453\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1222.2031 - mean_absolute_error: 20.0193 - val_loss: 1360.2211 - val_mean_absolute_error: 24.3390\n",
      "Epoch 606/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1097.3855 - mean_absolute_error: 18.5682\n",
      "Epoch 606: val_loss improved from 1356.64453 to 1348.33997, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.8516 - mean_absolute_error: 19.1027 - val_loss: 1348.3400 - val_mean_absolute_error: 24.2455\n",
      "Epoch 607/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1208.4504 - mean_absolute_error: 20.3142\n",
      "Epoch 607: val_loss did not improve from 1348.33997\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.7377 - mean_absolute_error: 19.0670 - val_loss: 1353.1797 - val_mean_absolute_error: 24.5359\n",
      "Epoch 608/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1807.9304 - mean_absolute_error: 23.6432\n",
      "Epoch 608: val_loss improved from 1348.33997 to 1342.68701, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1170.8296 - mean_absolute_error: 19.1936 - val_loss: 1342.6870 - val_mean_absolute_error: 24.2841\n",
      "Epoch 609/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 999.8181 - mean_absolute_error: 17.9772\n",
      "Epoch 609: val_loss improved from 1342.68701 to 1329.66382, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1157.7156 - mean_absolute_error: 19.2324 - val_loss: 1329.6638 - val_mean_absolute_error: 23.8960\n",
      "Epoch 610/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1065.7585 - mean_absolute_error: 19.3970\n",
      "Epoch 610: val_loss improved from 1329.66382 to 1316.52441, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1207.5258 - mean_absolute_error: 19.8485 - val_loss: 1316.5244 - val_mean_absolute_error: 23.5236\n",
      "Epoch 611/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 970.4915 - mean_absolute_error: 17.9162\n",
      "Epoch 611: val_loss improved from 1316.52441 to 1311.03540, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1223.5975 - mean_absolute_error: 19.5313 - val_loss: 1311.0354 - val_mean_absolute_error: 23.4840\n",
      "Epoch 612/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 723.1765 - mean_absolute_error: 16.1689\n",
      "Epoch 612: val_loss improved from 1311.03540 to 1307.25574, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1167.3431 - mean_absolute_error: 19.2666 - val_loss: 1307.2557 - val_mean_absolute_error: 23.1969\n",
      "Epoch 613/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 762.3239 - mean_absolute_error: 16.9201\n",
      "Epoch 613: val_loss did not improve from 1307.25574\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.4589 - mean_absolute_error: 19.0178 - val_loss: 1322.5891 - val_mean_absolute_error: 24.2689\n",
      "Epoch 614/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1150.7894 - mean_absolute_error: 20.6300\n",
      "Epoch 614: val_loss improved from 1307.25574 to 1305.13660, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.8608 - mean_absolute_error: 19.1553 - val_loss: 1305.1366 - val_mean_absolute_error: 23.6106\n",
      "Epoch 615/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1052.4561 - mean_absolute_error: 20.0870\n",
      "Epoch 615: val_loss improved from 1305.13660 to 1302.55725, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1162.1389 - mean_absolute_error: 19.4565 - val_loss: 1302.5573 - val_mean_absolute_error: 23.8117\n",
      "Epoch 616/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 568.9449 - mean_absolute_error: 14.3587\n",
      "Epoch 616: val_loss did not improve from 1302.55725\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.4136 - mean_absolute_error: 19.0185 - val_loss: 1316.9364 - val_mean_absolute_error: 24.2625\n",
      "Epoch 617/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1777.9514 - mean_absolute_error: 21.5239\n",
      "Epoch 617: val_loss improved from 1302.55725 to 1295.44421, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1198.7479 - mean_absolute_error: 19.3805 - val_loss: 1295.4442 - val_mean_absolute_error: 23.7148\n",
      "Epoch 618/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1584.3250 - mean_absolute_error: 23.1333\n",
      "Epoch 618: val_loss improved from 1295.44421 to 1293.05786, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.5636 - mean_absolute_error: 19.2367 - val_loss: 1293.0579 - val_mean_absolute_error: 23.7975\n",
      "Epoch 619/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1429.6584 - mean_absolute_error: 19.4680\n",
      "Epoch 619: val_loss improved from 1293.05786 to 1280.33093, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1149.4733 - mean_absolute_error: 19.1947 - val_loss: 1280.3309 - val_mean_absolute_error: 23.4179\n",
      "Epoch 620/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1126.8837 - mean_absolute_error: 18.7845\n",
      "Epoch 620: val_loss did not improve from 1280.33093\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1212.9325 - mean_absolute_error: 19.6051 - val_loss: 1282.5408 - val_mean_absolute_error: 23.3635\n",
      "Epoch 621/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 799.1270 - mean_absolute_error: 15.7162\n",
      "Epoch 621: val_loss improved from 1280.33093 to 1271.12061, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1108.0670 - mean_absolute_error: 18.6837 - val_loss: 1271.1206 - val_mean_absolute_error: 23.2188\n",
      "Epoch 622/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 936.4136 - mean_absolute_error: 18.3861\n",
      "Epoch 622: val_loss did not improve from 1271.12061\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1033.6643 - mean_absolute_error: 18.3762 - val_loss: 1277.9681 - val_mean_absolute_error: 23.6282\n",
      "Epoch 623/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1616.4629 - mean_absolute_error: 22.2077\n",
      "Epoch 623: val_loss improved from 1271.12061 to 1265.50110, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1225.7355 - mean_absolute_error: 19.7535 - val_loss: 1265.5011 - val_mean_absolute_error: 23.3068\n",
      "Epoch 624/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1422.5985 - mean_absolute_error: 21.2547\n",
      "Epoch 624: val_loss improved from 1265.50110 to 1262.87097, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.3944 - mean_absolute_error: 18.8547 - val_loss: 1262.8710 - val_mean_absolute_error: 23.3008\n",
      "Epoch 625/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 743.0504 - mean_absolute_error: 15.5153\n",
      "Epoch 625: val_loss did not improve from 1262.87097\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1157.7324 - mean_absolute_error: 19.1307 - val_loss: 1267.4774 - val_mean_absolute_error: 23.5543\n",
      "Epoch 626/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1154.3196 - mean_absolute_error: 17.6825\n",
      "Epoch 626: val_loss did not improve from 1262.87097\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.8854 - mean_absolute_error: 18.4543 - val_loss: 1284.4919 - val_mean_absolute_error: 24.0974\n",
      "Epoch 627/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1361.9905 - mean_absolute_error: 21.0622\n",
      "Epoch 627: val_loss did not improve from 1262.87097\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.3384 - mean_absolute_error: 18.8677 - val_loss: 1265.0920 - val_mean_absolute_error: 23.7165\n",
      "Epoch 628/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1626.9055 - mean_absolute_error: 21.4697\n",
      "Epoch 628: val_loss improved from 1262.87097 to 1246.86255, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1231.5272 - mean_absolute_error: 19.7058 - val_loss: 1246.8625 - val_mean_absolute_error: 23.2354\n",
      "Epoch 629/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1157.8062 - mean_absolute_error: 18.9966\n",
      "Epoch 629: val_loss did not improve from 1246.86255\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1178.2258 - mean_absolute_error: 19.5033 - val_loss: 1247.0081 - val_mean_absolute_error: 23.1990\n",
      "Epoch 630/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 788.7605 - mean_absolute_error: 17.3000\n",
      "Epoch 630: val_loss improved from 1246.86255 to 1244.22278, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1144.5248 - mean_absolute_error: 19.1065 - val_loss: 1244.2228 - val_mean_absolute_error: 23.1264\n",
      "Epoch 631/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 1588.5499 - mean_absolute_error: 23.5510\n",
      "Epoch 631: val_loss improved from 1244.22278 to 1231.67017, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1183.3142 - mean_absolute_error: 19.1635 - val_loss: 1231.6702 - val_mean_absolute_error: 22.7808\n",
      "Epoch 632/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1023.3392 - mean_absolute_error: 19.8080\n",
      "Epoch 632: val_loss improved from 1231.67017 to 1230.56653, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.3748 - mean_absolute_error: 18.9372 - val_loss: 1230.5665 - val_mean_absolute_error: 22.8795\n",
      "Epoch 633/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1169.5413 - mean_absolute_error: 18.4700\n",
      "Epoch 633: val_loss did not improve from 1230.56653\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.8899 - mean_absolute_error: 18.5082 - val_loss: 1250.5914 - val_mean_absolute_error: 23.7518\n",
      "Epoch 634/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1088.9204 - mean_absolute_error: 20.2878\n",
      "Epoch 634: val_loss did not improve from 1230.56653\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.4174 - mean_absolute_error: 19.1545 - val_loss: 1231.5084 - val_mean_absolute_error: 23.0867\n",
      "Epoch 635/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1355.8188 - mean_absolute_error: 18.3945\n",
      "Epoch 635: val_loss improved from 1230.56653 to 1221.40601, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.9471 - mean_absolute_error: 18.5049 - val_loss: 1221.4060 - val_mean_absolute_error: 22.8299\n",
      "Epoch 636/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1004.7089 - mean_absolute_error: 17.0984\n",
      "Epoch 636: val_loss did not improve from 1221.40601\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.3612 - mean_absolute_error: 18.4503 - val_loss: 1232.0306 - val_mean_absolute_error: 23.3449\n",
      "Epoch 637/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 976.7688 - mean_absolute_error: 19.0660\n",
      "Epoch 637: val_loss improved from 1221.40601 to 1218.66663, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1116.7169 - mean_absolute_error: 18.9795 - val_loss: 1218.6666 - val_mean_absolute_error: 22.9176\n",
      "Epoch 638/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1219.5217 - mean_absolute_error: 21.0534\n",
      "Epoch 638: val_loss improved from 1218.66663 to 1216.36084, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.2771 - mean_absolute_error: 19.1797 - val_loss: 1216.3608 - val_mean_absolute_error: 22.8326\n",
      "Epoch 639/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 912.3395 - mean_absolute_error: 17.9270\n",
      "Epoch 639: val_loss improved from 1216.36084 to 1213.29443, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1151.3285 - mean_absolute_error: 18.8558 - val_loss: 1213.2944 - val_mean_absolute_error: 22.9686\n",
      "Epoch 640/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1092.8198 - mean_absolute_error: 18.3025\n",
      "Epoch 640: val_loss did not improve from 1213.29443\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.4795 - mean_absolute_error: 18.9489 - val_loss: 1218.8843 - val_mean_absolute_error: 23.2468\n",
      "Epoch 641/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1048.9603 - mean_absolute_error: 18.2154\n",
      "Epoch 641: val_loss improved from 1213.29443 to 1199.62634, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1095.4106 - mean_absolute_error: 18.6867 - val_loss: 1199.6263 - val_mean_absolute_error: 22.4365\n",
      "Epoch 642/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1523.0500 - mean_absolute_error: 21.5279\n",
      "Epoch 642: val_loss improved from 1199.62634 to 1195.63110, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.5333 - mean_absolute_error: 18.9672 - val_loss: 1195.6311 - val_mean_absolute_error: 22.5450\n",
      "Epoch 643/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1581.0627 - mean_absolute_error: 23.1384\n",
      "Epoch 643: val_loss improved from 1195.63110 to 1186.65710, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.3135 - mean_absolute_error: 18.7777 - val_loss: 1186.6571 - val_mean_absolute_error: 22.2124\n",
      "Epoch 644/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 949.3440 - mean_absolute_error: 17.4667\n",
      "Epoch 644: val_loss did not improve from 1186.65710\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.8760 - mean_absolute_error: 18.9024 - val_loss: 1195.2913 - val_mean_absolute_error: 22.6561\n",
      "Epoch 645/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 684.9910 - mean_absolute_error: 15.3295\n",
      "Epoch 645: val_loss did not improve from 1186.65710\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1149.9934 - mean_absolute_error: 18.9797 - val_loss: 1186.7554 - val_mean_absolute_error: 22.1223\n",
      "Epoch 646/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 745.6458 - mean_absolute_error: 16.9202\n",
      "Epoch 646: val_loss improved from 1186.65710 to 1178.59192, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1041.1194 - mean_absolute_error: 18.3917 - val_loss: 1178.5919 - val_mean_absolute_error: 22.3279\n",
      "Epoch 647/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1300.1915 - mean_absolute_error: 18.7364\n",
      "Epoch 647: val_loss improved from 1178.59192 to 1175.51697, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1174.5557 - mean_absolute_error: 19.1444 - val_loss: 1175.5170 - val_mean_absolute_error: 22.1177\n",
      "Epoch 648/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1207.2960 - mean_absolute_error: 20.2987\n",
      "Epoch 648: val_loss did not improve from 1175.51697\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.4244 - mean_absolute_error: 19.1068 - val_loss: 1187.2709 - val_mean_absolute_error: 22.6795\n",
      "Epoch 649/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1215.1527 - mean_absolute_error: 21.1790\n",
      "Epoch 649: val_loss improved from 1175.51697 to 1170.12292, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.5630 - mean_absolute_error: 19.1495 - val_loss: 1170.1229 - val_mean_absolute_error: 22.4171\n",
      "Epoch 650/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1077.4626 - mean_absolute_error: 17.2619\n",
      "Epoch 650: val_loss did not improve from 1170.12292\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1067.8212 - mean_absolute_error: 18.4297 - val_loss: 1189.4045 - val_mean_absolute_error: 23.1690\n",
      "Epoch 651/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1284.1792 - mean_absolute_error: 23.0298\n",
      "Epoch 651: val_loss improved from 1170.12292 to 1162.67664, saving model to checkpoint.model5.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1142.9375 - mean_absolute_error: 19.4861 - val_loss: 1162.6766 - val_mean_absolute_error: 22.0013\n",
      "Epoch 652/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 795.5259 - mean_absolute_error: 16.8677\n",
      "Epoch 652: val_loss did not improve from 1162.67664\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1153.5800 - mean_absolute_error: 18.8039 - val_loss: 1163.2090 - val_mean_absolute_error: 22.2330\n",
      "Epoch 653/1500\n",
      "\u001b[1m22/33\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071.0740 - mean_absolute_error: 18.4079\n",
      "Epoch 653: val_loss did not improve from 1162.67664\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1091.4838 - mean_absolute_error: 18.5559 - val_loss: 1174.7053 - val_mean_absolute_error: 22.8436\n",
      "Epoch 654/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 717.2073 - mean_absolute_error: 16.0267"
     ]
    }
   ],
   "source": [
    "model5.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=1500, callbacks=[cp5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "AzIN93E2xRjE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1, 3)\n",
      "(31, 3)\n"
     ]
    }
   ],
   "source": [
    "def mae(true, pred):\n",
    "    return np.mean(np.abs(true - pred))\n",
    "\n",
    "def plot_predictions2(model, X, y, cols, start=0, end=100):\n",
    "    predictions = model.predict(X)+13\n",
    "    df = pd.DataFrame(data=predictions)\n",
    "    df.columns=cols\n",
    "    org = pd.DataFrame(data=y)\n",
    "    org.columns = cols\n",
    "    plt.plot(df['PM2.5 (µg/m³)'][start:end])\n",
    "    plt.plot(org['PM2.5 (µg/m³)'][start:end])\n",
    "    a = org.astype('float32')\n",
    "    print(predictions[:,-1].dtype)\n",
    "    ma = mae(a['PM2.5 (µg/m³)'],df['PM2.5 (µg/m³)'])\n",
    "    return df[start:end], org, ma\n",
    "x_test_start = df_corr.values[-1]\n",
    "x_test_start = np.reshape(x_test_start,(1,1,3))\n",
    "y_test_start = val.values[0]\n",
    "x_test_9 = np.vstack((x_test_start, X2_test))\n",
    "print(x_test_9.shape)\n",
    "y_test_9 = np.vstack((y_test_start, y3_test))\n",
    "print(y_test_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(InputLayer((1, 3)))\n",
    "model5.add(LSTM(64))\n",
    "model5.add(Dense(8, 'relu'))\n",
    "model5.add(Dense(3, 'linear'))\n",
    "\n",
    "# Load the previously saved weights\n",
    "model5.load_weights('checkpoint.model5.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "QzXcewu_zy2k",
    "outputId": "0f520f7f-6aa3-4079-edf5-4c5ff4626258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "float32\n",
      "mean absolute error:  38.74957\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5, org_5, mae_5 = plot_predictions2(model5, x_test_9, y_test_9,cols)\n",
    "print(\"mean absolute error: \",mae_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.202382</td>\n",
       "      <td>101.936302</td>\n",
       "      <td>205.528473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.477810</td>\n",
       "      <td>97.726280</td>\n",
       "      <td>178.758453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.283985</td>\n",
       "      <td>104.238693</td>\n",
       "      <td>204.755234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.159111</td>\n",
       "      <td>105.893639</td>\n",
       "      <td>216.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.202182</td>\n",
       "      <td>100.771057</td>\n",
       "      <td>203.339432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.433423</td>\n",
       "      <td>95.063545</td>\n",
       "      <td>174.886200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.382611</td>\n",
       "      <td>99.188515</td>\n",
       "      <td>188.778992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.400288</td>\n",
       "      <td>107.688126</td>\n",
       "      <td>194.782593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.012829</td>\n",
       "      <td>115.134758</td>\n",
       "      <td>237.061905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.538435</td>\n",
       "      <td>94.996887</td>\n",
       "      <td>167.240738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.465210</td>\n",
       "      <td>99.119926</td>\n",
       "      <td>181.959930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.312109</td>\n",
       "      <td>108.799339</td>\n",
       "      <td>205.880997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.617128</td>\n",
       "      <td>127.877274</td>\n",
       "      <td>169.640305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.842936</td>\n",
       "      <td>124.044052</td>\n",
       "      <td>256.685120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.945780</td>\n",
       "      <td>121.127434</td>\n",
       "      <td>246.061157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.371447</td>\n",
       "      <td>114.375832</td>\n",
       "      <td>200.016113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.412722</td>\n",
       "      <td>104.338951</td>\n",
       "      <td>194.124908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.423340</td>\n",
       "      <td>104.998909</td>\n",
       "      <td>193.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.261198</td>\n",
       "      <td>107.403122</td>\n",
       "      <td>209.379410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.452107</td>\n",
       "      <td>99.227005</td>\n",
       "      <td>183.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.204964</td>\n",
       "      <td>106.149063</td>\n",
       "      <td>212.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.393230</td>\n",
       "      <td>101.157234</td>\n",
       "      <td>191.614014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.160467</td>\n",
       "      <td>111.073174</td>\n",
       "      <td>222.086273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.149202</td>\n",
       "      <td>110.301468</td>\n",
       "      <td>223.147705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.083117</td>\n",
       "      <td>114.328957</td>\n",
       "      <td>231.126038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.196472</td>\n",
       "      <td>117.054306</td>\n",
       "      <td>219.256409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.624317</td>\n",
       "      <td>134.682281</td>\n",
       "      <td>274.741486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.238678</td>\n",
       "      <td>118.243797</td>\n",
       "      <td>216.463196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.049097</td>\n",
       "      <td>113.633667</td>\n",
       "      <td>235.478149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.210838</td>\n",
       "      <td>114.498306</td>\n",
       "      <td>217.997101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.156006</td>\n",
       "      <td>111.330109</td>\n",
       "      <td>221.316833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "0   13.202382  101.936302     205.528473\n",
       "1   13.477810   97.726280     178.758453\n",
       "2   13.283985  104.238693     204.755234\n",
       "3   13.159111  105.893639     216.004913\n",
       "4   13.202182  100.771057     203.339432\n",
       "5   13.433423   95.063545     174.886200\n",
       "6   13.382611   99.188515     188.778992\n",
       "7   13.400288  107.688126     194.782593\n",
       "8   13.012829  115.134758     237.061905\n",
       "9   13.538435   94.996887     167.240738\n",
       "10  13.465210   99.119926     181.959930\n",
       "11  13.312109  108.799339     205.880997\n",
       "12  13.617128  127.877274     169.640305\n",
       "13  12.842936  124.044052     256.685120\n",
       "14  12.945780  121.127434     246.061157\n",
       "15  13.371447  114.375832     200.016113\n",
       "16  13.412722  104.338951     194.124908\n",
       "17  13.423340  104.998909     193.006592\n",
       "18  13.261198  107.403122     209.379410\n",
       "19  13.452107   99.227005     183.501343\n",
       "20  13.204964  106.149063     212.848846\n",
       "21  13.393230  101.157234     191.614014\n",
       "22  13.160467  111.073174     222.086273\n",
       "23  13.149202  110.301468     223.147705\n",
       "24  13.083117  114.328957     231.126038\n",
       "25  13.196472  117.054306     219.256409\n",
       "26  12.624317  134.682281     274.741486\n",
       "27  13.238678  118.243797     216.463196\n",
       "28  13.049097  113.633667     235.478149\n",
       "29  13.210838  114.498306     217.997101\n",
       "30  13.156006  111.330109     221.316833"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51</td>\n",
       "      <td>74.96</td>\n",
       "      <td>159.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>81.38</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45</td>\n",
       "      <td>64.66</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.48</td>\n",
       "      <td>56.41</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.38</td>\n",
       "      <td>48.90</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.51</td>\n",
       "      <td>67.82</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40</td>\n",
       "      <td>102.06</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29</td>\n",
       "      <td>86.84</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.53</td>\n",
       "      <td>65.92</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.75</td>\n",
       "      <td>79.49</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>103.14</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>109.45</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.36</td>\n",
       "      <td>102.28</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.40</td>\n",
       "      <td>106.05</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.43</td>\n",
       "      <td>113.21</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.71</td>\n",
       "      <td>99.30</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.63</td>\n",
       "      <td>101.43</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.42</td>\n",
       "      <td>91.86</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.66</td>\n",
       "      <td>79.06</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.31</td>\n",
       "      <td>76.87</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.56</td>\n",
       "      <td>81.75</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.52</td>\n",
       "      <td>95.49</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.59</td>\n",
       "      <td>90.75</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.49</td>\n",
       "      <td>98.08</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.34</td>\n",
       "      <td>115.67</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.19</td>\n",
       "      <td>119.65</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.51</td>\n",
       "      <td>124.78</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.65</td>\n",
       "      <td>88.99</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.44</td>\n",
       "      <td>111.66</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.33</td>\n",
       "      <td>93.28</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.52</td>\n",
       "      <td>78.51</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "0       0.51       74.96         159.49\n",
       "1       0.50       81.38         201.22\n",
       "2       0.45       64.66         235.04\n",
       "3       0.48       56.41         223.36\n",
       "4       0.38       48.90         153.35\n",
       "5       0.51       67.82         176.58\n",
       "6       0.40      102.06         179.29\n",
       "7       0.29       86.84         260.26\n",
       "8       0.53       65.92         144.39\n",
       "9       0.75       79.49         176.85\n",
       "10      0.50      103.14         200.03\n",
       "11      0.50      109.45         161.85\n",
       "12      0.36      102.28         324.88\n",
       "13      0.40      106.05         285.11\n",
       "14      0.43      113.21         191.13\n",
       "15      0.71       99.30         194.15\n",
       "16      0.63      101.43         188.70\n",
       "17      0.42       91.86         201.74\n",
       "18      0.66       79.06         174.39\n",
       "19      0.31       76.87         206.83\n",
       "20      0.56       81.75         181.35\n",
       "21      0.52       95.49         234.13\n",
       "22      0.59       90.75         244.36\n",
       "23      0.49       98.08         252.99\n",
       "24      0.34      115.67         212.36\n",
       "25      0.19      119.65         401.43\n",
       "26      0.51      124.78         220.10\n",
       "27      0.65       88.99         284.35\n",
       "28      0.44      111.66         216.37\n",
       "29      0.33       93.28         219.25\n",
       "30      0.52       78.51         204.15"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.74957"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.index = val.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>13.202382</td>\n",
       "      <td>101.936302</td>\n",
       "      <td>205.528473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>13.477810</td>\n",
       "      <td>97.726280</td>\n",
       "      <td>178.758453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>13.283985</td>\n",
       "      <td>104.238693</td>\n",
       "      <td>204.755234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>13.159111</td>\n",
       "      <td>105.893639</td>\n",
       "      <td>216.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>13.202182</td>\n",
       "      <td>100.771057</td>\n",
       "      <td>203.339432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>13.433423</td>\n",
       "      <td>95.063545</td>\n",
       "      <td>174.886200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>13.382611</td>\n",
       "      <td>99.188515</td>\n",
       "      <td>188.778992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>13.400288</td>\n",
       "      <td>107.688126</td>\n",
       "      <td>194.782593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>13.012829</td>\n",
       "      <td>115.134758</td>\n",
       "      <td>237.061905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>13.538435</td>\n",
       "      <td>94.996887</td>\n",
       "      <td>167.240738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>13.465210</td>\n",
       "      <td>99.119926</td>\n",
       "      <td>181.959930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>13.312109</td>\n",
       "      <td>108.799339</td>\n",
       "      <td>205.880997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>13.617128</td>\n",
       "      <td>127.877274</td>\n",
       "      <td>169.640305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>12.842936</td>\n",
       "      <td>124.044052</td>\n",
       "      <td>256.685120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>12.945780</td>\n",
       "      <td>121.127434</td>\n",
       "      <td>246.061157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>13.371447</td>\n",
       "      <td>114.375832</td>\n",
       "      <td>200.016113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>13.412722</td>\n",
       "      <td>104.338951</td>\n",
       "      <td>194.124908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>13.423340</td>\n",
       "      <td>104.998909</td>\n",
       "      <td>193.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>13.261198</td>\n",
       "      <td>107.403122</td>\n",
       "      <td>209.379410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>13.452107</td>\n",
       "      <td>99.227005</td>\n",
       "      <td>183.501343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>13.204964</td>\n",
       "      <td>106.149063</td>\n",
       "      <td>212.848846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>13.393230</td>\n",
       "      <td>101.157234</td>\n",
       "      <td>191.614014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>13.160467</td>\n",
       "      <td>111.073174</td>\n",
       "      <td>222.086273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>13.149202</td>\n",
       "      <td>110.301468</td>\n",
       "      <td>223.147705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>13.083117</td>\n",
       "      <td>114.328957</td>\n",
       "      <td>231.126038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>13.196472</td>\n",
       "      <td>117.054306</td>\n",
       "      <td>219.256409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>12.624317</td>\n",
       "      <td>134.682281</td>\n",
       "      <td>274.741486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>13.238678</td>\n",
       "      <td>118.243797</td>\n",
       "      <td>216.463196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>13.049097</td>\n",
       "      <td>113.633667</td>\n",
       "      <td>235.478149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>13.210838</td>\n",
       "      <td>114.498306</td>\n",
       "      <td>217.997101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>13.156006</td>\n",
       "      <td>111.330109</td>\n",
       "      <td>221.316833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                       \n",
       "2024-01-01  13.202382  101.936302     205.528473\n",
       "2024-01-02  13.477810   97.726280     178.758453\n",
       "2024-01-03  13.283985  104.238693     204.755234\n",
       "2024-01-04  13.159111  105.893639     216.004913\n",
       "2024-01-05  13.202182  100.771057     203.339432\n",
       "2024-01-06  13.433423   95.063545     174.886200\n",
       "2024-01-07  13.382611   99.188515     188.778992\n",
       "2024-01-08  13.400288  107.688126     194.782593\n",
       "2024-01-09  13.012829  115.134758     237.061905\n",
       "2024-01-10  13.538435   94.996887     167.240738\n",
       "2024-01-11  13.465210   99.119926     181.959930\n",
       "2024-01-12  13.312109  108.799339     205.880997\n",
       "2024-01-13  13.617128  127.877274     169.640305\n",
       "2024-01-14  12.842936  124.044052     256.685120\n",
       "2024-01-15  12.945780  121.127434     246.061157\n",
       "2024-01-16  13.371447  114.375832     200.016113\n",
       "2024-01-17  13.412722  104.338951     194.124908\n",
       "2024-01-18  13.423340  104.998909     193.006592\n",
       "2024-01-19  13.261198  107.403122     209.379410\n",
       "2024-01-20  13.452107   99.227005     183.501343\n",
       "2024-01-21  13.204964  106.149063     212.848846\n",
       "2024-01-22  13.393230  101.157234     191.614014\n",
       "2024-01-23  13.160467  111.073174     222.086273\n",
       "2024-01-24  13.149202  110.301468     223.147705\n",
       "2024-01-25  13.083117  114.328957     231.126038\n",
       "2024-01-26  13.196472  117.054306     219.256409\n",
       "2024-01-27  12.624317  134.682281     274.741486\n",
       "2024-01-28  13.238678  118.243797     216.463196\n",
       "2024-01-29  13.049097  113.633667     235.478149\n",
       "2024-01-30  13.210838  114.498306     217.997101\n",
       "2024-01-31  13.156006  111.330109     221.316833"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2021-01-01    218.810000\n",
       "2021-01-02    138.800000\n",
       "2021-01-03     75.310000\n",
       "2021-01-04     53.340000\n",
       "2021-01-05     40.430000\n",
       "                 ...    \n",
       "2024-01-27    259.510071\n",
       "2024-01-28    219.164581\n",
       "2024-01-29    237.942719\n",
       "2024-01-30    220.667480\n",
       "2024-01-31    225.795547\n",
       "Length: 1126, dtype: float64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>138.990000</td>\n",
       "      <td>218.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>109.290000</td>\n",
       "      <td>138.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>111.440000</td>\n",
       "      <td>75.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>124.180000</td>\n",
       "      <td>53.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>104.250000</td>\n",
       "      <td>40.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>0.363021</td>\n",
       "      <td>106.197917</td>\n",
       "      <td>228.512153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>0.514931</td>\n",
       "      <td>99.705556</td>\n",
       "      <td>180.473188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>0.438437</td>\n",
       "      <td>95.739931</td>\n",
       "      <td>281.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-30</th>\n",
       "      <td>0.463750</td>\n",
       "      <td>83.224653</td>\n",
       "      <td>235.994318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>0.509792</td>\n",
       "      <td>58.152431</td>\n",
       "      <td>226.246875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                      \n",
       "2021-01-01  0.680000  138.990000     218.810000\n",
       "2021-01-02  0.710000  109.290000     138.800000\n",
       "2021-01-03  0.900000  111.440000      75.310000\n",
       "2021-01-04  0.700000  124.180000      53.340000\n",
       "2021-01-05  0.860000  104.250000      40.430000\n",
       "...              ...         ...            ...\n",
       "2023-12-27  0.363021  106.197917     228.512153\n",
       "2023-12-28  0.514931   99.705556     180.473188\n",
       "2023-12-29  0.438437   95.739931     281.644444\n",
       "2023-12-30  0.463750   83.224653     235.994318\n",
       "2023-12-31  0.509792   58.152431     226.246875\n",
       "\n",
       "[1095 rows x 3 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WS (m/s)</th>\n",
       "      <th>SR (W/mt2)</th>\n",
       "      <th>PM2.5 (µg/m³)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>0.51</td>\n",
       "      <td>74.96</td>\n",
       "      <td>159.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>0.50</td>\n",
       "      <td>81.38</td>\n",
       "      <td>201.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>0.45</td>\n",
       "      <td>64.66</td>\n",
       "      <td>235.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>0.48</td>\n",
       "      <td>56.41</td>\n",
       "      <td>223.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>0.38</td>\n",
       "      <td>48.90</td>\n",
       "      <td>153.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>0.51</td>\n",
       "      <td>67.82</td>\n",
       "      <td>176.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>0.40</td>\n",
       "      <td>102.06</td>\n",
       "      <td>179.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>0.29</td>\n",
       "      <td>86.84</td>\n",
       "      <td>260.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>0.53</td>\n",
       "      <td>65.92</td>\n",
       "      <td>144.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>0.75</td>\n",
       "      <td>79.49</td>\n",
       "      <td>176.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>0.50</td>\n",
       "      <td>103.14</td>\n",
       "      <td>200.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>109.45</td>\n",
       "      <td>161.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-13</th>\n",
       "      <td>0.36</td>\n",
       "      <td>102.28</td>\n",
       "      <td>324.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-14</th>\n",
       "      <td>0.40</td>\n",
       "      <td>106.05</td>\n",
       "      <td>285.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>0.43</td>\n",
       "      <td>113.21</td>\n",
       "      <td>191.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16</th>\n",
       "      <td>0.71</td>\n",
       "      <td>99.30</td>\n",
       "      <td>194.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>0.63</td>\n",
       "      <td>101.43</td>\n",
       "      <td>188.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-18</th>\n",
       "      <td>0.42</td>\n",
       "      <td>91.86</td>\n",
       "      <td>201.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>0.66</td>\n",
       "      <td>79.06</td>\n",
       "      <td>174.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-20</th>\n",
       "      <td>0.31</td>\n",
       "      <td>76.87</td>\n",
       "      <td>206.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-21</th>\n",
       "      <td>0.56</td>\n",
       "      <td>81.75</td>\n",
       "      <td>181.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>0.52</td>\n",
       "      <td>95.49</td>\n",
       "      <td>234.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>0.59</td>\n",
       "      <td>90.75</td>\n",
       "      <td>244.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>0.49</td>\n",
       "      <td>98.08</td>\n",
       "      <td>252.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>0.34</td>\n",
       "      <td>115.67</td>\n",
       "      <td>212.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>0.19</td>\n",
       "      <td>119.65</td>\n",
       "      <td>401.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-27</th>\n",
       "      <td>0.51</td>\n",
       "      <td>124.78</td>\n",
       "      <td>220.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-28</th>\n",
       "      <td>0.65</td>\n",
       "      <td>88.99</td>\n",
       "      <td>284.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>0.44</td>\n",
       "      <td>111.66</td>\n",
       "      <td>216.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>0.33</td>\n",
       "      <td>93.28</td>\n",
       "      <td>219.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0.52</td>\n",
       "      <td>78.51</td>\n",
       "      <td>204.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            WS (m/s)  SR (W/mt2)  PM2.5 (µg/m³)\n",
       "Timestamp                                      \n",
       "2024-01-01      0.51       74.96         159.49\n",
       "2024-01-02      0.50       81.38         201.22\n",
       "2024-01-03      0.45       64.66         235.04\n",
       "2024-01-04      0.48       56.41         223.36\n",
       "2024-01-05      0.38       48.90         153.35\n",
       "2024-01-06      0.51       67.82         176.58\n",
       "2024-01-07      0.40      102.06         179.29\n",
       "2024-01-08      0.29       86.84         260.26\n",
       "2024-01-09      0.53       65.92         144.39\n",
       "2024-01-10      0.75       79.49         176.85\n",
       "2024-01-11      0.50      103.14         200.03\n",
       "2024-01-12      0.50      109.45         161.85\n",
       "2024-01-13      0.36      102.28         324.88\n",
       "2024-01-14      0.40      106.05         285.11\n",
       "2024-01-15      0.43      113.21         191.13\n",
       "2024-01-16      0.71       99.30         194.15\n",
       "2024-01-17      0.63      101.43         188.70\n",
       "2024-01-18      0.42       91.86         201.74\n",
       "2024-01-19      0.66       79.06         174.39\n",
       "2024-01-20      0.31       76.87         206.83\n",
       "2024-01-21      0.56       81.75         181.35\n",
       "2024-01-22      0.52       95.49         234.13\n",
       "2024-01-23      0.59       90.75         244.36\n",
       "2024-01-24      0.49       98.08         252.99\n",
       "2024-01-25      0.34      115.67         212.36\n",
       "2024-01-26      0.19      119.65         401.43\n",
       "2024-01-27      0.51      124.78         220.10\n",
       "2024-01-28      0.65       88.99         284.35\n",
       "2024-01-29      0.44      111.66         216.37\n",
       "2024-01-30      0.33       93.28         219.25\n",
       "2024-01-31      0.52       78.51         204.15"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_5['PM2.5 (µg/m³)']])\n",
    "org_5.index = val.index\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], org_5['PM2.5 (µg/m³)']])\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train_last_samples')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction')\n",
    "plt.plot(df_org.index[1095:],df_org[1095:],color='green',label='actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmwCnsUj2B8A",
    "outputId": "475af39f-a4f9-40cd-bcfe-ce080d8539f1"
   },
   "source": [
    "model6 = Sequential()\n",
    "model6.add(InputLayer((1, 5)))\n",
    "model6.add(LSTM(32, return_sequences=True))\n",
    "model6.add(LSTM(64))\n",
    "model6.add(Dense(8, 'relu'))\n",
    "model6.add(Dense(5, 'linear'))\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWepnsFE2Tnl"
   },
   "source": [
    "cp6 = ModelCheckpoint('checkpoints.model6.keras', save_best_only=True)\n",
    "model6.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "7XnlR3om2aiA",
    "outputId": "404ce81e-7255-4c09-9e43-12057dc4d980"
   },
   "source": [
    "model6.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=200, callbacks=[cp6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fy6pKacl2bOW",
    "outputId": "fb3aad92-2323-421e-bc68-956bc39107f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m27\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803</span> (3.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m803\u001b[0m (3.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803</span> (3.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m803\u001b[0m (3.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(InputLayer((1, 3)))\n",
    "model7.add(Conv1D(64, kernel_size=1, activation='relu'))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(8, 'relu'))\n",
    "model7.add(Dense(3, 'linear'))\n",
    "model7.summary()\n",
    "\n",
    "cp7 = ModelCheckpoint('checkpoints.model7.keras', monitor='val_loss', verbose=1, \\\n",
    "                             save_best_only=True, save_weights_only=False, \\\n",
    "                             mode='auto')\n",
    "model7.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMRDXuFY27JA",
    "outputId": "54fa8a3f-ae81-4567-a40a-7652a7ec274f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 668ms/step - loss: 20228.1484 - mean_absolute_error: 113.4909\n",
      "Epoch 1: val_loss improved from inf to 14597.52734, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16839.4414 - mean_absolute_error: 103.9517 - val_loss: 14597.5273 - val_mean_absolute_error: 107.2712\n",
      "Epoch 2/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 15494.9551 - mean_absolute_error: 99.6673\n",
      "Epoch 2: val_loss improved from 14597.52734 to 13612.28027, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15435.3184 - mean_absolute_error: 99.0807 - val_loss: 13612.2803 - val_mean_absolute_error: 102.3033\n",
      "Epoch 3/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 16075.9277 - mean_absolute_error: 99.6959\n",
      "Epoch 3: val_loss improved from 13612.28027 to 12838.99121, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14929.6670 - mean_absolute_error: 97.2971 - val_loss: 12838.9912 - val_mean_absolute_error: 98.7055\n",
      "Epoch 4/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 17298.5039 - mean_absolute_error: 100.1249\n",
      "Epoch 4: val_loss improved from 12838.99121 to 12186.49512, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 14068.2402 - mean_absolute_error: 94.8275 - val_loss: 12186.4951 - val_mean_absolute_error: 95.8772\n",
      "Epoch 5/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14265.2266 - mean_absolute_error: 94.4454\n",
      "Epoch 5: val_loss improved from 12186.49512 to 11581.09277, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13116.4727 - mean_absolute_error: 91.4700 - val_loss: 11581.0928 - val_mean_absolute_error: 93.2206\n",
      "Epoch 6/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12497.7109 - mean_absolute_error: 90.5011\n",
      "Epoch 6: val_loss improved from 11581.09277 to 10944.66406, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12483.7080 - mean_absolute_error: 90.4214 - val_loss: 10944.6641 - val_mean_absolute_error: 90.4994\n",
      "Epoch 7/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 12896.8018 - mean_absolute_error: 90.7117\n",
      "Epoch 7: val_loss improved from 10944.66406 to 10304.24609, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11827.3691 - mean_absolute_error: 87.7077 - val_loss: 10304.2461 - val_mean_absolute_error: 87.9390\n",
      "Epoch 8/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 10443.4072 - mean_absolute_error: 84.8119\n",
      "Epoch 8: val_loss improved from 10304.24609 to 9655.56543, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11126.2070 - mean_absolute_error: 85.4139 - val_loss: 9655.5654 - val_mean_absolute_error: 85.2614\n",
      "Epoch 9/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 10356.4062 - mean_absolute_error: 82.8598\n",
      "Epoch 9: val_loss improved from 9655.56543 to 9021.17871, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10649.7324 - mean_absolute_error: 83.4221 - val_loss: 9021.1787 - val_mean_absolute_error: 82.4947\n",
      "Epoch 10/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 11065.3887 - mean_absolute_error: 85.8160\n",
      "Epoch 10: val_loss improved from 9021.17871 to 8429.42285, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10048.7754 - mean_absolute_error: 81.5082 - val_loss: 8429.4229 - val_mean_absolute_error: 79.7548\n",
      "Epoch 11/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8817.8418 - mean_absolute_error: 76.2744\n",
      "Epoch 11: val_loss improved from 8429.42285 to 7833.02783, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9071.9443 - mean_absolute_error: 77.4161 - val_loss: 7833.0278 - val_mean_absolute_error: 76.8504\n",
      "Epoch 12/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9013.1953 - mean_absolute_error: 78.9570\n",
      "Epoch 12: val_loss improved from 7833.02783 to 7267.66992, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8969.0293 - mean_absolute_error: 77.4734 - val_loss: 7267.6699 - val_mean_absolute_error: 73.8618\n",
      "Epoch 13/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9898.9941 - mean_absolute_error: 78.8936\n",
      "Epoch 13: val_loss improved from 7267.66992 to 6711.46045, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8552.4590 - mean_absolute_error: 74.8434 - val_loss: 6711.4604 - val_mean_absolute_error: 70.8359\n",
      "Epoch 14/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7580.2812 - mean_absolute_error: 69.8121\n",
      "Epoch 14: val_loss improved from 6711.46045 to 6180.61572, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7832.7651 - mean_absolute_error: 71.7974 - val_loss: 6180.6157 - val_mean_absolute_error: 67.7829\n",
      "Epoch 15/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7591.8574 - mean_absolute_error: 71.1871\n",
      "Epoch 15: val_loss improved from 6180.61572 to 5670.50244, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7421.3711 - mean_absolute_error: 69.6893 - val_loss: 5670.5024 - val_mean_absolute_error: 64.6480\n",
      "Epoch 16/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7024.0703 - mean_absolute_error: 68.7558\n",
      "Epoch 16: val_loss improved from 5670.50244 to 5185.96338, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6876.1851 - mean_absolute_error: 67.4058 - val_loss: 5185.9634 - val_mean_absolute_error: 61.4550\n",
      "Epoch 17/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8339.4443 - mean_absolute_error: 72.1498\n",
      "Epoch 17: val_loss improved from 5185.96338 to 4714.44189, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6597.3809 - mean_absolute_error: 65.5095 - val_loss: 4714.4419 - val_mean_absolute_error: 58.1428\n",
      "Epoch 18/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5194.1699 - mean_absolute_error: 58.3923\n",
      "Epoch 18: val_loss improved from 4714.44189 to 4297.55225, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6042.6816 - mean_absolute_error: 62.1821 - val_loss: 4297.5522 - val_mean_absolute_error: 54.9232\n",
      "Epoch 19/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5059.2637 - mean_absolute_error: 57.7921\n",
      "Epoch 19: val_loss improved from 4297.55225 to 3879.36230, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5361.9570 - mean_absolute_error: 59.0901 - val_loss: 3879.3623 - val_mean_absolute_error: 51.6060\n",
      "Epoch 20/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4794.7549 - mean_absolute_error: 59.1732\n",
      "Epoch 20: val_loss improved from 3879.36230 to 3508.32544, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5248.3755 - mean_absolute_error: 58.3949 - val_loss: 3508.3254 - val_mean_absolute_error: 48.5003\n",
      "Epoch 21/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4606.0957 - mean_absolute_error: 55.6512\n",
      "Epoch 21: val_loss improved from 3508.32544 to 3182.42065, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4849.2002 - mean_absolute_error: 55.7978 - val_loss: 3182.4207 - val_mean_absolute_error: 45.5489\n",
      "Epoch 22/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3877.4453 - mean_absolute_error: 51.4846\n",
      "Epoch 22: val_loss improved from 3182.42065 to 2864.59155, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4410.8115 - mean_absolute_error: 53.1968 - val_loss: 2864.5916 - val_mean_absolute_error: 42.6920\n",
      "Epoch 23/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4758.6553 - mean_absolute_error: 51.8684\n",
      "Epoch 23: val_loss improved from 2864.59155 to 2596.09546, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4135.7114 - mean_absolute_error: 50.5934 - val_loss: 2596.0955 - val_mean_absolute_error: 40.1617\n",
      "Epoch 24/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3088.7197 - mean_absolute_error: 46.7921\n",
      "Epoch 24: val_loss improved from 2596.09546 to 2352.16675, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3730.4702 - mean_absolute_error: 48.6618 - val_loss: 2352.1667 - val_mean_absolute_error: 37.8316\n",
      "Epoch 25/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3504.8696 - mean_absolute_error: 46.3742\n",
      "Epoch 25: val_loss improved from 2352.16675 to 2149.05371, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3658.5508 - mean_absolute_error: 47.1976 - val_loss: 2149.0537 - val_mean_absolute_error: 35.8094\n",
      "Epoch 26/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4181.8164 - mean_absolute_error: 51.7226\n",
      "Epoch 26: val_loss improved from 2149.05371 to 1964.93286, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3612.1548 - mean_absolute_error: 47.0190 - val_loss: 1964.9329 - val_mean_absolute_error: 33.9935\n",
      "Epoch 27/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3186.1309 - mean_absolute_error: 45.1821\n",
      "Epoch 27: val_loss improved from 1964.93286 to 1827.09375, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3215.0471 - mean_absolute_error: 44.6062 - val_loss: 1827.0938 - val_mean_absolute_error: 32.6147\n",
      "Epoch 28/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3976.3057 - mean_absolute_error: 50.9788\n",
      "Epoch 28: val_loss improved from 1827.09375 to 1703.51501, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3254.9954 - mean_absolute_error: 44.6201 - val_loss: 1703.5150 - val_mean_absolute_error: 31.3934\n",
      "Epoch 29/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3008.5415 - mean_absolute_error: 45.0626\n",
      "Epoch 29: val_loss improved from 1703.51501 to 1603.98572, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2856.5388 - mean_absolute_error: 41.9662 - val_loss: 1603.9857 - val_mean_absolute_error: 30.3657\n",
      "Epoch 30/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2223.4099 - mean_absolute_error: 38.8703\n",
      "Epoch 30: val_loss improved from 1603.98572 to 1535.77808, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2616.2058 - mean_absolute_error: 40.2213 - val_loss: 1535.7781 - val_mean_absolute_error: 29.6168\n",
      "Epoch 31/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2593.1372 - mean_absolute_error: 39.8265\n",
      "Epoch 31: val_loss improved from 1535.77808 to 1459.12634, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2531.1707 - mean_absolute_error: 39.5960 - val_loss: 1459.1263 - val_mean_absolute_error: 28.7384\n",
      "Epoch 32/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1673.1929 - mean_absolute_error: 33.0002\n",
      "Epoch 32: val_loss improved from 1459.12634 to 1403.06726, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2508.4714 - mean_absolute_error: 38.7688 - val_loss: 1403.0673 - val_mean_absolute_error: 28.1264\n",
      "Epoch 33/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2627.8242 - mean_absolute_error: 39.8907\n",
      "Epoch 33: val_loss improved from 1403.06726 to 1364.03662, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2466.9138 - mean_absolute_error: 38.7445 - val_loss: 1364.0366 - val_mean_absolute_error: 27.6800\n",
      "Epoch 34/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2191.8662 - mean_absolute_error: 38.7497\n",
      "Epoch 34: val_loss improved from 1364.03662 to 1337.26880, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2274.2258 - mean_absolute_error: 37.4960 - val_loss: 1337.2688 - val_mean_absolute_error: 27.3324\n",
      "Epoch 35/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2375.7642 - mean_absolute_error: 37.2449\n",
      "Epoch 35: val_loss improved from 1337.26880 to 1307.21533, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2237.6628 - mean_absolute_error: 36.6254 - val_loss: 1307.2153 - val_mean_absolute_error: 26.9173\n",
      "Epoch 36/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1965.0911 - mean_absolute_error: 34.5448\n",
      "Epoch 36: val_loss improved from 1307.21533 to 1290.96814, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2125.6716 - mean_absolute_error: 35.8219 - val_loss: 1290.9681 - val_mean_absolute_error: 26.6056\n",
      "Epoch 37/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2274.1450 - mean_absolute_error: 35.4255\n",
      "Epoch 37: val_loss improved from 1290.96814 to 1275.43298, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2099.8687 - mean_absolute_error: 34.8672 - val_loss: 1275.4330 - val_mean_absolute_error: 26.2171\n",
      "Epoch 38/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2106.8804 - mean_absolute_error: 35.5134\n",
      "Epoch 38: val_loss improved from 1275.43298 to 1266.49976, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2082.3523 - mean_absolute_error: 34.9293 - val_loss: 1266.4998 - val_mean_absolute_error: 25.9747\n",
      "Epoch 39/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2048.9497 - mean_absolute_error: 36.1215\n",
      "Epoch 39: val_loss improved from 1266.49976 to 1254.03748, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1964.8967 - mean_absolute_error: 34.1680 - val_loss: 1254.0375 - val_mean_absolute_error: 25.6302\n",
      "Epoch 40/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1811.7555 - mean_absolute_error: 32.3183\n",
      "Epoch 40: val_loss improved from 1254.03748 to 1245.35181, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1832.7770 - mean_absolute_error: 33.2436 - val_loss: 1245.3518 - val_mean_absolute_error: 25.3040\n",
      "Epoch 41/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2956.6108 - mean_absolute_error: 40.3565\n",
      "Epoch 41: val_loss improved from 1245.35181 to 1241.29895, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2036.3916 - mean_absolute_error: 34.0249 - val_loss: 1241.2990 - val_mean_absolute_error: 25.0654\n",
      "Epoch 42/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1230.9711 - mean_absolute_error: 28.6139\n",
      "Epoch 42: val_loss improved from 1241.29895 to 1229.79663, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1768.5057 - mean_absolute_error: 32.1604 - val_loss: 1229.7966 - val_mean_absolute_error: 24.6506\n",
      "Epoch 43/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2182.7861 - mean_absolute_error: 36.1255\n",
      "Epoch 43: val_loss improved from 1229.79663 to 1228.64832, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1778.0492 - mean_absolute_error: 31.9311 - val_loss: 1228.6483 - val_mean_absolute_error: 24.4079\n",
      "Epoch 44/1500\n",
      "\u001b[1m32/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1648.0668 - mean_absolute_error: 30.5041 \n",
      "Epoch 44: val_loss improved from 1228.64832 to 1218.31921, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1655.3341 - mean_absolute_error: 30.5573 - val_loss: 1218.3192 - val_mean_absolute_error: 24.0438\n",
      "Epoch 45/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1966.1553 - mean_absolute_error: 32.8845\n",
      "Epoch 45: val_loss improved from 1218.31921 to 1211.79907, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1885.1624 - mean_absolute_error: 32.1313 - val_loss: 1211.7991 - val_mean_absolute_error: 23.7386\n",
      "Epoch 46/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1465.2505 - mean_absolute_error: 26.6596\n",
      "Epoch 46: val_loss improved from 1211.79907 to 1207.75366, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1702.7118 - mean_absolute_error: 30.3559 - val_loss: 1207.7537 - val_mean_absolute_error: 23.5097\n",
      "Epoch 47/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1310.5026 - mean_absolute_error: 29.6371\n",
      "Epoch 47: val_loss improved from 1207.75366 to 1196.75195, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1650.8099 - mean_absolute_error: 30.0888 - val_loss: 1196.7520 - val_mean_absolute_error: 23.1261\n",
      "Epoch 48/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1798.3464 - mean_absolute_error: 31.6151\n",
      "Epoch 48: val_loss improved from 1196.75195 to 1196.34326, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1694.0088 - mean_absolute_error: 30.0224 - val_loss: 1196.3433 - val_mean_absolute_error: 22.9393\n",
      "Epoch 49/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1851.4381 - mean_absolute_error: 30.2441\n",
      "Epoch 49: val_loss improved from 1196.34326 to 1189.61194, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1686.3822 - mean_absolute_error: 29.7140 - val_loss: 1189.6119 - val_mean_absolute_error: 22.7094\n",
      "Epoch 50/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1536.8394 - mean_absolute_error: 29.3084\n",
      "Epoch 50: val_loss improved from 1189.61194 to 1182.57031, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1619.3311 - mean_absolute_error: 29.0508 - val_loss: 1182.5703 - val_mean_absolute_error: 22.3882\n",
      "Epoch 51/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2496.3591 - mean_absolute_error: 35.9233\n",
      "Epoch 51: val_loss improved from 1182.57031 to 1176.32727, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1581.8932 - mean_absolute_error: 28.5640 - val_loss: 1176.3273 - val_mean_absolute_error: 22.2466\n",
      "Epoch 52/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1376.7688 - mean_absolute_error: 26.2681\n",
      "Epoch 52: val_loss improved from 1176.32727 to 1175.31897, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1554.7860 - mean_absolute_error: 28.0220 - val_loss: 1175.3190 - val_mean_absolute_error: 22.1455\n",
      "Epoch 53/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1474.4761 - mean_absolute_error: 29.6917\n",
      "Epoch 53: val_loss improved from 1175.31897 to 1162.17371, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1473.2109 - mean_absolute_error: 27.3157 - val_loss: 1162.1737 - val_mean_absolute_error: 21.9244\n",
      "Epoch 54/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1776.3845 - mean_absolute_error: 31.5562\n",
      "Epoch 54: val_loss improved from 1162.17371 to 1158.09680, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1612.7726 - mean_absolute_error: 28.1018 - val_loss: 1158.0968 - val_mean_absolute_error: 21.8741\n",
      "Epoch 55/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1243.7766 - mean_absolute_error: 25.7072\n",
      "Epoch 55: val_loss improved from 1158.09680 to 1152.01245, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1495.7303 - mean_absolute_error: 26.8662 - val_loss: 1152.0125 - val_mean_absolute_error: 21.8008\n",
      "Epoch 56/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1104.0988 - mean_absolute_error: 24.6707\n",
      "Epoch 56: val_loss improved from 1152.01245 to 1150.61353, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1470.8429 - mean_absolute_error: 26.9009 - val_loss: 1150.6135 - val_mean_absolute_error: 21.8386\n",
      "Epoch 57/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1639.2037 - mean_absolute_error: 29.7498\n",
      "Epoch 57: val_loss improved from 1150.61353 to 1138.88098, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1403.2181 - mean_absolute_error: 26.3100 - val_loss: 1138.8810 - val_mean_absolute_error: 21.7108\n",
      "Epoch 58/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1480.6592 - mean_absolute_error: 28.4775\n",
      "Epoch 58: val_loss improved from 1138.88098 to 1133.41699, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1541.5127 - mean_absolute_error: 26.8389 - val_loss: 1133.4170 - val_mean_absolute_error: 21.6590\n",
      "Epoch 59/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1701.9059 - mean_absolute_error: 30.6277\n",
      "Epoch 59: val_loss improved from 1133.41699 to 1127.33081, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1442.2987 - mean_absolute_error: 26.3592 - val_loss: 1127.3308 - val_mean_absolute_error: 21.6126\n",
      "Epoch 60/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1020.5178 - mean_absolute_error: 24.0247\n",
      "Epoch 60: val_loss improved from 1127.33081 to 1123.53906, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1431.5946 - mean_absolute_error: 26.0160 - val_loss: 1123.5391 - val_mean_absolute_error: 21.6071\n",
      "Epoch 61/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2262.7805 - mean_absolute_error: 28.3896\n",
      "Epoch 61: val_loss improved from 1123.53906 to 1118.19006, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1444.6646 - mean_absolute_error: 25.6836 - val_loss: 1118.1901 - val_mean_absolute_error: 21.5627\n",
      "Epoch 62/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1502.5923 - mean_absolute_error: 24.2600\n",
      "Epoch 62: val_loss improved from 1118.19006 to 1109.49182, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1382.6978 - mean_absolute_error: 25.1240 - val_loss: 1109.4918 - val_mean_absolute_error: 21.4642\n",
      "Epoch 63/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1454.4121 - mean_absolute_error: 26.8841\n",
      "Epoch 63: val_loss improved from 1109.49182 to 1103.04822, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1388.7233 - mean_absolute_error: 25.0340 - val_loss: 1103.0482 - val_mean_absolute_error: 21.3689\n",
      "Epoch 64/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1307.3713 - mean_absolute_error: 25.2558\n",
      "Epoch 64: val_loss improved from 1103.04822 to 1096.05847, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1398.1670 - mean_absolute_error: 25.0478 - val_loss: 1096.0585 - val_mean_absolute_error: 21.2846\n",
      "Epoch 65/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1366.6357 - mean_absolute_error: 26.2822\n",
      "Epoch 65: val_loss improved from 1096.05847 to 1090.57434, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1237.6410 - mean_absolute_error: 23.9772 - val_loss: 1090.5743 - val_mean_absolute_error: 21.2361\n",
      "Epoch 66/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 1314.9114 - mean_absolute_error: 25.5071\n",
      "Epoch 66: val_loss improved from 1090.57434 to 1084.62488, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1327.8676 - mean_absolute_error: 24.6038 - val_loss: 1084.6249 - val_mean_absolute_error: 21.1910\n",
      "Epoch 67/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1269.0726 - mean_absolute_error: 25.4406\n",
      "Epoch 67: val_loss improved from 1084.62488 to 1084.55774, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1405.0258 - mean_absolute_error: 24.7891 - val_loss: 1084.5577 - val_mean_absolute_error: 21.2019\n",
      "Epoch 68/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 766.4229 - mean_absolute_error: 20.9635\n",
      "Epoch 68: val_loss improved from 1084.55774 to 1078.85449, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1309.6876 - mean_absolute_error: 23.9063 - val_loss: 1078.8545 - val_mean_absolute_error: 21.1336\n",
      "Epoch 69/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 980.1635 - mean_absolute_error: 21.4587\n",
      "Epoch 69: val_loss improved from 1078.85449 to 1077.37793, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1295.7898 - mean_absolute_error: 23.5595 - val_loss: 1077.3779 - val_mean_absolute_error: 21.1532\n",
      "Epoch 70/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1490.3120 - mean_absolute_error: 26.3104\n",
      "Epoch 70: val_loss improved from 1077.37793 to 1075.20251, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1448.1759 - mean_absolute_error: 24.6414 - val_loss: 1075.2025 - val_mean_absolute_error: 21.1669\n",
      "Epoch 71/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1870.4890 - mean_absolute_error: 25.6811\n",
      "Epoch 71: val_loss improved from 1075.20251 to 1071.37512, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1331.4054 - mean_absolute_error: 23.3156 - val_loss: 1071.3751 - val_mean_absolute_error: 21.1136\n",
      "Epoch 72/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1629.7029 - mean_absolute_error: 25.8853\n",
      "Epoch 72: val_loss improved from 1071.37512 to 1062.34436, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1365.8691 - mean_absolute_error: 23.9222 - val_loss: 1062.3444 - val_mean_absolute_error: 20.9751\n",
      "Epoch 73/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1304.9304 - mean_absolute_error: 21.2997\n",
      "Epoch 73: val_loss improved from 1062.34436 to 1056.87317, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1180.9752 - mean_absolute_error: 22.4501 - val_loss: 1056.8732 - val_mean_absolute_error: 20.8658\n",
      "Epoch 74/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1172.0857 - mean_absolute_error: 22.8725\n",
      "Epoch 74: val_loss improved from 1056.87317 to 1054.60938, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1222.0466 - mean_absolute_error: 22.4040 - val_loss: 1054.6094 - val_mean_absolute_error: 20.8540\n",
      "Epoch 75/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1222.6318 - mean_absolute_error: 21.6486\n",
      "Epoch 75: val_loss did not improve from 1054.60938\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1298.7794 - mean_absolute_error: 22.9019 - val_loss: 1056.0865 - val_mean_absolute_error: 20.8981\n",
      "Epoch 76/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 963.0310 - mean_absolute_error: 21.8171\n",
      "Epoch 76: val_loss improved from 1054.60938 to 1053.09680, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1249.6549 - mean_absolute_error: 22.8187 - val_loss: 1053.0968 - val_mean_absolute_error: 20.8712\n",
      "Epoch 77/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1672.0464 - mean_absolute_error: 25.3250\n",
      "Epoch 77: val_loss improved from 1053.09680 to 1047.01147, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1307.0120 - mean_absolute_error: 22.7776 - val_loss: 1047.0115 - val_mean_absolute_error: 20.7737\n",
      "Epoch 78/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 745.1298 - mean_absolute_error: 19.1952\n",
      "Epoch 78: val_loss improved from 1047.01147 to 1042.82239, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.8877 - mean_absolute_error: 21.6443 - val_loss: 1042.8224 - val_mean_absolute_error: 20.7116\n",
      "Epoch 79/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 967.2605 - mean_absolute_error: 19.8562\n",
      "Epoch 79: val_loss did not improve from 1042.82239\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1197.3113 - mean_absolute_error: 22.1200 - val_loss: 1044.1810 - val_mean_absolute_error: 20.7439\n",
      "Epoch 80/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 768.2186 - mean_absolute_error: 18.4064\n",
      "Epoch 80: val_loss did not improve from 1042.82239\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.6294 - mean_absolute_error: 21.4963 - val_loss: 1043.7896 - val_mean_absolute_error: 20.7056\n",
      "Epoch 81/1500\n",
      "\u001b[1m25/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1293.1617 - mean_absolute_error: 21.9527\n",
      "Epoch 81: val_loss improved from 1042.82239 to 1035.74243, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1273.4509 - mean_absolute_error: 21.9358 - val_loss: 1035.7424 - val_mean_absolute_error: 20.5840\n",
      "Epoch 82/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1269.0015 - mean_absolute_error: 20.7590\n",
      "Epoch 82: val_loss did not improve from 1035.74243\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1179.9569 - mean_absolute_error: 21.5245 - val_loss: 1037.8658 - val_mean_absolute_error: 20.5905\n",
      "Epoch 83/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1679.5710 - mean_absolute_error: 26.5494\n",
      "Epoch 83: val_loss did not improve from 1035.74243\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.1588 - mean_absolute_error: 22.0068 - val_loss: 1038.5199 - val_mean_absolute_error: 20.6019\n",
      "Epoch 84/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1287.2469 - mean_absolute_error: 23.4445\n",
      "Epoch 84: val_loss did not improve from 1035.74243\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.7715 - mean_absolute_error: 21.5317 - val_loss: 1037.6923 - val_mean_absolute_error: 20.5656\n",
      "Epoch 85/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1110.5317 - mean_absolute_error: 19.9627\n",
      "Epoch 85: val_loss improved from 1035.74243 to 1030.10144, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1225.3518 - mean_absolute_error: 21.5564 - val_loss: 1030.1014 - val_mean_absolute_error: 20.4251\n",
      "Epoch 86/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 871.9199 - mean_absolute_error: 19.1095\n",
      "Epoch 86: val_loss improved from 1030.10144 to 1029.07141, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.8199 - mean_absolute_error: 21.1034 - val_loss: 1029.0714 - val_mean_absolute_error: 20.3627\n",
      "Epoch 87/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1078.1014 - mean_absolute_error: 21.0000\n",
      "Epoch 87: val_loss improved from 1029.07141 to 1026.94299, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1242.8665 - mean_absolute_error: 21.5308 - val_loss: 1026.9430 - val_mean_absolute_error: 20.3279\n",
      "Epoch 88/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1346.8513 - mean_absolute_error: 21.7517\n",
      "Epoch 88: val_loss improved from 1026.94299 to 1025.12659, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1193.1809 - mean_absolute_error: 21.2777 - val_loss: 1025.1266 - val_mean_absolute_error: 20.2817\n",
      "Epoch 89/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 681.9553 - mean_absolute_error: 18.0188\n",
      "Epoch 89: val_loss improved from 1025.12659 to 1019.00665, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1021.9011 - mean_absolute_error: 19.9189 - val_loss: 1019.0067 - val_mean_absolute_error: 20.0871\n",
      "Epoch 90/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 983.3735 - mean_absolute_error: 19.3014\n",
      "Epoch 90: val_loss did not improve from 1019.00665\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1142.3265 - mean_absolute_error: 20.3835 - val_loss: 1022.2021 - val_mean_absolute_error: 20.1259\n",
      "Epoch 91/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1265.8311 - mean_absolute_error: 21.1722\n",
      "Epoch 91: val_loss improved from 1019.00665 to 1016.15454, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1156.1512 - mean_absolute_error: 20.5771 - val_loss: 1016.1545 - val_mean_absolute_error: 19.9773\n",
      "Epoch 92/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1125.7935 - mean_absolute_error: 20.4162\n",
      "Epoch 92: val_loss did not improve from 1016.15454\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.2145 - mean_absolute_error: 20.3354 - val_loss: 1017.9214 - val_mean_absolute_error: 19.9833\n",
      "Epoch 93/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1108.9399 - mean_absolute_error: 20.9571\n",
      "Epoch 93: val_loss did not improve from 1016.15454\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.2520 - mean_absolute_error: 20.2587 - val_loss: 1018.5099 - val_mean_absolute_error: 19.9514\n",
      "Epoch 94/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1167.5547 - mean_absolute_error: 20.0803\n",
      "Epoch 94: val_loss improved from 1016.15454 to 1012.93353, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.3138 - mean_absolute_error: 20.1583 - val_loss: 1012.9335 - val_mean_absolute_error: 19.8237\n",
      "Epoch 95/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1203.2505 - mean_absolute_error: 21.4121\n",
      "Epoch 95: val_loss improved from 1012.93353 to 1012.71906, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.8995 - mean_absolute_error: 20.5480 - val_loss: 1012.7191 - val_mean_absolute_error: 19.7481\n",
      "Epoch 96/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 543.6690 - mean_absolute_error: 15.8819\n",
      "Epoch 96: val_loss did not improve from 1012.71906\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1230.8822 - mean_absolute_error: 20.4949 - val_loss: 1016.2018 - val_mean_absolute_error: 19.7515\n",
      "Epoch 97/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 974.0518 - mean_absolute_error: 20.3997\n",
      "Epoch 97: val_loss improved from 1012.71906 to 1009.17621, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1214.3643 - mean_absolute_error: 20.7725 - val_loss: 1009.1762 - val_mean_absolute_error: 19.5643\n",
      "Epoch 98/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2307.9575 - mean_absolute_error: 27.6426\n",
      "Epoch 98: val_loss improved from 1009.17621 to 1008.56586, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1369.5946 - mean_absolute_error: 21.2836 - val_loss: 1008.5659 - val_mean_absolute_error: 19.5398\n",
      "Epoch 99/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 730.7074 - mean_absolute_error: 16.4843\n",
      "Epoch 99: val_loss improved from 1008.56586 to 1006.19458, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.2804 - mean_absolute_error: 19.6341 - val_loss: 1006.1946 - val_mean_absolute_error: 19.4175\n",
      "Epoch 100/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1916.0708 - mean_absolute_error: 24.1388\n",
      "Epoch 100: val_loss did not improve from 1006.19458\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1144.4198 - mean_absolute_error: 19.6950 - val_loss: 1006.3716 - val_mean_absolute_error: 19.3852\n",
      "Epoch 101/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1004.0824 - mean_absolute_error: 18.4979\n",
      "Epoch 101: val_loss improved from 1006.19458 to 1000.84021, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1254.6494 - mean_absolute_error: 20.4992 - val_loss: 1000.8402 - val_mean_absolute_error: 19.2568\n",
      "Epoch 102/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1302.4646 - mean_absolute_error: 19.7213\n",
      "Epoch 102: val_loss did not improve from 1000.84021\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1180.5594 - mean_absolute_error: 19.7041 - val_loss: 1009.2136 - val_mean_absolute_error: 19.3500\n",
      "Epoch 103/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1109.3447 - mean_absolute_error: 18.4464\n",
      "Epoch 103: val_loss did not improve from 1000.84021\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.9393 - mean_absolute_error: 19.9219 - val_loss: 1002.2108 - val_mean_absolute_error: 19.2236\n",
      "Epoch 104/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 621.4470 - mean_absolute_error: 15.7570\n",
      "Epoch 104: val_loss did not improve from 1000.84021\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.1526 - mean_absolute_error: 18.9298 - val_loss: 1008.6593 - val_mean_absolute_error: 19.2823\n",
      "Epoch 105/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1667.9563 - mean_absolute_error: 21.7677\n",
      "Epoch 105: val_loss did not improve from 1000.84021\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.8164 - mean_absolute_error: 19.7743 - val_loss: 1003.5627 - val_mean_absolute_error: 19.1794\n",
      "Epoch 106/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 890.2718 - mean_absolute_error: 16.2073\n",
      "Epoch 106: val_loss improved from 1000.84021 to 999.26160, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1075.6626 - mean_absolute_error: 19.1570 - val_loss: 999.2616 - val_mean_absolute_error: 19.0885\n",
      "Epoch 107/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1175.9338 - mean_absolute_error: 17.2076\n",
      "Epoch 107: val_loss improved from 999.26160 to 999.18549, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1192.1029 - mean_absolute_error: 19.5127 - val_loss: 999.1855 - val_mean_absolute_error: 19.0691\n",
      "Epoch 108/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1117.4268 - mean_absolute_error: 21.6808\n",
      "Epoch 108: val_loss did not improve from 999.18549\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.4326 - mean_absolute_error: 19.6871 - val_loss: 1006.2437 - val_mean_absolute_error: 19.1034\n",
      "Epoch 109/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 664.1320 - mean_absolute_error: 16.3403\n",
      "Epoch 109: val_loss improved from 999.18549 to 998.23010, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1128.4517 - mean_absolute_error: 19.3659 - val_loss: 998.2301 - val_mean_absolute_error: 18.9777\n",
      "Epoch 110/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2435.6636 - mean_absolute_error: 26.5049\n",
      "Epoch 110: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1343.9427 - mean_absolute_error: 20.1990 - val_loss: 1006.5406 - val_mean_absolute_error: 19.0517\n",
      "Epoch 111/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 623.4893 - mean_absolute_error: 16.5533\n",
      "Epoch 111: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.3698 - mean_absolute_error: 19.2242 - val_loss: 1005.0388 - val_mean_absolute_error: 18.9884\n",
      "Epoch 112/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1021.7036 - mean_absolute_error: 19.7575\n",
      "Epoch 112: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1090.4778 - mean_absolute_error: 18.8774 - val_loss: 1002.5638 - val_mean_absolute_error: 18.9707\n",
      "Epoch 113/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 993.6470 - mean_absolute_error: 20.0525\n",
      "Epoch 113: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.4834 - mean_absolute_error: 19.2918 - val_loss: 1003.3121 - val_mean_absolute_error: 19.0236\n",
      "Epoch 114/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1110.9641 - mean_absolute_error: 19.1490\n",
      "Epoch 114: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.8250 - mean_absolute_error: 19.1593 - val_loss: 1001.5395 - val_mean_absolute_error: 19.0121\n",
      "Epoch 115/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1462.2362 - mean_absolute_error: 23.3723\n",
      "Epoch 115: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.6200 - mean_absolute_error: 19.0628 - val_loss: 1000.8404 - val_mean_absolute_error: 19.0109\n",
      "Epoch 116/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 949.1319 - mean_absolute_error: 17.5935\n",
      "Epoch 116: val_loss did not improve from 998.23010\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1040.2450 - mean_absolute_error: 18.6343 - val_loss: 1000.4780 - val_mean_absolute_error: 19.0422\n",
      "Epoch 117/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 715.1837 - mean_absolute_error: 18.1103\n",
      "Epoch 117: val_loss improved from 998.23010 to 997.62036, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1076.0149 - mean_absolute_error: 18.8847 - val_loss: 997.6204 - val_mean_absolute_error: 18.9676\n",
      "Epoch 118/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 663.0963 - mean_absolute_error: 16.0219\n",
      "Epoch 118: val_loss did not improve from 997.62036\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.6771 - mean_absolute_error: 18.9750 - val_loss: 1008.5855 - val_mean_absolute_error: 19.1041\n",
      "Epoch 119/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1047.8746 - mean_absolute_error: 19.1499\n",
      "Epoch 119: val_loss improved from 997.62036 to 993.89740, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1063.1436 - mean_absolute_error: 18.5473 - val_loss: 993.8974 - val_mean_absolute_error: 18.9624\n",
      "Epoch 120/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 808.3768 - mean_absolute_error: 17.4253\n",
      "Epoch 120: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.1128 - mean_absolute_error: 19.0108 - val_loss: 1007.3043 - val_mean_absolute_error: 19.1151\n",
      "Epoch 121/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 978.7394 - mean_absolute_error: 17.2159\n",
      "Epoch 121: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1052.5941 - mean_absolute_error: 18.2951 - val_loss: 1005.3655 - val_mean_absolute_error: 19.1069\n",
      "Epoch 122/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1522.8220 - mean_absolute_error: 22.0595\n",
      "Epoch 122: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.3435 - mean_absolute_error: 19.3505 - val_loss: 1003.8657 - val_mean_absolute_error: 19.1097\n",
      "Epoch 123/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1038.2521 - mean_absolute_error: 18.5005\n",
      "Epoch 123: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.7301 - mean_absolute_error: 18.8239 - val_loss: 1005.6874 - val_mean_absolute_error: 19.1677\n",
      "Epoch 124/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1251.2855 - mean_absolute_error: 21.3678\n",
      "Epoch 124: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.6086 - mean_absolute_error: 19.0165 - val_loss: 1001.1965 - val_mean_absolute_error: 19.0853\n",
      "Epoch 125/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 887.5751 - mean_absolute_error: 17.1951\n",
      "Epoch 125: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.5826 - mean_absolute_error: 18.9170 - val_loss: 1003.4081 - val_mean_absolute_error: 19.1424\n",
      "Epoch 126/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 647.1715 - mean_absolute_error: 15.3785\n",
      "Epoch 126: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1058.0848 - mean_absolute_error: 18.2255 - val_loss: 1004.7288 - val_mean_absolute_error: 19.1783\n",
      "Epoch 127/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1743.1892 - mean_absolute_error: 20.0977\n",
      "Epoch 127: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1255.5750 - mean_absolute_error: 19.0929 - val_loss: 1008.0870 - val_mean_absolute_error: 19.2293\n",
      "Epoch 128/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1247.7759 - mean_absolute_error: 19.1359\n",
      "Epoch 128: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.5758 - mean_absolute_error: 18.4119 - val_loss: 998.8911 - val_mean_absolute_error: 19.1233\n",
      "Epoch 129/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 906.4071 - mean_absolute_error: 17.2810\n",
      "Epoch 129: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1075.5288 - mean_absolute_error: 18.2268 - val_loss: 1006.1350 - val_mean_absolute_error: 19.2181\n",
      "Epoch 130/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 991.9697 - mean_absolute_error: 19.3030\n",
      "Epoch 130: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.5862 - mean_absolute_error: 18.8019 - val_loss: 1011.0558 - val_mean_absolute_error: 19.3103\n",
      "Epoch 131/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1489.6094 - mean_absolute_error: 20.5293\n",
      "Epoch 131: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1180.4005 - mean_absolute_error: 18.8454 - val_loss: 1009.4392 - val_mean_absolute_error: 19.2874\n",
      "Epoch 132/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1951.4283 - mean_absolute_error: 24.9654\n",
      "Epoch 132: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1230.3582 - mean_absolute_error: 19.0173 - val_loss: 1005.9598 - val_mean_absolute_error: 19.2394\n",
      "Epoch 133/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1805.3979 - mean_absolute_error: 24.1007\n",
      "Epoch 133: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257.3386 - mean_absolute_error: 19.6518 - val_loss: 1010.3758 - val_mean_absolute_error: 19.3256\n",
      "Epoch 134/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1149.5686 - mean_absolute_error: 20.2559\n",
      "Epoch 134: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.8280 - mean_absolute_error: 18.8871 - val_loss: 1012.2807 - val_mean_absolute_error: 19.3699\n",
      "Epoch 135/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1153.8945 - mean_absolute_error: 19.6241\n",
      "Epoch 135: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046.6393 - mean_absolute_error: 18.0142 - val_loss: 1009.6125 - val_mean_absolute_error: 19.2945\n",
      "Epoch 136/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1369.9727 - mean_absolute_error: 20.9582\n",
      "Epoch 136: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1171.3557 - mean_absolute_error: 19.0745 - val_loss: 1006.1125 - val_mean_absolute_error: 19.3032\n",
      "Epoch 137/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 897.3864 - mean_absolute_error: 14.9989\n",
      "Epoch 137: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.1792 - mean_absolute_error: 18.2434 - val_loss: 1006.7991 - val_mean_absolute_error: 19.3134\n",
      "Epoch 138/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1099.4583 - mean_absolute_error: 17.3251\n",
      "Epoch 138: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.4137 - mean_absolute_error: 18.2940 - val_loss: 1006.1649 - val_mean_absolute_error: 19.2904\n",
      "Epoch 139/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 776.5027 - mean_absolute_error: 16.0702\n",
      "Epoch 139: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.6434 - mean_absolute_error: 18.4928 - val_loss: 1011.1224 - val_mean_absolute_error: 19.3743\n",
      "Epoch 140/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1204.9333 - mean_absolute_error: 19.2344\n",
      "Epoch 140: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.0690 - mean_absolute_error: 18.7926 - val_loss: 1003.6988 - val_mean_absolute_error: 19.2458\n",
      "Epoch 141/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1670.1592 - mean_absolute_error: 21.1037\n",
      "Epoch 141: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.3087 - mean_absolute_error: 18.3185 - val_loss: 1005.1235 - val_mean_absolute_error: 19.2401\n",
      "Epoch 142/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1403.1145 - mean_absolute_error: 19.0740\n",
      "Epoch 142: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.6310 - mean_absolute_error: 18.1846 - val_loss: 1008.7898 - val_mean_absolute_error: 19.3442\n",
      "Epoch 143/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1038.2644 - mean_absolute_error: 17.8898\n",
      "Epoch 143: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1096.7498 - mean_absolute_error: 18.5235 - val_loss: 1013.4238 - val_mean_absolute_error: 19.3893\n",
      "Epoch 144/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 775.8600 - mean_absolute_error: 16.0348\n",
      "Epoch 144: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.5017 - mean_absolute_error: 18.0598 - val_loss: 1008.2028 - val_mean_absolute_error: 19.3539\n",
      "Epoch 145/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1069.6260 - mean_absolute_error: 18.2467\n",
      "Epoch 145: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.7742 - mean_absolute_error: 18.3191 - val_loss: 1006.8192 - val_mean_absolute_error: 19.3138\n",
      "Epoch 146/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 966.8920 - mean_absolute_error: 17.6516\n",
      "Epoch 146: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.8108 - mean_absolute_error: 18.5603 - val_loss: 1003.6660 - val_mean_absolute_error: 19.2832\n",
      "Epoch 147/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 914.1088 - mean_absolute_error: 17.3114\n",
      "Epoch 147: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.6621 - mean_absolute_error: 18.0790 - val_loss: 1008.7570 - val_mean_absolute_error: 19.3245\n",
      "Epoch 148/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1221.8115 - mean_absolute_error: 20.5834\n",
      "Epoch 148: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.7098 - mean_absolute_error: 18.4899 - val_loss: 1011.8760 - val_mean_absolute_error: 19.4021\n",
      "Epoch 149/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1294.9062 - mean_absolute_error: 17.4231\n",
      "Epoch 149: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.6348 - mean_absolute_error: 18.4258 - val_loss: 1007.2325 - val_mean_absolute_error: 19.3155\n",
      "Epoch 150/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 842.0232 - mean_absolute_error: 18.3570\n",
      "Epoch 150: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1153.8962 - mean_absolute_error: 18.6259 - val_loss: 1007.2318 - val_mean_absolute_error: 19.3315\n",
      "Epoch 151/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 915.4020 - mean_absolute_error: 16.7225\n",
      "Epoch 151: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062.6097 - mean_absolute_error: 17.9465 - val_loss: 1015.2551 - val_mean_absolute_error: 19.4604\n",
      "Epoch 152/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 917.7698 - mean_absolute_error: 17.1177\n",
      "Epoch 152: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.3010 - mean_absolute_error: 17.6273 - val_loss: 1014.0640 - val_mean_absolute_error: 19.4048\n",
      "Epoch 153/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1261.7595 - mean_absolute_error: 19.6398\n",
      "Epoch 153: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.8921 - mean_absolute_error: 18.4298 - val_loss: 1008.6984 - val_mean_absolute_error: 19.3593\n",
      "Epoch 154/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1061.9861 - mean_absolute_error: 18.4953\n",
      "Epoch 154: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.4127 - mean_absolute_error: 18.2899 - val_loss: 1008.0835 - val_mean_absolute_error: 19.3275\n",
      "Epoch 155/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1254.5198 - mean_absolute_error: 19.0107\n",
      "Epoch 155: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260.9421 - mean_absolute_error: 19.1649 - val_loss: 1013.6682 - val_mean_absolute_error: 19.4311\n",
      "Epoch 156/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 457.6508 - mean_absolute_error: 13.1433\n",
      "Epoch 156: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.5203 - mean_absolute_error: 17.6644 - val_loss: 1008.3972 - val_mean_absolute_error: 19.3449\n",
      "Epoch 157/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2165.8911 - mean_absolute_error: 23.2313\n",
      "Epoch 157: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1210.5380 - mean_absolute_error: 18.8156 - val_loss: 1010.7112 - val_mean_absolute_error: 19.4114\n",
      "Epoch 158/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 935.2948 - mean_absolute_error: 16.5720\n",
      "Epoch 158: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1152.4404 - mean_absolute_error: 18.4908 - val_loss: 1014.9027 - val_mean_absolute_error: 19.4522\n",
      "Epoch 159/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 701.7595 - mean_absolute_error: 15.2674\n",
      "Epoch 159: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1160.2246 - mean_absolute_error: 18.3741 - val_loss: 1010.6208 - val_mean_absolute_error: 19.3974\n",
      "Epoch 160/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 966.4822 - mean_absolute_error: 18.7606\n",
      "Epoch 160: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.0394 - mean_absolute_error: 18.2087 - val_loss: 1002.6360 - val_mean_absolute_error: 19.2866\n",
      "Epoch 161/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 971.5625 - mean_absolute_error: 17.7171\n",
      "Epoch 161: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.3455 - mean_absolute_error: 18.2474 - val_loss: 1013.8413 - val_mean_absolute_error: 19.3979\n",
      "Epoch 162/1500\n",
      "\u001b[1m27/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1217.3956 - mean_absolute_error: 18.9701 \n",
      "Epoch 162: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1195.2699 - mean_absolute_error: 18.8195 - val_loss: 1008.8511 - val_mean_absolute_error: 19.3515\n",
      "Epoch 163/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1152.1532 - mean_absolute_error: 18.1561\n",
      "Epoch 163: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.2678 - mean_absolute_error: 18.6274 - val_loss: 1008.4096 - val_mean_absolute_error: 19.3639\n",
      "Epoch 164/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1811.1775 - mean_absolute_error: 23.4858\n",
      "Epoch 164: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.9506 - mean_absolute_error: 18.4490 - val_loss: 1006.9102 - val_mean_absolute_error: 19.3369\n",
      "Epoch 165/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 836.1035 - mean_absolute_error: 16.0620\n",
      "Epoch 165: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.3984 - mean_absolute_error: 18.3126 - val_loss: 1008.2836 - val_mean_absolute_error: 19.3230\n",
      "Epoch 166/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 978.8033 - mean_absolute_error: 18.0075\n",
      "Epoch 166: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.6411 - mean_absolute_error: 17.9526 - val_loss: 1004.2613 - val_mean_absolute_error: 19.2764\n",
      "Epoch 167/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1363.0005 - mean_absolute_error: 19.3366\n",
      "Epoch 167: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.1957 - mean_absolute_error: 17.9583 - val_loss: 1005.9868 - val_mean_absolute_error: 19.3079\n",
      "Epoch 168/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 943.0679 - mean_absolute_error: 17.1379\n",
      "Epoch 168: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.6653 - mean_absolute_error: 18.3505 - val_loss: 1013.1101 - val_mean_absolute_error: 19.4350\n",
      "Epoch 169/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1187.0261 - mean_absolute_error: 20.8624\n",
      "Epoch 169: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1098.1844 - mean_absolute_error: 18.2884 - val_loss: 1016.8047 - val_mean_absolute_error: 19.4204\n",
      "Epoch 170/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 811.0394 - mean_absolute_error: 18.6294\n",
      "Epoch 170: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.3776 - mean_absolute_error: 18.3031 - val_loss: 1005.8354 - val_mean_absolute_error: 19.3040\n",
      "Epoch 171/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1854.8043 - mean_absolute_error: 22.2420\n",
      "Epoch 171: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1222.4089 - mean_absolute_error: 18.6770 - val_loss: 1006.7042 - val_mean_absolute_error: 19.3160\n",
      "Epoch 172/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 491.6520 - mean_absolute_error: 13.2354\n",
      "Epoch 172: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1028.4098 - mean_absolute_error: 17.5928 - val_loss: 1011.4700 - val_mean_absolute_error: 19.3765\n",
      "Epoch 173/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1410.9321 - mean_absolute_error: 18.4533\n",
      "Epoch 173: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1187.3110 - mean_absolute_error: 18.7215 - val_loss: 1012.2492 - val_mean_absolute_error: 19.4117\n",
      "Epoch 174/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1311.7969 - mean_absolute_error: 19.7404\n",
      "Epoch 174: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.8973 - mean_absolute_error: 18.4135 - val_loss: 1009.2944 - val_mean_absolute_error: 19.3335\n",
      "Epoch 175/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1062.2283 - mean_absolute_error: 19.5737\n",
      "Epoch 175: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1178.6785 - mean_absolute_error: 18.4875 - val_loss: 1007.2581 - val_mean_absolute_error: 19.3170\n",
      "Epoch 176/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1320.0831 - mean_absolute_error: 19.1318\n",
      "Epoch 176: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1180.6860 - mean_absolute_error: 18.8297 - val_loss: 1012.2054 - val_mean_absolute_error: 19.3537\n",
      "Epoch 177/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1263.5256 - mean_absolute_error: 20.8832\n",
      "Epoch 177: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1094.6545 - mean_absolute_error: 18.4124 - val_loss: 1007.3859 - val_mean_absolute_error: 19.3069\n",
      "Epoch 178/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1173.8202 - mean_absolute_error: 17.5514\n",
      "Epoch 178: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1143.7469 - mean_absolute_error: 18.4310 - val_loss: 1009.7885 - val_mean_absolute_error: 19.3456\n",
      "Epoch 179/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1295.6917 - mean_absolute_error: 19.4825\n",
      "Epoch 179: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.3744 - mean_absolute_error: 18.4144 - val_loss: 1008.2823 - val_mean_absolute_error: 19.2918\n",
      "Epoch 180/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 915.6490 - mean_absolute_error: 16.2641\n",
      "Epoch 180: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1204.5653 - mean_absolute_error: 19.0146 - val_loss: 999.2618 - val_mean_absolute_error: 19.1653\n",
      "Epoch 181/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1319.3315 - mean_absolute_error: 18.4398\n",
      "Epoch 181: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1028.2562 - mean_absolute_error: 17.6484 - val_loss: 1012.7496 - val_mean_absolute_error: 19.3318\n",
      "Epoch 182/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 854.9862 - mean_absolute_error: 17.8218\n",
      "Epoch 182: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1157.5667 - mean_absolute_error: 18.7436 - val_loss: 1003.3876 - val_mean_absolute_error: 19.2619\n",
      "Epoch 183/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1541.1826 - mean_absolute_error: 22.3173\n",
      "Epoch 183: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.1608 - mean_absolute_error: 18.4716 - val_loss: 1007.5890 - val_mean_absolute_error: 19.2870\n",
      "Epoch 184/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1303.2766 - mean_absolute_error: 22.2591\n",
      "Epoch 184: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1189.4453 - mean_absolute_error: 18.9170 - val_loss: 1004.4341 - val_mean_absolute_error: 19.2335\n",
      "Epoch 185/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 792.9437 - mean_absolute_error: 16.6192\n",
      "Epoch 185: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.0482 - mean_absolute_error: 18.6584 - val_loss: 1010.7349 - val_mean_absolute_error: 19.2933\n",
      "Epoch 186/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2179.7104 - mean_absolute_error: 21.9061\n",
      "Epoch 186: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1256.1156 - mean_absolute_error: 18.8444 - val_loss: 1003.8022 - val_mean_absolute_error: 19.1975\n",
      "Epoch 187/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1189.8260 - mean_absolute_error: 19.2963\n",
      "Epoch 187: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.8448 - mean_absolute_error: 18.5118 - val_loss: 1008.1347 - val_mean_absolute_error: 19.3121\n",
      "Epoch 188/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 766.9980 - mean_absolute_error: 14.7407\n",
      "Epoch 188: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.5315 - mean_absolute_error: 17.6286 - val_loss: 1004.3598 - val_mean_absolute_error: 19.2040\n",
      "Epoch 189/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1302.9890 - mean_absolute_error: 20.2154\n",
      "Epoch 189: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1273.4005 - mean_absolute_error: 19.1727 - val_loss: 1008.1267 - val_mean_absolute_error: 19.2344\n",
      "Epoch 190/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1304.1599 - mean_absolute_error: 17.8465\n",
      "Epoch 190: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.7928 - mean_absolute_error: 18.2151 - val_loss: 1003.6024 - val_mean_absolute_error: 19.2074\n",
      "Epoch 191/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1435.8694 - mean_absolute_error: 20.0299\n",
      "Epoch 191: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233.3279 - mean_absolute_error: 19.0615 - val_loss: 1007.2333 - val_mean_absolute_error: 19.2264\n",
      "Epoch 192/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2412.1218 - mean_absolute_error: 25.3775\n",
      "Epoch 192: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1321.7059 - mean_absolute_error: 19.3712 - val_loss: 1011.5589 - val_mean_absolute_error: 19.3021\n",
      "Epoch 193/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 815.3639 - mean_absolute_error: 14.4773\n",
      "Epoch 193: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1039.9451 - mean_absolute_error: 17.6507 - val_loss: 1001.7823 - val_mean_absolute_error: 19.1446\n",
      "Epoch 194/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1173.7897 - mean_absolute_error: 20.1088\n",
      "Epoch 194: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1154.4520 - mean_absolute_error: 18.3894 - val_loss: 1004.5175 - val_mean_absolute_error: 19.1942\n",
      "Epoch 195/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1117.1128 - mean_absolute_error: 18.6185\n",
      "Epoch 195: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1192.8571 - mean_absolute_error: 18.4830 - val_loss: 998.0104 - val_mean_absolute_error: 19.1417\n",
      "Epoch 196/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1001.7396 - mean_absolute_error: 16.8394\n",
      "Epoch 196: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.0645 - mean_absolute_error: 17.9577 - val_loss: 1009.2468 - val_mean_absolute_error: 19.2568\n",
      "Epoch 197/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1202.3145 - mean_absolute_error: 18.6412\n",
      "Epoch 197: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.2769 - mean_absolute_error: 17.5055 - val_loss: 1000.1848 - val_mean_absolute_error: 19.1196\n",
      "Epoch 198/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 959.2650 - mean_absolute_error: 18.2331\n",
      "Epoch 198: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1024.9260 - mean_absolute_error: 17.7975 - val_loss: 1001.7348 - val_mean_absolute_error: 19.1251\n",
      "Epoch 199/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1150.2041 - mean_absolute_error: 19.1951\n",
      "Epoch 199: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1118.4833 - mean_absolute_error: 18.1821 - val_loss: 998.1359 - val_mean_absolute_error: 19.0878\n",
      "Epoch 200/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 559.4217 - mean_absolute_error: 13.9376\n",
      "Epoch 200: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.2509 - mean_absolute_error: 18.0345 - val_loss: 997.3143 - val_mean_absolute_error: 19.0881\n",
      "Epoch 201/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1239.8014 - mean_absolute_error: 20.1156\n",
      "Epoch 201: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.7164 - mean_absolute_error: 18.4014 - val_loss: 1000.7400 - val_mean_absolute_error: 19.1249\n",
      "Epoch 202/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 958.2661 - mean_absolute_error: 17.4909\n",
      "Epoch 202: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.5535 - mean_absolute_error: 18.3914 - val_loss: 1002.6091 - val_mean_absolute_error: 19.1649\n",
      "Epoch 203/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1504.9496 - mean_absolute_error: 18.6074\n",
      "Epoch 203: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1105.5035 - mean_absolute_error: 17.8841 - val_loss: 1003.8574 - val_mean_absolute_error: 19.1373\n",
      "Epoch 204/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1133.7766 - mean_absolute_error: 17.3534\n",
      "Epoch 204: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1127.0598 - mean_absolute_error: 17.9860 - val_loss: 1006.1703 - val_mean_absolute_error: 19.1796\n",
      "Epoch 205/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1141.4392 - mean_absolute_error: 20.3818\n",
      "Epoch 205: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.2423 - mean_absolute_error: 18.5276 - val_loss: 998.4586 - val_mean_absolute_error: 19.0737\n",
      "Epoch 206/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1649.8187 - mean_absolute_error: 21.3465\n",
      "Epoch 206: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1185.1278 - mean_absolute_error: 18.4564 - val_loss: 998.7726 - val_mean_absolute_error: 19.0830\n",
      "Epoch 207/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1262.7426 - mean_absolute_error: 17.8971\n",
      "Epoch 207: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1109.2476 - mean_absolute_error: 17.9100 - val_loss: 1006.0823 - val_mean_absolute_error: 19.1388\n",
      "Epoch 208/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 723.9014 - mean_absolute_error: 14.3507\n",
      "Epoch 208: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1164.8840 - mean_absolute_error: 18.1258 - val_loss: 998.5091 - val_mean_absolute_error: 19.0893\n",
      "Epoch 209/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2050.0193 - mean_absolute_error: 22.2631\n",
      "Epoch 209: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1198.9564 - mean_absolute_error: 18.4971 - val_loss: 1003.9395 - val_mean_absolute_error: 19.1421\n",
      "Epoch 210/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1081.0496 - mean_absolute_error: 18.2948\n",
      "Epoch 210: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.7206 - mean_absolute_error: 18.2049 - val_loss: 1001.6976 - val_mean_absolute_error: 19.0994\n",
      "Epoch 211/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1617.4459 - mean_absolute_error: 20.4796\n",
      "Epoch 211: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1157.1569 - mean_absolute_error: 18.4340 - val_loss: 1008.4440 - val_mean_absolute_error: 19.1672\n",
      "Epoch 212/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 619.5006 - mean_absolute_error: 14.7353\n",
      "Epoch 212: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1063.9191 - mean_absolute_error: 17.7521 - val_loss: 998.4933 - val_mean_absolute_error: 19.0314\n",
      "Epoch 213/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1005.0449 - mean_absolute_error: 18.3953\n",
      "Epoch 213: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1164.4296 - mean_absolute_error: 18.6783 - val_loss: 1002.8390 - val_mean_absolute_error: 19.1097\n",
      "Epoch 214/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1158.1338 - mean_absolute_error: 17.3341\n",
      "Epoch 214: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.7314 - mean_absolute_error: 17.7780 - val_loss: 998.1504 - val_mean_absolute_error: 19.0707\n",
      "Epoch 215/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 552.0942 - mean_absolute_error: 13.7239\n",
      "Epoch 215: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.3778 - mean_absolute_error: 17.9725 - val_loss: 1005.0970 - val_mean_absolute_error: 19.1682\n",
      "Epoch 216/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1021.5851 - mean_absolute_error: 19.0740\n",
      "Epoch 216: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.2590 - mean_absolute_error: 18.6840 - val_loss: 998.6722 - val_mean_absolute_error: 19.0627\n",
      "Epoch 217/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1571.3489 - mean_absolute_error: 21.7427\n",
      "Epoch 217: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1157.2864 - mean_absolute_error: 18.3927 - val_loss: 999.4518 - val_mean_absolute_error: 19.0319\n",
      "Epoch 218/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1053.0367 - mean_absolute_error: 18.5258\n",
      "Epoch 218: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.3973 - mean_absolute_error: 18.1900 - val_loss: 999.9859 - val_mean_absolute_error: 19.0776\n",
      "Epoch 219/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1393.4696 - mean_absolute_error: 22.7340\n",
      "Epoch 219: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057.8768 - mean_absolute_error: 17.9273 - val_loss: 1002.2001 - val_mean_absolute_error: 19.0748\n",
      "Epoch 220/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 574.7916 - mean_absolute_error: 15.3699\n",
      "Epoch 220: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.3621 - mean_absolute_error: 17.8265 - val_loss: 994.6199 - val_mean_absolute_error: 18.9806\n",
      "Epoch 221/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1723.5098 - mean_absolute_error: 18.9129\n",
      "Epoch 221: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1186.5879 - mean_absolute_error: 18.2372 - val_loss: 996.6130 - val_mean_absolute_error: 19.0447\n",
      "Epoch 222/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 626.3274 - mean_absolute_error: 15.0551\n",
      "Epoch 222: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.9430 - mean_absolute_error: 17.8512 - val_loss: 1000.9957 - val_mean_absolute_error: 19.0081\n",
      "Epoch 223/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 797.5042 - mean_absolute_error: 18.0876\n",
      "Epoch 223: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1018.5464 - mean_absolute_error: 17.7346 - val_loss: 997.2980 - val_mean_absolute_error: 19.0040\n",
      "Epoch 224/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 884.1221 - mean_absolute_error: 18.8023\n",
      "Epoch 224: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1144.3828 - mean_absolute_error: 18.3819 - val_loss: 1002.4730 - val_mean_absolute_error: 19.0823\n",
      "Epoch 225/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1021.2682 - mean_absolute_error: 19.1984\n",
      "Epoch 225: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.3105 - mean_absolute_error: 18.3529 - val_loss: 995.6951 - val_mean_absolute_error: 18.9904\n",
      "Epoch 226/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1158.6078 - mean_absolute_error: 19.4406\n",
      "Epoch 226: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.1458 - mean_absolute_error: 18.0947 - val_loss: 1004.0964 - val_mean_absolute_error: 19.1052\n",
      "Epoch 227/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1105.5020 - mean_absolute_error: 18.2064\n",
      "Epoch 227: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1087.5962 - mean_absolute_error: 18.0649 - val_loss: 995.7850 - val_mean_absolute_error: 18.9646\n",
      "Epoch 228/1500\n",
      "\u001b[1m26/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.7223 - mean_absolute_error: 17.6966\n",
      "Epoch 228: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1108.8398 - mean_absolute_error: 17.8079 - val_loss: 997.9151 - val_mean_absolute_error: 19.0056\n",
      "Epoch 229/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 481.1429 - mean_absolute_error: 12.5445\n",
      "Epoch 229: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1091.4542 - mean_absolute_error: 17.8355 - val_loss: 1001.0139 - val_mean_absolute_error: 19.0079\n",
      "Epoch 230/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1113.5399 - mean_absolute_error: 18.8654\n",
      "Epoch 230: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.8422 - mean_absolute_error: 17.9809 - val_loss: 997.3378 - val_mean_absolute_error: 18.9845\n",
      "Epoch 231/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 684.9412 - mean_absolute_error: 13.9962\n",
      "Epoch 231: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.1541 - mean_absolute_error: 17.6258 - val_loss: 1000.6745 - val_mean_absolute_error: 19.0020\n",
      "Epoch 232/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1628.5054 - mean_absolute_error: 23.2852\n",
      "Epoch 232: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.0861 - mean_absolute_error: 18.4106 - val_loss: 997.7708 - val_mean_absolute_error: 18.9685\n",
      "Epoch 233/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 967.1147 - mean_absolute_error: 17.9036\n",
      "Epoch 233: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1041.0864 - mean_absolute_error: 17.5818 - val_loss: 995.2050 - val_mean_absolute_error: 18.9772\n",
      "Epoch 234/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 961.5542 - mean_absolute_error: 17.9490\n",
      "Epoch 234: val_loss did not improve from 993.89740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.0669 - mean_absolute_error: 18.3717 - val_loss: 995.6350 - val_mean_absolute_error: 18.9679\n",
      "Epoch 235/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1304.9529 - mean_absolute_error: 18.4177\n",
      "Epoch 235: val_loss improved from 993.89740 to 993.57898, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1216.7061 - mean_absolute_error: 18.4948 - val_loss: 993.5790 - val_mean_absolute_error: 18.9359\n",
      "Epoch 236/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1724.6586 - mean_absolute_error: 21.0000\n",
      "Epoch 236: val_loss did not improve from 993.57898\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1191.0497 - mean_absolute_error: 18.5274 - val_loss: 993.8344 - val_mean_absolute_error: 18.9013\n",
      "Epoch 237/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1487.0355 - mean_absolute_error: 20.9640\n",
      "Epoch 237: val_loss did not improve from 993.57898\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.6615 - mean_absolute_error: 18.2973 - val_loss: 998.2241 - val_mean_absolute_error: 19.0256\n",
      "Epoch 238/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1762.7867 - mean_absolute_error: 20.4128\n",
      "Epoch 238: val_loss did not improve from 993.57898\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1177.1587 - mean_absolute_error: 18.2550 - val_loss: 994.3292 - val_mean_absolute_error: 18.9521\n",
      "Epoch 239/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1282.3335 - mean_absolute_error: 18.3656\n",
      "Epoch 239: val_loss did not improve from 993.57898\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.4912 - mean_absolute_error: 18.3190 - val_loss: 997.9285 - val_mean_absolute_error: 18.9953\n",
      "Epoch 240/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1379.6399 - mean_absolute_error: 20.8169\n",
      "Epoch 240: val_loss did not improve from 993.57898\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.8092 - mean_absolute_error: 18.3699 - val_loss: 998.1878 - val_mean_absolute_error: 18.9600\n",
      "Epoch 241/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 852.9753 - mean_absolute_error: 15.9230\n",
      "Epoch 241: val_loss improved from 993.57898 to 992.81281, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1182.1938 - mean_absolute_error: 18.4801 - val_loss: 992.8128 - val_mean_absolute_error: 18.9717\n",
      "Epoch 242/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1302.8925 - mean_absolute_error: 14.4227\n",
      "Epoch 242: val_loss did not improve from 992.81281\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1160.4347 - mean_absolute_error: 17.8472 - val_loss: 993.3879 - val_mean_absolute_error: 18.9269\n",
      "Epoch 243/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 896.5751 - mean_absolute_error: 18.1636\n",
      "Epoch 243: val_loss improved from 992.81281 to 992.49261, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1032.2118 - mean_absolute_error: 17.6044 - val_loss: 992.4926 - val_mean_absolute_error: 18.8927\n",
      "Epoch 244/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 579.1678 - mean_absolute_error: 14.5938\n",
      "Epoch 244: val_loss did not improve from 992.49261\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1005.8302 - mean_absolute_error: 17.4868 - val_loss: 993.8928 - val_mean_absolute_error: 18.9091\n",
      "Epoch 245/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 960.8972 - mean_absolute_error: 17.7473\n",
      "Epoch 245: val_loss did not improve from 992.49261\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1035.3615 - mean_absolute_error: 17.4181 - val_loss: 996.5453 - val_mean_absolute_error: 18.9267\n",
      "Epoch 246/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 974.1693 - mean_absolute_error: 17.8348\n",
      "Epoch 246: val_loss did not improve from 992.49261\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.1526 - mean_absolute_error: 17.9570 - val_loss: 992.9503 - val_mean_absolute_error: 18.8661\n",
      "Epoch 247/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 793.0906 - mean_absolute_error: 16.3010\n",
      "Epoch 247: val_loss improved from 992.49261 to 990.47711, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.7253 - mean_absolute_error: 18.2704 - val_loss: 990.4771 - val_mean_absolute_error: 18.8888\n",
      "Epoch 248/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1291.2117 - mean_absolute_error: 19.6880\n",
      "Epoch 248: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1199.7427 - mean_absolute_error: 18.7345 - val_loss: 993.4761 - val_mean_absolute_error: 18.9147\n",
      "Epoch 249/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1608.5564 - mean_absolute_error: 20.1959\n",
      "Epoch 249: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.9098 - mean_absolute_error: 17.6427 - val_loss: 994.7891 - val_mean_absolute_error: 18.9220\n",
      "Epoch 250/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1224.9894 - mean_absolute_error: 19.5350\n",
      "Epoch 250: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1098.2269 - mean_absolute_error: 18.0589 - val_loss: 996.1205 - val_mean_absolute_error: 18.9588\n",
      "Epoch 251/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 917.2309 - mean_absolute_error: 17.5198\n",
      "Epoch 251: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062.5082 - mean_absolute_error: 17.8847 - val_loss: 995.7011 - val_mean_absolute_error: 18.9197\n",
      "Epoch 252/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1019.8834 - mean_absolute_error: 17.6467\n",
      "Epoch 252: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.8656 - mean_absolute_error: 17.9857 - val_loss: 991.6351 - val_mean_absolute_error: 18.8828\n",
      "Epoch 253/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 982.8160 - mean_absolute_error: 17.4702\n",
      "Epoch 253: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.7386 - mean_absolute_error: 17.5365 - val_loss: 995.9749 - val_mean_absolute_error: 18.8747\n",
      "Epoch 254/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 605.6826 - mean_absolute_error: 15.3279\n",
      "Epoch 254: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1022.7117 - mean_absolute_error: 17.6535 - val_loss: 993.4027 - val_mean_absolute_error: 18.8684\n",
      "Epoch 255/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 905.5085 - mean_absolute_error: 16.4446\n",
      "Epoch 255: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.1896 - mean_absolute_error: 18.0665 - val_loss: 993.7710 - val_mean_absolute_error: 18.8954\n",
      "Epoch 256/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1836.4460 - mean_absolute_error: 22.5072\n",
      "Epoch 256: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.7631 - mean_absolute_error: 18.7384 - val_loss: 995.9813 - val_mean_absolute_error: 18.9175\n",
      "Epoch 257/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1428.6902 - mean_absolute_error: 21.2028\n",
      "Epoch 257: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1266.3499 - mean_absolute_error: 18.7725 - val_loss: 992.5528 - val_mean_absolute_error: 18.8560\n",
      "Epoch 258/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 534.9652 - mean_absolute_error: 13.9531\n",
      "Epoch 258: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1111.9480 - mean_absolute_error: 17.9902 - val_loss: 995.1260 - val_mean_absolute_error: 18.8714\n",
      "Epoch 259/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1068.1262 - mean_absolute_error: 17.4294\n",
      "Epoch 259: val_loss did not improve from 990.47711\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.3694 - mean_absolute_error: 18.0790 - val_loss: 990.5139 - val_mean_absolute_error: 18.8409\n",
      "Epoch 260/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 995.6311 - mean_absolute_error: 16.9782\n",
      "Epoch 260: val_loss improved from 990.47711 to 990.43762, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.6123 - mean_absolute_error: 17.6980 - val_loss: 990.4376 - val_mean_absolute_error: 18.8503\n",
      "Epoch 261/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1253.9467 - mean_absolute_error: 19.2955\n",
      "Epoch 261: val_loss did not improve from 990.43762\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1182.5027 - mean_absolute_error: 18.5680 - val_loss: 995.9691 - val_mean_absolute_error: 18.9099\n",
      "Epoch 262/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1065.3931 - mean_absolute_error: 18.1354\n",
      "Epoch 262: val_loss improved from 990.43762 to 989.33740, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1078.3745 - mean_absolute_error: 17.9420 - val_loss: 989.3374 - val_mean_absolute_error: 18.7979\n",
      "Epoch 263/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 887.3328 - mean_absolute_error: 16.3442\n",
      "Epoch 263: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.8590 - mean_absolute_error: 17.7864 - val_loss: 993.2195 - val_mean_absolute_error: 18.8964\n",
      "Epoch 264/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 722.6039 - mean_absolute_error: 16.5101\n",
      "Epoch 264: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.0726 - mean_absolute_error: 17.9758 - val_loss: 1000.3288 - val_mean_absolute_error: 18.8990\n",
      "Epoch 265/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1373.6843 - mean_absolute_error: 19.2178\n",
      "Epoch 265: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.9562 - mean_absolute_error: 18.0239 - val_loss: 989.9624 - val_mean_absolute_error: 18.8364\n",
      "Epoch 266/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 760.9167 - mean_absolute_error: 15.9290\n",
      "Epoch 266: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 969.6066 - mean_absolute_error: 17.1654 - val_loss: 995.6205 - val_mean_absolute_error: 18.8581\n",
      "Epoch 267/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 665.0315 - mean_absolute_error: 15.3352\n",
      "Epoch 267: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.3398 - mean_absolute_error: 17.9209 - val_loss: 994.3881 - val_mean_absolute_error: 18.8826\n",
      "Epoch 268/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1337.6665 - mean_absolute_error: 21.1156\n",
      "Epoch 268: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1205.0337 - mean_absolute_error: 18.7284 - val_loss: 993.0012 - val_mean_absolute_error: 18.8983\n",
      "Epoch 269/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 739.0041 - mean_absolute_error: 15.4312\n",
      "Epoch 269: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.0525 - mean_absolute_error: 18.0002 - val_loss: 989.4851 - val_mean_absolute_error: 18.8543\n",
      "Epoch 270/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1058.4712 - mean_absolute_error: 19.8602\n",
      "Epoch 270: val_loss did not improve from 989.33740\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1178.9928 - mean_absolute_error: 18.4511 - val_loss: 996.3958 - val_mean_absolute_error: 18.8570\n",
      "Epoch 271/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 828.8479 - mean_absolute_error: 16.7468\n",
      "Epoch 271: val_loss improved from 989.33740 to 988.06281, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1082.7599 - mean_absolute_error: 17.9700 - val_loss: 988.0628 - val_mean_absolute_error: 18.7714\n",
      "Epoch 272/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 738.2100 - mean_absolute_error: 14.2972\n",
      "Epoch 272: val_loss improved from 988.06281 to 985.78748, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.3982 - mean_absolute_error: 17.8877 - val_loss: 985.7875 - val_mean_absolute_error: 18.8174\n",
      "Epoch 273/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 626.0797 - mean_absolute_error: 15.1108\n",
      "Epoch 273: val_loss did not improve from 985.78748\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.0431 - mean_absolute_error: 17.7768 - val_loss: 997.5348 - val_mean_absolute_error: 18.8969\n",
      "Epoch 274/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1177.6377 - mean_absolute_error: 16.6634\n",
      "Epoch 274: val_loss did not improve from 985.78748\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1178.4700 - mean_absolute_error: 18.1278 - val_loss: 993.1677 - val_mean_absolute_error: 18.8241\n",
      "Epoch 275/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1064.1627 - mean_absolute_error: 17.9206\n",
      "Epoch 275: val_loss did not improve from 985.78748\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.1053 - mean_absolute_error: 17.6230 - val_loss: 991.2056 - val_mean_absolute_error: 18.7820\n",
      "Epoch 276/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 714.2711 - mean_absolute_error: 15.9271\n",
      "Epoch 276: val_loss did not improve from 985.78748\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.4108 - mean_absolute_error: 17.9268 - val_loss: 998.7828 - val_mean_absolute_error: 18.8682\n",
      "Epoch 277/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 578.6921 - mean_absolute_error: 14.8950\n",
      "Epoch 277: val_loss improved from 985.78748 to 980.56586, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1038.9673 - mean_absolute_error: 17.5200 - val_loss: 980.5659 - val_mean_absolute_error: 18.6737\n",
      "Epoch 278/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 953.1007 - mean_absolute_error: 17.1219\n",
      "Epoch 278: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.8453 - mean_absolute_error: 17.7370 - val_loss: 995.4365 - val_mean_absolute_error: 18.8683\n",
      "Epoch 279/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1602.4521 - mean_absolute_error: 18.3570\n",
      "Epoch 279: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1257.3339 - mean_absolute_error: 18.5640 - val_loss: 992.0112 - val_mean_absolute_error: 18.7929\n",
      "Epoch 280/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1813.3293 - mean_absolute_error: 20.1465\n",
      "Epoch 280: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.7635 - mean_absolute_error: 17.8545 - val_loss: 992.9457 - val_mean_absolute_error: 18.8365\n",
      "Epoch 281/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 552.2784 - mean_absolute_error: 14.1131\n",
      "Epoch 281: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1143.2821 - mean_absolute_error: 17.8301 - val_loss: 987.5155 - val_mean_absolute_error: 18.7609\n",
      "Epoch 282/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 791.1862 - mean_absolute_error: 16.1840\n",
      "Epoch 282: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1127.0575 - mean_absolute_error: 18.2297 - val_loss: 991.2603 - val_mean_absolute_error: 18.7968\n",
      "Epoch 283/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 868.7522 - mean_absolute_error: 14.2536\n",
      "Epoch 283: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1089.3827 - mean_absolute_error: 17.4583 - val_loss: 988.5367 - val_mean_absolute_error: 18.7845\n",
      "Epoch 284/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 775.6949 - mean_absolute_error: 17.1105\n",
      "Epoch 284: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1087.5420 - mean_absolute_error: 17.8520 - val_loss: 993.3160 - val_mean_absolute_error: 18.7936\n",
      "Epoch 285/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 941.0687 - mean_absolute_error: 17.8778\n",
      "Epoch 285: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1184.6456 - mean_absolute_error: 18.5960 - val_loss: 988.2744 - val_mean_absolute_error: 18.7801\n",
      "Epoch 286/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1085.7556 - mean_absolute_error: 18.6571\n",
      "Epoch 286: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1044.5219 - mean_absolute_error: 17.4441 - val_loss: 992.9927 - val_mean_absolute_error: 18.8297\n",
      "Epoch 287/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 828.8452 - mean_absolute_error: 17.4846\n",
      "Epoch 287: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1041.8251 - mean_absolute_error: 17.6988 - val_loss: 989.4034 - val_mean_absolute_error: 18.7889\n",
      "Epoch 288/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 896.3007 - mean_absolute_error: 17.9538\n",
      "Epoch 288: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1002.1222 - mean_absolute_error: 17.2651 - val_loss: 990.5297 - val_mean_absolute_error: 18.7346\n",
      "Epoch 289/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 931.2518 - mean_absolute_error: 18.2276\n",
      "Epoch 289: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1039.5613 - mean_absolute_error: 17.8391 - val_loss: 993.1812 - val_mean_absolute_error: 18.8078\n",
      "Epoch 290/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 856.8961 - mean_absolute_error: 16.2234\n",
      "Epoch 290: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1026.5052 - mean_absolute_error: 17.4296 - val_loss: 991.5414 - val_mean_absolute_error: 18.7986\n",
      "Epoch 291/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1402.9679 - mean_absolute_error: 19.5990\n",
      "Epoch 291: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.3756 - mean_absolute_error: 18.0457 - val_loss: 992.4326 - val_mean_absolute_error: 18.8717\n",
      "Epoch 292/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 948.8762 - mean_absolute_error: 17.9664\n",
      "Epoch 292: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.3964 - mean_absolute_error: 17.8981 - val_loss: 993.7491 - val_mean_absolute_error: 18.7583\n",
      "Epoch 293/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1421.6846 - mean_absolute_error: 20.7215\n",
      "Epoch 293: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.9832 - mean_absolute_error: 18.0257 - val_loss: 989.3669 - val_mean_absolute_error: 18.7498\n",
      "Epoch 294/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2268.7815 - mean_absolute_error: 25.8721\n",
      "Epoch 294: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1352.1549 - mean_absolute_error: 19.2624 - val_loss: 988.4155 - val_mean_absolute_error: 18.7286\n",
      "Epoch 295/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1732.1875 - mean_absolute_error: 22.5775\n",
      "Epoch 295: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1189.8147 - mean_absolute_error: 18.4889 - val_loss: 987.3456 - val_mean_absolute_error: 18.7168\n",
      "Epoch 296/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1676.5549 - mean_absolute_error: 20.2642\n",
      "Epoch 296: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.6984 - mean_absolute_error: 18.3517 - val_loss: 986.4769 - val_mean_absolute_error: 18.7415\n",
      "Epoch 297/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1300.6433 - mean_absolute_error: 19.1397\n",
      "Epoch 297: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.6013 - mean_absolute_error: 17.5982 - val_loss: 999.1371 - val_mean_absolute_error: 18.8444\n",
      "Epoch 298/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1138.0422 - mean_absolute_error: 17.5020\n",
      "Epoch 298: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.8881 - mean_absolute_error: 17.7465 - val_loss: 989.6801 - val_mean_absolute_error: 18.7203\n",
      "Epoch 299/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 847.9475 - mean_absolute_error: 13.5807\n",
      "Epoch 299: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.3730 - mean_absolute_error: 17.5413 - val_loss: 989.4133 - val_mean_absolute_error: 18.7557\n",
      "Epoch 300/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1865.7621 - mean_absolute_error: 22.5801\n",
      "Epoch 300: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.4298 - mean_absolute_error: 18.1490 - val_loss: 989.8572 - val_mean_absolute_error: 18.7030\n",
      "Epoch 301/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1378.7808 - mean_absolute_error: 20.6745\n",
      "Epoch 301: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.2388 - mean_absolute_error: 18.1243 - val_loss: 990.3157 - val_mean_absolute_error: 18.7347\n",
      "Epoch 302/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1205.5544 - mean_absolute_error: 18.5360\n",
      "Epoch 302: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.8383 - mean_absolute_error: 18.1523 - val_loss: 990.1644 - val_mean_absolute_error: 18.7840\n",
      "Epoch 303/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 879.9094 - mean_absolute_error: 16.6453\n",
      "Epoch 303: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.9796 - mean_absolute_error: 17.6021 - val_loss: 985.6296 - val_mean_absolute_error: 18.6819\n",
      "Epoch 304/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 796.2436 - mean_absolute_error: 17.1500\n",
      "Epoch 304: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.8468 - mean_absolute_error: 18.5759 - val_loss: 988.1398 - val_mean_absolute_error: 18.7843\n",
      "Epoch 305/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1034.5117 - mean_absolute_error: 18.2078\n",
      "Epoch 305: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1184.4255 - mean_absolute_error: 18.5010 - val_loss: 990.2419 - val_mean_absolute_error: 18.7651\n",
      "Epoch 306/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1045.7793 - mean_absolute_error: 17.2836\n",
      "Epoch 306: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.2788 - mean_absolute_error: 18.1417 - val_loss: 986.3907 - val_mean_absolute_error: 18.6355\n",
      "Epoch 307/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 692.4249 - mean_absolute_error: 15.8077\n",
      "Epoch 307: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.0164 - mean_absolute_error: 18.1905 - val_loss: 988.2809 - val_mean_absolute_error: 18.7636\n",
      "Epoch 308/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1346.2480 - mean_absolute_error: 18.2462\n",
      "Epoch 308: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.1346 - mean_absolute_error: 18.1014 - val_loss: 990.6177 - val_mean_absolute_error: 18.7587\n",
      "Epoch 309/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1035.1104 - mean_absolute_error: 17.8801\n",
      "Epoch 309: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1141.5024 - mean_absolute_error: 18.2910 - val_loss: 982.7861 - val_mean_absolute_error: 18.6767\n",
      "Epoch 310/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1640.0216 - mean_absolute_error: 19.1773\n",
      "Epoch 310: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1201.8792 - mean_absolute_error: 18.5594 - val_loss: 985.7236 - val_mean_absolute_error: 18.7106\n",
      "Epoch 311/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1735.6624 - mean_absolute_error: 23.7184\n",
      "Epoch 311: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.1680 - mean_absolute_error: 18.0398 - val_loss: 989.3060 - val_mean_absolute_error: 18.7359\n",
      "Epoch 312/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1228.0155 - mean_absolute_error: 16.9410\n",
      "Epoch 312: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.2819 - mean_absolute_error: 17.7364 - val_loss: 986.3616 - val_mean_absolute_error: 18.7120\n",
      "Epoch 313/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 741.4764 - mean_absolute_error: 15.7423\n",
      "Epoch 313: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.3655 - mean_absolute_error: 17.7506 - val_loss: 990.1664 - val_mean_absolute_error: 18.7443\n",
      "Epoch 314/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 720.8091 - mean_absolute_error: 15.7088\n",
      "Epoch 314: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1191.0472 - mean_absolute_error: 18.6739 - val_loss: 985.3266 - val_mean_absolute_error: 18.6915\n",
      "Epoch 315/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 653.3723 - mean_absolute_error: 14.2247\n",
      "Epoch 315: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.8009 - mean_absolute_error: 17.4254 - val_loss: 992.5606 - val_mean_absolute_error: 18.7641\n",
      "Epoch 316/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1056.3956 - mean_absolute_error: 20.5615\n",
      "Epoch 316: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1036.1677 - mean_absolute_error: 17.8868 - val_loss: 996.2853 - val_mean_absolute_error: 18.8140\n",
      "Epoch 317/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1484.4506 - mean_absolute_error: 20.8503\n",
      "Epoch 317: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1216.7317 - mean_absolute_error: 18.8762 - val_loss: 993.2551 - val_mean_absolute_error: 18.7392\n",
      "Epoch 318/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1032.5563 - mean_absolute_error: 17.2938\n",
      "Epoch 318: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071.2157 - mean_absolute_error: 17.7113 - val_loss: 990.9965 - val_mean_absolute_error: 18.7641\n",
      "Epoch 319/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1024.4990 - mean_absolute_error: 18.0896\n",
      "Epoch 319: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1130.7261 - mean_absolute_error: 18.0456 - val_loss: 983.1538 - val_mean_absolute_error: 18.6567\n",
      "Epoch 320/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1490.0726 - mean_absolute_error: 20.2688\n",
      "Epoch 320: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.5164 - mean_absolute_error: 18.0740 - val_loss: 983.6085 - val_mean_absolute_error: 18.6679\n",
      "Epoch 321/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 719.1681 - mean_absolute_error: 14.0573\n",
      "Epoch 321: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.3766 - mean_absolute_error: 17.5379 - val_loss: 989.8275 - val_mean_absolute_error: 18.7535\n",
      "Epoch 322/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 885.8967 - mean_absolute_error: 17.5711\n",
      "Epoch 322: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1004.5008 - mean_absolute_error: 17.5069 - val_loss: 990.6202 - val_mean_absolute_error: 18.7373\n",
      "Epoch 323/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1534.2202 - mean_absolute_error: 21.6025\n",
      "Epoch 323: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.0204 - mean_absolute_error: 18.0131 - val_loss: 986.4029 - val_mean_absolute_error: 18.6941\n",
      "Epoch 324/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1421.2793 - mean_absolute_error: 18.9492\n",
      "Epoch 324: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1154.9639 - mean_absolute_error: 17.9356 - val_loss: 984.4433 - val_mean_absolute_error: 18.6334\n",
      "Epoch 325/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1251.5500 - mean_absolute_error: 17.6092\n",
      "Epoch 325: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1087.4623 - mean_absolute_error: 17.5129 - val_loss: 987.7320 - val_mean_absolute_error: 18.7022\n",
      "Epoch 326/1500\n",
      "\u001b[1m19/33\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1027.3135 - mean_absolute_error: 17.9691\n",
      "Epoch 326: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1062.1787 - mean_absolute_error: 17.9948 - val_loss: 987.1308 - val_mean_absolute_error: 18.7039\n",
      "Epoch 327/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1179.1716 - mean_absolute_error: 18.7151\n",
      "Epoch 327: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.8307 - mean_absolute_error: 17.6564 - val_loss: 985.7690 - val_mean_absolute_error: 18.6687\n",
      "Epoch 328/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 718.4161 - mean_absolute_error: 14.9578\n",
      "Epoch 328: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1076.6371 - mean_absolute_error: 17.9096 - val_loss: 991.0684 - val_mean_absolute_error: 18.7411\n",
      "Epoch 329/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1659.3269 - mean_absolute_error: 20.5757\n",
      "Epoch 329: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1203.8551 - mean_absolute_error: 18.3917 - val_loss: 988.4284 - val_mean_absolute_error: 18.6839\n",
      "Epoch 330/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1754.9315 - mean_absolute_error: 21.9969\n",
      "Epoch 330: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1188.8226 - mean_absolute_error: 18.5680 - val_loss: 982.9803 - val_mean_absolute_error: 18.6192\n",
      "Epoch 331/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1360.4393 - mean_absolute_error: 20.4996\n",
      "Epoch 331: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1130.3177 - mean_absolute_error: 18.0869 - val_loss: 981.3178 - val_mean_absolute_error: 18.6157\n",
      "Epoch 332/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1082.1945 - mean_absolute_error: 16.8472\n",
      "Epoch 332: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.9288 - mean_absolute_error: 17.5110 - val_loss: 987.4042 - val_mean_absolute_error: 18.6830\n",
      "Epoch 333/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 681.5117 - mean_absolute_error: 14.5822\n",
      "Epoch 333: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1105.2128 - mean_absolute_error: 17.5332 - val_loss: 982.5085 - val_mean_absolute_error: 18.6165\n",
      "Epoch 334/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1568.3000 - mean_absolute_error: 22.0393\n",
      "Epoch 334: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1126.5737 - mean_absolute_error: 18.2328 - val_loss: 985.9332 - val_mean_absolute_error: 18.6663\n",
      "Epoch 335/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1130.9919 - mean_absolute_error: 19.0407\n",
      "Epoch 335: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.8676 - mean_absolute_error: 18.2965 - val_loss: 982.4593 - val_mean_absolute_error: 18.6480\n",
      "Epoch 336/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2021.8777 - mean_absolute_error: 23.0807\n",
      "Epoch 336: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1293.1675 - mean_absolute_error: 19.1465 - val_loss: 993.6581 - val_mean_absolute_error: 18.7754\n",
      "Epoch 337/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 887.1473 - mean_absolute_error: 17.4704\n",
      "Epoch 337: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.8770 - mean_absolute_error: 18.0423 - val_loss: 987.7120 - val_mean_absolute_error: 18.6710\n",
      "Epoch 338/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 755.2860 - mean_absolute_error: 14.9198\n",
      "Epoch 338: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.3722 - mean_absolute_error: 17.9265 - val_loss: 990.8176 - val_mean_absolute_error: 18.7047\n",
      "Epoch 339/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 973.3329 - mean_absolute_error: 16.4987\n",
      "Epoch 339: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1083.2388 - mean_absolute_error: 17.9042 - val_loss: 986.2968 - val_mean_absolute_error: 18.6535\n",
      "Epoch 340/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1892.0913 - mean_absolute_error: 19.4514\n",
      "Epoch 340: val_loss did not improve from 980.56586\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1191.6576 - mean_absolute_error: 18.3365 - val_loss: 989.1550 - val_mean_absolute_error: 18.7172\n",
      "Epoch 341/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1298.2079 - mean_absolute_error: 19.4414\n",
      "Epoch 341: val_loss improved from 980.56586 to 979.38074, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.8231 - mean_absolute_error: 18.2105 - val_loss: 979.3807 - val_mean_absolute_error: 18.6057\n",
      "Epoch 342/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1039.0671 - mean_absolute_error: 17.9663\n",
      "Epoch 342: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.6932 - mean_absolute_error: 18.1316 - val_loss: 989.6071 - val_mean_absolute_error: 18.6970\n",
      "Epoch 343/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1350.3816 - mean_absolute_error: 19.4618\n",
      "Epoch 343: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1172.9131 - mean_absolute_error: 18.3996 - val_loss: 988.0949 - val_mean_absolute_error: 18.6854\n",
      "Epoch 344/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1068.8284 - mean_absolute_error: 17.4261\n",
      "Epoch 344: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1082.1179 - mean_absolute_error: 17.9056 - val_loss: 988.2265 - val_mean_absolute_error: 18.6769\n",
      "Epoch 345/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1434.9971 - mean_absolute_error: 21.0390\n",
      "Epoch 345: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.6891 - mean_absolute_error: 18.1595 - val_loss: 988.0997 - val_mean_absolute_error: 18.6414\n",
      "Epoch 346/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 775.4078 - mean_absolute_error: 14.7333\n",
      "Epoch 346: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 999.0996 - mean_absolute_error: 17.1816 - val_loss: 990.0110 - val_mean_absolute_error: 18.6670\n",
      "Epoch 347/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1523.1443 - mean_absolute_error: 19.6379\n",
      "Epoch 347: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.3481 - mean_absolute_error: 17.7526 - val_loss: 986.9448 - val_mean_absolute_error: 18.6397\n",
      "Epoch 348/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1284.4092 - mean_absolute_error: 19.3590\n",
      "Epoch 348: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1184.1967 - mean_absolute_error: 18.3430 - val_loss: 979.8456 - val_mean_absolute_error: 18.5918\n",
      "Epoch 349/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2160.6477 - mean_absolute_error: 22.8149\n",
      "Epoch 349: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1161.0327 - mean_absolute_error: 18.0212 - val_loss: 981.9603 - val_mean_absolute_error: 18.6012\n",
      "Epoch 350/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 775.7162 - mean_absolute_error: 15.1410\n",
      "Epoch 350: val_loss did not improve from 979.38074\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1011.3422 - mean_absolute_error: 17.1357 - val_loss: 988.8058 - val_mean_absolute_error: 18.6847\n",
      "Epoch 351/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1094.8314 - mean_absolute_error: 19.7768\n",
      "Epoch 351: val_loss improved from 979.38074 to 977.69177, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.1156 - mean_absolute_error: 17.8446 - val_loss: 977.6918 - val_mean_absolute_error: 18.5426\n",
      "Epoch 352/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 808.2980 - mean_absolute_error: 15.0472\n",
      "Epoch 352: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1002.4963 - mean_absolute_error: 17.2363 - val_loss: 993.1304 - val_mean_absolute_error: 18.6768\n",
      "Epoch 353/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1135.7753 - mean_absolute_error: 17.9429\n",
      "Epoch 353: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.1331 - mean_absolute_error: 17.9804 - val_loss: 984.5005 - val_mean_absolute_error: 18.6188\n",
      "Epoch 354/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 879.5122 - mean_absolute_error: 15.9606\n",
      "Epoch 354: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1080.0480 - mean_absolute_error: 17.8976 - val_loss: 982.5725 - val_mean_absolute_error: 18.6015\n",
      "Epoch 355/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 887.6553 - mean_absolute_error: 17.0579\n",
      "Epoch 355: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1033.7861 - mean_absolute_error: 17.5810 - val_loss: 985.7988 - val_mean_absolute_error: 18.6292\n",
      "Epoch 356/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1796.7302 - mean_absolute_error: 18.9779\n",
      "Epoch 356: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1171.1776 - mean_absolute_error: 17.8766 - val_loss: 985.0184 - val_mean_absolute_error: 18.6538\n",
      "Epoch 357/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1114.5010 - mean_absolute_error: 18.7682\n",
      "Epoch 357: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.9705 - mean_absolute_error: 17.9290 - val_loss: 989.4146 - val_mean_absolute_error: 18.6651\n",
      "Epoch 358/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1551.8135 - mean_absolute_error: 21.7048\n",
      "Epoch 358: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1149.2650 - mean_absolute_error: 18.2654 - val_loss: 985.9783 - val_mean_absolute_error: 18.6221\n",
      "Epoch 359/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 753.3972 - mean_absolute_error: 16.5647\n",
      "Epoch 359: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.0573 - mean_absolute_error: 18.0124 - val_loss: 989.4476 - val_mean_absolute_error: 18.7113\n",
      "Epoch 360/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 899.9484 - mean_absolute_error: 15.9234\n",
      "Epoch 360: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1130.8596 - mean_absolute_error: 17.9297 - val_loss: 988.6089 - val_mean_absolute_error: 18.6488\n",
      "Epoch 361/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1288.6912 - mean_absolute_error: 19.0491\n",
      "Epoch 361: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.4410 - mean_absolute_error: 18.1700 - val_loss: 988.8161 - val_mean_absolute_error: 18.6045\n",
      "Epoch 362/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 781.6556 - mean_absolute_error: 15.8933\n",
      "Epoch 362: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.8984 - mean_absolute_error: 18.0527 - val_loss: 983.1293 - val_mean_absolute_error: 18.5925\n",
      "Epoch 363/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 946.4077 - mean_absolute_error: 17.4073\n",
      "Epoch 363: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.2019 - mean_absolute_error: 18.1183 - val_loss: 984.7857 - val_mean_absolute_error: 18.6252\n",
      "Epoch 364/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 957.1019 - mean_absolute_error: 16.8965\n",
      "Epoch 364: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1111.2577 - mean_absolute_error: 18.0092 - val_loss: 982.2953 - val_mean_absolute_error: 18.5608\n",
      "Epoch 365/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1062.0822 - mean_absolute_error: 18.3614\n",
      "Epoch 365: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1066.2793 - mean_absolute_error: 17.8258 - val_loss: 982.9875 - val_mean_absolute_error: 18.5585\n",
      "Epoch 366/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 977.8661 - mean_absolute_error: 17.2193\n",
      "Epoch 366: val_loss did not improve from 977.69177\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1044.8519 - mean_absolute_error: 17.3464 - val_loss: 982.5294 - val_mean_absolute_error: 18.5846\n",
      "Epoch 367/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1853.7853 - mean_absolute_error: 23.4282\n",
      "Epoch 367: val_loss improved from 977.69177 to 977.04871, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1175.3069 - mean_absolute_error: 18.4005 - val_loss: 977.0487 - val_mean_absolute_error: 18.4879\n",
      "Epoch 368/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 836.6508 - mean_absolute_error: 15.6041\n",
      "Epoch 368: val_loss did not improve from 977.04871\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1025.4473 - mean_absolute_error: 17.1847 - val_loss: 984.6436 - val_mean_absolute_error: 18.6041\n",
      "Epoch 369/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 628.2291 - mean_absolute_error: 14.8486\n",
      "Epoch 369: val_loss did not improve from 977.04871\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.9530 - mean_absolute_error: 17.5866 - val_loss: 989.4808 - val_mean_absolute_error: 18.6293\n",
      "Epoch 370/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1352.0522 - mean_absolute_error: 19.3898\n",
      "Epoch 370: val_loss did not improve from 977.04871\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.7747 - mean_absolute_error: 17.9457 - val_loss: 984.6039 - val_mean_absolute_error: 18.5943\n",
      "Epoch 371/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 835.6033 - mean_absolute_error: 15.9407\n",
      "Epoch 371: val_loss improved from 977.04871 to 976.54602, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.8850 - mean_absolute_error: 17.8556 - val_loss: 976.5460 - val_mean_absolute_error: 18.5021\n",
      "Epoch 372/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1352.5288 - mean_absolute_error: 21.4742\n",
      "Epoch 372: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.0961 - mean_absolute_error: 18.1679 - val_loss: 988.5910 - val_mean_absolute_error: 18.6472\n",
      "Epoch 373/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1287.0492 - mean_absolute_error: 19.4115\n",
      "Epoch 373: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.8518 - mean_absolute_error: 18.0824 - val_loss: 980.9925 - val_mean_absolute_error: 18.5848\n",
      "Epoch 374/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1289.0691 - mean_absolute_error: 20.7056\n",
      "Epoch 374: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.7449 - mean_absolute_error: 18.2698 - val_loss: 988.3932 - val_mean_absolute_error: 18.6044\n",
      "Epoch 375/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1699.7090 - mean_absolute_error: 21.7082\n",
      "Epoch 375: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.0807 - mean_absolute_error: 17.9136 - val_loss: 987.6088 - val_mean_absolute_error: 18.6493\n",
      "Epoch 376/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 734.6201 - mean_absolute_error: 16.1801\n",
      "Epoch 376: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.1415 - mean_absolute_error: 18.0477 - val_loss: 987.7864 - val_mean_absolute_error: 18.6229\n",
      "Epoch 377/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1014.7352 - mean_absolute_error: 17.4645\n",
      "Epoch 377: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1153.1400 - mean_absolute_error: 18.2669 - val_loss: 993.8035 - val_mean_absolute_error: 18.7405\n",
      "Epoch 378/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1322.5138 - mean_absolute_error: 17.9758\n",
      "Epoch 378: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1137.0205 - mean_absolute_error: 17.9972 - val_loss: 977.7734 - val_mean_absolute_error: 18.5153\n",
      "Epoch 379/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 939.1858 - mean_absolute_error: 17.4121\n",
      "Epoch 379: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1070.7499 - mean_absolute_error: 17.8293 - val_loss: 986.1188 - val_mean_absolute_error: 18.5334\n",
      "Epoch 380/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1136.5133 - mean_absolute_error: 18.6636\n",
      "Epoch 380: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1172.2142 - mean_absolute_error: 18.4845 - val_loss: 988.1819 - val_mean_absolute_error: 18.6441\n",
      "Epoch 381/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 702.2053 - mean_absolute_error: 15.5531\n",
      "Epoch 381: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1026.8983 - mean_absolute_error: 17.2544 - val_loss: 984.4117 - val_mean_absolute_error: 18.5946\n",
      "Epoch 382/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1273.7532 - mean_absolute_error: 20.1728\n",
      "Epoch 382: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.9707 - mean_absolute_error: 18.2915 - val_loss: 980.0999 - val_mean_absolute_error: 18.5388\n",
      "Epoch 383/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1212.6030 - mean_absolute_error: 18.5454\n",
      "Epoch 383: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.3390 - mean_absolute_error: 17.8270 - val_loss: 987.3228 - val_mean_absolute_error: 18.6476\n",
      "Epoch 384/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 638.8450 - mean_absolute_error: 14.5853\n",
      "Epoch 384: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1090.7006 - mean_absolute_error: 17.9563 - val_loss: 983.3008 - val_mean_absolute_error: 18.5682\n",
      "Epoch 385/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 816.7786 - mean_absolute_error: 16.1515\n",
      "Epoch 385: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1068.9281 - mean_absolute_error: 17.7561 - val_loss: 990.3128 - val_mean_absolute_error: 18.6656\n",
      "Epoch 386/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1615.7010 - mean_absolute_error: 20.5755\n",
      "Epoch 386: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1297.4196 - mean_absolute_error: 18.9594 - val_loss: 977.3393 - val_mean_absolute_error: 18.4959\n",
      "Epoch 387/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 974.8989 - mean_absolute_error: 17.3150\n",
      "Epoch 387: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.9026 - mean_absolute_error: 17.6803 - val_loss: 991.0526 - val_mean_absolute_error: 18.6347\n",
      "Epoch 388/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1287.1863 - mean_absolute_error: 19.1887\n",
      "Epoch 388: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.5135 - mean_absolute_error: 18.0910 - val_loss: 981.2829 - val_mean_absolute_error: 18.4903\n",
      "Epoch 389/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 943.6856 - mean_absolute_error: 17.8027\n",
      "Epoch 389: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.8479 - mean_absolute_error: 18.1381 - val_loss: 987.6099 - val_mean_absolute_error: 18.5949\n",
      "Epoch 390/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 871.3412 - mean_absolute_error: 16.5180\n",
      "Epoch 390: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.6924 - mean_absolute_error: 17.7290 - val_loss: 985.3964 - val_mean_absolute_error: 18.5728\n",
      "Epoch 391/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 695.9595 - mean_absolute_error: 15.8984\n",
      "Epoch 391: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.2373 - mean_absolute_error: 17.4931 - val_loss: 982.6342 - val_mean_absolute_error: 18.5665\n",
      "Epoch 392/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1062.1852 - mean_absolute_error: 16.8562\n",
      "Epoch 392: val_loss did not improve from 976.54602\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.4547 - mean_absolute_error: 17.6191 - val_loss: 989.1294 - val_mean_absolute_error: 18.6217\n",
      "Epoch 393/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1631.5466 - mean_absolute_error: 21.6577\n",
      "Epoch 393: val_loss improved from 976.54602 to 975.40619, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1118.4679 - mean_absolute_error: 17.8496 - val_loss: 975.4062 - val_mean_absolute_error: 18.4683\n",
      "Epoch 394/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1540.1130 - mean_absolute_error: 21.0678\n",
      "Epoch 394: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046.1851 - mean_absolute_error: 17.5188 - val_loss: 979.0515 - val_mean_absolute_error: 18.4360\n",
      "Epoch 395/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1077.0264 - mean_absolute_error: 16.1472\n",
      "Epoch 395: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1055.8768 - mean_absolute_error: 17.4948 - val_loss: 987.0092 - val_mean_absolute_error: 18.6330\n",
      "Epoch 396/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1285.0906 - mean_absolute_error: 19.5789\n",
      "Epoch 396: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1209.5554 - mean_absolute_error: 18.5770 - val_loss: 979.1140 - val_mean_absolute_error: 18.4787\n",
      "Epoch 397/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 852.8165 - mean_absolute_error: 16.8012\n",
      "Epoch 397: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1055.0570 - mean_absolute_error: 17.8357 - val_loss: 984.1387 - val_mean_absolute_error: 18.5611\n",
      "Epoch 398/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 593.8288 - mean_absolute_error: 13.9035\n",
      "Epoch 398: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1009.5441 - mean_absolute_error: 17.1622 - val_loss: 982.1234 - val_mean_absolute_error: 18.5393\n",
      "Epoch 399/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 943.9462 - mean_absolute_error: 14.9112\n",
      "Epoch 399: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.0344 - mean_absolute_error: 17.6469 - val_loss: 980.6276 - val_mean_absolute_error: 18.5290\n",
      "Epoch 400/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 977.6971 - mean_absolute_error: 17.6559\n",
      "Epoch 400: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1041.2595 - mean_absolute_error: 17.5892 - val_loss: 980.6993 - val_mean_absolute_error: 18.4433\n",
      "Epoch 401/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1655.7029 - mean_absolute_error: 22.9638\n",
      "Epoch 401: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1205.1896 - mean_absolute_error: 18.7877 - val_loss: 991.0359 - val_mean_absolute_error: 18.6546\n",
      "Epoch 402/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 652.6860 - mean_absolute_error: 15.3510\n",
      "Epoch 402: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1108.5084 - mean_absolute_error: 18.0331 - val_loss: 983.5134 - val_mean_absolute_error: 18.5530\n",
      "Epoch 403/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 889.4453 - mean_absolute_error: 14.5348\n",
      "Epoch 403: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.6522 - mean_absolute_error: 17.3793 - val_loss: 985.8025 - val_mean_absolute_error: 18.5695\n",
      "Epoch 404/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 661.0939 - mean_absolute_error: 14.8587\n",
      "Epoch 404: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.7537 - mean_absolute_error: 17.2785 - val_loss: 984.6664 - val_mean_absolute_error: 18.5466\n",
      "Epoch 405/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1888.1067 - mean_absolute_error: 21.0006\n",
      "Epoch 405: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1191.8367 - mean_absolute_error: 18.1845 - val_loss: 990.2018 - val_mean_absolute_error: 18.6134\n",
      "Epoch 406/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 576.6973 - mean_absolute_error: 14.1501\n",
      "Epoch 406: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.0240 - mean_absolute_error: 18.0422 - val_loss: 984.5038 - val_mean_absolute_error: 18.5345\n",
      "Epoch 407/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 998.6275 - mean_absolute_error: 17.6038\n",
      "Epoch 407: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1052.8599 - mean_absolute_error: 17.7196 - val_loss: 983.0943 - val_mean_absolute_error: 18.6006\n",
      "Epoch 408/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1228.0371 - mean_absolute_error: 19.7999\n",
      "Epoch 408: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1076.8114 - mean_absolute_error: 17.9113 - val_loss: 989.3603 - val_mean_absolute_error: 18.5920\n",
      "Epoch 409/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 921.8441 - mean_absolute_error: 17.7234\n",
      "Epoch 409: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1053.6187 - mean_absolute_error: 17.7826 - val_loss: 988.4103 - val_mean_absolute_error: 18.4975\n",
      "Epoch 410/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 868.3011 - mean_absolute_error: 15.3935\n",
      "Epoch 410: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.7831 - mean_absolute_error: 17.5490 - val_loss: 978.7828 - val_mean_absolute_error: 18.5229\n",
      "Epoch 411/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 804.8462 - mean_absolute_error: 16.8044\n",
      "Epoch 411: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1037.7056 - mean_absolute_error: 17.2115 - val_loss: 978.3157 - val_mean_absolute_error: 18.4214\n",
      "Epoch 412/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 963.9524 - mean_absolute_error: 18.9492\n",
      "Epoch 412: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.5127 - mean_absolute_error: 18.1172 - val_loss: 985.2173 - val_mean_absolute_error: 18.5385\n",
      "Epoch 413/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 799.3961 - mean_absolute_error: 15.2139\n",
      "Epoch 413: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.3060 - mean_absolute_error: 17.4107 - val_loss: 984.0720 - val_mean_absolute_error: 18.5511\n",
      "Epoch 414/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 894.1033 - mean_absolute_error: 16.1083\n",
      "Epoch 414: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1087.9951 - mean_absolute_error: 17.5143 - val_loss: 981.5644 - val_mean_absolute_error: 18.5273\n",
      "Epoch 415/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 548.0972 - mean_absolute_error: 14.5101\n",
      "Epoch 415: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.7723 - mean_absolute_error: 17.6308 - val_loss: 984.2328 - val_mean_absolute_error: 18.5044\n",
      "Epoch 416/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 843.7431 - mean_absolute_error: 15.0213\n",
      "Epoch 416: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.1080 - mean_absolute_error: 17.6220 - val_loss: 987.6078 - val_mean_absolute_error: 18.6117\n",
      "Epoch 417/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1269.5865 - mean_absolute_error: 20.1207\n",
      "Epoch 417: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.3402 - mean_absolute_error: 17.8671 - val_loss: 980.1047 - val_mean_absolute_error: 18.4756\n",
      "Epoch 418/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1423.4644 - mean_absolute_error: 19.3815\n",
      "Epoch 418: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.8801 - mean_absolute_error: 18.1949 - val_loss: 985.3680 - val_mean_absolute_error: 18.5446\n",
      "Epoch 419/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 512.9537 - mean_absolute_error: 12.9497\n",
      "Epoch 419: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1034.0088 - mean_absolute_error: 17.2057 - val_loss: 980.0402 - val_mean_absolute_error: 18.4595\n",
      "Epoch 420/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 731.8960 - mean_absolute_error: 15.7153\n",
      "Epoch 420: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1052.7845 - mean_absolute_error: 17.5171 - val_loss: 980.6347 - val_mean_absolute_error: 18.5261\n",
      "Epoch 421/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2213.3115 - mean_absolute_error: 23.8335\n",
      "Epoch 421: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.9801 - mean_absolute_error: 18.1120 - val_loss: 985.8309 - val_mean_absolute_error: 18.5280\n",
      "Epoch 422/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1186.1296 - mean_absolute_error: 17.4512\n",
      "Epoch 422: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.5441 - mean_absolute_error: 17.8598 - val_loss: 980.2466 - val_mean_absolute_error: 18.5288\n",
      "Epoch 423/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1629.5363 - mean_absolute_error: 22.8836\n",
      "Epoch 423: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.3855 - mean_absolute_error: 18.0606 - val_loss: 976.5541 - val_mean_absolute_error: 18.4129\n",
      "Epoch 424/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1303.1149 - mean_absolute_error: 17.0720\n",
      "Epoch 424: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1044.4785 - mean_absolute_error: 17.3998 - val_loss: 981.9774 - val_mean_absolute_error: 18.4738\n",
      "Epoch 425/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 803.0741 - mean_absolute_error: 16.2287\n",
      "Epoch 425: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1028.0459 - mean_absolute_error: 17.3304 - val_loss: 982.3523 - val_mean_absolute_error: 18.5638\n",
      "Epoch 426/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1533.2385 - mean_absolute_error: 22.0170\n",
      "Epoch 426: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.8726 - mean_absolute_error: 18.3160 - val_loss: 987.0190 - val_mean_absolute_error: 18.5054\n",
      "Epoch 427/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1124.8052 - mean_absolute_error: 19.4719\n",
      "Epoch 427: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1179.3762 - mean_absolute_error: 18.3392 - val_loss: 981.8928 - val_mean_absolute_error: 18.5139\n",
      "Epoch 428/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 614.5421 - mean_absolute_error: 14.8203\n",
      "Epoch 428: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1022.6668 - mean_absolute_error: 17.2878 - val_loss: 979.3062 - val_mean_absolute_error: 18.4299\n",
      "Epoch 429/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 991.4241 - mean_absolute_error: 17.7212\n",
      "Epoch 429: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1184.1816 - mean_absolute_error: 18.5254 - val_loss: 985.7087 - val_mean_absolute_error: 18.5476\n",
      "Epoch 430/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1499.2375 - mean_absolute_error: 20.5672\n",
      "Epoch 430: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1253.5057 - mean_absolute_error: 18.6423 - val_loss: 979.3063 - val_mean_absolute_error: 18.4916\n",
      "Epoch 431/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1133.3556 - mean_absolute_error: 18.4146\n",
      "Epoch 431: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.6670 - mean_absolute_error: 17.5607 - val_loss: 982.0143 - val_mean_absolute_error: 18.4567\n",
      "Epoch 432/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1811.5142 - mean_absolute_error: 20.8856\n",
      "Epoch 432: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1179.9479 - mean_absolute_error: 18.1425 - val_loss: 981.6820 - val_mean_absolute_error: 18.5300\n",
      "Epoch 433/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1058.3472 - mean_absolute_error: 16.9024\n",
      "Epoch 433: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.6025 - mean_absolute_error: 17.9085 - val_loss: 984.1394 - val_mean_absolute_error: 18.4648\n",
      "Epoch 434/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 701.8594 - mean_absolute_error: 15.4600\n",
      "Epoch 434: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1097.1195 - mean_absolute_error: 17.9686 - val_loss: 989.9592 - val_mean_absolute_error: 18.5733\n",
      "Epoch 435/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 964.6393 - mean_absolute_error: 16.5529\n",
      "Epoch 435: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.4332 - mean_absolute_error: 17.4553 - val_loss: 990.3192 - val_mean_absolute_error: 18.5569\n",
      "Epoch 436/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1204.8481 - mean_absolute_error: 18.4076\n",
      "Epoch 436: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.8489 - mean_absolute_error: 17.6451 - val_loss: 982.3386 - val_mean_absolute_error: 18.4532\n",
      "Epoch 437/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 898.0707 - mean_absolute_error: 14.9518\n",
      "Epoch 437: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1175.6135 - mean_absolute_error: 18.0851 - val_loss: 979.6745 - val_mean_absolute_error: 18.4462\n",
      "Epoch 438/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 688.8815 - mean_absolute_error: 15.3954\n",
      "Epoch 438: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062.5515 - mean_absolute_error: 17.7034 - val_loss: 982.0664 - val_mean_absolute_error: 18.4616\n",
      "Epoch 439/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1158.7878 - mean_absolute_error: 18.4631\n",
      "Epoch 439: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.2592 - mean_absolute_error: 17.8613 - val_loss: 982.8009 - val_mean_absolute_error: 18.4891\n",
      "Epoch 440/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 611.5499 - mean_absolute_error: 14.7360\n",
      "Epoch 440: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057.6146 - mean_absolute_error: 17.6875 - val_loss: 985.5729 - val_mean_absolute_error: 18.5029\n",
      "Epoch 441/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 800.5178 - mean_absolute_error: 16.7113\n",
      "Epoch 441: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.9788 - mean_absolute_error: 17.8124 - val_loss: 980.9277 - val_mean_absolute_error: 18.4897\n",
      "Epoch 442/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 943.2623 - mean_absolute_error: 17.0775\n",
      "Epoch 442: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1090.8800 - mean_absolute_error: 17.9052 - val_loss: 986.5386 - val_mean_absolute_error: 18.5130\n",
      "Epoch 443/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1410.5259 - mean_absolute_error: 19.8475\n",
      "Epoch 443: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1144.2637 - mean_absolute_error: 18.3522 - val_loss: 980.6630 - val_mean_absolute_error: 18.4922\n",
      "Epoch 444/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 812.9379 - mean_absolute_error: 17.5971\n",
      "Epoch 444: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 957.2313 - mean_absolute_error: 17.1597 - val_loss: 982.8751 - val_mean_absolute_error: 18.5313\n",
      "Epoch 445/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1131.3591 - mean_absolute_error: 17.8452\n",
      "Epoch 445: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1109.5444 - mean_absolute_error: 18.0100 - val_loss: 987.4382 - val_mean_absolute_error: 18.4949\n",
      "Epoch 446/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 707.5170 - mean_absolute_error: 14.8505\n",
      "Epoch 446: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.3518 - mean_absolute_error: 17.8216 - val_loss: 976.0273 - val_mean_absolute_error: 18.3685\n",
      "Epoch 447/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1070.3296 - mean_absolute_error: 17.4529\n",
      "Epoch 447: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1139.4601 - mean_absolute_error: 17.8301 - val_loss: 987.7946 - val_mean_absolute_error: 18.5451\n",
      "Epoch 448/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 908.3442 - mean_absolute_error: 18.0635\n",
      "Epoch 448: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1030.4543 - mean_absolute_error: 17.5397 - val_loss: 981.5179 - val_mean_absolute_error: 18.4588\n",
      "Epoch 449/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1169.2256 - mean_absolute_error: 17.9502\n",
      "Epoch 449: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.1963 - mean_absolute_error: 17.9695 - val_loss: 980.2358 - val_mean_absolute_error: 18.4600\n",
      "Epoch 450/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 949.8138 - mean_absolute_error: 15.8969\n",
      "Epoch 450: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1037.9928 - mean_absolute_error: 17.1690 - val_loss: 978.8755 - val_mean_absolute_error: 18.4094\n",
      "Epoch 451/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1597.1273 - mean_absolute_error: 21.0750\n",
      "Epoch 451: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1172.6382 - mean_absolute_error: 18.1371 - val_loss: 985.1954 - val_mean_absolute_error: 18.5100\n",
      "Epoch 452/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1172.7634 - mean_absolute_error: 18.9914\n",
      "Epoch 452: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1068.9280 - mean_absolute_error: 17.7496 - val_loss: 980.8585 - val_mean_absolute_error: 18.4560\n",
      "Epoch 453/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1045.2772 - mean_absolute_error: 17.0161\n",
      "Epoch 453: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1132.6321 - mean_absolute_error: 17.9275 - val_loss: 986.3439 - val_mean_absolute_error: 18.4894\n",
      "Epoch 454/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 967.8208 - mean_absolute_error: 16.3259\n",
      "Epoch 454: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1096.1005 - mean_absolute_error: 17.6318 - val_loss: 978.5624 - val_mean_absolute_error: 18.4223\n",
      "Epoch 455/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1320.1146 - mean_absolute_error: 18.4243\n",
      "Epoch 455: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.6243 - mean_absolute_error: 18.0378 - val_loss: 984.1157 - val_mean_absolute_error: 18.5036\n",
      "Epoch 456/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 963.6281 - mean_absolute_error: 17.4791\n",
      "Epoch 456: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.7584 - mean_absolute_error: 17.7498 - val_loss: 981.2720 - val_mean_absolute_error: 18.3967\n",
      "Epoch 457/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1029.1316 - mean_absolute_error: 17.6306\n",
      "Epoch 457: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.9806 - mean_absolute_error: 17.9008 - val_loss: 986.8012 - val_mean_absolute_error: 18.4895\n",
      "Epoch 458/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1155.0170 - mean_absolute_error: 17.4782\n",
      "Epoch 458: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1146.7512 - mean_absolute_error: 17.6956 - val_loss: 980.1901 - val_mean_absolute_error: 18.4552\n",
      "Epoch 459/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1073.6208 - mean_absolute_error: 17.4506\n",
      "Epoch 459: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1130.8164 - mean_absolute_error: 18.0725 - val_loss: 979.8716 - val_mean_absolute_error: 18.4010\n",
      "Epoch 460/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1005.8821 - mean_absolute_error: 17.0644\n",
      "Epoch 460: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.0304 - mean_absolute_error: 17.2866 - val_loss: 979.9941 - val_mean_absolute_error: 18.4455\n",
      "Epoch 461/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1056.8083 - mean_absolute_error: 18.1145\n",
      "Epoch 461: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1101.6023 - mean_absolute_error: 17.8964 - val_loss: 985.8446 - val_mean_absolute_error: 18.5190\n",
      "Epoch 462/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1339.6016 - mean_absolute_error: 17.9253\n",
      "Epoch 462: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.7599 - mean_absolute_error: 17.2523 - val_loss: 986.2935 - val_mean_absolute_error: 18.5026\n",
      "Epoch 463/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1456.3816 - mean_absolute_error: 19.2799\n",
      "Epoch 463: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1070.1183 - mean_absolute_error: 17.5990 - val_loss: 983.6446 - val_mean_absolute_error: 18.4529\n",
      "Epoch 464/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1028.6416 - mean_absolute_error: 17.1178\n",
      "Epoch 464: val_loss did not improve from 975.40619\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.5970 - mean_absolute_error: 17.5371 - val_loss: 984.6290 - val_mean_absolute_error: 18.4661\n",
      "Epoch 465/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1378.6348 - mean_absolute_error: 20.4307\n",
      "Epoch 465: val_loss improved from 975.40619 to 973.60834, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1094.6182 - mean_absolute_error: 17.7879 - val_loss: 973.6083 - val_mean_absolute_error: 18.4106\n",
      "Epoch 466/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1564.9604 - mean_absolute_error: 18.4449\n",
      "Epoch 466: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.8540 - mean_absolute_error: 17.3766 - val_loss: 982.9952 - val_mean_absolute_error: 18.4491\n",
      "Epoch 467/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 992.8672 - mean_absolute_error: 17.5942\n",
      "Epoch 467: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1250.0704 - mean_absolute_error: 18.5804 - val_loss: 988.2966 - val_mean_absolute_error: 18.5171\n",
      "Epoch 468/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1048.8647 - mean_absolute_error: 19.2279\n",
      "Epoch 468: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1021.5358 - mean_absolute_error: 17.7204 - val_loss: 982.7060 - val_mean_absolute_error: 18.5126\n",
      "Epoch 469/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1143.6055 - mean_absolute_error: 18.2469\n",
      "Epoch 469: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.9957 - mean_absolute_error: 17.8057 - val_loss: 980.4999 - val_mean_absolute_error: 18.4706\n",
      "Epoch 470/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1040.5029 - mean_absolute_error: 18.6791\n",
      "Epoch 470: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.2155 - mean_absolute_error: 18.0386 - val_loss: 987.1370 - val_mean_absolute_error: 18.5215\n",
      "Epoch 471/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1542.4673 - mean_absolute_error: 21.2831\n",
      "Epoch 471: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.1025 - mean_absolute_error: 17.8038 - val_loss: 984.0378 - val_mean_absolute_error: 18.4568\n",
      "Epoch 472/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1452.4917 - mean_absolute_error: 19.3130\n",
      "Epoch 472: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.3322 - mean_absolute_error: 17.6818 - val_loss: 983.7318 - val_mean_absolute_error: 18.4780\n",
      "Epoch 473/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 962.9352 - mean_absolute_error: 17.4088\n",
      "Epoch 473: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1096.5973 - mean_absolute_error: 17.8985 - val_loss: 989.1989 - val_mean_absolute_error: 18.5489\n",
      "Epoch 474/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1872.1035 - mean_absolute_error: 23.1190\n",
      "Epoch 474: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.1200 - mean_absolute_error: 17.9981 - val_loss: 982.7603 - val_mean_absolute_error: 18.4565\n",
      "Epoch 475/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 652.8344 - mean_absolute_error: 14.8778\n",
      "Epoch 475: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.1525 - mean_absolute_error: 16.6800 - val_loss: 982.3316 - val_mean_absolute_error: 18.4518\n",
      "Epoch 476/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1376.9224 - mean_absolute_error: 19.4034\n",
      "Epoch 476: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1174.4559 - mean_absolute_error: 18.1968 - val_loss: 978.0271 - val_mean_absolute_error: 18.3819\n",
      "Epoch 477/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1824.4731 - mean_absolute_error: 19.6285\n",
      "Epoch 477: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1170.0640 - mean_absolute_error: 18.0326 - val_loss: 978.0073 - val_mean_absolute_error: 18.3891\n",
      "Epoch 478/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1164.4930 - mean_absolute_error: 19.1735\n",
      "Epoch 478: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1060.9648 - mean_absolute_error: 17.7729 - val_loss: 982.3392 - val_mean_absolute_error: 18.3832\n",
      "Epoch 479/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1231.0833 - mean_absolute_error: 17.6005\n",
      "Epoch 479: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.1196 - mean_absolute_error: 17.8309 - val_loss: 977.5308 - val_mean_absolute_error: 18.4132\n",
      "Epoch 480/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1711.5662 - mean_absolute_error: 22.0253\n",
      "Epoch 480: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1167.8674 - mean_absolute_error: 18.5292 - val_loss: 977.6140 - val_mean_absolute_error: 18.4114\n",
      "Epoch 481/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 895.4337 - mean_absolute_error: 16.0019\n",
      "Epoch 481: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1048.9951 - mean_absolute_error: 17.5888 - val_loss: 986.2484 - val_mean_absolute_error: 18.4545\n",
      "Epoch 482/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1062.3563 - mean_absolute_error: 16.7710\n",
      "Epoch 482: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.8879 - mean_absolute_error: 17.3582 - val_loss: 989.5160 - val_mean_absolute_error: 18.5728\n",
      "Epoch 483/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 840.3138 - mean_absolute_error: 17.3642\n",
      "Epoch 483: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1041.1138 - mean_absolute_error: 17.3728 - val_loss: 975.7899 - val_mean_absolute_error: 18.3678\n",
      "Epoch 484/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 627.5575 - mean_absolute_error: 14.5464\n",
      "Epoch 484: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1008.8892 - mean_absolute_error: 17.1779 - val_loss: 985.4581 - val_mean_absolute_error: 18.5032\n",
      "Epoch 485/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1649.8683 - mean_absolute_error: 20.9971\n",
      "Epoch 485: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1184.3260 - mean_absolute_error: 18.2232 - val_loss: 985.4042 - val_mean_absolute_error: 18.4425\n",
      "Epoch 486/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1509.1394 - mean_absolute_error: 19.5451\n",
      "Epoch 486: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1203.5508 - mean_absolute_error: 18.3794 - val_loss: 981.6520 - val_mean_absolute_error: 18.4363\n",
      "Epoch 487/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2123.6228 - mean_absolute_error: 23.7552\n",
      "Epoch 487: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1218.5878 - mean_absolute_error: 18.4830 - val_loss: 986.6755 - val_mean_absolute_error: 18.4639\n",
      "Epoch 488/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 948.0375 - mean_absolute_error: 17.3350\n",
      "Epoch 488: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1097.1600 - mean_absolute_error: 17.8576 - val_loss: 984.1169 - val_mean_absolute_error: 18.5197\n",
      "Epoch 489/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1188.6510 - mean_absolute_error: 18.8057\n",
      "Epoch 489: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.6309 - mean_absolute_error: 17.7148 - val_loss: 987.2108 - val_mean_absolute_error: 18.4945\n",
      "Epoch 490/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 804.3204 - mean_absolute_error: 16.0781\n",
      "Epoch 490: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1034.8837 - mean_absolute_error: 17.5160 - val_loss: 978.3492 - val_mean_absolute_error: 18.3385\n",
      "Epoch 491/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1389.7817 - mean_absolute_error: 20.6281\n",
      "Epoch 491: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1164.2029 - mean_absolute_error: 18.3364 - val_loss: 985.9968 - val_mean_absolute_error: 18.5549\n",
      "Epoch 492/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1041.4358 - mean_absolute_error: 17.1952\n",
      "Epoch 492: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1067.4818 - mean_absolute_error: 17.5502 - val_loss: 985.5427 - val_mean_absolute_error: 18.4526\n",
      "Epoch 493/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 682.2215 - mean_absolute_error: 14.2961\n",
      "Epoch 493: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.2272 - mean_absolute_error: 17.3957 - val_loss: 976.9487 - val_mean_absolute_error: 18.3677\n",
      "Epoch 494/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1465.5592 - mean_absolute_error: 19.0489\n",
      "Epoch 494: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.0907 - mean_absolute_error: 17.5987 - val_loss: 983.4382 - val_mean_absolute_error: 18.4758\n",
      "Epoch 495/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1674.5667 - mean_absolute_error: 22.1912\n",
      "Epoch 495: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.4650 - mean_absolute_error: 18.3937 - val_loss: 980.7449 - val_mean_absolute_error: 18.4414\n",
      "Epoch 496/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 795.2847 - mean_absolute_error: 15.8248\n",
      "Epoch 496: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1019.3093 - mean_absolute_error: 17.2125 - val_loss: 985.7195 - val_mean_absolute_error: 18.5160\n",
      "Epoch 497/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 871.8708 - mean_absolute_error: 17.6495\n",
      "Epoch 497: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.8589 - mean_absolute_error: 17.6816 - val_loss: 985.6981 - val_mean_absolute_error: 18.4521\n",
      "Epoch 498/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1296.9792 - mean_absolute_error: 18.6274\n",
      "Epoch 498: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1186.2198 - mean_absolute_error: 17.8872 - val_loss: 982.4887 - val_mean_absolute_error: 18.4806\n",
      "Epoch 499/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1127.7173 - mean_absolute_error: 17.3311\n",
      "Epoch 499: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1013.8539 - mean_absolute_error: 17.2176 - val_loss: 974.2997 - val_mean_absolute_error: 18.3378\n",
      "Epoch 500/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1028.3230 - mean_absolute_error: 19.4658\n",
      "Epoch 500: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.2207 - mean_absolute_error: 17.8340 - val_loss: 993.1136 - val_mean_absolute_error: 18.5479\n",
      "Epoch 501/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 938.8732 - mean_absolute_error: 18.3351\n",
      "Epoch 501: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1203.8793 - mean_absolute_error: 18.3268 - val_loss: 986.2043 - val_mean_absolute_error: 18.4867\n",
      "Epoch 502/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1242.4329 - mean_absolute_error: 19.6663\n",
      "Epoch 502: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.8998 - mean_absolute_error: 18.0849 - val_loss: 985.8547 - val_mean_absolute_error: 18.4798\n",
      "Epoch 503/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 511.6928 - mean_absolute_error: 13.8368\n",
      "Epoch 503: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 977.3998 - mean_absolute_error: 16.9587 - val_loss: 984.6107 - val_mean_absolute_error: 18.4591\n",
      "Epoch 504/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 867.2893 - mean_absolute_error: 16.6449\n",
      "Epoch 504: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.6824 - mean_absolute_error: 17.8130 - val_loss: 979.4077 - val_mean_absolute_error: 18.4105\n",
      "Epoch 505/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1446.0519 - mean_absolute_error: 20.6174\n",
      "Epoch 505: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1092.8184 - mean_absolute_error: 17.9051 - val_loss: 983.9825 - val_mean_absolute_error: 18.4134\n",
      "Epoch 506/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 516.2201 - mean_absolute_error: 12.8701\n",
      "Epoch 506: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 988.8308 - mean_absolute_error: 16.9263 - val_loss: 990.0749 - val_mean_absolute_error: 18.5302\n",
      "Epoch 507/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1168.1436 - mean_absolute_error: 19.3739\n",
      "Epoch 507: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.4886 - mean_absolute_error: 17.5453 - val_loss: 981.0273 - val_mean_absolute_error: 18.4339\n",
      "Epoch 508/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 991.0985 - mean_absolute_error: 18.2315\n",
      "Epoch 508: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.9132 - mean_absolute_error: 17.5388 - val_loss: 989.5872 - val_mean_absolute_error: 18.6139\n",
      "Epoch 509/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 961.9624 - mean_absolute_error: 16.7507\n",
      "Epoch 509: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1163.7561 - mean_absolute_error: 18.2222 - val_loss: 979.2732 - val_mean_absolute_error: 18.4209\n",
      "Epoch 510/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1731.7019 - mean_absolute_error: 18.8187\n",
      "Epoch 510: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1175.5967 - mean_absolute_error: 17.8635 - val_loss: 983.4601 - val_mean_absolute_error: 18.4476\n",
      "Epoch 511/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1245.9138 - mean_absolute_error: 18.1172\n",
      "Epoch 511: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1116.6115 - mean_absolute_error: 17.8189 - val_loss: 975.9813 - val_mean_absolute_error: 18.3552\n",
      "Epoch 512/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 518.6999 - mean_absolute_error: 13.9820\n",
      "Epoch 512: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.6161 - mean_absolute_error: 17.6251 - val_loss: 983.7817 - val_mean_absolute_error: 18.4385\n",
      "Epoch 513/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1283.6008 - mean_absolute_error: 18.3656\n",
      "Epoch 513: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1203.9366 - mean_absolute_error: 18.2840 - val_loss: 982.7894 - val_mean_absolute_error: 18.4340\n",
      "Epoch 514/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 986.0818 - mean_absolute_error: 18.0835\n",
      "Epoch 514: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1103.8734 - mean_absolute_error: 17.9800 - val_loss: 986.9003 - val_mean_absolute_error: 18.4237\n",
      "Epoch 515/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1228.0609 - mean_absolute_error: 18.7453\n",
      "Epoch 515: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1075.6560 - mean_absolute_error: 17.6423 - val_loss: 977.6733 - val_mean_absolute_error: 18.4233\n",
      "Epoch 516/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1302.4229 - mean_absolute_error: 20.2381\n",
      "Epoch 516: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.0878 - mean_absolute_error: 17.8520 - val_loss: 985.9482 - val_mean_absolute_error: 18.4807\n",
      "Epoch 517/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1148.8817 - mean_absolute_error: 18.7078\n",
      "Epoch 517: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.4075 - mean_absolute_error: 17.9402 - val_loss: 981.2293 - val_mean_absolute_error: 18.3966\n",
      "Epoch 518/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 525.9018 - mean_absolute_error: 14.1362\n",
      "Epoch 518: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.5247 - mean_absolute_error: 17.9281 - val_loss: 978.2189 - val_mean_absolute_error: 18.3994\n",
      "Epoch 519/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1156.7806 - mean_absolute_error: 18.9931\n",
      "Epoch 519: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1200.5035 - mean_absolute_error: 18.4196 - val_loss: 984.3281 - val_mean_absolute_error: 18.4433\n",
      "Epoch 520/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1315.9150 - mean_absolute_error: 20.0723\n",
      "Epoch 520: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.1829 - mean_absolute_error: 17.9893 - val_loss: 979.4208 - val_mean_absolute_error: 18.4063\n",
      "Epoch 521/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2034.4741 - mean_absolute_error: 24.3244\n",
      "Epoch 521: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1240.4541 - mean_absolute_error: 18.6967 - val_loss: 982.8735 - val_mean_absolute_error: 18.4319\n",
      "Epoch 522/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 667.9935 - mean_absolute_error: 15.0236\n",
      "Epoch 522: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.4080 - mean_absolute_error: 17.8892 - val_loss: 981.7714 - val_mean_absolute_error: 18.4663\n",
      "Epoch 523/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 744.8608 - mean_absolute_error: 15.7642\n",
      "Epoch 523: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 995.0832 - mean_absolute_error: 17.0897 - val_loss: 980.7089 - val_mean_absolute_error: 18.3788\n",
      "Epoch 524/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1579.4531 - mean_absolute_error: 17.8010\n",
      "Epoch 524: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1175.0006 - mean_absolute_error: 18.1235 - val_loss: 979.4327 - val_mean_absolute_error: 18.4376\n",
      "Epoch 525/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1302.7241 - mean_absolute_error: 16.8905\n",
      "Epoch 525: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.1746 - mean_absolute_error: 17.9043 - val_loss: 985.1262 - val_mean_absolute_error: 18.4411\n",
      "Epoch 526/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1159.7979 - mean_absolute_error: 18.7742\n",
      "Epoch 526: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.9250 - mean_absolute_error: 18.2299 - val_loss: 982.2469 - val_mean_absolute_error: 18.3791\n",
      "Epoch 527/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 863.5443 - mean_absolute_error: 16.6792\n",
      "Epoch 527: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.3417 - mean_absolute_error: 17.8070 - val_loss: 983.0220 - val_mean_absolute_error: 18.3809\n",
      "Epoch 528/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1274.9697 - mean_absolute_error: 20.5499\n",
      "Epoch 528: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.4097 - mean_absolute_error: 18.1481 - val_loss: 977.9282 - val_mean_absolute_error: 18.3662\n",
      "Epoch 529/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 931.2261 - mean_absolute_error: 17.3884\n",
      "Epoch 529: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.2332 - mean_absolute_error: 18.2036 - val_loss: 979.8715 - val_mean_absolute_error: 18.4108\n",
      "Epoch 530/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 978.1505 - mean_absolute_error: 16.6106\n",
      "Epoch 530: val_loss did not improve from 973.60834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1150.0115 - mean_absolute_error: 17.9322 - val_loss: 981.1589 - val_mean_absolute_error: 18.4221\n",
      "Epoch 531/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 732.2157 - mean_absolute_error: 15.0506\n",
      "Epoch 531: val_loss improved from 973.60834 to 971.60461, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1080.9409 - mean_absolute_error: 17.3062 - val_loss: 971.6046 - val_mean_absolute_error: 18.3271\n",
      "Epoch 532/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 846.9712 - mean_absolute_error: 16.3577\n",
      "Epoch 532: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.1736 - mean_absolute_error: 18.3381 - val_loss: 977.8616 - val_mean_absolute_error: 18.3727\n",
      "Epoch 533/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1287.4253 - mean_absolute_error: 18.5419\n",
      "Epoch 533: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.7333 - mean_absolute_error: 18.0526 - val_loss: 982.8683 - val_mean_absolute_error: 18.3657\n",
      "Epoch 534/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1907.4971 - mean_absolute_error: 20.2942\n",
      "Epoch 534: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260.7231 - mean_absolute_error: 18.5698 - val_loss: 973.2704 - val_mean_absolute_error: 18.3248\n",
      "Epoch 535/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1240.5297 - mean_absolute_error: 17.8114\n",
      "Epoch 535: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.1160 - mean_absolute_error: 17.9059 - val_loss: 979.3549 - val_mean_absolute_error: 18.3823\n",
      "Epoch 536/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 974.4431 - mean_absolute_error: 18.6414\n",
      "Epoch 536: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1111.1667 - mean_absolute_error: 18.0662 - val_loss: 987.5854 - val_mean_absolute_error: 18.4558\n",
      "Epoch 537/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 879.5076 - mean_absolute_error: 18.0463\n",
      "Epoch 537: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.1434 - mean_absolute_error: 18.0779 - val_loss: 976.4897 - val_mean_absolute_error: 18.4013\n",
      "Epoch 538/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1041.0396 - mean_absolute_error: 17.2929\n",
      "Epoch 538: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.2893 - mean_absolute_error: 18.1643 - val_loss: 977.4582 - val_mean_absolute_error: 18.3631\n",
      "Epoch 539/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1237.9961 - mean_absolute_error: 17.4082\n",
      "Epoch 539: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1083.7990 - mean_absolute_error: 17.5289 - val_loss: 988.7531 - val_mean_absolute_error: 18.4708\n",
      "Epoch 540/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 747.0735 - mean_absolute_error: 15.0213\n",
      "Epoch 540: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.8823 - mean_absolute_error: 17.2717 - val_loss: 981.9590 - val_mean_absolute_error: 18.4099\n",
      "Epoch 541/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 809.4678 - mean_absolute_error: 14.5132\n",
      "Epoch 541: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.2018 - mean_absolute_error: 17.3189 - val_loss: 982.7557 - val_mean_absolute_error: 18.4042\n",
      "Epoch 542/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1204.9955 - mean_absolute_error: 18.0856\n",
      "Epoch 542: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1127.7751 - mean_absolute_error: 18.0227 - val_loss: 977.3403 - val_mean_absolute_error: 18.3913\n",
      "Epoch 543/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 675.1546 - mean_absolute_error: 14.0284\n",
      "Epoch 543: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1014.8386 - mean_absolute_error: 17.0669 - val_loss: 980.0829 - val_mean_absolute_error: 18.3390\n",
      "Epoch 544/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1865.9148 - mean_absolute_error: 22.9217\n",
      "Epoch 544: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.7555 - mean_absolute_error: 18.0258 - val_loss: 983.8267 - val_mean_absolute_error: 18.4460\n",
      "Epoch 545/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 963.9876 - mean_absolute_error: 16.5216\n",
      "Epoch 545: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1043.9025 - mean_absolute_error: 17.3317 - val_loss: 980.4789 - val_mean_absolute_error: 18.3519\n",
      "Epoch 546/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 971.1960 - mean_absolute_error: 17.0219\n",
      "Epoch 546: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.7854 - mean_absolute_error: 17.6987 - val_loss: 979.0558 - val_mean_absolute_error: 18.4500\n",
      "Epoch 547/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1227.1504 - mean_absolute_error: 17.2933\n",
      "Epoch 547: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1088.1016 - mean_absolute_error: 17.6572 - val_loss: 977.6285 - val_mean_absolute_error: 18.3786\n",
      "Epoch 548/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 680.5917 - mean_absolute_error: 16.4931\n",
      "Epoch 548: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.9033 - mean_absolute_error: 17.6436 - val_loss: 983.9300 - val_mean_absolute_error: 18.4029\n",
      "Epoch 549/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1288.5225 - mean_absolute_error: 19.7530\n",
      "Epoch 549: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.0592 - mean_absolute_error: 17.8862 - val_loss: 977.1214 - val_mean_absolute_error: 18.3523\n",
      "Epoch 550/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1001.7529 - mean_absolute_error: 18.2134\n",
      "Epoch 550: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1145.4570 - mean_absolute_error: 18.1745 - val_loss: 980.3144 - val_mean_absolute_error: 18.4141\n",
      "Epoch 551/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1166.0773 - mean_absolute_error: 18.7513\n",
      "Epoch 551: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1032.4506 - mean_absolute_error: 17.5278 - val_loss: 979.8398 - val_mean_absolute_error: 18.3398\n",
      "Epoch 552/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 874.4797 - mean_absolute_error: 13.2541\n",
      "Epoch 552: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1060.9026 - mean_absolute_error: 17.0136 - val_loss: 979.7858 - val_mean_absolute_error: 18.3539\n",
      "Epoch 553/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1583.8861 - mean_absolute_error: 20.7364\n",
      "Epoch 553: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1142.5114 - mean_absolute_error: 18.1195 - val_loss: 980.2632 - val_mean_absolute_error: 18.5114\n",
      "Epoch 554/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1132.5034 - mean_absolute_error: 18.8455\n",
      "Epoch 554: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.7759 - mean_absolute_error: 18.3286 - val_loss: 978.9462 - val_mean_absolute_error: 18.3646\n",
      "Epoch 555/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1191.0945 - mean_absolute_error: 17.1043\n",
      "Epoch 555: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.7015 - mean_absolute_error: 17.8339 - val_loss: 983.8690 - val_mean_absolute_error: 18.3392\n",
      "Epoch 556/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1096.3729 - mean_absolute_error: 16.1256\n",
      "Epoch 556: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.7218 - mean_absolute_error: 17.4344 - val_loss: 974.7448 - val_mean_absolute_error: 18.2655\n",
      "Epoch 557/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 876.4745 - mean_absolute_error: 16.2765\n",
      "Epoch 557: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.0028 - mean_absolute_error: 17.9502 - val_loss: 982.0284 - val_mean_absolute_error: 18.4230\n",
      "Epoch 558/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1006.3142 - mean_absolute_error: 17.9418\n",
      "Epoch 558: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1150.3668 - mean_absolute_error: 17.8747 - val_loss: 984.7816 - val_mean_absolute_error: 18.4326\n",
      "Epoch 559/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1647.7958 - mean_absolute_error: 19.8245\n",
      "Epoch 559: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.2694 - mean_absolute_error: 17.3211 - val_loss: 983.2938 - val_mean_absolute_error: 18.3992\n",
      "Epoch 560/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1042.8552 - mean_absolute_error: 18.3029\n",
      "Epoch 560: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.2365 - mean_absolute_error: 17.8975 - val_loss: 980.5870 - val_mean_absolute_error: 18.3736\n",
      "Epoch 561/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1332.5208 - mean_absolute_error: 21.3349\n",
      "Epoch 561: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.7576 - mean_absolute_error: 17.6603 - val_loss: 976.5665 - val_mean_absolute_error: 18.3851\n",
      "Epoch 562/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1259.6494 - mean_absolute_error: 17.7429\n",
      "Epoch 562: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1080.7393 - mean_absolute_error: 17.4824 - val_loss: 985.0949 - val_mean_absolute_error: 18.3587\n",
      "Epoch 563/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 545.3058 - mean_absolute_error: 13.7259\n",
      "Epoch 563: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.9960 - mean_absolute_error: 17.2099 - val_loss: 985.6552 - val_mean_absolute_error: 18.3757\n",
      "Epoch 564/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1073.0601 - mean_absolute_error: 17.3969\n",
      "Epoch 564: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.1162 - mean_absolute_error: 17.9406 - val_loss: 976.5391 - val_mean_absolute_error: 18.3539\n",
      "Epoch 565/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1005.5715 - mean_absolute_error: 15.9187\n",
      "Epoch 565: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1129.8053 - mean_absolute_error: 17.9139 - val_loss: 982.1114 - val_mean_absolute_error: 18.4184\n",
      "Epoch 566/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1305.8691 - mean_absolute_error: 19.5760\n",
      "Epoch 566: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1165.5503 - mean_absolute_error: 18.1153 - val_loss: 979.5964 - val_mean_absolute_error: 18.4266\n",
      "Epoch 567/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1153.4883 - mean_absolute_error: 19.5231\n",
      "Epoch 567: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.6620 - mean_absolute_error: 17.8386 - val_loss: 978.3203 - val_mean_absolute_error: 18.3208\n",
      "Epoch 568/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1141.2146 - mean_absolute_error: 17.4507\n",
      "Epoch 568: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.1693 - mean_absolute_error: 17.7762 - val_loss: 982.8672 - val_mean_absolute_error: 18.4329\n",
      "Epoch 569/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 643.3880 - mean_absolute_error: 13.9083\n",
      "Epoch 569: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.9423 - mean_absolute_error: 17.6991 - val_loss: 972.8104 - val_mean_absolute_error: 18.2755\n",
      "Epoch 570/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 910.2836 - mean_absolute_error: 15.6869\n",
      "Epoch 570: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.7280 - mean_absolute_error: 17.5775 - val_loss: 980.4650 - val_mean_absolute_error: 18.3538\n",
      "Epoch 571/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 591.2222 - mean_absolute_error: 15.1120\n",
      "Epoch 571: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 995.2733 - mean_absolute_error: 17.0203 - val_loss: 982.1810 - val_mean_absolute_error: 18.4318\n",
      "Epoch 572/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 761.4667 - mean_absolute_error: 13.9613\n",
      "Epoch 572: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1006.9175 - mean_absolute_error: 16.9144 - val_loss: 977.4942 - val_mean_absolute_error: 18.3851\n",
      "Epoch 573/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 839.7955 - mean_absolute_error: 15.5619\n",
      "Epoch 573: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1035.4976 - mean_absolute_error: 17.3207 - val_loss: 980.1823 - val_mean_absolute_error: 18.4179\n",
      "Epoch 574/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1104.9707 - mean_absolute_error: 19.0970\n",
      "Epoch 574: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1080.9008 - mean_absolute_error: 17.8668 - val_loss: 979.1814 - val_mean_absolute_error: 18.3601\n",
      "Epoch 575/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1399.3591 - mean_absolute_error: 17.8222\n",
      "Epoch 575: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1194.2565 - mean_absolute_error: 18.0788 - val_loss: 977.4095 - val_mean_absolute_error: 18.3295\n",
      "Epoch 576/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 953.6420 - mean_absolute_error: 17.5574\n",
      "Epoch 576: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1094.5947 - mean_absolute_error: 17.7574 - val_loss: 979.0997 - val_mean_absolute_error: 18.3397\n",
      "Epoch 577/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 922.3824 - mean_absolute_error: 17.1237\n",
      "Epoch 577: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.3628 - mean_absolute_error: 17.6205 - val_loss: 980.2534 - val_mean_absolute_error: 18.3755\n",
      "Epoch 578/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1096.8428 - mean_absolute_error: 18.2355\n",
      "Epoch 578: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1050.3226 - mean_absolute_error: 17.5041 - val_loss: 985.0698 - val_mean_absolute_error: 18.4557\n",
      "Epoch 579/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1386.6044 - mean_absolute_error: 19.4759\n",
      "Epoch 579: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1066.1616 - mean_absolute_error: 17.3849 - val_loss: 977.2026 - val_mean_absolute_error: 18.3056\n",
      "Epoch 580/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 680.2412 - mean_absolute_error: 14.5376\n",
      "Epoch 580: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1035.1346 - mean_absolute_error: 17.2399 - val_loss: 977.2730 - val_mean_absolute_error: 18.3484\n",
      "Epoch 581/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1390.9155 - mean_absolute_error: 17.4092\n",
      "Epoch 581: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.2875 - mean_absolute_error: 17.7972 - val_loss: 979.4230 - val_mean_absolute_error: 18.3923\n",
      "Epoch 582/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1798.8286 - mean_absolute_error: 21.9458\n",
      "Epoch 582: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.7241 - mean_absolute_error: 17.8612 - val_loss: 977.7976 - val_mean_absolute_error: 18.3697\n",
      "Epoch 583/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 750.9888 - mean_absolute_error: 15.9975\n",
      "Epoch 583: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1003.1345 - mean_absolute_error: 17.3566 - val_loss: 979.5419 - val_mean_absolute_error: 18.3991\n",
      "Epoch 584/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1661.4946 - mean_absolute_error: 20.7918\n",
      "Epoch 584: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.0087 - mean_absolute_error: 18.0864 - val_loss: 982.6931 - val_mean_absolute_error: 18.3203\n",
      "Epoch 585/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1171.4146 - mean_absolute_error: 18.5118\n",
      "Epoch 585: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1170.3723 - mean_absolute_error: 18.1945 - val_loss: 983.7500 - val_mean_absolute_error: 18.4430\n",
      "Epoch 586/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 856.6471 - mean_absolute_error: 16.0296\n",
      "Epoch 586: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1010.6924 - mean_absolute_error: 17.3171 - val_loss: 975.7772 - val_mean_absolute_error: 18.3198\n",
      "Epoch 587/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 773.9340 - mean_absolute_error: 15.3254\n",
      "Epoch 587: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1043.4644 - mean_absolute_error: 17.2785 - val_loss: 980.7122 - val_mean_absolute_error: 18.3932\n",
      "Epoch 588/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1057.8721 - mean_absolute_error: 17.9875\n",
      "Epoch 588: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1172.1436 - mean_absolute_error: 18.2629 - val_loss: 980.0433 - val_mean_absolute_error: 18.3576\n",
      "Epoch 589/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 811.2120 - mean_absolute_error: 16.3523\n",
      "Epoch 589: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.8027 - mean_absolute_error: 17.9297 - val_loss: 978.4297 - val_mean_absolute_error: 18.3904\n",
      "Epoch 590/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1330.0593 - mean_absolute_error: 19.2788\n",
      "Epoch 590: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1089.7467 - mean_absolute_error: 17.6523 - val_loss: 975.0452 - val_mean_absolute_error: 18.3242\n",
      "Epoch 591/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 742.8703 - mean_absolute_error: 14.9290\n",
      "Epoch 591: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1060.8695 - mean_absolute_error: 17.3262 - val_loss: 983.2200 - val_mean_absolute_error: 18.4214\n",
      "Epoch 592/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1153.8212 - mean_absolute_error: 18.8582\n",
      "Epoch 592: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.6241 - mean_absolute_error: 18.4374 - val_loss: 978.7102 - val_mean_absolute_error: 18.3930\n",
      "Epoch 593/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 592.8407 - mean_absolute_error: 13.4860\n",
      "Epoch 593: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1099.7196 - mean_absolute_error: 17.3021 - val_loss: 977.4146 - val_mean_absolute_error: 18.3644\n",
      "Epoch 594/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1126.2274 - mean_absolute_error: 17.1199\n",
      "Epoch 594: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.2476 - mean_absolute_error: 17.6746 - val_loss: 978.4973 - val_mean_absolute_error: 18.3081\n",
      "Epoch 595/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1110.5139 - mean_absolute_error: 18.0079\n",
      "Epoch 595: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.1537 - mean_absolute_error: 17.5380 - val_loss: 980.2568 - val_mean_absolute_error: 18.3825\n",
      "Epoch 596/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1783.6956 - mean_absolute_error: 20.9296\n",
      "Epoch 596: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1092.2828 - mean_absolute_error: 17.6671 - val_loss: 982.7794 - val_mean_absolute_error: 18.3627\n",
      "Epoch 597/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1007.0887 - mean_absolute_error: 16.6111\n",
      "Epoch 597: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.1349 - mean_absolute_error: 17.7996 - val_loss: 981.4791 - val_mean_absolute_error: 18.3318\n",
      "Epoch 598/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1345.3182 - mean_absolute_error: 19.3650\n",
      "Epoch 598: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1148.1244 - mean_absolute_error: 18.2006 - val_loss: 980.8967 - val_mean_absolute_error: 18.4091\n",
      "Epoch 599/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1091.4016 - mean_absolute_error: 17.3128\n",
      "Epoch 599: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1051.1462 - mean_absolute_error: 17.6404 - val_loss: 975.1761 - val_mean_absolute_error: 18.2840\n",
      "Epoch 600/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 922.7758 - mean_absolute_error: 17.2747\n",
      "Epoch 600: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.1924 - mean_absolute_error: 17.8105 - val_loss: 979.4225 - val_mean_absolute_error: 18.3696\n",
      "Epoch 601/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 629.9864 - mean_absolute_error: 14.3065\n",
      "Epoch 601: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.0629 - mean_absolute_error: 17.5607 - val_loss: 974.6038 - val_mean_absolute_error: 18.2527\n",
      "Epoch 602/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 918.4421 - mean_absolute_error: 17.1049\n",
      "Epoch 602: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1202.2854 - mean_absolute_error: 18.3229 - val_loss: 986.3403 - val_mean_absolute_error: 18.4908\n",
      "Epoch 603/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1103.3608 - mean_absolute_error: 17.3761\n",
      "Epoch 603: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.2714 - mean_absolute_error: 17.6440 - val_loss: 978.4083 - val_mean_absolute_error: 18.3193\n",
      "Epoch 604/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 780.3609 - mean_absolute_error: 15.2972\n",
      "Epoch 604: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.7996 - mean_absolute_error: 17.5648 - val_loss: 979.6580 - val_mean_absolute_error: 18.3358\n",
      "Epoch 605/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1095.3986 - mean_absolute_error: 18.0962\n",
      "Epoch 605: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.5411 - mean_absolute_error: 17.6125 - val_loss: 978.0880 - val_mean_absolute_error: 18.3307\n",
      "Epoch 606/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 996.6816 - mean_absolute_error: 16.2610\n",
      "Epoch 606: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 998.9882 - mean_absolute_error: 17.2406 - val_loss: 971.7386 - val_mean_absolute_error: 18.2769\n",
      "Epoch 607/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1827.3943 - mean_absolute_error: 21.0906\n",
      "Epoch 607: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1077.0707 - mean_absolute_error: 17.4683 - val_loss: 985.1668 - val_mean_absolute_error: 18.3499\n",
      "Epoch 608/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1740.8164 - mean_absolute_error: 19.3989\n",
      "Epoch 608: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1196.1768 - mean_absolute_error: 18.2505 - val_loss: 978.1716 - val_mean_absolute_error: 18.3207\n",
      "Epoch 609/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 870.3036 - mean_absolute_error: 16.6619\n",
      "Epoch 609: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1092.0450 - mean_absolute_error: 17.7900 - val_loss: 980.7662 - val_mean_absolute_error: 18.3699\n",
      "Epoch 610/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 697.4158 - mean_absolute_error: 14.7651\n",
      "Epoch 610: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.8547 - mean_absolute_error: 17.7570 - val_loss: 979.5937 - val_mean_absolute_error: 18.3281\n",
      "Epoch 611/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1152.3516 - mean_absolute_error: 19.1055\n",
      "Epoch 611: val_loss did not improve from 971.60461\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.8821 - mean_absolute_error: 18.0861 - val_loss: 981.0184 - val_mean_absolute_error: 18.3450\n",
      "Epoch 612/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 943.9546 - mean_absolute_error: 18.0496\n",
      "Epoch 612: val_loss improved from 971.60461 to 970.01288, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1179.8311 - mean_absolute_error: 18.3322 - val_loss: 970.0129 - val_mean_absolute_error: 18.2604\n",
      "Epoch 613/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1205.7434 - mean_absolute_error: 18.7607\n",
      "Epoch 613: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1078.6069 - mean_absolute_error: 17.8745 - val_loss: 982.2366 - val_mean_absolute_error: 18.3552\n",
      "Epoch 614/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1243.5308 - mean_absolute_error: 16.1720\n",
      "Epoch 614: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1131.8293 - mean_absolute_error: 17.6501 - val_loss: 977.4527 - val_mean_absolute_error: 18.3578\n",
      "Epoch 615/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1104.1082 - mean_absolute_error: 19.6280\n",
      "Epoch 615: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.3152 - mean_absolute_error: 18.0364 - val_loss: 984.7637 - val_mean_absolute_error: 18.4757\n",
      "Epoch 616/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1244.8218 - mean_absolute_error: 16.7173\n",
      "Epoch 616: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.0348 - mean_absolute_error: 17.5769 - val_loss: 974.9017 - val_mean_absolute_error: 18.2376\n",
      "Epoch 617/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 735.3928 - mean_absolute_error: 15.7744\n",
      "Epoch 617: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1061.6016 - mean_absolute_error: 17.5548 - val_loss: 986.0118 - val_mean_absolute_error: 18.4360\n",
      "Epoch 618/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1471.0388 - mean_absolute_error: 16.9336\n",
      "Epoch 618: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.3145 - mean_absolute_error: 17.9618 - val_loss: 983.3676 - val_mean_absolute_error: 18.3574\n",
      "Epoch 619/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 585.7764 - mean_absolute_error: 14.5807\n",
      "Epoch 619: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1097.0894 - mean_absolute_error: 17.9172 - val_loss: 983.7558 - val_mean_absolute_error: 18.4279\n",
      "Epoch 620/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 586.0513 - mean_absolute_error: 14.3716\n",
      "Epoch 620: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1115.0604 - mean_absolute_error: 17.8351 - val_loss: 973.6747 - val_mean_absolute_error: 18.3018\n",
      "Epoch 621/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1951.6995 - mean_absolute_error: 20.5164\n",
      "Epoch 621: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.1339 - mean_absolute_error: 17.6224 - val_loss: 984.1141 - val_mean_absolute_error: 18.3590\n",
      "Epoch 622/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1225.1228 - mean_absolute_error: 19.4986\n",
      "Epoch 622: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.8064 - mean_absolute_error: 17.7273 - val_loss: 983.7512 - val_mean_absolute_error: 18.4457\n",
      "Epoch 623/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1967.8173 - mean_absolute_error: 24.1738\n",
      "Epoch 623: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1247.2454 - mean_absolute_error: 18.7300 - val_loss: 982.7659 - val_mean_absolute_error: 18.4002\n",
      "Epoch 624/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1796.0264 - mean_absolute_error: 22.1040\n",
      "Epoch 624: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1165.3179 - mean_absolute_error: 17.9421 - val_loss: 984.3163 - val_mean_absolute_error: 18.3731\n",
      "Epoch 625/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1309.3501 - mean_absolute_error: 18.7420\n",
      "Epoch 625: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1138.0834 - mean_absolute_error: 18.2164 - val_loss: 977.3521 - val_mean_absolute_error: 18.2894\n",
      "Epoch 626/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1614.2701 - mean_absolute_error: 22.6118\n",
      "Epoch 626: val_loss did not improve from 970.01288\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1173.6337 - mean_absolute_error: 18.2229 - val_loss: 980.5716 - val_mean_absolute_error: 18.4021\n",
      "Epoch 627/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1998.3931 - mean_absolute_error: 20.9724\n",
      "Epoch 627: val_loss improved from 970.01288 to 968.84967, saving model to checkpoints.model7.keras\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1168.6440 - mean_absolute_error: 17.8662 - val_loss: 968.8497 - val_mean_absolute_error: 18.2155\n",
      "Epoch 628/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1112.1290 - mean_absolute_error: 19.6932\n",
      "Epoch 628: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1111.7751 - mean_absolute_error: 17.9629 - val_loss: 977.6882 - val_mean_absolute_error: 18.3042\n",
      "Epoch 629/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 772.6542 - mean_absolute_error: 16.1161\n",
      "Epoch 629: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.9071 - mean_absolute_error: 17.6556 - val_loss: 978.1058 - val_mean_absolute_error: 18.3420\n",
      "Epoch 630/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1939.2356 - mean_absolute_error: 21.3426\n",
      "Epoch 630: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1146.2036 - mean_absolute_error: 17.9233 - val_loss: 977.5134 - val_mean_absolute_error: 18.3086\n",
      "Epoch 631/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1413.8851 - mean_absolute_error: 20.2926\n",
      "Epoch 631: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1169.4752 - mean_absolute_error: 18.3082 - val_loss: 975.7454 - val_mean_absolute_error: 18.2735\n",
      "Epoch 632/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1117.4185 - mean_absolute_error: 19.0164\n",
      "Epoch 632: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.6847 - mean_absolute_error: 17.6978 - val_loss: 981.8309 - val_mean_absolute_error: 18.3149\n",
      "Epoch 633/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 974.1818 - mean_absolute_error: 17.4051\n",
      "Epoch 633: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1093.5122 - mean_absolute_error: 17.6488 - val_loss: 974.5851 - val_mean_absolute_error: 18.3370\n",
      "Epoch 634/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 857.2368 - mean_absolute_error: 17.5521\n",
      "Epoch 634: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1062.6230 - mean_absolute_error: 17.5624 - val_loss: 983.2104 - val_mean_absolute_error: 18.4316\n",
      "Epoch 635/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 920.3513 - mean_absolute_error: 17.5178\n",
      "Epoch 635: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.1384 - mean_absolute_error: 17.8781 - val_loss: 968.9761 - val_mean_absolute_error: 18.2101\n",
      "Epoch 636/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1341.0334 - mean_absolute_error: 19.3186\n",
      "Epoch 636: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1169.0432 - mean_absolute_error: 18.0954 - val_loss: 983.6288 - val_mean_absolute_error: 18.3234\n",
      "Epoch 637/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 977.5781 - mean_absolute_error: 16.3093\n",
      "Epoch 637: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.4121 - mean_absolute_error: 17.6244 - val_loss: 979.3581 - val_mean_absolute_error: 18.3756\n",
      "Epoch 638/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 913.8646 - mean_absolute_error: 17.4921\n",
      "Epoch 638: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1015.2206 - mean_absolute_error: 17.4465 - val_loss: 981.4722 - val_mean_absolute_error: 18.3830\n",
      "Epoch 639/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1122.6345 - mean_absolute_error: 18.0758\n",
      "Epoch 639: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233.8075 - mean_absolute_error: 18.3873 - val_loss: 981.1477 - val_mean_absolute_error: 18.4247\n",
      "Epoch 640/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 909.5489 - mean_absolute_error: 18.5316\n",
      "Epoch 640: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.8330 - mean_absolute_error: 17.6750 - val_loss: 978.6063 - val_mean_absolute_error: 18.2987\n",
      "Epoch 641/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1110.3900 - mean_absolute_error: 18.6893\n",
      "Epoch 641: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1103.9080 - mean_absolute_error: 17.9052 - val_loss: 978.1196 - val_mean_absolute_error: 18.3625\n",
      "Epoch 642/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 746.3371 - mean_absolute_error: 14.6561\n",
      "Epoch 642: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.0389 - mean_absolute_error: 17.8410 - val_loss: 982.5195 - val_mean_absolute_error: 18.3559\n",
      "Epoch 643/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1444.3552 - mean_absolute_error: 20.2629\n",
      "Epoch 643: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.3666 - mean_absolute_error: 18.1274 - val_loss: 973.4379 - val_mean_absolute_error: 18.2594\n",
      "Epoch 644/1500\n",
      "\u001b[1m20/33\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1074.9438 - mean_absolute_error: 17.1852 \n",
      "Epoch 644: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1085.8961 - mean_absolute_error: 17.3891 - val_loss: 977.0519 - val_mean_absolute_error: 18.2949\n",
      "Epoch 645/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1666.3313 - mean_absolute_error: 18.8091\n",
      "Epoch 645: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1092.3259 - mean_absolute_error: 17.4222 - val_loss: 977.6567 - val_mean_absolute_error: 18.3063\n",
      "Epoch 646/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1310.9724 - mean_absolute_error: 19.2747\n",
      "Epoch 646: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1067.3739 - mean_absolute_error: 17.6548 - val_loss: 980.9802 - val_mean_absolute_error: 18.4385\n",
      "Epoch 647/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 774.1216 - mean_absolute_error: 16.1447\n",
      "Epoch 647: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1136.2521 - mean_absolute_error: 17.8391 - val_loss: 974.1304 - val_mean_absolute_error: 18.2489\n",
      "Epoch 648/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 934.8508 - mean_absolute_error: 16.6317\n",
      "Epoch 648: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.8218 - mean_absolute_error: 17.9063 - val_loss: 981.6843 - val_mean_absolute_error: 18.3548\n",
      "Epoch 649/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 613.3248 - mean_absolute_error: 14.0614\n",
      "Epoch 649: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1113.6543 - mean_absolute_error: 17.7705 - val_loss: 971.0918 - val_mean_absolute_error: 18.1873\n",
      "Epoch 650/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1237.5522 - mean_absolute_error: 17.4242\n",
      "Epoch 650: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.8362 - mean_absolute_error: 17.9834 - val_loss: 979.6641 - val_mean_absolute_error: 18.3254\n",
      "Epoch 651/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 763.2383 - mean_absolute_error: 15.9443\n",
      "Epoch 651: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 987.1778 - mean_absolute_error: 16.9307 - val_loss: 974.0134 - val_mean_absolute_error: 18.2526\n",
      "Epoch 652/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1400.6024 - mean_absolute_error: 19.3942\n",
      "Epoch 652: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.1016 - mean_absolute_error: 17.3473 - val_loss: 976.6870 - val_mean_absolute_error: 18.2761\n",
      "Epoch 653/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 939.7169 - mean_absolute_error: 17.9740\n",
      "Epoch 653: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.0648 - mean_absolute_error: 17.6736 - val_loss: 975.9428 - val_mean_absolute_error: 18.3457\n",
      "Epoch 654/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 901.9374 - mean_absolute_error: 16.6825\n",
      "Epoch 654: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.1324 - mean_absolute_error: 17.5375 - val_loss: 978.9510 - val_mean_absolute_error: 18.3036\n",
      "Epoch 655/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 988.0669 - mean_absolute_error: 17.6078\n",
      "Epoch 655: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.5834 - mean_absolute_error: 17.8395 - val_loss: 983.4919 - val_mean_absolute_error: 18.3661\n",
      "Epoch 656/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 799.3789 - mean_absolute_error: 17.2684\n",
      "Epoch 656: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.2765 - mean_absolute_error: 17.1800 - val_loss: 983.1718 - val_mean_absolute_error: 18.3767\n",
      "Epoch 657/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 940.1100 - mean_absolute_error: 16.7519\n",
      "Epoch 657: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1128.9939 - mean_absolute_error: 18.2016 - val_loss: 978.5739 - val_mean_absolute_error: 18.3582\n",
      "Epoch 658/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1254.5498 - mean_absolute_error: 19.3779\n",
      "Epoch 658: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.8972 - mean_absolute_error: 18.0520 - val_loss: 983.6989 - val_mean_absolute_error: 18.3766\n",
      "Epoch 659/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1329.2618 - mean_absolute_error: 20.9269\n",
      "Epoch 659: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1067.0596 - mean_absolute_error: 17.6791 - val_loss: 974.5984 - val_mean_absolute_error: 18.2416\n",
      "Epoch 660/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 987.2512 - mean_absolute_error: 18.0821\n",
      "Epoch 660: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1230.5814 - mean_absolute_error: 18.5305 - val_loss: 987.5803 - val_mean_absolute_error: 18.4149\n",
      "Epoch 661/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1400.7300 - mean_absolute_error: 20.9730\n",
      "Epoch 661: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1186.4863 - mean_absolute_error: 18.4052 - val_loss: 979.4913 - val_mean_absolute_error: 18.3971\n",
      "Epoch 662/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1265.4709 - mean_absolute_error: 18.6023\n",
      "Epoch 662: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1049.5464 - mean_absolute_error: 17.2598 - val_loss: 976.5206 - val_mean_absolute_error: 18.2462\n",
      "Epoch 663/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1133.3949 - mean_absolute_error: 17.4152\n",
      "Epoch 663: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1035.7446 - mean_absolute_error: 16.9787 - val_loss: 983.3212 - val_mean_absolute_error: 18.3660\n",
      "Epoch 664/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1286.2266 - mean_absolute_error: 16.7812\n",
      "Epoch 664: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.9092 - mean_absolute_error: 17.9045 - val_loss: 981.2399 - val_mean_absolute_error: 18.3041\n",
      "Epoch 665/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 483.0443 - mean_absolute_error: 12.6518\n",
      "Epoch 665: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 991.4467 - mean_absolute_error: 17.0122 - val_loss: 978.4957 - val_mean_absolute_error: 18.3664\n",
      "Epoch 666/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 902.2469 - mean_absolute_error: 16.2813\n",
      "Epoch 666: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1103.7306 - mean_absolute_error: 17.7395 - val_loss: 978.2784 - val_mean_absolute_error: 18.2133\n",
      "Epoch 667/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 835.9127 - mean_absolute_error: 15.5968\n",
      "Epoch 667: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 950.5235 - mean_absolute_error: 16.8788 - val_loss: 985.8712 - val_mean_absolute_error: 18.3935\n",
      "Epoch 668/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1269.8574 - mean_absolute_error: 18.6860\n",
      "Epoch 668: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1095.2238 - mean_absolute_error: 18.0269 - val_loss: 985.4316 - val_mean_absolute_error: 18.3452\n",
      "Epoch 669/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 889.5095 - mean_absolute_error: 17.2019\n",
      "Epoch 669: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1182.2317 - mean_absolute_error: 18.0417 - val_loss: 972.7828 - val_mean_absolute_error: 18.2608\n",
      "Epoch 670/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1084.0164 - mean_absolute_error: 16.4250\n",
      "Epoch 670: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.3824 - mean_absolute_error: 17.2945 - val_loss: 983.5468 - val_mean_absolute_error: 18.2955\n",
      "Epoch 671/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 555.5405 - mean_absolute_error: 13.1713\n",
      "Epoch 671: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1110.5028 - mean_absolute_error: 17.7510 - val_loss: 978.9919 - val_mean_absolute_error: 18.3230\n",
      "Epoch 672/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1178.7747 - mean_absolute_error: 19.2129\n",
      "Epoch 672: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.5371 - mean_absolute_error: 17.7456 - val_loss: 984.7347 - val_mean_absolute_error: 18.3643\n",
      "Epoch 673/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 876.3749 - mean_absolute_error: 17.0690\n",
      "Epoch 673: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1086.6273 - mean_absolute_error: 17.7882 - val_loss: 980.7884 - val_mean_absolute_error: 18.3240\n",
      "Epoch 674/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2008.9430 - mean_absolute_error: 22.6742\n",
      "Epoch 674: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1181.3739 - mean_absolute_error: 18.3185 - val_loss: 983.6892 - val_mean_absolute_error: 18.4172\n",
      "Epoch 675/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 700.2941 - mean_absolute_error: 14.9300\n",
      "Epoch 675: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046.4104 - mean_absolute_error: 17.5440 - val_loss: 985.6301 - val_mean_absolute_error: 18.3690\n",
      "Epoch 676/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1194.0232 - mean_absolute_error: 18.8490\n",
      "Epoch 676: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057.0905 - mean_absolute_error: 17.4699 - val_loss: 980.7973 - val_mean_absolute_error: 18.3979\n",
      "Epoch 677/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1158.6301 - mean_absolute_error: 17.6698\n",
      "Epoch 677: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.1055 - mean_absolute_error: 17.6156 - val_loss: 976.7601 - val_mean_absolute_error: 18.2438\n",
      "Epoch 678/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1424.2775 - mean_absolute_error: 20.8240\n",
      "Epoch 678: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.9446 - mean_absolute_error: 18.2294 - val_loss: 975.0096 - val_mean_absolute_error: 18.2910\n",
      "Epoch 679/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 659.8907 - mean_absolute_error: 15.3593\n",
      "Epoch 679: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 972.0640 - mean_absolute_error: 16.8509 - val_loss: 994.7022 - val_mean_absolute_error: 18.5418\n",
      "Epoch 680/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 930.4831 - mean_absolute_error: 16.2392\n",
      "Epoch 680: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.5925 - mean_absolute_error: 17.3483 - val_loss: 977.5832 - val_mean_absolute_error: 18.2814\n",
      "Epoch 681/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1489.6445 - mean_absolute_error: 19.7014\n",
      "Epoch 681: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.1102 - mean_absolute_error: 18.1485 - val_loss: 976.8672 - val_mean_absolute_error: 18.2509\n",
      "Epoch 682/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1073.2582 - mean_absolute_error: 19.7318\n",
      "Epoch 682: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1189.9376 - mean_absolute_error: 18.5185 - val_loss: 975.6835 - val_mean_absolute_error: 18.3431\n",
      "Epoch 683/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1011.9253 - mean_absolute_error: 17.3218\n",
      "Epoch 683: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 933.4659 - mean_absolute_error: 16.6771 - val_loss: 977.7473 - val_mean_absolute_error: 18.2537\n",
      "Epoch 684/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 901.6108 - mean_absolute_error: 17.3110\n",
      "Epoch 684: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1040.0586 - mean_absolute_error: 17.2894 - val_loss: 980.1877 - val_mean_absolute_error: 18.3243\n",
      "Epoch 685/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 965.9803 - mean_absolute_error: 14.4504\n",
      "Epoch 685: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1135.8463 - mean_absolute_error: 17.6994 - val_loss: 976.5759 - val_mean_absolute_error: 18.3200\n",
      "Epoch 686/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 956.6605 - mean_absolute_error: 15.9866\n",
      "Epoch 686: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046.8473 - mean_absolute_error: 17.3467 - val_loss: 974.1012 - val_mean_absolute_error: 18.2160\n",
      "Epoch 687/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 851.6152 - mean_absolute_error: 15.9232\n",
      "Epoch 687: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1175.3539 - mean_absolute_error: 18.1379 - val_loss: 985.0654 - val_mean_absolute_error: 18.3516\n",
      "Epoch 688/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 922.2419 - mean_absolute_error: 16.8989\n",
      "Epoch 688: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1102.5851 - mean_absolute_error: 17.6039 - val_loss: 974.3718 - val_mean_absolute_error: 18.2664\n",
      "Epoch 689/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 666.8934 - mean_absolute_error: 14.8946\n",
      "Epoch 689: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1153.1689 - mean_absolute_error: 18.1821 - val_loss: 977.8148 - val_mean_absolute_error: 18.2762\n",
      "Epoch 690/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1256.4893 - mean_absolute_error: 18.2939\n",
      "Epoch 690: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.8671 - mean_absolute_error: 17.7212 - val_loss: 985.6603 - val_mean_absolute_error: 18.4373\n",
      "Epoch 691/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 789.3412 - mean_absolute_error: 15.7873\n",
      "Epoch 691: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.7307 - mean_absolute_error: 17.3527 - val_loss: 973.9531 - val_mean_absolute_error: 18.2616\n",
      "Epoch 692/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1056.6548 - mean_absolute_error: 17.0255\n",
      "Epoch 692: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1120.3439 - mean_absolute_error: 17.4646 - val_loss: 977.8676 - val_mean_absolute_error: 18.2834\n",
      "Epoch 693/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 900.2589 - mean_absolute_error: 16.5192\n",
      "Epoch 693: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.2830 - mean_absolute_error: 17.4958 - val_loss: 987.1372 - val_mean_absolute_error: 18.4901\n",
      "Epoch 694/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 707.8845 - mean_absolute_error: 14.5404\n",
      "Epoch 694: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1042.6426 - mean_absolute_error: 17.5161 - val_loss: 981.8552 - val_mean_absolute_error: 18.2940\n",
      "Epoch 695/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1137.9524 - mean_absolute_error: 17.8913\n",
      "Epoch 695: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1209.3572 - mean_absolute_error: 18.1936 - val_loss: 982.1793 - val_mean_absolute_error: 18.4346\n",
      "Epoch 696/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 818.2708 - mean_absolute_error: 17.7814\n",
      "Epoch 696: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1081.4376 - mean_absolute_error: 17.5215 - val_loss: 975.4418 - val_mean_absolute_error: 18.2843\n",
      "Epoch 697/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 980.8997 - mean_absolute_error: 17.2829\n",
      "Epoch 697: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 999.6231 - mean_absolute_error: 17.1765 - val_loss: 988.9778 - val_mean_absolute_error: 18.4093\n",
      "Epoch 698/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 901.1623 - mean_absolute_error: 17.5806\n",
      "Epoch 698: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1029.0104 - mean_absolute_error: 17.5922 - val_loss: 975.9366 - val_mean_absolute_error: 18.3034\n",
      "Epoch 699/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1038.3557 - mean_absolute_error: 17.1331\n",
      "Epoch 699: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1121.7854 - mean_absolute_error: 17.9661 - val_loss: 978.8409 - val_mean_absolute_error: 18.3310\n",
      "Epoch 700/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 925.9679 - mean_absolute_error: 17.7539\n",
      "Epoch 700: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1063.1487 - mean_absolute_error: 17.6735 - val_loss: 979.4843 - val_mean_absolute_error: 18.3111\n",
      "Epoch 701/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1352.0245 - mean_absolute_error: 21.3683\n",
      "Epoch 701: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.4657 - mean_absolute_error: 17.9011 - val_loss: 982.0350 - val_mean_absolute_error: 18.3635\n",
      "Epoch 702/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1067.0409 - mean_absolute_error: 18.2061\n",
      "Epoch 702: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1151.6737 - mean_absolute_error: 18.0343 - val_loss: 980.5296 - val_mean_absolute_error: 18.3401\n",
      "Epoch 703/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1066.5710 - mean_absolute_error: 19.4520\n",
      "Epoch 703: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.9962 - mean_absolute_error: 18.0903 - val_loss: 975.8466 - val_mean_absolute_error: 18.2829\n",
      "Epoch 704/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1114.4504 - mean_absolute_error: 16.6602\n",
      "Epoch 704: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.6260 - mean_absolute_error: 17.9770 - val_loss: 982.5527 - val_mean_absolute_error: 18.3738\n",
      "Epoch 705/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 860.8063 - mean_absolute_error: 15.6825\n",
      "Epoch 705: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1078.0378 - mean_absolute_error: 17.7537 - val_loss: 974.3841 - val_mean_absolute_error: 18.2650\n",
      "Epoch 706/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1795.5814 - mean_absolute_error: 19.6106\n",
      "Epoch 706: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1192.0314 - mean_absolute_error: 18.2412 - val_loss: 976.2843 - val_mean_absolute_error: 18.2621\n",
      "Epoch 707/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 951.1881 - mean_absolute_error: 16.2288\n",
      "Epoch 707: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.9702 - mean_absolute_error: 17.4356 - val_loss: 974.6492 - val_mean_absolute_error: 18.2423\n",
      "Epoch 708/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1125.1105 - mean_absolute_error: 18.6731\n",
      "Epoch 708: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1078.9073 - mean_absolute_error: 17.5869 - val_loss: 976.4560 - val_mean_absolute_error: 18.2817\n",
      "Epoch 709/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1486.0132 - mean_absolute_error: 21.0075\n",
      "Epoch 709: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.2644 - mean_absolute_error: 18.2561 - val_loss: 978.3458 - val_mean_absolute_error: 18.3153\n",
      "Epoch 710/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1092.6604 - mean_absolute_error: 20.3662\n",
      "Epoch 710: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1103.2379 - mean_absolute_error: 17.8995 - val_loss: 971.4037 - val_mean_absolute_error: 18.1940\n",
      "Epoch 711/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1041.3835 - mean_absolute_error: 18.1195\n",
      "Epoch 711: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1106.4688 - mean_absolute_error: 17.8180 - val_loss: 983.7316 - val_mean_absolute_error: 18.3901\n",
      "Epoch 712/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1550.8247 - mean_absolute_error: 19.7961\n",
      "Epoch 712: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1088.7603 - mean_absolute_error: 17.8077 - val_loss: 972.1489 - val_mean_absolute_error: 18.2428\n",
      "Epoch 713/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1251.5425 - mean_absolute_error: 19.0019\n",
      "Epoch 713: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 988.4195 - mean_absolute_error: 17.1008 - val_loss: 973.5524 - val_mean_absolute_error: 18.1716\n",
      "Epoch 714/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 914.8218 - mean_absolute_error: 17.5210\n",
      "Epoch 714: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1020.8043 - mean_absolute_error: 17.3042 - val_loss: 985.3553 - val_mean_absolute_error: 18.3850\n",
      "Epoch 715/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1051.3713 - mean_absolute_error: 17.1969\n",
      "Epoch 715: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1065.6725 - mean_absolute_error: 17.3676 - val_loss: 980.8883 - val_mean_absolute_error: 18.3730\n",
      "Epoch 716/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1032.2308 - mean_absolute_error: 19.0097\n",
      "Epoch 716: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1001.2120 - mean_absolute_error: 17.3460 - val_loss: 986.2226 - val_mean_absolute_error: 18.3369\n",
      "Epoch 717/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1081.4709 - mean_absolute_error: 16.8932\n",
      "Epoch 717: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1064.3380 - mean_absolute_error: 17.4362 - val_loss: 975.4070 - val_mean_absolute_error: 18.2608\n",
      "Epoch 718/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1440.0372 - mean_absolute_error: 19.3442\n",
      "Epoch 718: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1155.6084 - mean_absolute_error: 18.2428 - val_loss: 972.7005 - val_mean_absolute_error: 18.2405\n",
      "Epoch 719/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 742.9968 - mean_absolute_error: 14.5640\n",
      "Epoch 719: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1052.6949 - mean_absolute_error: 17.3949 - val_loss: 978.7194 - val_mean_absolute_error: 18.3330\n",
      "Epoch 720/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1029.8838 - mean_absolute_error: 17.8213\n",
      "Epoch 720: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1072.1471 - mean_absolute_error: 17.7853 - val_loss: 987.9216 - val_mean_absolute_error: 18.4168\n",
      "Epoch 721/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 830.1148 - mean_absolute_error: 14.6999\n",
      "Epoch 721: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 948.4297 - mean_absolute_error: 16.6658 - val_loss: 976.6321 - val_mean_absolute_error: 18.2891\n",
      "Epoch 722/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1511.1418 - mean_absolute_error: 19.2707\n",
      "Epoch 722: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.9636 - mean_absolute_error: 17.9962 - val_loss: 975.9816 - val_mean_absolute_error: 18.2859\n",
      "Epoch 723/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 997.0065 - mean_absolute_error: 17.6241\n",
      "Epoch 723: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1169.8108 - mean_absolute_error: 18.1309 - val_loss: 980.0750 - val_mean_absolute_error: 18.2856\n",
      "Epoch 724/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 642.4539 - mean_absolute_error: 15.4375\n",
      "Epoch 724: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.0071 - mean_absolute_error: 17.7162 - val_loss: 975.6487 - val_mean_absolute_error: 18.2319\n",
      "Epoch 725/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 793.8001 - mean_absolute_error: 15.9672\n",
      "Epoch 725: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1073.1920 - mean_absolute_error: 17.6480 - val_loss: 983.5665 - val_mean_absolute_error: 18.3958\n",
      "Epoch 726/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1180.8640 - mean_absolute_error: 17.9734\n",
      "Epoch 726: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1059.2777 - mean_absolute_error: 17.4818 - val_loss: 980.0491 - val_mean_absolute_error: 18.3339\n",
      "Epoch 727/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1575.1816 - mean_absolute_error: 20.8264\n",
      "Epoch 727: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1123.6907 - mean_absolute_error: 17.7119 - val_loss: 977.3759 - val_mean_absolute_error: 18.2668\n",
      "Epoch 728/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 795.8204 - mean_absolute_error: 15.9379\n",
      "Epoch 728: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071.8734 - mean_absolute_error: 17.4245 - val_loss: 980.4762 - val_mean_absolute_error: 18.3262\n",
      "Epoch 729/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 468.5960 - mean_absolute_error: 13.7132\n",
      "Epoch 729: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 977.4735 - mean_absolute_error: 16.7341 - val_loss: 975.6685 - val_mean_absolute_error: 18.3193\n",
      "Epoch 730/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 472.7960 - mean_absolute_error: 12.4899\n",
      "Epoch 730: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1029.7621 - mean_absolute_error: 17.2408 - val_loss: 995.1987 - val_mean_absolute_error: 18.4047\n",
      "Epoch 731/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1383.1008 - mean_absolute_error: 17.5899\n",
      "Epoch 731: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.8811 - mean_absolute_error: 18.0864 - val_loss: 976.3034 - val_mean_absolute_error: 18.2444\n",
      "Epoch 732/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 865.2534 - mean_absolute_error: 18.2084\n",
      "Epoch 732: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1091.3389 - mean_absolute_error: 17.8719 - val_loss: 981.4555 - val_mean_absolute_error: 18.3222\n",
      "Epoch 733/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1343.8661 - mean_absolute_error: 20.9373\n",
      "Epoch 733: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1134.3914 - mean_absolute_error: 17.8887 - val_loss: 981.0308 - val_mean_absolute_error: 18.3405\n",
      "Epoch 734/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1039.2101 - mean_absolute_error: 18.5886\n",
      "Epoch 734: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.9363 - mean_absolute_error: 18.0133 - val_loss: 979.8019 - val_mean_absolute_error: 18.3028\n",
      "Epoch 735/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1050.7727 - mean_absolute_error: 18.6084\n",
      "Epoch 735: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1143.0789 - mean_absolute_error: 18.0271 - val_loss: 972.4573 - val_mean_absolute_error: 18.2509\n",
      "Epoch 736/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1093.4801 - mean_absolute_error: 18.1795\n",
      "Epoch 736: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1056.4093 - mean_absolute_error: 17.4793 - val_loss: 983.9415 - val_mean_absolute_error: 18.3388\n",
      "Epoch 737/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1619.5491 - mean_absolute_error: 21.5650\n",
      "Epoch 737: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.7026 - mean_absolute_error: 17.7283 - val_loss: 977.6755 - val_mean_absolute_error: 18.2969\n",
      "Epoch 738/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 678.0040 - mean_absolute_error: 13.8407\n",
      "Epoch 738: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1107.8389 - mean_absolute_error: 17.4596 - val_loss: 978.7175 - val_mean_absolute_error: 18.2868\n",
      "Epoch 739/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1095.3286 - mean_absolute_error: 18.1998\n",
      "Epoch 739: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1157.0421 - mean_absolute_error: 18.1218 - val_loss: 975.1046 - val_mean_absolute_error: 18.2640\n",
      "Epoch 740/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1209.3191 - mean_absolute_error: 20.9563\n",
      "Epoch 740: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1071.8113 - mean_absolute_error: 17.7391 - val_loss: 976.4978 - val_mean_absolute_error: 18.2448\n",
      "Epoch 741/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 873.9028 - mean_absolute_error: 16.1807\n",
      "Epoch 741: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1025.2490 - mean_absolute_error: 17.1544 - val_loss: 980.8887 - val_mean_absolute_error: 18.3352\n",
      "Epoch 742/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1428.1464 - mean_absolute_error: 19.6770\n",
      "Epoch 742: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1112.0928 - mean_absolute_error: 17.8227 - val_loss: 980.8531 - val_mean_absolute_error: 18.3033\n",
      "Epoch 743/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1016.2175 - mean_absolute_error: 16.8230\n",
      "Epoch 743: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1084.1027 - mean_absolute_error: 17.7189 - val_loss: 977.7385 - val_mean_absolute_error: 18.2611\n",
      "Epoch 744/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 975.1106 - mean_absolute_error: 17.5592\n",
      "Epoch 744: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1085.3256 - mean_absolute_error: 17.5503 - val_loss: 982.0470 - val_mean_absolute_error: 18.3727\n",
      "Epoch 745/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 812.3983 - mean_absolute_error: 15.9409\n",
      "Epoch 745: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1038.6163 - mean_absolute_error: 17.2211 - val_loss: 979.3524 - val_mean_absolute_error: 18.3179\n",
      "Epoch 746/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1111.6167 - mean_absolute_error: 18.7192\n",
      "Epoch 746: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.0846 - mean_absolute_error: 17.8956 - val_loss: 980.8453 - val_mean_absolute_error: 18.3147\n",
      "Epoch 747/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 914.0555 - mean_absolute_error: 15.8964\n",
      "Epoch 747: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1025.5906 - mean_absolute_error: 17.2678 - val_loss: 971.5316 - val_mean_absolute_error: 18.1681\n",
      "Epoch 748/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 843.7470 - mean_absolute_error: 14.9819\n",
      "Epoch 748: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1119.3191 - mean_absolute_error: 17.5971 - val_loss: 981.7983 - val_mean_absolute_error: 18.3393\n",
      "Epoch 749/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 666.3586 - mean_absolute_error: 14.6115\n",
      "Epoch 749: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 985.9248 - mean_absolute_error: 16.9983 - val_loss: 981.5997 - val_mean_absolute_error: 18.2994\n",
      "Epoch 750/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2299.0923 - mean_absolute_error: 22.7709\n",
      "Epoch 750: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1208.4156 - mean_absolute_error: 18.1526 - val_loss: 980.6895 - val_mean_absolute_error: 18.3013\n",
      "Epoch 751/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1255.3009 - mean_absolute_error: 19.6303\n",
      "Epoch 751: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1125.7676 - mean_absolute_error: 17.9137 - val_loss: 975.3009 - val_mean_absolute_error: 18.2575\n",
      "Epoch 752/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1421.1266 - mean_absolute_error: 19.2630\n",
      "Epoch 752: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1133.6895 - mean_absolute_error: 17.7609 - val_loss: 980.4320 - val_mean_absolute_error: 18.3146\n",
      "Epoch 753/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1862.6034 - mean_absolute_error: 19.6400\n",
      "Epoch 753: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1181.6246 - mean_absolute_error: 18.0861 - val_loss: 977.6404 - val_mean_absolute_error: 18.2960\n",
      "Epoch 754/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1312.9906 - mean_absolute_error: 19.7408\n",
      "Epoch 754: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.7855 - mean_absolute_error: 17.8105 - val_loss: 981.1871 - val_mean_absolute_error: 18.2584\n",
      "Epoch 755/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1197.3113 - mean_absolute_error: 19.4269\n",
      "Epoch 755: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1161.1400 - mean_absolute_error: 18.0806 - val_loss: 974.5020 - val_mean_absolute_error: 18.2726\n",
      "Epoch 756/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 917.9784 - mean_absolute_error: 17.0069\n",
      "Epoch 756: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1021.8595 - mean_absolute_error: 17.0930 - val_loss: 979.2800 - val_mean_absolute_error: 18.2233\n",
      "Epoch 757/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 978.0310 - mean_absolute_error: 18.6166\n",
      "Epoch 757: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1171.4575 - mean_absolute_error: 18.2407 - val_loss: 983.7899 - val_mean_absolute_error: 18.4004\n",
      "Epoch 758/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1217.4137 - mean_absolute_error: 17.4217\n",
      "Epoch 758: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1021.0518 - mean_absolute_error: 17.0679 - val_loss: 979.8608 - val_mean_absolute_error: 18.2819\n",
      "Epoch 759/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1654.9240 - mean_absolute_error: 19.9525\n",
      "Epoch 759: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1147.5770 - mean_absolute_error: 18.1929 - val_loss: 980.9684 - val_mean_absolute_error: 18.2713\n",
      "Epoch 760/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1506.2600 - mean_absolute_error: 20.5243\n",
      "Epoch 760: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1104.4554 - mean_absolute_error: 17.7430 - val_loss: 981.6130 - val_mean_absolute_error: 18.3197\n",
      "Epoch 761/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 715.4987 - mean_absolute_error: 15.2351\n",
      "Epoch 761: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1054.6139 - mean_absolute_error: 17.5839 - val_loss: 981.3543 - val_mean_absolute_error: 18.3491\n",
      "Epoch 762/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1242.0131 - mean_absolute_error: 18.7097\n",
      "Epoch 762: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1122.1322 - mean_absolute_error: 17.9462 - val_loss: 979.4081 - val_mean_absolute_error: 18.2737\n",
      "Epoch 763/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1314.2644 - mean_absolute_error: 17.8047\n",
      "Epoch 763: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1098.0345 - mean_absolute_error: 17.4495 - val_loss: 975.3731 - val_mean_absolute_error: 18.3065\n",
      "Epoch 764/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 863.3130 - mean_absolute_error: 14.7130\n",
      "Epoch 764: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1074.5530 - mean_absolute_error: 17.5801 - val_loss: 974.7349 - val_mean_absolute_error: 18.2222\n",
      "Epoch 765/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 907.7454 - mean_absolute_error: 14.8886\n",
      "Epoch 765: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1087.2341 - mean_absolute_error: 17.7008 - val_loss: 979.4618 - val_mean_absolute_error: 18.2688\n",
      "Epoch 766/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1117.1433 - mean_absolute_error: 18.4315\n",
      "Epoch 766: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.3805 - mean_absolute_error: 17.5649 - val_loss: 986.6187 - val_mean_absolute_error: 18.4020\n",
      "Epoch 767/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1373.3474 - mean_absolute_error: 16.9587\n",
      "Epoch 767: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1023.5922 - mean_absolute_error: 17.1123 - val_loss: 973.8620 - val_mean_absolute_error: 18.2028\n",
      "Epoch 768/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 880.8015 - mean_absolute_error: 17.7652\n",
      "Epoch 768: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1057.3533 - mean_absolute_error: 17.8104 - val_loss: 980.1030 - val_mean_absolute_error: 18.3204\n",
      "Epoch 769/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 960.1968 - mean_absolute_error: 18.0089\n",
      "Epoch 769: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1079.6167 - mean_absolute_error: 17.8767 - val_loss: 973.7960 - val_mean_absolute_error: 18.2224\n",
      "Epoch 770/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 983.2777 - mean_absolute_error: 18.1802\n",
      "Epoch 770: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1038.7891 - mean_absolute_error: 17.5077 - val_loss: 979.8358 - val_mean_absolute_error: 18.3347\n",
      "Epoch 771/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1625.5640 - mean_absolute_error: 23.6981\n",
      "Epoch 771: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1152.3035 - mean_absolute_error: 18.1154 - val_loss: 974.0861 - val_mean_absolute_error: 18.2186\n",
      "Epoch 772/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1323.9945 - mean_absolute_error: 16.6218\n",
      "Epoch 772: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1144.1321 - mean_absolute_error: 17.6856 - val_loss: 985.0437 - val_mean_absolute_error: 18.3722\n",
      "Epoch 773/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 502.8543 - mean_absolute_error: 12.9809\n",
      "Epoch 773: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1124.8300 - mean_absolute_error: 17.4955 - val_loss: 977.9360 - val_mean_absolute_error: 18.2992\n",
      "Epoch 774/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 838.3752 - mean_absolute_error: 17.4382\n",
      "Epoch 774: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 999.3742 - mean_absolute_error: 16.9989 - val_loss: 982.0134 - val_mean_absolute_error: 18.3631\n",
      "Epoch 775/1500\n",
      "\u001b[1m 1/33\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1228.8484 - mean_absolute_error: 19.7324\n",
      "Epoch 775: val_loss did not improve from 968.84967\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1069.7710 - mean_absolute_error: 17.7198 - val_loss: 974.3734 - val_mean_absolute_error: 18.1406\n",
      "Epoch 776/1500\n"
     ]
    }
   ],
   "source": [
    "model7.fit(X3_train, y3_train, validation_data=(X3_val, y3_val), epochs=1500, callbacks=[cp7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(InputLayer((1, 3)))\n",
    "model7.add(Conv1D(64, kernel_size=1, activation='relu'))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(8, 'relu'))\n",
    "model7.add(Dense(3, 'linear'))\n",
    "model7.load_weights('checkpoints.model7.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions3(model, X, y, cols, start=0, end=100):\n",
    "    predictions = model.predict(X)+30\n",
    "    df = pd.DataFrame(data=predictions)\n",
    "    df.columns=cols\n",
    "    org = pd.DataFrame(data=y)\n",
    "    org.columns = cols\n",
    "    plt.plot(df['PM2.5 (µg/m³)'][start:end])\n",
    "    plt.plot(org['PM2.5 (µg/m³)'][start:end])\n",
    "    a = org.astype('float32')\n",
    "    print(predictions[:,-1].dtype)\n",
    "    ma = mae(a['PM2.5 (µg/m³)'],df['PM2.5 (µg/m³)'])\n",
    "    return df[start:end], org, ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_7, org_7, mae_7 = plot_predictions3(model7, x_test_9, y_test_9,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.400463"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df1 and df2 are your dataframes and 'time' is the time column\n",
    "# Also assuming that 'value' is the column you want to plot\n",
    "\n",
    "# Join the dataframes\n",
    "df_7.index = val.index\n",
    "df = pd.concat([df_corr['PM2.5 (µg/m³)'], df_7['PM2.5 (µg/m³)']])\n",
    "org_7.index = val.index\n",
    "df_org = pd.concat([df_corr['PM2.5 (µg/m³)'], org_7['PM2.5 (µg/m³)']])\n",
    "df.columns = 'PM2.5 (µg/m³)'\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_org.index[-72:len(df_corr['PM2.5 (µg/m³)'])+1], df_org[-72:len(df_corr['PM2.5 (µg/m³)'])+1], color='blue', label='train')\n",
    "plt.plot(df.index[len(df_corr['PM2.5 (µg/m³)']):], df[len(df_corr['PM2.5 (µg/m³)']):], color='red', label='prediction')\n",
    "plt.plot(df_org.index[len(df_corr['PM2.5 (µg/m³)']):],df_org[len(df_corr['PM2.5 (µg/m³)']):],color='green',label='actual')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('PM2.5 (µg/m³)')\n",
    "plt.title('Time Series Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
